<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[tr-转换、删除、压缩重复字符]]></title>
    <url>%2Fposts%2F46339.html</url>
    <content type="text"><![CDATA[这里写摘要，显示更好看开始于二级标题参考链接IBM tr 命令tr命令Shell tr 命令简介SHELL脚本–tr命令用法和特性全解23. Linux tr命令]]></content>
  </entry>
  <entry>
    <title><![CDATA[Linux隔行输出文本信息]]></title>
    <url>%2Fposts%2F43739.html</url>
    <content type="text"><![CDATA[这里写摘要，显示更好看开始于二级标题方法包括：使用sed命令使用awk命令]]></content>
  </entry>
  <entry>
    <title><![CDATA[Python系列之rpy2-在Python中使用R]]></title>
    <url>%2Fposts%2F63643.html</url>
    <content type="text"><![CDATA[这篇文章主要学习了可以在Python中使用R的模块rpy2，具体的用法参见文章内容。rpy2简介本来我一直以为Python是完全可以替代R的。以前我一直以为R最强大的功能在于绘图，使用R语言可以绘制很漂亮的图片，然而自从Python的各种绘图包(eg：matplotlib、seabrn、plotly…)出现以来，R在这方面的优势在我看来就有些弱化，我开始将自己的工作重心转移到Python上，然而最近需要做一个非线性拟合的工作，查找的很多资料都是R的，这才让我意识到R在统计分析方面的优势是非常巨大的，Python虽然也有scipy这种包，但是相比于R来说还是太弱了，毕竟R就是搞统计使用的。言归正传，Python和R两者是相互补充的，而不是相互竞争的，所以将这两种语言联合起来使用非常重要，因为自己还是使用Python比较顺手，所以这里就介绍能够在Python中调用R的rpy2包，关于R中使用Python的包这里就不做介绍了。rpy2安装rpy2官方文档提供了很多安装方法，其中最简单的当然是直接使用pip的方式进行安装，有其他需要的可以查看官方文档：1pip install rpy2rpy2使用准备导入rpy2包rpy2提供了两种接口：low-level：rpy2.rinterfacehigh-level：rpy2.robjects，高级的接口使得在Python中使用R更加的自然查看版本信息：123import rpy2# 输出版本信息print(rpy2.__version__)3.0.4 查看使用的R信息：1!which R/home/softwares/anaconda3/bin/R 导入高级接口：1import rpy2.robjects as robjects导入R包12345# 导入引用R包的函数importrfrom rpy2.robjects.packages import importr# 导入base包base = importr('base')安装R包正式开始安装R包之前的准备工作1234567# import rpy2's package module# 可以用于判断相应的包是不是已经安装import rpy2.robjects.packages as rpackages# import R's utility packageutils = rpackages.importr('utils')# select a mirror for R packagesutils.chooseCRANmirror(ind=1) # select the first mirror in the list&lt;rpy2.rinterface.NULLType object at 0x7f14e864b7c8&gt; [RTYPES.NILSXP] 12# 判断相应的包是不是已经安装rpackages.isinstalled('base')True 开始安装相应的R包12345678910# 需要安装的R包的名称packnames = ('ggplot2')# 导入R的字符串向量函数from rpy2.robjects.vectors import StrVector# 判断需要安装R包是不是已经安装过，如果没有再进行安装names_to_install = [x for x in packnames if not rpackages.isinstalled(x)]if len(names_to_install) &gt; 0: utils.install_packages(StrVector(names_to_install))The r instanceGetting R objects得到像在R console中一样的输出，如下使用robjects.r[&#39;pi&#39;]就相当于在R中直接输入pi一样，得到pi的值12pi = robjects.r['pi']piFloatVector with 1 elements.3.141593需要注意的：上面的返回值是一个vector，而不是一个值，如果希望得到这个值，可以使用类似Python列表操作的方法这里使用下标为0即可得到值，但是在R console中需要使用pi[1]1pi[0]3.141592653589793 计算R代码的值运行单行代码前面使用robjects.r[&#39;pi&#39;]是直接调用了__getitem__方法，这里是使用了计算代码的值，两者的结果相同，但是实际的内部实现不同12pi = robjects.r('pi')piFloatVector with 1 elements.3.141593和前面相同，上面返回的也是vector而不是具体的值1pi[0]3.141592653589793 运行大段代码运行大段代码时创建的变量和返回的结果保存在Global Environment中(也就是说是所有R代码的global variables，不是局部的变量)，Global Environment就是Rstudio右上角的分栏。1234567891011robjects.r(''' # create a function `f` f &lt;- function(r, verbose=FALSE) &#123; if (verbose) &#123; cat("I am calling f().\n") &#125; 2 * pi * r &#125; # call the function `f` with argument value 3 f(3) ''')FloatVector with 1 elements.18.8495561234# 因为函数f已经存在于Global Environment# 所有后面如果需要使用，可以直接调用，不用再次声明r_f = robjects.r['f']r_f(5)FloatVector with 1 elements.31.4159271robjects.r('xx &lt;- seq(-.3, 5, len = 101)')FloatVector with 101 elements.-0.300000-0.247000-0.194000...4.8940004.9470005.00000012# 仍然可以调用前面的xx变量结果robjects.r('xx')FloatVector with 101 elements.-0.300000-0.247000-0.194000...4.8940004.9470005.000000R向量在R中，大部分的数据都是以vectors的形式保存的，即使有些可能看上去像是值12# 前面的pi其实就是一个长度为1的vectorlen(robjects.r['pi'])1 如果直接使用R脚本得到一个vector然后再使用Python的add()操作，会相当于对R的vector进行了concatenation操作(function c() in R)：12piplus2 = robjects.r('pi') + 2piplus2FloatVector with 2 elements.3.1415932.000000以R的形式显示vector(显示为c()的形式)，可以使用vector.r_repr():1print (piplus2.r_repr())c(3.14159265358979, 2) 创建R向量创建的向量可以是字符串类型的(robjects.StrVector)、整型的(robjects.IntVector)以及浮点型的(robjects.FloatVector)，不同的类型使用不用的方法创建：123# 字符串向量res = robjects.StrVector(['abc', 'def'])print(res.r_repr())c(&quot;abc&quot;, &quot;def&quot;) 123# 整型向量res=robjects.IntVector([1,2,3])print (res.r_repr())1:3 123# 浮点型向量res=robjects.FloatVector([1.1,1.2,1])print (res.r_repr())c(1.1, 1.2, 1) 创建矩阵：1234v = robjects.FloatVector([1.1, 2.2, 3.3, 4.4, 5.5, 6.6])# 通过matrix函数来创建m = robjects.r['matrix'](v, nrow = 2)print(m) [,1] [,2] [,3] [1,] 1.1 3.3 5.5 [2,] 2.2 4.4 6.6 调用R函数默认情况下，调用R函数返回的是R对象：12345# 调用sum函数rsum = robjects.r['sum']# 计算vector的值rsum(robjects.IntVector([1,2,3]))# 返回的结果还是vectorIntVector with 1 elements.6调用可以传递参数的函数：12345rsort = robjects.r['sort']# 传递参数：是否降序排列res = rsort(robjects.IntVector([1,2,3]), decreasing=True)# 输出结果print(res.r_repr())3:1 获取帮助文档12345from rpy2.robjects.packages import importrutils=importr('utils')help_doc=utils.help("help")# 返回的仍然是vectorhelp_docStrVector with 1 elements.'/home/softwares/anaconda3/lib/R/library/utils/he...12# 得到具体的值help_doc[0]&apos;/home/softwares/anaconda3/lib/R/library/utils/help/help&apos; 12# 输出完整的帮助文档，而不是帮助文档的位置str(help_doc)1str(utils.help("sum"))1?importr将pandas的dataframe转为R的dataframe创建pandas的dataframe：12345import pandas as pdpd_df = pd.DataFrame(&#123;'int_values': [1,2,3], 'str_values': ['abc', 'def', 'ghi']&#125;)pd_df转化为R的dataframe：1234567891011121314import pandas as pdimport rpy2.robjects as rofrom rpy2.robjects.packages import importrfrom rpy2.robjects import pandas2rifrom rpy2.robjects.conversion import localconverter# 具体的转化过程with localconverter(ro.default_converter + pandas2ri.converter): r_from_pd_df = ro.conversion.py2rpy(pd_df)r_from_pd_dfprint (r_from_pd_df)参考链接rpy2官方文档dataframe之间的相互转换]]></content>
      <categories>
        <category>Python</category>
        <category>常用模块</category>
      </categories>
      <tags>
        <tag>常用模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux解决软件缺失库文件]]></title>
    <url>%2Fposts%2F62465.html</url>
    <content type="text"><![CDATA[这篇文章记录了如何在没有root、不能直接安装缺失共享库的前提下如何补全缺失共享库的方法，主要是借助其他软件安装好的该共享库并建立软连接实现。背景今天使用bgzip命令的时候报错：1bgzip: error while loading shared libraries: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory按照错误来说是缺失了共享库的信息，具体缺失的共享库为libcrypto.so.1.0.0解决有root最简单粗暴的方法就是缺什么安装什么，但是这种共享库文件的安装肯定是需要root权限的，因为使用的是学校的集群，所以肯定没有权限，这种方法对于大部分用户来说都不是很适用，但还是列出来，万一是自家的集群呢：1234567# Ubuntu系统使用# 重装libssl1.0.0sudo apt-get install libssl1.0.0sudo apt-get install apt-filesudo apt-file updateapt-file search libcrypto.so.1.0.0参考链接：libraries: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory没有root权限没有root权限下的解决是主要的解决方式(有root权限当然也可以使用这种做法)，也是今天想要记录的原因，之前没有这么解决过。使用ldd命令查看依赖ldd命令是用来查看命令运行所需的共享库,常用来解决命令因缺少某个库文件而不能运行的一些问题。123456789# 查看命令的绝对路径which test# 查看命令的依赖信息ldd /usr/bin/test# 返回信息 linux-vdso.so.1 =&gt; (0x00007ffe16971000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007fa91c0db000) /lib64/ld-linux-x86-64.so.2 (0x00007fa91c4a9000)如果不能找到相应的依赖会返回：1libcrypto.so.1.0.0 =&gt; not foundldd命令一定要使用绝对路径，即使是linux系统自带的命令(built-in)，不然不会得到结果结果信息解读：第一列: 程序需要依赖什么库第二列: 系统提供的与程序需要的库所对应的库第三列: 库加载的开始地址直接在集群上查找丢失的共享库很多共享库其他软件在安装的时候可能会自动安装，所以直接查找其他软件安装的共享库并使用是个不错的选择：12# 查找丢失的共享库信息find ~ -name libcrypto.so.1.0.0建立软连接将找到的共享库建立软连接到软件安装的lib目录中：1234567# 查看软件安装路径which bgzip# 软件是使用anaconda安装的 ~/usr/anaconda2/bin/bgzip# 建立软连接ln -s /Share2/home/wangjb/usr/anaconda2/pkgs/openssl-1.0.2l-0/lib/libcrypto.so.1.0.0 /Share2/home/wangjb/usr/anaconda2/bin/../lib/libcrypto.so.1.0.0注意：这的/Share2/home/wangjb/usr/anaconda2/bin/../lib目录其实就是/Share2/home/wangjb/usr/anaconda2/lib目录，但是看软件所有的依赖包都是这种写法，所以这里也采用了这种写法。再次查看依赖包12345678910111213141516171819202122232425262728ldd ~/usr/anaconda2/bin/bgzip linux-vdso.so.1 =&gt; (0x00007ffc36ddb000) liblzma.so.5 =&gt; /Share2/home/wangjb/usr/anaconda2/bin/../lib/liblzma.so.5 (0x00007fa05de85000) libbz2.so.1.0 =&gt; /Share2/home/wangjb/usr/anaconda2/bin/../lib/libbz2.so.1.0 (0x00007fa05dc73000) libz.so.1 =&gt; /Share2/home/wangjb/usr/anaconda2/bin/../lib/libz.so.1 (0x00007fa05da5b000) libm.so.6 =&gt; /lib64/libm.so.6 (0x00007fa05d759000) libcurl.so.4 =&gt; /Share2/home/wangjb/usr/anaconda2/bin/../lib/libcurl.so.4 (0x00007fa05e220000) # 之前缺失的共享包这里有了 libcrypto.so.1.0.0 =&gt; /Share2/home/wangjb/usr/anaconda2/bin/../lib/libcrypto.so.1.0.0 (0x00007fa05d322000) libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007fa05d106000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007fa05cd43000) librt.so.1 =&gt; /lib64/librt.so.1 (0x00007fa05cb3b000) /lib64/ld-linux-x86-64.so.2 (0x00007fa05e0ab000) libssh2.so.1 =&gt; /Share2/home/wangjb/usr/anaconda2/bin/../lib/./libssh2.so.1 (0x00007fa05e1ed000) libssl.so.1.1 =&gt; /Share2/home/wangjb/usr/anaconda2/bin/../lib/./libssl.so.1.1 (0x00007fa05e157000) libcrypto.so.1.1 =&gt; /Share2/home/wangjb/usr/anaconda2/bin/../lib/./libcrypto.so.1.1 (0x00007fa05c843000) libgssapi_krb5.so.2 =&gt; /Share2/home/wangjb/usr/anaconda2/bin/../lib/./libgssapi_krb5.so.2 (0x00007fa05e107000) libkrb5.so.3 =&gt; /Share2/home/wangjb/usr/anaconda2/bin/../lib/./libkrb5.so.3 (0x00007fa05c767000) libk5crypto.so.3 =&gt; /Share2/home/wangjb/usr/anaconda2/bin/../lib/./libk5crypto.so.3 (0x00007fa05e0e8000) libcom_err.so.3 =&gt; /Share2/home/wangjb/usr/anaconda2/bin/../lib/./libcom_err.so.3 (0x00007fa05e0e1000) libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007fa05c563000) libkrb5support.so.0 =&gt; /Share2/home/wangjb/usr/anaconda2/bin/../lib/././libkrb5support.so.0 (0x00007fa05e0d1000) libresolv.so.2 =&gt; /lib64/libresolv.so.2 (0x00007fa05c349000)# 再次测试软件bgzip --help# 正常使用参考链接ldd 查看程序依赖库WGS数据分析流程学习与开发过程全纪录（1）]]></content>
      <categories>
        <category>Linux</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux没有root权限安装软件]]></title>
    <url>%2Fposts%2F62231.html</url>
    <content type="text"><![CDATA[这篇文章总结了在没有root权限下如何下载安装软件，主要包括下载源码包(yumdownloader)、配置(./configure)、编译(make)和安装(make install)四步。背景使用集群的过程中难免会遇到需要root权限才能安装一些软件的问题，比如在centos上使用yum install这种包管理程序来安装软件就需要使用sudo yum install才能正确安装，但是作为一般的用户，哪里会有roo权限可以使用，但是有些软件又是必须的，所以才有了这篇文章。安装步骤下载并解压12# 这里以nginx为例tar -zvxf nginx-1.2.3.tar.gz关于如何下载源码：1234567# 下载yum-utils，支持yumdownloader命令yum install yum-utils# 下载mypkg的源码yumdownloader --source mypkg --destdir=DESTDIR# --destdir=DESTDIR 指定下载目录，默认是当前目录 destination directory (defaults to current directory)# --source operate on source packages参考链接：How to use yum to download a package without installing it创建软件安装目录12cd ~mkdir nginx配置1234# 进入第一步压缩包解压目录cd source_code_folder# 配置信息，prefix为软件安装目录./configure --prefix=/path/to/install/nginx非root用户最重要的配置项是安装目录prefix，例如 ./configure –prefix=/path/to/bin，在无法自动找到依赖库位置的情况下，用 –with-xx-dir=xxx 的形式配置依赖库位置.编译安装12makemake installmake时指定 -j 参数并行编译，能显著减少编译耗时关于configure、make、make install./configure 是用来检测你的安装平台的目标特征的，可以生成 Makefile。比如它会检测你是不是有CC或GCC，并不是需要CC或GCC，它是个shell脚本；make 是用来编译的，它从Makefile中读取指令，然后编译；make install是用来安装的，它也从Makefile中读取指令，安装到指定的位置。configureconfigure命令一般用来生成 Makefile，为下一步的编译做准备，你可以通过在 configure 后加上参数来对安装进行控制，比如代码:./configure –prefix=/usr 意思是将该软件安装在 /usr 下面，执行文件就会安装在 /usr/bin （而不是默认的 /usr/local/bin)，资源文件就会安装在 /usr/share（而不是默认的/usr/local/share）。同时一些软件的配置文件你可以通过指定 –sys-config= 参数进行设定。有一些软件还可以加上 –with、–enable、–without、–disable 等等参数对编译加以控制，你可以通过允许 ./configure –help 察看详细的说明帮助。用了 --prefix 选项的好处：方便维护，如果没有用这个选项，安装过程结束后，该软件所需的软件被复制到不同的系统目录下，很难弄清楚到底复制了那些文件、都复制到哪里去了—基本上是一塌糊涂卸载软件或移植软件。当某个安装的软件不再需要时，只须简单的删除该安装目录，就可以把软件卸载得干干净净；移植软件只需拷贝整个目录到另外一个机器即可（相同的操作系统）make这一步就是编译，大多数的源代码包都经过这一步进行编译（当然有些perl或python编写的软件需要调用perl或python来进行编译）。如果 在 make 过程中出现 error ，你就要记下错误代码（注意不仅仅是最后一行），然后你可以向开发者提交 bugreport（一般在 INSTALL 里有提交地址），或者你的系统少了一些依赖库等，这些需要自己仔细研究错误代码。可能遇到的错误：make * 没有指明目标并且找不到 makefile。 停止。问题很明了，没有Makefile，怎么办，原来是要先./configure 一下，再make**make install这条命令来进行安装（当然有些软件需要先运行 make check 或 make test 来进行一些测试）。如果安装失败可以使用make clean来清除编译产生的可执行文件及目标文件(object file，*.o)。参考链接linux无root权限安装软件linux下非root用户安装软件入门Linux 命令详解（三）./configure、make、make install 命令Linux ./configure –prefix 命令]]></content>
      <categories>
        <category>Linux</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rename-批量修改文件名称]]></title>
    <url>%2Fposts%2F50712.html</url>
    <content type="text"><![CDATA[这篇文章学习了用来修改文件名称的命令rename(不是系统自带的，需要下载)，相比于传统的mv命令，rename可以支持使用正则表达式来批量操作文件列表(可以使用通配符)；但是需要注意的是rename只能修改文件的名称，而不能修改目录的名称，但是mv却可以修改文件名称，只是不能支持批量操作而已，借助循环就可以达到批量替换的目的。背景由于课题的需要，要对很多文件的名称进行修改，然而每个单独进行修改会很麻烦，并且还希望只替代部分信息，比如a_1.txt，后面的_1.txt是还需要保留的信息。mv命令修改mv命令是move的简写，原本是用来移动文件(相当于是剪切)，但是如果被移动文件和目标文件在同一个目录下就可以实现名称的修改，但是这个在单独修改每个文件名称时比较好用(也包括循环修改，其实也是每次只修改一个，只是加了循环而已)：12# 将当前目录下的a_1.txt修改为b_1.txtmv ./a_1.txt ./b_1.txtrename命令rename顾名思义就是直接修改名称的命令，这个命令是linux自带的命令，之前一直没有发现，最近遇到问题需要进行大规模修改的时候，直接搜索到这个命令可以更加方便地使用。rename有两个版本，一个是linux自带的，在功能不是很强大，在/usr/bin/rename中，和mv命令差不多，另一个是perl语言的rename，功能更加强大，但需要自己安装，后面使用的都是这个自己安装的rename命令。rename安装下载安装包，从这个链接下载12# 下载perl安装包wget https://cpan.metacpan.org/authors/id/P/PE/PEDERST/rename-1.9.tar.gz解压1tar -zxvf rename-1.9.tar.gz安装123456789101112131415161718cd "rename-1.9"perl "Makefile.PL" Checking if your kit is complete... Looks good Generating a Unix-style Makefile Writing Makefile for rename Writing MYMETA.yml and MYMETA.jsonmake "/Share2/home/wangjb/usr/anaconda2/bin/perl" "-Iblib/arch" "-Iblib/lib" bin/rename.PL bin/rename Extracting rename cp bin/rename blib/script/rename "/Share2/home/wangjb/usr/anaconda2/bin/perl" -MExtUtils::MY -e 'MY-&gt;fixin(shift)' -- blib/script/rename Manifying 1 pod documentmake install Manifying 1 pod document Installing /Share2/home/wangjb/usr/anaconda2/man/man1/rename.1 Installing /Share2/home/wangjb/usr/anaconda2/bin/rename Appending installation info to /Share2/home/wangjb/usr/anaconda2/lib/perl5/5.22.0/x86_64-linux-thread-multi/perllocal.podPS：安装直接将其安装在anaconda中了如果想指定安装路径可以在perl &quot;Makefile.PL&quot;的时候加上INSTALL_BASE( can be set to modify the base installation directory.)。eg: perl &quot;Makefile.PL&quot; INSTALL_BASE=/usr/local也可以直接使用cpan安装，具体的安装教程请参考这个链接rename格式12345Usage: rename [OPTION]... PERLEXPR FILE... Rename FILE(s) using PERLEXPR on each filename. # 另一种写法，感觉有点像sed命令的使用 rename [options] "s/oldname/newname/" file原字符串oldname：将要被替换的字符串目标字符串newname：原字符替换成的目标字符串文件file：指定要改变文件名的文件列表上面的oldname和newname都支持正则表达式file列表支持通配符Linux通配符和正则表达式及其区别rename使用实例替换文件名中特定字段123456789101112131415161718192021222324252627282930 -rw-rw-r--. 1 user user 0 Jun 5 22:39 1_ab.txt -rw-rw-r--. 1 user user 0 Jun 5 22:39 1_ac.txt -rw-rw-r--. 1 user user 0 Jun 5 22:39 1_ad.txt -rw-rw-r--. 1 user user 0 Jun 5 22:39 2_aa.txt# 将所有文件名中的a替换为b# 后面语法的书写很像sed命令# 默认只会替换第一个出现的字符，如2_aa.txt被修改为了2_ba.txt，第二个a没有被替换rename 's/a/b/' * -rw-rw-r--. 1 user user 0 Jun 5 22:39 1_bb.txt -rw-rw-r--. 1 user user 0 Jun 5 22:39 1_bc.txt -rw-rw-r--. 1 user user 0 Jun 5 22:39 1_bd.txt -rw-rw-r--. 1 user user 0 Jun 5 22:39 2_ba.txt# 全局替换# 替换所有的模式rename 's/a/b/g' * -rw-rw-r--. 1 user user 0 Jun 5 22:39 1_bb.txt -rw-rw-r--. 1 user user 0 Jun 5 22:39 1_bc.txt -rw-rw-r--. 1 user user 0 Jun 5 22:39 1_bd.txt -rw-rw-r--. 1 user user 0 Jun 5 22:39 2_bb.txt# 结合正则表达式进行替换# 不仅将正则匹配的内容进行了替换，并且将1_也直接替换掉了# 这里使用$1、$2表示匹配上的分组信息，而不是常规的\1、\2这种rename 's/1_(.)(.)/$2-$1/' * -rw-rw-r--. 1 user user 0 Jun 6 05:52 2_bb.txt -rw-rw-r--. 1 user user 0 Jun 6 05:52 b-b.txt -rw-rw-r--. 1 user user 0 Jun 6 05:52 c-b.txt -rw-rw-r--. 1 user user 0 Jun 6 05:52 d-b.txt使用正则表达式进行替换的时候使用$1`$2这种来**表示匹配上的分组信息**，这和之前常规的\1、\2`不同，需要注意修改文件后缀123456# 将文件后缀由txt修改为shrename 's/.txt/.sh/' * -rw-rw-r--. 1 user user 0 Jun 6 05:52 2_bb.sh -rw-rw-r--. 1 user user 0 Jun 6 05:52 b-b.sh -rw-rw-r--. 1 user user 0 Jun 6 05:52 c-b.sh -rw-rw-r--. 1 user user 0 Jun 6 05:52 d-b.sh添加和删除后缀12345678910111213# 将所有文件的后缀删除rename 's/.sh//' * -rw-rw-r--. 1 user user 0 Jun 6 05:52 2_bb -rw-rw-r--. 1 user user 0 Jun 6 05:52 b-b -rw-rw-r--. 1 user user 0 Jun 6 05:52 c-b -rw-rw-r--. 1 user user 0 Jun 6 05:52 d-b# 给所有文件统一添加后缀txtrename 's/$/.txt/' * -rw-rw-r--. 1 user user 0 Jun 6 05:52 2_bb.txt -rw-rw-r--. 1 user user 0 Jun 6 05:52 b-b.txt -rw-rw-r--. 1 user user 0 Jun 6 05:52 c-b.txt -rw-rw-r--. 1 user user 0 Jun 6 05:52 d-b.txt修改文件夹关于文件夹的名称如果需要修改会比较麻烦，上面的rename支持修改文件的名称，但是不能支持修改目录的名称；而前面提到的mv不仅能够修改文件名称还能修目录名称(都是剪切然后粘贴的原理嘛)：12# 批量修改文件夹的名称for i in `ls`;do mv $i $(echo $i |sed 's/LJ_mtDNA_590/LJ0590_fro_wbc_190310/');done参考链接每天学习一个命令: rename 批量修改文件名rename命令]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jupyter版的IGV之igv-jupyter]]></title>
    <url>%2Fposts%2F53124.html</url>
    <content type="text"><![CDATA[这篇文章初步探索了igv-jupyter的配置和使用，后续使用可以添加。IGV整合基因组浏览器(IGV)是一种高性能的可视化工具，用来交互式地探索大型综合基因组数据。IGV一直以来就是一个桌面版的软件，使用需要下载安装，但是一般的bam文件都在服务器上，这样使用起来就比较麻烦，因此igvteam相继推出了igv.js以及igv-jupyter用于在线查看，方便快捷。这是一篇对igv-jupyter的使用进行探索的文章。下载安装使用如下命令进行安装和下载：12# 使用pip进行安装pip install igv-jupyter安装完成之后结合到nbextension作为插件使用：1234567891011# To install to configuration in your home directoryjupyter serverextension enable --py igvjupyter nbextension install --py igvjupyter nbextension enable --py igv# 我用的是anaconda安装的，需要使用这个# 实际上我都尝试了，使用上面的命令不管用# If using a virtual environmentjupyter serverextension enable --py igv --sys-prefixjupyter nbextension install --py igv --sys-prefixjupyter nbextension enable --py igv --sys-prefix关于安装，还可以参考这篇文章：Python系列之从github源码安装python包使用基础用法按照官网的示例：12345678910# 导入igv包import igv# 创建一个igv broswer对象# 该对象会显示hg19的参考基因组b = igv.Browser(&#123;"genome": "hg19"&#125;)# 显示这个对象# 具体的显示出桌面版的界面b.show()创建对象时导入的信息可以查看igv.js documentationtrack实例的track：1234567b.load_track( &#123; "name": "Segmented CN", "url": "https://data.broadinstitute.org/igvdata/test/igv-web/segmented_data_080520.seg.gz", "format": "seg", "indexed": False &#125;)这一步正常情况下会出现OK，如果出错可能会出现IGV Browser not ready，出现这个问题是因为igv还没有完全配置好，可能是上面的结合nbextension作为插件使用这一步的问题，需要注意使用相对应的情况，如果实在不能解决可以查看这个issue中创建新的虚拟环境安装的过程，亲测可用。注意：是先调用b.show()之后再load track，然后就可以在前面b.show()的结果中看到新添加的track，不用新调用b.show()自定义track需要按照这个说明：igv.js documentation定义track的各种示例实际效果如下：辅助功能####放大或者缩小12345# 缩小b.zoom_in()# 放大b.zoom_out()搜索12# 搜索chr1染色体的3000-4000区域b.search('chr1:3000-4000')跳转到特定的基因1b.search('myc')目前跳转到特定的基因目前只支持hg38、hg19、mm10，如果想自定义搜索服务需要查看igv.js documentation输出SVG保存当前的视图到SVG需要如下两个命令：123b.get_svg()b.display_svg()参考链接igv-jupyter的github定义track的各种示例igv.js的wiki文档]]></content>
      <categories>
        <category>Python</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之从github源码安装python包]]></title>
    <url>%2Fposts%2F42671.html</url>
    <content type="text"><![CDATA[这篇文章学习了使用github源码以及 setup.py安装Python包的方法，主要是作为直接使用 pip install package name的补充。背景最近想安装一个Python包：igv-jupyter，github链接，github上提供的安装方法如下：123456789101112pip install igv-jupyter# To install to configuration in your home directoryjupyter serverextension enable --py igvjupyter nbextension install --py igvjupyter nbextension enable --py igv# If using a virtual environmentjupyter serverextension enable --py igv --sys-prefixjupyter nbextension install --py igv --sys-prefixjupyter nbextension enable --py igv --sys-prefix按照上述方法安装总是报错：123456789pip install igv-jupyterCollecting igv-jupyter WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('&lt;pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f74f867a630&gt;: Failed to establish a new connection: [Errno 101] Network is unreachable')': /simple/igv-jupyter/ WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('&lt;pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f74f867a6d8&gt;: Failed to establish a new connection: [Errno 101] Network is unreachable')': /simple/igv-jupyter/ WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('&lt;pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f74f867a4a8&gt;: Failed to establish a new connection: [Errno 101] Network is unreachable')': /simple/igv-jupyter/ WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('&lt;pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f74f867a518&gt;: Failed to establish a new connection: [Errno 101] Network is unreachable')': /simple/igv-jupyter/ WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('&lt;pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f74f867a668&gt;: Failed to establish a new connection: [Errno 101] Network is unreachable')': /simple/igv-jupyter/ ERROR: Could not find a version that satisfies the requirement igv-jupyter (from versions: none)ERROR: No matching distribution found for igv-jupyter后来发现是实验室的网坏掉了，不能上外网，所以下载不了。。。。。解决通过pip安装pip install 支持很多方式的安装，如git、svn等，具体的讲解说明这个文档都有上述办法不能安装，但是源代码在github上啊，所以就想看看能不能直接使用github源码进行安装：12# 使用pip安装github源代码pip install git+git://github.com/igvteam/igv-jupyter.git这里直接复制的github链接为`git@github.com:igvteam/igv-jupyter.git，但是好像不能正确运行ERROR: Invalid requirement: &#39;git+git@github.com:igvteam/igv-jupyter.git’，需要将前面的修改为git://github.com/`。通过setup.py安装12345# 先clone到本地git clone https://github.com/igvteam/igv-jupyter.git# 运行setup.pypython setup.py install注意不要使用sudo，因为使用sudo之后会使用系统自带的python版本，我的是2.7，但是我的2.7没有安装jupyter，所以会报错；不使用sudo就会使用自己安装的环境中的3.7。参考链接How to install Python package from GitHub? [duplicate]]]></content>
      <categories>
        <category>Python</category>
        <category>tricks</category>
      </categories>
      <tags>
        <tag>tricks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之numpy-数组与矩阵运算(五)：常用函数汇总]]></title>
    <url>%2Fposts%2F15933.html</url>
    <content type="text"><![CDATA[这篇文章汇总了numpy中常用的方法，便于查询使用。按作用划分创建数组arangearraycopyemptyempty_likeeyefromfilefromfunctionidentitylinspacelogspacemgridogridonesones_likerzeroszeros_likenumpy-数组创建操作array splitcolumn stackconcatenatediagonaldsplitdstackhsplithstackitemnewaxisravelrepeatreshaperesizesqueezeswapaxestaketransposevsplitvstacknumpy-切片、截取和堆叠numpy-广播、迭代以及数组相关操作排序argmaxargminargsortamaxaminptpsearchsortedsortnumpy-常用函数询问allanynonzerowherenumpy-常用函数基本统计统计函数含义average/mean平均值。其中 average 还可以用 weight 参数指定权重median中位数diff一阶差分cumsum/cumprod累和／累积sum/prod求和 / 求积std/var标准差 / 方差numpy-常用函数基本线性代数crossdotoutersvdvdot按元素个数划分一元函数直接从元素操作中移植的函数，比如幂指函数等等。一元函数调用形式是 np.function(arr) 简表如下：一元函数含义abs/fabs求模。对于非复数矩阵，fabs更快。sqrt/square平方根/平方exp指数log/log10/log2/log1p对数：自然对数/10/2为底，以及以2为底的log(1+x)sign正负号判断函数：返回 1, 0, 或者 -1ceil/floor向上取整/向下取整rint四舍五入到整数isnan返回关于非数值（np.nan）判断的布尔型数组isfinite/isinf判断非无限大值/无限大值sin/cos/tan三角函数arcsin/arccos/arctan反三角函数sinh/cosh/tanh/arcsinh/arccosh/arctanh以上三角函数的双曲形式二元函数以及矩阵的二元函数，调用形式是 np.function(x, y):二元函数含义add/substract/multiply对应元素相加/相减/相乘divide/floor_divide对应元素除法及向下整除法（弃余数）power计算 x(i,j)^y(i,j)maximum/fmax元素级的最大值。fmax 表示忽略 NaN&nbsp;注：在比较含有 NaN 的矩阵时可能出现问题，我尚不清楚 NumPy 做出了怎样的改变。minimum/fmin仿上mod取余copysign将y的符号传递给x中的对应元素参考链接Python科学计算：numpyNumpy详细教程]]></content>
      <categories>
        <category>Python</category>
        <category>常用模块</category>
      </categories>
      <tags>
        <tag>常用模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python-在字符串中查找所有子字符串]]></title>
    <url>%2Fposts%2F31648.html</url>
    <content type="text"><![CDATA[这篇文章学习了如何使用python查找子串在字符串中所有出现位置的索引，主要是使用了迭代器re.finditer以及find函数；相比之下，使用迭代器re.finditer速度更快、代码更加简洁，但是移植性不强，不能将框架移植到shell中，而find函数比迭代器re.finditer慢一点，但是框架移植性强。目的在字符串中查找所有子字符串，而不是第一次出现的字符串。如果想使用python在字符串中查找符合条件的子字符串，可以使用的函数包括find、index。index方法和find方法基本相同，区别在于:使用index，如果子字符串不在字符串中，则会报错，而使用find方法这种情况会返回-1，两者返回的都是子字符串第一次出现的索引位置，这也是两个方法最大的缺点，不能直接查找所有符合条件的子字符串。index和find函数形式：12345# find函数形式S.find(sub[, start[, end]]) -&gt; int# index函数形式S.index(sub[, start[, end]]) -&gt; intfind和index虽然没有直接查找所有子字符串的方法，但是可以利用其中的start参数进行递归查找使用re.finditer作用和re.findall类似，但是findall会返回所有匹配的字符串，并将其存为一个列表，而finditer则并不直接返回这些字符串，而是返回一个迭代器，里面包括了匹配的字符串以及匹配的字符串开始和结束的索引位置：1234567891011121314151617181920212223242526s='aaaabbaaaabbaaaa'for i in re.finditer(r'aaaa' , s ): print (i)# 输出&lt;re.Match object; span=(0, 4), match='aaaa'&gt;&lt;re.Match object; span=(6, 10), match='aaaa'&gt;&lt;re.Match object; span=(12, 16), match='aaaa'&gt;# 输出匹配上的字符串s='aaaabbaaaabbaaaa'for i in re.finditer(r'aaaa' , s ): print (i.group())# 输出aaaaaaaaaaaa# 分别输出开始和结束索引s='aaaabbaaaabbaaaa'for i in re.finditer(r'aaaa' , s ): print (i.start(),i.end())# 输出索引位置0 46 1012 16如果需要允许滑动匹配，可以使用如下的方式：123456789101112131415s='aaaabbaaaabbaaaa'for i in re.finditer(r'(?=aa)' , s ): print (i)# 输出结果# 这时的匹配结果为空字符串&lt;re.Match object; span=(0, 0), match=''&gt;&lt;re.Match object; span=(1, 1), match=''&gt;&lt;re.Match object; span=(2, 2), match=''&gt;&lt;re.Match object; span=(6, 6), match=''&gt;&lt;re.Match object; span=(7, 7), match=''&gt;&lt;re.Match object; span=(8, 8), match=''&gt;&lt;re.Match object; span=(12, 12), match=''&gt;&lt;re.Match object; span=(13, 13), match=''&gt;&lt;re.Match object; span=(14, 14), match=''&gt;缺点：依赖于python的re模块，如果不是在python中(shell中也有类似的函数)，拓展性不是很强优点：速度快使用find函数递归查找函数形式：12# find函数形式S.find(sub[, start[, end]]) -&gt; int可以通过不断更新start参数来实现递归查找：123456789101112131415161718192021222324252627s='bbaaaabbaaaabbaaaa'final_li=[]start=0while 1: index=s.find('aaaa',start) if index == -1: break final_li.append(index) start= index+len('aaaa')# 输出结果final_li [2, 8, 14]# 如果想要查询带有滑框的结果，可以修改每次start迭代的值s='bbaaaabbaaaabbaaaa'final_li=[]start=0while 1: index=s.find('aa',start) if index == -1: break final_li.append(index) # 这里修改为+1即可实现 start= index+1# 输出final_li [2, 3, 4, 8, 9, 10, 14, 15, 16]缺点：速度没有前面的re.finditer快优点：可移植性强，可以很轻松地将框架移植到shell中参考链接How to find all occurrences of a substring?Calculate difference between adjacent items in a python list]]></content>
      <categories>
        <category>Python</category>
        <category>tricks</category>
      </categories>
      <tags>
        <tag>tricks</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之numpy-数组与矩阵运算(四)：常用函数]]></title>
    <url>%2Fposts%2F54407.html</url>
    <content type="text"><![CDATA[这篇文章学习了numpy中常用的函数，主要包括四舍五入相关、统计函数、排序函数和查找函数。np.around()、np.floor()、np.ceil()、np.amin()、np.argmin()、np.amax()、np.ptp()、np.percentile()、np.median()、np.average()、np.std()、np.sort()、np.argsort()、np.lexsort()、np.nonzero()、np.where()、np.extract()。四舍五入相关相关函数汇总：函数说明np.around(a, decimals=0, out=None)四舍五入，注意如果是x.5这种情况就会约到最近的偶数，其他情况就是正常的四舍五入np.floor(*args, **kwargs)不进行四舍五入，直接向下取整，得到邻近的最小整数np.ceil(*args, **kwargs)不进行四舍五入，直接向上取整，得到邻近的最大整数四舍五入-np.around()作用：四舍五入，和round函数类似，但是需要注意如果是x.5这种情况就会约到最近的偶数，其他情况就是正常的四舍五入函数形式：1234np.around(a, decimals=0, out=None)# a：数组或者列表等# decimals：保留的小数点位数，默认为0, 如果为负，整数将四舍五入到小数点左侧的位置# out：输出的数组使用实例：1234567891011121314151617# 对列表进行四舍五入np.around([0.37, 1.64]) array([0., 2.])# 保留一位小数np.around([0.37, 1.64], decimals=1) array([0.4, 1.6])# 如果是.5结束，会约到最近的小数# 这个需要注意# 如果不是.5，就是正常的四舍五入np.around([.5, 1.5, 2.5, 3.5, 4.5]) array([0., 2., 2., 4., 4.])# 将0.5改为0.6，正常的四舍五入np.around([.6, 1.5, 2.5, 3.5, 4.5]) array([1., 2., 2., 4., 4.])向下取整-np.floor()作用：不进行四舍五入，得到数字邻近的最小整数函数形式：1np.floor(*args, **kwargs)使用实例：123456789# 直接操作列表np.floor([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0]) array([-2., -2., -1., 0., 1., 1., 2.])# 操作数组a = np.array([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0])# 1.7向下取整之后得到1，而不是四舍五入得到2np.floor(a) array([-2., -2., -1., 0., 1., 1., 2.])向上取整-np.ceil()作用：也不进行四舍五入，直接向上取整，和floor作用相反函数形式：1np.ceil(*args, **kwargs)使用实例：123456789# 直接操作列表np.ceil([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0]) array([-1., -1., -0., 1., 2., 2., 2.])# 操作数组a = np.array([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0])# 不进行取整，而是得到邻近的最大整数np.ceil(a) array([-1., -1., -0., 1., 2., 2., 2.])统计函数常用的统计函数汇总：函数说明np.amin(a, axis=None, out=None, keepdims=&lt;no value&gt;, initial=&lt;no value&gt;)整个数组或者某一维的最小值np.argmin(a, axis=None, out=None)数组或者某一维最小值的索引np.amax(a, axis=None, out=None, keepdims=&lt;no value&gt;, initial=&lt;no value&gt;)整个数组或者某一维的最大值np.argmax(a, axis=None, out=None)数组或者某一维最大值的索引np.ptp(a, axis=None, out=None, keepdims=&lt;no value&gt;)整个数组或者某一维的极差np.percentile(a, q, axis=None, out=None, overwrite_input=False, interpolation='linear', keepdims=False)整个数组或者某一维的百分位数np.median(a, axis=None, out=None, overwrite_input=False, keepdims=False)数组或者某一维的中位数np.mean(a, axis=None, dtype=None, out=None, keepdims=&lt;no value&gt;)数组或者某一维的平均数np.average(a, axis=None, weights=None, returned=False)数组或者某一维的加权平均np.std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=&lt;no value&gt;)数组或者某一维的标准差np.var(a, axis=None, dtype=None, out=None, ddof=0, keepdims=&lt;no value&gt;)数组或者某一维的方差数组或者某一维的最小值-np.amin()函数形式：1234np.amin(a, axis=None, out=None, keepdims=&lt;no value&gt;, initial=&lt;no value&gt;)# a：array_like，可以为列表等# axis：默认为None，表示整个数组的最小值；0表示每一列的最小值；1表示每一行的最小值# keepdims：保持原始数组的维度使用实例：1234567891011121314# 2行2列的数组a = np.arange(4).reshape((2,2)) array([[0, 1], [2, 3]])# 不指定axis，默认是这个数组最小np.amin(a) 0# 指定axis=0，表示对每列取最小np.amin(a,axis=0) array([0, 1])# 指定axis=1，表示对每行取最小np.amin(a,axis=1) array([0, 2])数组或者某一维最小值的索引-np.argmin()上面的函数np.amin()返回的是数组或某一维最小值的数值，这里则会返回数组或某一维最小值的索引。函数形式：123np.argmin(a, axis=None, out=None)# a：array_like，可以为列表等# axis：默认为None，表示整个数组的最小值；0表示每一列的最小值；1表示每一行的最小值使用实例：123456789101112131415# 3行2列的数组a = np.arange(6).reshape(2,3) + 10 array([[10, 11, 12], [13, 14, 15]])# axis=None，表示整个数组最小值的索引 0 # 最小值为10，索引为0# axis=0，表示每列np.argmin(a,axis=0) array([0, 0, 0])# axis=1，表示每行np.argmin(a,axis=1) array([0, 0])数组或者某一维的最大值-np.amax()函数形式：1234np.amax(a, axis=None, out=None, keepdims=&lt;no value&gt;, initial=&lt;no value&gt;)# a：array_like，可以为列表等# axis：默认为None，表示整个数组的最小值；0表示每一列的最小值；1表示每一行的最小值# keepdims：保持原始数组的维度用法和前面的np.amin类似数组或者某一维的极差-np.ptp()如果想要得到 (整个或者某一维)数组最大值和最小值的差值(极差)，可以使用np.ptp()函数形式：1234np.ptp(a, axis=None, out=None, keepdims=&lt;no value&gt;)# a：array_like，可以为列表等# axis：默认为None，表示整个数组的极差；0表示每一列的极差；1表示每一行的极差# keepdims：保持原始数组的维度使用实例：123456789101112a array([[0, 1], [2, 3]])# 整个数组的极差np.ptp(a) 3# 每一列的极差np.ptp(a,axis=0) array([2, 2])# 每一行的极差np.ptp(a,axis=1) array([1, 1])数组或者某一维的百分位数-np.percentile()函数形式：12345np.percentile(a, q, axis=None, out=None, overwrite_input=False, interpolation='linear', keepdims=False)# a：array_like，可以为列表等# q：百分位数，0-100范围内的，不用写成百分比# axis：默认为None，表示整个数组的百分位数；0表示每一列的百分位数；1表示每一行的百分位数# keepdims：保持原始数组的维度使用实例：12345678910111213141516171819a = np.array([[10, 7, 4], [3, 2, 1]]) array([[10, 7, 4], [ 3, 2, 1]])# 50%分位数，相当于中位数np.percentile(a, 50) # 3 + 4 /2 3.5# 对列求50%分位数np.percentile(a,50,axis=0) array([6.5, 4.5, 2.5])# 对行求50%分位数np.percentile(a,50,axis=1) array([7., 2.])# 保持原始数组的维度np.percentile(a,50,axis=1,keepdims=True) array([[7.], [2.]])数组或者某一维的中位数-np.median()函数形式：1234np.median(a, axis=None, out=None, overwrite_input=False, keepdims=False)# a：array_like，可以为列表等# axis：默认为None，表示整个数组的中位数；0表示每一列的中位数；1表示每一行的中位数# keepdims：保持原始数组的维度使用实例：123456789101112a = np.array([[10, 7, 4], [3, 2, 1]]) array([[10, 7, 4], [ 3, 2, 1]])# 整个函数的中位数，相当于50%百分位数np.median(a) 3.5# 对列求中位数，和上面百分位数的结果相同np.median(a,axis=0) array([6.5, 4.5, 2.5])# 对行求中位数，和上面百分位数的结果相同np.median(a,axis=1) array([7., 2.])数组或者某一维的加权平均-np.average()加权平均值即将各数值乘以相应的权数，然后加总求和得到总体值，再除以总的单位数。例如：考虑数组[1,2,3,4]和相应的权重[4,3,2,1]，通过将相应元素的乘积相加，并将和除以权重的和，来计算加权平均值。函数形式：1234np.average(a, axis=None, weights=None, returned=False)# a：array_like，可以为列表等# axis：默认为None，表示对整个数组进行加权平均；0表示对每一列进行加权平均；1表示对每一行进行加权平均# weights：权重，可以是数组，要和axis对应才行使用实例：12345678910111213141516171819# 数组a = np.array([1,2,3,4]) # weight数组wts = np.array([4,3,2,1]) # 以weight数组作为weight对数组进行加权平均 np.average(a,weights=wts) 2.0data = np.arange(6).reshape((3,2)) array([[0, 1], [2, 3], [4, 5]])# 对列赋予权值，得到行的加权平均# 注意这里的列为2，所以传入的维度也是2np.average(data, axis=1, weights=[1./4, 3./4]) array([0.75, 2.75, 4.75])# 如果将传入维度修改为3，则会报错np.average(data,axis=1,weights=[1.0/4,3.0/4,1.0/4]) ValueError: Length of weights not compatible with specified axis.使用注意事项：权重可以是数组，也可以是列表，但是维度一定要和axis对应，例如，对行加权，那么指定的权重数组或列表长度一定要和列的长度匹配，不然就会报错。数组或者某一维的标准差-np.std()函数形式：12345np.std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=&lt;no value&gt;)# a：array_like，可以为列表等# axis：默认为None，表示整个数组的标准差；0表示每一列的标准差；1表示每一行的标准差# ddof：Means Delta Degrees of Freedom.也就是样本对整体的有偏和无偏的问题# 默认的是ddof=0，是有偏估计，ddof=1，表示N-1，是无偏估计使用实例：12345678910111213141516a = np.array([[1, 2], [3, 4]])# 整个数组的标准差np.std(a) 1.1180339887498949np.std(a, axis=0) array([ 1., 1.])np.std(a, axis=1) array([ 0.5, 0.5])# 等同于这个，其中用到了广播的机制np.sqrt(((a- np.mean(a,axis=1,keepdims=True))**2).mean(axis=1))# 如果设置ddofnp.std(a,ddof=1) 1.2909944487358056# 等同于如下np.sqrt(((a-np.mean(a))**2).sum()/(a.size-1))使用注意事项：ddof参数的使用需要注意np.var()也类似，也有ddof参数排序函数函数说明np.sort(a, axis=-1, kind='quicksort', order=None)对整个数组或者某一维进行排序(升序)np.argsort(a, axis=-1, kind='quicksort', order=None)得到排序后的索引(升序)lexsort(keys, axis=-1)借助其他序列排序(升序)对整个数组或者某一维进行排序-np.sort()函数形式：12345np.sort(a, axis=-1, kind='quicksort', order=None)# a：array_like# axis：排序的axis，默认是-1(2维的是行)，which sorts along the last axis# kind：排序的算法，&#123;'quicksort', 'mergesort', 'heapsort', 'stable'&#125;# order： 如果数组包含字段，则是要排序的字段三种排序算法比较：种类速度最坏情况工作空间稳定性'quicksort'（快速排序）1O(n^2)0否'mergesort'（归并排序）2O(n*log(n))~n/2是'heapsort'（堆排序）3O(n*log(n))0否使用实例：123456789101112131415161718192021222324252627282930a = np.array([[3,7],[9,1]]) array([[3, 7], [9, 1]])# 默认排序，对行，最小的值放在各行的第一个np.sort(a) array([[3, 7], [1, 9]])# 对整个数组进行排序np.sort(a,axis=None) array([1, 3, 7, 9])# 对列进行排序，最小的值放在各列的第一个np.sort(a,axis=0) array([[3, 1], [9, 7]])# 指定order# dtype相当于成了字典dt = np.dtype([('name', 'S10'),('age', int)]) dtype([('name', 'S10'), ('age', '&lt;i8')])a = np.array([("raju",21),("anil",25),("ravi", 17), ("amar",27)], dtype = dt) array([(b'raju', 21), (b'anil', 25), (b'ravi', 17), (b'amar', 27)], dtype=[('name', 'S10'), ('age', '&lt;i8')])# 对name进行排序np.sort(a, order = 'name') array([(b'amar', 27), (b'anil', 25), (b'raju', 21), (b'ravi', 17)], dtype=[('name', 'S10'), ('age', '&lt;i8')])得到排序后的索引-np.argsort()函数形式：12345np.argsort(a, axis=-1, kind='quicksort', order=None)# a：array_like# axis：排序的axis，默认是-1(2维的是行)，which sorts along the last axis# kind：排序的算法，&#123;'quicksort', 'mergesort', 'heapsort', 'stable'&#125;# order： 如果数组包含字段，则是要排序的字段使用实例：123456789101112131415161718x = np.array([[0, 3], [2, 2]]) array([[0, 3], [2, 2]])# 对列进行排序，也就是把每一列最小的放在第一行# 返回的是对应数值的索引np.argsort(x, axis=0) array([[0, 1], [1, 0]])# 默认是对行进行排序np.argsort(x) array([[0, 1], [0, 1]])# 对整个数组排序# 返回索引np.argsort(x,axis=None) array([0, 2, 3, 1])借助其他序列排序-np.lexsort()如果一个数组或序列中存在多个相同的值，普通的排序会按照出现的先后顺序进行排序，np.lexsort()会借助其他数组或序列实现排序而不是按照默认的方式。函数形式：123np.lexsort((a,b), axis=-1)# (a,b)：多个序列，会优先对后面的也就是b进行排序，b中相同的则会借助a中的信息对b进行排序# axis：-1表示sort over the last axis.使用实例：1234567891011121314151617a = [1,5,1,4,3,4,4] # First columnb = [9,4,0,4,0,2,1] # Second column# 对a进行排序，返回排序后的数组np.sort(a) array([1, 1, 3, 4, 4, 4, 5])# 直接对a进行排序，返回索引值# a中有2个1、3个4，默认使用argsort会按照出现的先后顺序np.argsort(a) array([0, 2, 4, 3, 5, 6, 1])# 借助序列b对a进行排序# a中的两个1在b中分别对应9、0，所以后面的1排在前面的1之前# 默认的0、2就变成了2、0np.lexsort((b,a)) array([2, 0, 4, 6, 5, 3, 1])查找函数函数说明np.nonzero(a)查找非零(True)元素索引np.where(condition, [x, y])类似三目运算符或相当于np.nonzero(a)，如果不指定x和ynp.extract(condition, arr)从数组中以某个条件来抽取元素查找非零元素索引-np.nonzero()函数形式：1np.nonzero(a)使用实例：123456789101112131415161718192021222324252627282930313233x = np.array([[3, 0, 0], [0, 4, 0], [5, 6, 0]]) array([[3, 0, 0], [0, 4, 0], [5, 6, 0]])# 查找非0元素的索引np.nonzero(x) (array([0, 1, 2, 2]), array([0, 1, 0, 1]))# 返回的是非零元素的索引# 和切片中的整数索引切片相同，返回的是一一对应的# 获取非0元素的值x[np.array([0, 1, 2, 2]), np.array([0, 1, 0, 1])] array([3, 4, 5, 6])# 还可以结合判断语句a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])a &gt; 3 array([[False, False, False], [ True, True, True], [ True, True, True]])# 查找满足a&gt;3的索引np.nonzero(a&gt;3)(array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))# 获取对应的值a[np.array([1, 1, 1, 2, 2, 2]), np.array([0, 1, 2, 0, 1, 2])] array([4, 5, 6, 7, 8, 9])# 直接使用布尔索引a[a&gt;3] array([4, 5, 6, 7, 8, 9])三目运算符或查找索引-np.where()如果想在数组或列表等中进行类似三目运算符的操作，可以使用np.where()，同时np.where()还可以有np.nonzero()的功能。函数形式：12345where(condition, [x, y])# condition：筛选条件# x：条件成立时的选择# y：条件不成立的选择# 如果x、y不指定，就相当于np.nonzero()使用实例：12345678910111213141516171819202122232425262728293031323334353637383940# 创建一个一维数组a = np.arange(10) array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])# 如果小于5，就设置为1，否则就设置为-1np.where(a &lt; 5, 1,-1) array([ 1, 1, 1, 1, 1, -1, -1, -1, -1, -1])# 在二维数组中的应用x=np.arange(1,5,1).reshape((2,2)) array([[1, 2], [3, 4]])y=np.arange(6,10,1)[::-1].reshape((2,2)) array([[9, 8], [7, 6]])condition=np.array([[True, False], [True, True]]) array([[ True, False], [ True, True]])# np.where还是一一对应的问题# condition中(0,0)为true，对应地在x中取(0,0)，而不取y中的(0,0)# condition中(0,1)为false，对应地不在x中取(0,1)，而取y中的(0,1)# 以此类推得到下面的结果np.where(condition,x,y) array([[1, 8], [3, 4]])# 如果condition为数组，而x、y为一个数字，那么就会被广播# 相当于所有不满足条件的都设置为同一个值a = np.array([[0, 1, 2],[0, 2, 4],[0, 3, 6]]) array([[0, 1, 2], [0, 2, 4], [0, 3, 6]])# 小于4的都会被赋值-1np.where(a &lt; 4, a, -1) array([[ 0, 1, 2], [ 0, 2, -1], [ 0, 3, -1]])抽取元素-np.extract()函数形式：1234np.extract(condition, arr)This is equivalent to np.compress(ravel(condition), ravel(arr)).# 返回的应该会是一维数组使用实例：123456789101112arr = np.arange(12).reshape((3, 4)) array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]])# 设置条件condition = np.mod(arr, 3)==0 array([[ True, False, False, True], [False, False, True, False], [False, True, False, False]])# 抽取元素np.extract(condition, arr) array([0, 3, 6, 9])参考链接NumPy 数学函数NumPy 统计函数numpy.where() 用法详解]]></content>
      <categories>
        <category>Python</category>
        <category>常用模块</category>
      </categories>
      <tags>
        <tag>常用模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之numpy-数组与矩阵运算(三)：广播、迭代以及数组相关操作]]></title>
    <url>%2Fposts%2F24353.html</url>
    <content type="text"><![CDATA[这篇文章学习了numpy的广播、迭代以及数组相关操作；在广播中学习了numpy广播的机制和原理以及进行广播的条件；在迭代中学习了普通的循环遍历数组元素、使用numpy的迭代器对象 numpy.nditer进行数组元素的迭代、使用np.ndenumerate进行枚举迭代、使用np.ndindex迭代索引；在数组操作中学习了修改数组形状、分割数组、数组元素的添加(append、insert)和删除(delete、unique)等。numpy广播numpy数组间的基础运算是element-by-element的，如a+b的结果就是a与b数组对应位进行相应的运算(不是矩阵运算，矩阵运算有特殊的方法)，必须满足a.shape == b.shape，也就是两个数组的维数相同，且各维度的长度相同，以下是a.shape == b.shape的一个示例：12345678910# a为一维数组a = np.array([1,2,3,4]) array([1, 2, 3, 4])# b也为一维数组b = np.array([10,20,30,40]) array([10, 20, 30, 40])# 对应位置元素相乘a * b array([ 10, 40, 90, 160])如果运算中的2个数组的shape不同时，只有当他们的trailing dimensions（尾部维度）`compatible（兼容）时才会触发广播，否则报错ValueError: frames are not aligned exception`，这里面有两个概念需要理解，一个是尾部维度，另一个是兼容：关于尾部维度，简单来说就是使用array.shape之后得到的最后一个维度信息关于兼容，一下是两个基本条件：尾部维度是相等的(见下面实例以及补充)尾部维度其中有一方是1(见下面的实例和补充)尾部维度相等使用实例：123456789101112131415161718192021222324# 创建一个4行3列的数组a = np.array([[ 0, 0, 0], [10,10,10], [20,20,20], [30,30,30]])a.shape (4, 3)# 创建一个一维的数组# 长度为3b = np.array([1,2,3])b.shape (3,)# 尾部维度相同# 满足广播机制4 x 3 3a + b array([[ 1, 2, 3], [11, 12, 13], [21, 22, 23], [31, 32, 33]])不是所有的尾部维度相同的都可以进行广播：12345678# 将上面的b修改为2行3列的数组b=np.arange(6).reshape((2,3))# 尾部维度相同# 但是不满足广播机制4 x 32 x 3ValueError: operands could not be broadcast together with shapes (4,3) (2,3)广播一定要体会到维度较小的可以在某一个或者几个维度上存在拉伸和拓展的感觉，本质上还是满足数组按位一一对应进行运算，只是维度较小的复制成了和维度较大的一样的shape，比如上面的4 x 3和3，可以看成维度为3的先复制成了4 x 3的(每一行的内容相同)，然后按位一一对应进行运算，而后面将b改为2 x 3之后就不能进行类似的操作。其中一个尾部维度为1使用实例：1234567891011b=np.array([1])# 尾部维度不同，但第二个的尾部维度为1# 满足广播机制4 x 3 1a + b array([[ 1, 1, 1], [11, 11, 11], [21, 21, 21], [31, 31, 31]])不是只要其中一个尾部维度为1就行：123456789101112131415161718192021222324252627282930b=np.arange(6).reshape((6,1))# 尾部维度不同，第二个的尾部维度为1# 但是不满足广播机制4 x 36 x 1a + b ValueError: operands could not be broadcast together with shapes (4,3) (6,1)# 官网示例# 倒数后三位，a和b总有一个为1A (4d array): 8 x 1 x 6 x 1B (3d array): 7 x 1 x 5Result (4d array): 8 x 7 x 6 x 5# 按照官网实例修改a=np.arange(3).reshape((1,3))b=np.arange(6).reshape((6,1))# 维度相同，但在各个维度上a和b总有一个为11 x 36 x 1a + b array([[0, 1, 2], [1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7]])数组迭代普通的循环遍历1234567# 双重for循环进行迭代for row in a: for cell in row: print (cell,end=', ')# 输出内容0, 1, 4, 3, 4, 5,使用迭代器对象迭代元素NumPy 迭代器对象 numpy.nditer 提供了一种灵活访问一个或者多个数组元素的方式.默认迭代顺序12345678910111213# 创建一个2行3列的数组a=np.arange(6).reshape((2,3))a array([[0, 1, 2], [3, 4, 5]])# 迭代数组中的元素for i in np.nditer(a): # 修改默认是输出结束符为, print (i,end=',')# 输出内容0,1,2,3,4,5,需要注意的是数组的存储是带有顺序的，即order设置；在迭代数组元素时，默认情况下选择的顺序是和数组内存布局一致的对数组进行转置后会不会影响迭代元素的顺序：123456789101112# 对数组进行转置操作a.T array([[0, 3], [1, 4], [2, 5]])# 迭代数组中的元素for i in np.nditer(a.T): print (i,end=',')# 输出内容0,1,2,3,4,5,通过上述对转置后数组元素的迭代可以发现，两者的输出完全相同，也就是说a 和 a.T 的遍历顺序是一样的，即他们在内存中的存储顺序是一样的，转置只是改变了形态，而没有改变内部的存储顺序。控制迭代顺序for x in np.nditer(a, order=&#39;F&#39;):Fortran order，即是列序优先for x in np.nditer(a.T, order=&#39;C&#39;):C order，即是行序优先123456789101112131415161718a array([[0, 1, 2], [3, 4, 5]])# 列序优先迭代输出for i in np.nditer(a,order='F'): print (i,end=',')# 输出结果0,3,1,4,2,5,# 行序优先迭代输出for i in np.nditer(a,order='C'): print (i,end=',')# 输出结果0,1,2,3,4,5,迭代过程中修改数组值默认情况下，nditer 将视待迭代遍历的数组为只读对象（read-only），为了在遍历数组的同时，实现对数组元素值得修改，必须使用nditer 对象的可选参数 op_flags来指定 read-write 或者 write-only 的模式。1234567891011121314151617181920a array([[0, 1, 2], [3, 4, 5]])# 不设置op_flags进行直接修改# 会报错显示read-onlyfor i in np.nditer(a,order='C'): # 注意这里必须要使用i[...]进行赋值，不然不会起效 i[...] = 2 * ia ValueError: assignment destination is read-only# 设置op_flags为readwritefor i in np.nditer(a,op_flags=['readwrite']): if i == 2: i[...] = 2 * ia array([[0, 1, 4], [3, 4, 5]])两个数组广播迭代如果两个数组是可广播的，nditer 组合对象能够同时迭代它们。 假设数组 a 的维度为 3X4，数组 b 的维度为 1X4 ，则使用以下迭代器（数组 b 被广播到 a 的大小）。1234567891011121314import numpy as np a = np.arange(0,60,5) a = a.reshape(3,4) print ('第一个数组为：')print (a)print ('\n')print ('第二个数组为：')b = np.array([1, 2, 3, 4], dtype = int) print (b)print ('\n')print ('修改后的数组为：')for x,y in np.nditer([a,b]): print ("%d:%d" % (x,y), end=", " )输出：123456789101112第一个数组为：[[ 0 5 10 15] [20 25 30 35] [40 45 50 55]]第二个数组为：[1 2 3 4]修改后的数组为：0:1, 5:2, 10:3, 15:4, 20:1, 25:2, 30:3, 35:4, 40:1, 45:2, 50:3, 55:4,枚举迭代类似于list的enumerate函数，numpy也专门有一个可以用来枚举元素的函数，可以同时得到每个元素的索引和value：12345678910111213# 注意函数只能返回两个值# 一个是索引的元素，一个是value# 不能写成x,y,value这种for (x,y),value in np.ndenumerate(a): print (x,y,value)# 输出内容0 0 00 1 10 2 41 0 31 1 41 2 5迭代索引如果想单纯地迭代得到索引，可以使用np.ndindex函数，只用将array的shape传递给函数即可：123456789101112# 不会直接遍历得到元素值# 只会得到指定shape的索引for index in np.ndindex(a.shape): print (index)# 输出内容(0, 0)(0, 1)(0, 2)(1, 0)(1, 1)(1, 2)数组操作修改数组形状主要使用的函数如下：函数描述np.reshape(a, newshape, order='C')不改变数据的条件下修改形状np.resize(a, new_shape)修改数组形状np.ndarray.flat数组元素迭代器numpy.ndarray.flatten(order='C')返回一份数组拷贝，对拷贝所做的修改不会影响原始数组np.ravel(a, order='C')返回展开数组np.reshape函数形式：1234np.reshape(array, newshape, order='C')# array：需要转换形状的数组# newshape：元组或者整数# order：'C' -- 按行，'F' -- 按列，'A' -- 原顺序，'k' -- 元素在内存中的出现顺序使用实例：12345678# 创建一维数组a=np.arange(8) array([0, 1, 2, 3, 4, 5, 6, 7])# 修改数组的shapea.reshape(2,4) array([[0, 1, 2, 3], [4, 5, 6, 7]])np.resize函数形式：1np.resize(a, new_shape)使用实例：1234567891011121314151617181920212223242526272829303132a array([[0, 2, 2, 3], [4, 5, 6, 7]])# 原位修改# 没有返回值# 如果使用np.resize就不会原位修改a.resize((4,2))# 原始数组a已经发生改变a array([[0, 2], [2, 3], [4, 5], [6, 7]])# 如果使用reshape# 返回reshape之后的数组# 原始数组没有发生改变a.reshape((4,2)) array([[0, 2], [2, 3], [4, 5], [6, 7]])# 如果新的shape比原始的大，默认不会报错，而会复制# 这里只能使用np.resize，而不能使用a.resizenp.resize(a,(3,4)) # 返回的结果中原始数组第一行重复了一次 array([[0, 2, 2, 3], [4, 5, 6, 7], [0, 2, 2, 3]])# 使用np.reshape进行类似的操作就会报错np.reshape和np.resize的区别：np.resize没有order参数了，它只有跟reshape里面order=&#39;C&#39;的方式当使用a.resize时可以进行原位修改，直接修改原始数组，不会返回修改的数组(使用np.resize时就不会有这个效果)，而a.reshape不会假如要转换成的矩阵形状中的元素数量跟原矩阵不同，它会强制进行转换(重复)，而不报错(必须使用np.resize，不能使用a.resize)，reshape就会报错flat和flatten()1234567891011121314151617# 使用np.ndarray.flata.flat &lt;numpy.flatiter at 0x7faaf8ed9b60&gt;for i in a.flat: print (i,end=', ')# 输出0, 1, 2, 3, 4, 5, 6, 7, # 使用numpy.ndarray.flattena.flatten() array([0, 1, 2, 3, 4, 5, 6, 7])for i in a.flatten(): print (i,end=', ')# 输出0, 1, 2, 3, 4, 5, 6, 7,np.ravel-展开数组函数形式：123np.ravel(array, order='C')# array：需要转换形状的数组# order：'C' -- 按行，'F' -- 按列，'A' -- 原顺序，'k' -- 元素在内存中的出现顺序使用实例：123456a array([[0, 1, 2, 3], [4, 5, 6, 7]])# ravela.ravel() array([0, 1, 2, 3, 4, 5, 6, 7])注意np.ravel和numpy.ndarray.flatten的区别：numpy.ndarray.flatten返回的是数组的拷贝，而不是原始数组，对拷贝的修改不会影响原始数组np.ravel则是直接会操作原始数组12345678910111213# 修改flatten函数返回的数组的值a.flatten()[1] = 2a # 原始的数组a并没有发生改变 array([[0, 1, 2, 3], [4, 5, 6, 7]])# 修改ravel函数返回的数组的值a.ravel()[1]=2a # 原始的数组已经发生改变 array([[0, 2, 2, 3], [4, 5, 6, 7]])分割数组分割数组使用的函数如下：函数数组及操作np.split(ary, indices_or_sections, axis=0)将一个数组分割为多个子数组np.hsplit(ary, indices_or_sections)将一个数组水平分割为多个子数组（按列）np.vsplit(ary, indices_or_sections)将一个数组垂直分割为多个子数组（按行）split函数函数形式：1234np.split(array, indices_or_sections, axis=0)# indices_or_sections：索引列表或者sections数目# 返回数组的列表# axis：0表示对行进行划分(列不变，行划分)、1表示对列进行划分(行不变，列划分)使用实例：123456789101112131415161718192021222324252627282930313233# 创建一个一维的数组x = np.arange(9.0) array([0., 1., 2., 3., 4., 5., 6., 7., 8.])# 均分为3个np.split(x, 3) [array([0., 1., 2.]), array([3., 4., 5.]), array([6., 7., 8.])]# 按索引划分# 0-3、3-5、5-6、6-10np.split(x, [3, 5, 6, 10]) [array([0., 1., 2.]), array([3., 4.]), array([5.]), array([6., 7., 8.]), array([], dtype=float64)]# 二维数组a array([[0, 2, 2, 3], [4, 5, 6, 7]])# 均分为2个# 列不变，行划分np.split(a,2,0) [array([[0, 2, 2, 3]]), array([[4, 5, 6, 7]])]# 行不变，列划分np.split(a,2,1)[array([[0, 2], [4, 5]]), array([[2, 3], [6, 7]])]hsplit-分割列函数形式：1np.hsplit(ary, indices_or_sections)使用实例：1234567891011121314151617# 均分为2个# 相当于np.split(a,2,1)np.hsplit(a,2) [array([[0, 2], [4, 5]]), array([[2, 3], [6, 7]])]# 按索引划分# 0-1、1-3、3-np.hsplit(a,[1,3]) [array([[0], [4]]), array([[2, 2], [5, 6]]), array([[3], [7]])]vsplit-分割行函数形式：1np.vsplit(ary, indices_or_sections)使用实例：12345# 对行进行划分# 相当于np.split(a,2,0)np.vsplit(a,2) [array([[0, 2, 2, 3]]), array([[4, 5, 6, 7]])]数组元素的添加与删除使用函数汇总：函数元素及描述append将值添加到数组末尾insert沿指定轴将值插入到指定下标之前delete删掉某个轴的子数组，并返回删除后的新数组unique查找数组内的唯一元素numpy.append-追加元素到末尾numpy.append 函数在数组的末尾添加值，追加操作会分配整个数组，并把原来的数组复制到新数组中。此外，输入数组的维度必须匹配否则将生成ValueError。函数形式：1np.append(arr, values, axis=None)axis:None(默认)：是横向加成，返回总是为一维数组0：列不变，行加成1：行不变，列加成使用实例：123456789101112131415161718192021222324252627a = np.array([[1,2,3],[4,5,6]]) array([[1, 2, 3], [4, 5, 6]])# 不加axis# 默认的axis=None，这样直接会变成一维的数组np.append(a,[7,8,9]) array([1, 2, 3, 4, 5, 6, 7, 8, 9])# 注意不能想列表一样使用li.append()这种a.append([7,8,9]) AttributeError: 'numpy.ndarray' object has no attribute 'append'# axis=0，列不变，行增加np.append(a,[7,8,9],axis=0) ValueError: all the input arrays must have same number of dimensions# 上面报错是因为a为二维数组，而用于append的是一维，两者维度不同，合并出错# 使用下面的二维列表形式即可np.append(a,[[7,8,9]],axis=0) array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])# axis=1，行不变，列增加np.append(a,[[1],[2]],axis=1) array([[1, 2, 3, 1], [4, 5, 6, 2]])使用注意事项：不能直接使用array.append()这种，必须使用np.append()，不像列表一样axis=0|1需要注意append的维度要和原始数组的维度对应，不然会出错numpy.insert-插入到指定位置上面的append是将元素追加到数组的末尾，而如果想要把元素插入到数组的某个位置，可以使用np.insert()函数，该函数可以在给定索引之前，沿给定轴在输入数组中插入值，需要注意的是和append一样如果未提供轴，则输入数组会被展开。函数形式：12345np.insert(arr, obj, values, axis=None)# arr:待插入的数组# obj：插入的索引，可以是数字、列表、slice、元组等# value：插入的值# axis和append的规则相同使用实例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546a = np.array([[1, 1], [2, 2], [3, 3]]) array([[1, 1], [2, 2], [3, 3]])# 在索引1之前插入数字5# 没有指定axis，直接会展开np.insert(a,1,5) array([1, 5, 1, 2, 2, 3, 3])# 指定axis=1，列会拓展，行不变# 这个会产生类似广播的机制# 和append不同，不用插入相同维度的信息np.insert(a,1,5,axis=1) array([[1, 5, 1], [2, 5, 2], [3, 5, 3]])# 指定axis=0，行会拓展，列不变# 这个会产生类似广播的机制# 和append不同，不用插入相同维度的信息np.insert(a,1,5,axis=0) array([[1, 1], [5, 5], [2, 2], [3, 3]])# 如果不想在一列或者一行插入相同的值，可以使用列表# 在第二列之前插入一列，数值为1,2,3np.insert(a, 1, [1,2,3], axis=1) array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])# 使用内置的切片函数slice# 在索引2和3之前分别插入5、6# 这里的索引2、3是原始数组的索引，不是插入一个之后更新一遍np.insert(a, slice(2, 4), [5, 6]) array([1, 1, 5, 2, 6, 2, 3, 3])# 不同的数据类型会进行强制统一np.insert(a, [2, 2], [7.13, False]) # 在相同位置插入两个 array([1, 1, 7, 0, 2, 2, 3, 3])使用注意事项：不需要像append一样，插入的维度要和原始数组维度相同，直接插入数字(数字会重复)或列表(每行或者每列插入内容不同)插入的index可以使用数字、列表、slice以及元组等axis的规则和append相同numpy.delete-删除元素前面的append和insert都是在数组中增加元素，如果想要删除元素，可以使用numpy.delete函数，与前面的两个函数相同，如果不指定axis，则会将输入数组展开。函数形式：1234np.delete(arr, obj, axis=None)# arr：数组# obj：索引位置，和insert的想听# axis：和insert的相同使用实例：1234567891011121314151617181920# 二维数组arr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]]) array([[ 1, 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12]])# 没有指定axis，数组先展开，然后删除指定索引np.delete(arr, [1,3,5], None) array([ 1, 3, 5, 7, 8, 9, 10, 11, 12])# axis=0，删除行，1：索引为1的行np.delete(arr, 1, 0) array([[ 1, 2, 3, 4], [ 9, 10, 11, 12]])# 删除第二列和第四列np.delete(arr, [1,3], 1) array([[ 1, 3], [ 5, 7], [ 9, 11]])numpy.unique-去重numpy.unique 函数用于去除数组中的重复元素。函数形式：1np.unique(ar, return_index=False, return_inverse=False, return_counts=False, axis=None)arr：输入数组return_index：如果为true，返回去重后列表元素在原始列表中的首次出现索引(也就是返回的长度和去重后数组相同)以及去重后的数组return_inverse：如果为true，返回原始列表元素在去重后列表中的索引(也就是返回的长度和原始数组相同)以及去重后的数组return_counts：如果为true，返回去重数组中的元素在原数组中的出现次数axis:默认(None)：输入数组会被展开0：去除列上的重复1：去除行上的重复使用实例：1234567891011121314151617181920212223242526272829303132333435# 可以直接对列表去重# 返回去重之后的数组np.unique([1, 1, 2, 2, 3, 3]) array([1, 2, 3]) # 二维数组去重a = np.array([[1, 1], [2, 3]]) array([[1, 1], [2, 3]])# 没有指定axis，数组会被展开，和前面的列表相同np.unique(a) array([1, 2, 3])# 对列去重a = np.array([[1, 0, 0], [1, 0, 0], [2, 3, 4]])# axis为0，表示列去重np.unique(a, axis=0) array([[1, 0, 0], [2, 3, 4]])# 返回去重后数组元素在原始数组中首次出现的索引a = np.array(['a', 'b', 'b', 'c', 'a'])u, indices = np.unique(a, return_index=True)u array(['a', 'b', 'c'], dtype='&lt;U1')indices array([0, 1, 3])# 返回原始列表元素在去重后列表中的索引a = np.array([1, 2, 6, 4, 2, 3, 2])u, indices = np.unique(a, return_inverse=True)u array([1, 2, 3, 4, 6])indices array([0, 1, 4, 3, 1, 2, 1])参考链接Numpy广播机制小结Broadcasting官方Numpy 数组操作NumPy 迭代数组]]></content>
      <categories>
        <category>Python</category>
        <category>常用模块</category>
      </categories>
      <tags>
        <tag>常用模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之numpy-数组与矩阵运算(二)：切片、截取和堆叠]]></title>
    <url>%2Fposts%2F35386.html</url>
    <content type="text"><![CDATA[这篇文章主要学习了numpy中的切片、截取和堆叠等内容；在切片中主要学习了常规切片、整数索引切片、布尔索引以及花式索引；在截取操作中学习了截取对角线以及截取上下三角阵；在数组堆叠中主要学习了纵向、横向堆叠的各种不同的命令；最后学习了关于np.r_和np.c_的内容。切片操作常规切片一维数组连续切片：12345678# 创建一个等差数列，从0-9，步长为1x=np.arange(0,10,1) array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])# 使用冒号的切片操作，连续的切片# 返回一个数组x[2:4] array([2, 3])如果想要实现非连续切片，直接输入非连续切片组成的列表即可:1234567891011121314# 直接使用非连续的索引进行切片操作，这个列表的很不同# 但是在pandas的dataframe中可以进行这种类似的操作x[[2,5,4]] array([2, 5, 4])# 在列表中就不能使用这种方法来得到非连续的索引a=[1,2,3,4,5]a[[2,3]]# 会直接报错： TypeError: list indices must be integers or slices, not list# 解决列表中不能得到非连续索引的问题from operator import itemgetteritemgetter(2,3)(a)多维数组123456# 创建一个三行三列的二维数组a = np.array([[1,2,3],[3,4,5],[4,5,6]]) a array([[1, 2, 3], [3, 4, 5], [4, 5, 6]])连续切片：123456789101112131415161718# 获取第二行到最后一行、所有列的内容a[1:,] array([[3, 4, 5], [4, 5, 6]]) # 获取第二行、所有列的信息a[1] array([3, 4, 5])# 获取某一行的另一种方法# 倒数第几行，这里-1是最后一行a[-1,:] array([4, 5, 6])# 获取第二行到最后一行，第三到最后一列a[1:,2:] array([[5], [6]])非连续切片：123456789101112131415# 获取第1行和第三行、所有列的信息a[[0,2]] array([[1, 2, 3], [4, 5, 6]])# 注意这里不能在加上非连续的列索引，不然会进行后面整数索引提到的内容a[[0,2],[0,2]] # 得到的就不是第1行和第三行、第1列和第三列的内容 # 而是0,0、2,2的内容 array([1, 6])# 而列使用连续的则可以和非连续的行组合a[[0,2],0:2] array([[1, 2], [4, 5]])多维数组的非连续索引只能允许某一维是非连续的，如果两维都是非连续的则会进行整数索引切片内容，得不到想要的结果。整数索引切片整数索引切片其实就是非连续索引进行切片。123456# 创建一个3行2列的数组x = np.array([[1, 2], [3, 4], [5, 6]]) x array([[1, 2], [3, 4], [5, 6]])通过各个维度离散索引的一一对应进行数组元素的筛选筛选，各个维度离散索引之间不会进行组合：12345678910111213141516171819202122# 两个维度分别指定了列表，以此来进行一一对应获取# 这里得到的就是0,0、1,1、2,0的内容x[[0,1,2], [0,1,0]] array([1, 4, 5])# 利用数组来进行离散索引的一一对应# 得到3x3数组四个角落的元素x = np.array([[ 0, 1, 2],[ 3, 4, 5],[ 6, 7, 8],[ 9, 10, 11]]) x array([[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8], [ 9, 10, 11]])# 行 rows=np.array([[0,0],[3,3]]) # 列cols=np.array([[0,2],[0,2]]) # 通过数组进行一一对应的slice# 获取四个角落的元素x[rows,cols] array([[ 0, 2], [ 9, 11]])布尔索引布尔索引会将一个多维数组转化为一个一维数组123456789101112x array([[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8], [ 9, 10, 11]])# 通过布尔之后相当于直接展开了# 将一个多维数组转化为了一维数组x[x &gt; 5] array([ 6, 7, 8, 9, 10, 11])x[x != 10] array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11])~表示取补操作：1234567891011121314151617a = np.array([np.nan, 1,2,np.nan,3,4,5]) a array([nan, 1., 2., nan, 3., 4., 5.])# ~表示的是取补# 去掉数组中是nan的元素a[~np.isnan(a)] array([1., 2., 3., 4., 5.])~np.isnan(a) array([False, True, True, False, True, True, True])# 另外~还有和-类似的结果，可以表示倒数第几行的元素x[~1] array([6, 7, 8])x[-1] array([ 9, 10, 11])花式索引花式索引其实感觉和整数索引相差不多：123456789101112131415161718192021222324252627# 创建一个8行4列的数组x=np.arange(32).reshape((8,4))x array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]])# 只提供一维信息的话就是另一维的信息全部保留# 可以调整行的顺序x[[4,2,1,7]] array([[16, 17, 18, 19], [ 8, 9, 10, 11], [ 4, 5, 6, 7], [28, 29, 30, 31]])# 也可以从后面开始提取# 提供负数就是从最后一行开始选取，最后一行表示-1，从上依次递推x[[-4,-2,-1,-7]] array([[ 4, 7, 5, 6], [20, 23, 21, 22], [28, 31, 29, 30], [ 8, 11, 9, 10]])前面提到如果二维数组中使用两个离散索引会进行一一对应地选取元素，不会进行组合，如果想要进行组合可以使用如下命令：12345678910# 使用np.ix_之后相当于是组合，两个维度之间进行组合x[np.ix_([1,5,7,2],[0,3,1,2])] array([[ 4, 7, 5, 6], [20, 23, 21, 22], [28, 31, 29, 30], [ 8, 11, 9, 10]])# 作为对比，下面的这个就只是一一对应的，不是上面的组合x[[1,5,7,2],[0,3,1,2]] array([ 4, 23, 29, 10])截取操作截取对角线元素截取对角线元素其实就是前面创建对角矩阵的反向操作：函数形式：123np.diag(v, k=0)# k：表示对角线的位置，默认为0，表示主对角线# k可以指定对角线索引偏移使用实例：12345678910111213141516171819202122232425262728293031# 创建一个4x4的矩阵x=np.arange(1,17,1).reshape((4,4))x array([[ 1, 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12], [13, 14, 15, 16]])# 获取主对角线元素np.diag(x) array([ 1, 6, 11, 16])# 对角线向上偏移1np.diag(x,k=1) array([ 2, 7, 12])# diagflat是创建对角矩阵，指定的是对角线的元素np.diagflat([1,2,3],k=0) array([[1, 0, 0], [0, 2, 0], [0, 0, 3]])# 如果数组不是标准的正方数组x=np.arange(12).reshape((3,4))x array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]])# 获取主对角线元素np.diag(x) array([ 0, 5, 10])截取上下三角阵1234567# 创建下三角矩阵，下三角内容的填充由array_like内容中选取# 相当于先使用array_like创建矩阵，然后将上三角的内容设置为0np.tril(array_like, k=0)# 创建上三角矩阵，上三角内容的填充由array_like内容中选取# 相当于先使用array_like创建矩阵，然后将下三角的内容设置为0np.triu(array_like, k=0)使用实例：123456789101112131415# 创建上三角矩阵，内容从指定的array_like中选取# 相当于先使用array_like创建矩阵，然后将下三角的内容设置为0np.triu([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], 0) array([[1, 2, 3], [0, 5, 6], [0, 0, 9], [0, 0, 0]])# 创建下三角矩阵，内容从指定的array_like中选取# 相当于先使用array_like创建矩阵，然后将上三角的内容设置为0np.triu([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], 0) array([[ 1, 0, 0], [ 4, 5, 0], [ 7, 8, 9], [10, 11, 12]])数组堆叠123456789a=np.arange(1,7,1).reshape((2,3))a array([[1, 2, 3], [4, 5, 6]])b=np.arange(7,13,1).reshape((2,3))b array([[ 7, 8, 9], [10, 11, 12]])纵向堆叠函数形式：123456# 传入元组# 纵向堆叠多个数组np.vstack(tup)# 纵向堆叠多个数组np.row_stack(tup)使用实例：1234567891011np.vstack((a,b)) array([[ 1, 2, 3], [ 4, 5, 6], [ 7, 8, 9], [10, 11, 12]])np.row_stack((a,b)) array([[ 1, 2, 3], [ 4, 5, 6], [ 7, 8, 9], [10, 11, 12]])横向拓展函数形式：123456# 传入元组# 横向拓展np.hstack(tup)# 横向拓展多个数组np.column_stack(tup)使用实例：1234567np.hstack((a,b)) array([[ 1, 2, 3, 7, 8, 9], [ 4, 5, 6, 10, 11, 12]])np.column_stack((a,b)) array([[ 1, 2, 3, 7, 8, 9], [ 4, 5, 6, 10, 11, 12]])使用统一的函数函数形式：123# 横向或者纵向堆叠数组# 传入的也是元组np.concatenate((a1, a2, ...), axis=0, out=None)使用实例：12345678910111213# 沿列方向进行concat，就是列不变，行增加# 和pandas的concat相同np.concatenate((a,b),axis=0) array([[ 1, 2, 3], [ 4, 5, 6], [ 7, 8, 9], [10, 11, 12]])# 沿行方向进行concat，就是行不变，列增加# 和pandas的concat相同np.concatenate((a,b),axis=1) array([[ 1, 2, 3, 7, 8, 9], [ 4, 5, 6, 10, 11, 12]])关于np.r_和np.c_np.r_和np.c_可以将一系列的序列合并到一个数组中，调用是要用中括号[],而不是()：1234567891011121314151617181920212223242526# 传递两个列表，会对其进行拓展np.r_[[1,2,3], [4,5,6]] array([1, 2, 3, 4, 5, 6])# 传递两个列表，先变为列，然后进行列的拓展np.c_[[1,2,3], [4,5,6]] array([[1, 4], [2, 5], [3, 6]])# 可以指定合并后的维度以及维度提升的轴np.r_['0,2,0', [1,2,3]] array([[1], [2], [3]])np.r_['0,2,1', [1,2,3]] array([[1, 2, 3]])# 上面代码片段的第一个控制参数0表示将在第一个维度对后面的序列进行合并# 第二个控制参数2表示：合并后的结果最少要2维，所以在合并前对维度较少的序列进行维度提升# 提升的方式则是有第3个参数决定的，提升的具体方法是在原始序列的维度中添加1# 关于这个1添加的位置，默认情况下，是放在维度元组的前面，np.array([1,2,3])的维度为(3,)，1放在前面就是(1,3)# 如果指定了第三个参数为0，则会将1放在维度元组的后面，即(3,1)# In other words the third integer allows you to specify # where the 1's should be placed in the shape of the arrays that have their shapes upgraded# By default, they are placed in the front of the shape tuple.# a third argument of '0' would place the 1's at the end of the array shape.参考链接NumPy 切片和索引NumPy 高级索引Python科学计算：numpy]]></content>
      <categories>
        <category>Python</category>
        <category>常用模块</category>
      </categories>
      <tags>
        <tag>常用模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jupyter NoteBook 的快捷键使用指南(转载)]]></title>
    <url>%2Fposts%2F36813.html</url>
    <content type="text"><![CDATA[这是一篇转载的文章，主要介绍了jupyter中常用的快捷键。jupyter中的快捷键主要包括两种：命令模式的快捷键和编辑模式的快捷键，两张模式之间的切换：从命令模式进入编辑模式需按 Enter 键，从编辑模式切换到命令模式需按 Esc 键。简介Jupyter Notebook 有两种键盘输入模式：命令模式和编辑模式，这与 Vim 有些类似。在编辑模式下，可以往单元中键入代码或文本，此时单元格被绿色的框线包围，且命令模式下的快捷键不生效在命令模式下，可以用快捷键命令运行单元格，移动单元格，切换单元格编辑状态等等，此时的单元格被蓝色的框线包围，且编辑模式下的快捷键不生效。从命令模式进入编辑模式需按 Enter 键，从编辑模式切换到命令模式需按 Esc 键。以下两表分别是对命令和编辑两种模式下快捷键的简单说明.命令模式快捷键（按 Esc 键开启）注意要使用这里面的快捷键需要先使用ESC键开启命令模式快捷键：快捷键作用说明Enter转入编辑模式Shift-Enter运行本单元，选中下个单元新单元默认为命令模式Ctrl-Enter运行本单元Alt-Enter运行本单元，在其下插入新单元新单元默认为编辑模式Y单元转入代码状态M单元转入 markdown 状态R单元转入 raw 状态ALT + UP单元格上移ALT + DOWN单元格下移1设定 1 级标题仅在 markdown 状态下时建议使用标题相关快捷键，如果单元处于其他状态，则会强制切换到 markdown 状态2设定 2 级标题3设定 3 级标题4设定 4 级标题5设定 5 级标题6设定 6 级标题Up选中上方单元K选中上方单元Down选中下方单元J选中下方单元Shift-K连续选择上方单元Shift-J连续选择下方单元A在上方插入新单元B在下方插入新单元X剪切选中的单元C复制选中的单元Shift-V粘贴到上方单元V粘贴到下方单元Z恢复删除的最后一个单元D,D删除选中的单元连续按两个 D 键Shift-M合并选中的单元Ctrl-S保存当前 NoteBookS保存当前 NoteBookL开关行号编辑框的行号是可以开启和关闭的O转换输出Shift-O转换输出滚动Esc关闭页面Q关闭页面H显示快捷键帮助I,I中断 NoteBook 内核0,0重启 NoteBook 内核Shift忽略Shift-Space向上滚动Space向下滚动编辑模式快捷键（ 按 Enter 键启动）注意要使用这里面的快捷键需要先使用Enter键开启编辑模式快捷键：快捷键作用说明Tab代码补全或缩进Shift-Tab提示输出帮助信息，部分函数、类、方法等会显示其定义原型，如果在其后加 ? 再运行会显示更加详细的帮助Ctrl-]缩进向右缩进Ctrl-[解除缩进向左缩进Ctrl-A全选Ctrl-Z撤销Ctrl-Shift-Z重做Ctrl-Y重做Ctrl-Home跳到单元开头Ctrl-Up跳到单元开头Ctrl-End跳到单元末尾Ctrl-Down跳到单元末尾Ctrl-Left跳到左边一个字首Ctrl-Right跳到右边一个字首Ctrl-Backspace删除前面一个字Ctrl-Delete删除后面一个字Esc切换到命令模式Ctrl-M切换到命令模式Shift-Enter运行本单元，选中下一单元新单元默认为命令模式Ctrl-Enter运行本单元Alt-Enter运行本单元，在下面插入一单元新单元默认为编辑模式Ctrl-Shift--分割单元按光标所在行进行分割Ctrl-Shift-Subtract分割单元Ctrl-S保存当前 NoteBookShift忽略Up光标上移或转入上一单元Down光标下移或转入下一单元Ctrl-/注释整行/撤销注释仅代码状态有效参考链接Jupyter NoteBook 的快捷键使用指南]]></content>
      <categories>
        <category>Python</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之numpy-数组与矩阵运算(一)：数组创建]]></title>
    <url>%2Fposts%2F24507.html</url>
    <content type="text"><![CDATA[这篇文章主要学习了使用numpy创建数组的一些方法，包括 从列表或元组创建、创建特殊的数组(预分配数组、全0、全1、填充数组、单位矩阵、对角矩阵、上下三角矩阵)，期间也对numpy 数组的属性以及 支持的数据类型进行了学习；还学习了 创建数列的方法，包括 指定步长的数列、指定数列长度的数列(等差、等比数列)；也学习了创建内容随机并且符合某种分布的numpy.random中的一些常见方法。numpy简介NumPy 代表 “Numeric Python”，是一个由多维数组对象和用于处理数组的例程集合组成的库。NumPy提供了大量的库函数和操作，可以帮助程序员轻松地进行数值计算，这类数值计算广泛用于以下任务：机器学习模型：在编写机器学习算法时，需要对矩阵进行各种数值计算。例如矩阵乘法、换位、加法等。NumPy提供了一个非常好的库，用于简单(在编写代码方面)和快速(在速度方面)计算。NumPy数组用于存储训练数据和机器学习模型的参数。图像处理和计算机图形学：计算机中的图像表示为多维数字数组。NumPy成为同样情况下最自然的选择。实际上，NumPy提供了一些优秀的库函数来快速处理图像。例如，镜像图像、按特定角度旋转图像等。数学任务：NumPy对于执行各种数学任务非常有用，如数值积分、微分、内插、外推等。因此，当涉及到数学任务时，它形成了一种基于Python的MATLAB的快速替代。由列表或者元组创建数组使用的方法为np.array(list or tuple)或者np.asarray(list or tuple)，数据类型将由原序列中的元素类型推导而来。函数形式：1234numpy.array(object, dtype = None, copy = True, order = 'K', subok = False, ndmin = 0)# Convert the input to an array.numpy.asarray(a, dtype = None, order = None)函数参数说明：名称描述object数组或嵌套的数列dtype数组元素的数据类型，可选copy对象是否需要复制，可选order创建数组的样式(数据在内存中存储的方向)，C为行方向，F为列方向subok默认返回一个与基类类型一致的数组ndmin指定生成数组的最小维度使用实例：123456789101112131415161718192021222324252627282930313233import numpy as np# 由一维列表创建一维数组dt1 = [1, 2, 3, 4, 5, 6]arr1 = np.array(dt1)arr1 # 一行六列的数组 array([1, 2, 3, 4, 5, 6])# 二维列表创建二维数组dt2=[[1,2],[3,4]]arr2=np.array(dt2)arr2 array([[1, 2], [3, 4]])# 设置最小维度为2# dt1是一维的列表，设置最小维度为2# 使得创建的数组是2维数组，和由二维列表创建的dt2维度相同dt1 = [1, 2, 3, 4, 5, 6]arr1 = np.array(dt1,ndmin=2)arr1 array([[1, 2, 3, 4, 5, 6]])# 由一维元组创建dt3 = np.array((1,2,3))dt3 array([1, 2, 3])# 由二维元组创建dt4 = np.array(((1,2,3),(4,5,6)))dt4 array([[1, 2, 3], [4, 5, 6]])注意：如果序列中的元素类型不统一，会将所有的转化为同一种类型：123456# 列表中的元素类型不统一，包括字符串和数字dt1 = [1, 2, 3, 4, 5, '6']arr1 = np.array(dt1)arr1 # 返回的结果是'&lt;U21'，数字和字符串的mix array(['1', '2', '3', '4', '5', '6'], dtype='&lt;U21')如果不想让数组自动推断序列的元素数据类型(防止出现上面那种不想看到的结果)，可以在数组创建时，直接指定数据类型：1234dt1 = [1, 2, 3, 4, 5, '6']arr1 = np.array(dt1,dtype='int16')arr1 array([1, 2, 3, 4, 5, 6], dtype=int16)关于可以指定的数据类型，可以参考下面的numpy支持的数据类型如果创建的时候没有指定数据类型，在也可以在后续通过np.astype来转换数据类型：1234567891011121314151617181920212223dt1 = [1, 2, 3, 4, 5, '6']arr1 = np.array(dt1)arr1 array(['1', '2', '3', '4', '5', '6'], dtype='&lt;U21')# 后续数据类型的转换# 这种转换方式是错的arr1.dtype='int16'arr1 # 输出结果和真是的结果相差较大 # 实际上就是将上面的unicode转化为了int16，不会得到1,2,3,4,5,6这种结果 array([49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ............. 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int16)# 如果使用np.astype进行后续的转换，就可以得到正确的结果arr1=arr1.astype(np.int)arr1 array([1, 2, 3, 4, 5, 6])# 查看数据类型arr1.dtype dtype('int64')可以由其他的序列直接创建numpy数组，原始的序列是几维的，创建得到的数组就是几维的如果序列中存在多种数据类型(尤其是数组中存在数字和字符这种mix)，最好的解决方法就是在创建数组的同时指定数据类型(默认创建时numpy会进行统一数据类型处理)，以免得到自己不想要的结果，影响后续的计算上述两个函数将列表或元组转换为数组其实并没有什么差别，numpy.asarray是将输入转化为数组，而np.array是创建数组，还可以从可迭代对象中建立数组等，更多的方法请查看这个链接.numpy中的数据类型numpy 支持的数据类型比 Python 内置的类型要多很多，基本上可以和 C 语言的数据类型对应上，其中部分类型对应为 Python 内置的类型。下表列举了常用 NumPy 基本类型:名称描述bool_布尔型数据类型（True 或者 False）int_默认的整数类型（类似于 C 语言中的 long，int32 或 int64）intc与 C 的 int 类型一样，一般是 int32 或 int 64intp用于索引的整数类型（类似于 C 的 ssize_t，一般情况下仍然是 int32 或 int64）int8字节（-128 to 127）int16整数（-32768 to 32767）int32整数（-2147483648 to 2147483647）int64整数（-9223372036854775808 to 9223372036854775807）uint8无符号整数（0 to 255）uint16无符号整数（0 to 65535）uint32无符号整数（0 to 4294967295）uint64无符号整数（0 to 18446744073709551615）float_float64 类型的简写float16半精度浮点数，包括：1 个符号位，5 个指数位，10 个尾数位float32单精度浮点数，包括：1 个符号位，8 个指数位，23 个尾数位float64双精度浮点数，包括：1 个符号位，11 个指数位，52 个尾数位complex_complex128 类型的简写，即 128 位复数complex64复数，表示双 32 位浮点数（实数部分和虚数部分）complex128复数，表示双 64 位浮点数（实数部分和虚数部分）有时候我们会看到一些特殊的情况，比如前面的dtype=&#39;&lt;U21&#39;，这个是什么含义呢？U其实代表的是Unicode类型，具体的每个内建类型都有一个唯一定义它的字符代码，如下：字符对应类型b布尔型i(有符号) 整型u无符号整型 integerf浮点型c复数浮点型mtimedelta（时间间隔）Mdatetime（日期时间）O(Python) 对象S, a(byte-)字符串UUnicodeV原始数据 (void)数组属性在NumPy中维度(dimensions)叫做轴(axis)，轴的个数叫做秩(rank)。上面由一维列表或者元组创建的数组都是一个秩为1的数组，因为它们只有一个轴，如array([1, 2, 3, 4, 5, 6])，且这个轴的长度为6；而由二维列表或者元组创建的数组都是秩为2的数组。在使用中的很多时候需要声明 axis：axis=0，表示沿着第 0 轴进行操作，即对每一列进行操作axis=1，表示沿着第1轴进行操作，即对每一行进行操作NumPy的数组类被称作ndarray，通常被称作数组，相比于标准Python库类array.array，ndarray提供了更多的对象属性：属性说明ndarray.ndim秩，即轴的数量或维度的数量，如二维数组的秩就是2ndarray.shape数组的维度，返回一个元组。一个n排m列的矩阵，它的shape属性将是(n,m)，这个元组的长度显然是秩，即ndim属性ndarray.size数组元素的总个数，相当于 .shape 中 n*m 的值ndarray.dtypendarray 对象的元素类型ndarray.itemsizendarray 对象中每个元素的大小，以字节为单位ndarray.flagsndarray 对象的内存信息ndarray.realndarray元素的实部ndarray.imagndarray 元素的虚部ndarray.data包含实际数组元素的缓冲区，由于一般通过数组的索引获取元素，所以通常不需要使用这个属性。使用实例：12345678910111213141516171819202122dt4 array([[1, 2, 3], [4, 5, 6]])# 查看数组的秩，即维度数目dt4.ndim # 返回2表示为2维数组 2# 查看数组维度dt4.shape# 返回的元组表示数组为二维数组，且每一维的长度分别为2和3 (2, 3)# 查看数组大小dt4.size # 返回为6，上面的每一位长度的乘积 6# 查看数组的数据类型dt4.dtype dtype('int64')创建特殊数组通常，数组的元素开始都是未知的，但是它的大小已知。因此，NumPy提供了一些使用占位符创建数组的函数。创建预分配数组-np.empty()|empty_like()预分配数组只是初始化了数组尺寸，但是不保证元素值为0或者1，其内容是随机并且依赖与内存状态的，默认创建得到的数据类型都为float。函数形式：1234567numpy.empty(shape, dtype = float, order = 'C')# shape为数组的维度，可以使用元组或者列表，为了和np.shape的返回值保持一致，使用元组最好# order有"C"和"F"两个选项,分别代表，行优先和列优先，在计算机内存中的存储元素的顺序# order一般用不上# 以a为模板，创建相同维度的预分配数组numpy.empty_like(a, dtype=None, order='K', subok=True)使用实例：123456789101112np.empty((2,3)) # 返回一个内容随机的数组 array([[1., 2., 3.], [4., 5., 6.]])# 依据模板创建dt3.shape # dt3是一个一维的数组 (3,)# 创建一个和dt3同shape的数组np.empty_like(dt4) array([1, 2, 3])创建全0|全1数组-np.zeros()|ones()和前面的empty函数不同的是，这里创建的数组的内容都为0(np.zeros)或1(np.ones)，而非随机，默认创建得到的数据类型都为float。函数形式：123456numpy.zeros(shape, dtype = float, order = 'C')numpy.ones(shape, dtype = None, order = 'C')# 以a为模板，创建相同维度的全1或0数组np.ones_like(a, dtype=None, order='K', subok=True)np.zeros_like(a, dtype=None, order='K', subok=True)使用实例：123456789101112131415161718# 创建全1数组np.ones((2,3)) # 数组的内容全为1 array([[1., 1., 1.], [1., 1., 1.]])# 创建全0数组np.zeros((2,3)) # 数组的内容全为0 array([[0., 0., 0.], [0., 0., 0.]])# 以dt3为模板创建相同维度的全1数组np.ones_like(dt3) array([1, 1, 1])# 以dt3为模板创建相同维度的全0数组np.zeros_like(dt3) array([0, 0, 0])创建填充数组前面的几个创建数组的方式，要么内容是全随机的，要么是全为0或1的数组，如果希望使用指定的值来填充数组，得到全为指定值的数据可以使用np.full函数。函数形式：123np.full(shape, fill_value, dtype=None, order='C')np.full_like(a, fill_value, dtype=None, order='K', subok=True)使用实例：12345# 创建一个2行3列，内容全为0.2的数组np.full((2,3),0.2) # 输出2行3列，内容全为0.2的数组 array([[0.2, 0.2, 0.2], [0.2, 0.2, 0.2]])创建单位矩阵-np.identity()|eye()单位矩阵是指对角线上元素全为1并且除此以外元素全都为0的矩阵，严格的单位阵使用 np.identity() 命令创建，非严格的单位矩阵可以使用np.eye()创建。函数形式：123456np.identity(n, dtype=None)np.eye(N, M=None, k=0, dtype=&lt;class 'float'&gt;, order='C')# N：行数# M：列数# k：对角线的索引，默认是主对角线，大于0表示偏上的对角线，小于0表示偏下的对角线使用实例：123456789101112131415161718192021# 创建3行3列的单位矩阵np.identity(3) array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])# 创建2行3列的单位矩阵# 默认的对角线索引为0np.eye(2,3) array([[1., 0., 0.], [0., 1., 0.]])# 创建2行3列的单位矩阵，对角线索引为1，向上平移np.eye(2,3,k=1) array([[0., 1., 0.], [0., 0., 1.]])# 创建2行3列的单位矩阵，对角线索引为-1，向下平移np.eye(2,3,k=-1) array([[0., 0., 0.], [1., 0., 0.]])np.identity()创建的是严格的单位矩阵，首先，矩阵是正方矩阵(行数和列数相同)，其次，只有主对角线的元素为1np.eye()创建的是非严格的单位矩阵，对应地，矩阵不一定是正方矩阵，并且元素为1的对角线位置可以调整创建对角矩阵-np.diagflat()对角矩阵是一个主对角线之外的元素皆为0的矩阵，对角线上的元素可以为0或其他值，单位矩阵就是对角矩阵的一种，其对角线上的元素为1。对角矩阵的创建使用np.diagflat()。函数形式：1234np.diagflat(array_like, k=0)# array_like：类似数组的序列，可以是列表、数组、元组，序列的元素数目表示了矩阵的行数(在未指定k的前提下)# 序列的每个元素依次填充在对角矩阵的每一行对应的位置# k：对角线的索引位置使用实例：12345678910111213141516171819202122# 创建对角线元素为1,2,3,4的对角矩阵# 列表元素数目为2，所以对角矩阵为4行4列np.diagflat([1,2,3,4]) array([[1, 0, 0, 0], [0, 2, 0, 0], [0, 0, 3, 0], [0, 0, 0, 4]])# 也可以使用二维的列表创建np.diagflat([[1,2],[3,4]]) array([[1, 0, 0, 0], [0, 2, 0, 0], [0, 0, 3, 0], [0, 0, 0, 4]])# 对角矩阵对角线填充位置开始于1# 此时的元素数目为4，但是因为设置了k=1，所以行数和列数都变为了5np.diagflat([1,2,3,4],k=1) array([[0, 1, 0, 0, 0], [0, 0, 2, 0, 0], [0, 0, 0, 3, 0], [0, 0, 0, 0, 4], [0, 0, 0, 0, 0]])创建上下三角矩阵下三角矩阵是指对角线上方的元素全部为0的矩阵，同样的，上三角矩阵是指对角线下方的元素全部为0的矩阵。创建这种矩阵，numpy提供了几种函数：12345678910111213# 创建下三角矩阵，且下三角中的元素全为1np.tri(N, M=None, k=0, dtype=&lt;class 'float'&gt;)# N：行数# M：列数# k：对角线的索引# 创建下三角矩阵，下三角内容的填充由array_like内容中选取# 相当于先使用array_like创建矩阵，然后将上三角的内容设置为0np.tril(array_like, k=0)# 创建上三角矩阵，上三角内容的填充由array_like内容中选取# 相当于先使用array_like创建矩阵，然后将下三角的内容设置为0np.triu(array_like, k=0)使用实例：123456789101112131415161718192021222324252627# 创建不严格的下三角矩阵，2行3列# 且下三角矩阵的元素为1np.tri(2,3) array([[1., 0., 0.], [1., 1., 0.]])# 创建严格的下三角矩阵，3行3列np.tri(3,3) array([[1., 0., 0.], [1., 1., 0.], [1., 1., 1.]])# 创建上三角矩阵，内容从指定的array_like中选取# 相当于先使用array_like创建矩阵，然后将下三角的内容设置为0np.triu([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], 0) array([[1, 2, 3], [0, 5, 6], [0, 0, 9], [0, 0, 0]])# 创建下三角矩阵，内容从指定的array_like中选取# 相当于先使用array_like创建矩阵，然后将上三角的内容设置为0np.triu([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], 0) array([[ 1, 0, 0], [ 4, 5, 0], [ 7, 8, 9], [10, 11, 12]])创建数列创建非等差或等比数列如果想要创建的数列不是等步长或者等比这种规律性比较明显的数列，可以使用如下方法创建：123456789101112# 内容完全是没有规律的# 直接通过np.array对象创建np.array([1,3,7,9]) array([1, 3, 7, 9])# 一部分存在规律# 比如得到1,2,3,7,9np.r_[1:4,7,9] array([1, 2, 3, 7, 9])# 拼接两个列表得到数组np.r_[[1,2,3], [4,5,6]] array([1, 2, 3, 4, 5, 6])创建指定步长的数列函数形式：1numpy.arange([start,] stop[, step,], dtype=None)参数说明：参数描述start起始值，默认为0stop终止值（不包含）step步长，默认为1dtype返回ndarray的数据类型，如果没有提供，则会使用输入数据的类型。使用实例：123# 创建从1开始，到5结束(不包括5)，步长为1的数列np.arange(1,5,1) array([1, 2, 3, 4])创建指定长度的数组等差数组函数形式：1np.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0)参数说明：参数描述start序列的起始值stop序列的终止值，如果endpoint为true，该值包含于数列中num要生成的等步长的样本数量，默认为50endpoint该值为 ture 时，数列中中包含stop值，反之不包含，默认是True。retstep如果为 True 时，生成的数组中会显示间距，反之不显示。dtypendarray 的数据类型使用实例：12345678910111213141516# 创建从1到9，长度为10的等差数列# 默认是包括9的np.linspace(1,9,10) array([1. , 1.88888889, 2.77777778, 3.66666667, 4.55555556, 5.44444444, 6.33333333, 7.22222222, 8.11111111, 9. ])# 如果设置不包括9 np.linspace(1,9,10,endpoint=False) array([1. , 1.8, 2.6, 3.4, 4.2, 5. , 5.8, 6.6, 7.4, 8.2])# 显示间距# 返回数组和间距构成的元组np.linspace(1,9,10,retstep=True) (array([1. , 1.88888889, 2.77777778, 3.66666667, 4.55555556, 5.44444444, 6.33333333, 7.22222222, 8.11111111, 9. ]), 0.8888888888888888)与前面的np.arange()相比：np.linspace()：不能指定间距，但可以显示间距np.linspace()：可以设置长度；默认是包含endpoint(可以设置为不包含)，而np.arange()默认是不包含，并且不可以设置等比数组函数形式：1np.logspace(start, stop, num=50, endpoint=True, base=10.0, dtype=None, axis=0)参数说明：参数描述start序列的起始值，实际起始值为：base ** startstop序列的终止值为，实际起始值为：base ** stop。如果endpoint为true，该值包含于数列中num要生成的等步长的样本数量，默认为50endpoint该值为 ture 时，数列中中包含stop值，反之不包含，默认是True。base对数 log 的底数。dtypendarray 的数据类型使用实例：1234567891011# 默认是以10为底np.logspace(1,2,10)# 实际上是从10^1-10^2，长度为10的等比数列 array([ 10. , 12.91549665, 16.68100537, 21.5443469 , 27.82559402, 35.93813664, 46.41588834, 59.94842503, 77.42636827, 100. ])# 设置以2为底# 从2^0-2^9，长度为10的等比数列np.logspace(0,9,10,base=2) array([ 1., 2., 4., 8., 16., 32., 64., 128., 256., 512.])创建随机且符合某种分布的数组-np.random在实际使用中，经常需要用到numpy的随机函数，由于随机函数random的功能比较多，经常会混淆或记不住，下面就学习和列举几种比较常用的。[0,1)之间的随机数-numpy.random.rand()rand函数根据给定维度生成[0,1)之间的数据，包含0，不包含1.函数形式：12numpy.random.rand(d0, d1, ..., dn)# dn表示维度信息使用实例：1234567# 产生一个四行两列的随机数组# 元素的取值范围为[0,1)np.random.rand(4,2) array([[0.6126271 , 0.84776825], [0.5572775 , 0.02186394], [0.51725555, 0.76771822], [0.65649717, 0.80120975]])N(0,1)的标准正态分布-numpy.random.randn()函数形式：1randn(d0, d1, ..., dn)使用实例：12345# 产生一个3行2列的标准正太分布np.random.randn(3,2) array([[ 1.79853947, 0.57042178], [-0.07007952, -1.45797489], [ 0.82423002, -0.4111874 ]])如果想要产生的不是标准正太分布可以变换：12345# 产生一个N(3, 6.25)的正太分布# 2.5 * 2.5 = 6.252.5 * np.random.randn(2, 4) + 3 array([[ 3.87050085, 4.90415633, 0.86676374, 1.07284953], [ 2.1834204 , 1.54992813, -2.60284824, 3.54083072]])[low,high)范围内的随机整数-numpy.random.randint()前面几个函数得到的都是随机的浮点型数，如果想要得到随机整数，可以使用numpy.random.randint()函数。函数形式：12randint(low, high=None, size=None, dtype='l')# size:shape使用实例：12345678# 产生10个在0-3范围内的随机整数np.random.randint(3,size=10) array([2, 2, 1, 2, 2, 0, 1, 0, 2, 2])# 产生一个2行3列的，元素在0-3范围内的随机整数np.random.randint(3,size=(2,3)) array([[0, 1, 2], [0, 0, 2]])固定随机数-numpy.random.seed()默认情况下，每次运行一遍上面的几个函数，得到的结果都会和前一次的不同，需要需要每次运行得到的随机数相同，可以使用numpy.random.seed()。函数形式：1np.random.seed(seed=None)使用实例：1234567891011121314# 首次运行np.random.rand(2,3) array([[0.22489862, 0.53165975, 0.57325016], [0.75665698, 0.14746711, 0.7346116 ]])# 再次运行 array([[0.51628755, 0.41312364, 0.3912831 ], [0.92598188, 0.88553487, 0.22607687]])# 设定seed，多次运行都不会变np.random.seed(123)np.random.rand(2,3) array([[0.69646919, 0.28613933, 0.22685145], [0.55131477, 0.71946897, 0.42310646]])参考链接为什么你用不好Numpy的random函数？numpy-random函数np.random函数总结简单的随机数据函数说明rand(d0, d1, ..., dn)[0,1)之间的随机值，dn表示维度信息randn(d0, d1, ..., dn)标准正态分布，可以进行变换得到非标准正太分布randint(low[, high, size])位于半开区间 [low, high)的随机整数，不指定high的情况下是从[0,low)random_integers(low[, high, size])位于闭区间 [low, high]的随机整数，不指定high的情况下是从[1,low]random_sample([size])在半开区间 [0.0, 1.0)的随机浮点数，可以变换(b - a) * random_sample() + a；与此类似的还有random([size])、ranf([size])、sample([size])choice(a[, size, replace, p])从一个给定的一维数组生成一个随机样本bytes(length)返回随机字节重新排列数组函数说明shuffle(array)打乱array的顺序，原位修改permutation(array)返回array的一个随机排列分布函数说明beta(a, b[, size])贝塔分布样本，在 [0, 1]内。binomial(n, p[, size])二项分布的样本。chisquare(df[, size])卡方分布样本。dirichlet(alpha[, size])狄利克雷分布样本。exponential([scale, size])指数分布f(dfnum, dfden[, size])F分布样本。gamma(shape[, scale, size])伽马分布geometric(p[, size])几何分布gumbel([loc, scale, size])耿贝尔分布。hypergeometric(ngood, nbad, nsample[, size])超几何分布样本。laplace([loc, scale, size])拉普拉斯或双指数分布样本logistic([loc, scale, size])Logistic分布样本lognormal([mean, sigma, size])对数正态分布logseries(p[, size])对数级数分布。multinomial(n, pvals[, size])多项分布multivariate_normal(mean, cov[, size])多元正态分布negative_binomial(n, p[, size])负二项分布noncentral_chisquare(df, nonc[, size])非中心卡方分布noncentral_f(dfnum, dfden, nonc[, size])非中心F分布normal([loc, scale, size])正态(高斯)分布pareto(a[, size])帕累托（Lomax）分布poisson([lam, size])泊松分布power(a[, size])Draws samples in [0, 1] from a power distribution with positive exponent a - 1.rayleigh([scale, size])Rayleigh 分布standard_cauchy([size])标准柯西分布standard_exponential([size])标准的指数分布standard_gamma(shape[, size])标准伽马分布standard_normal([size])标准正态分布 (mean=0, stdev=1).standard_t(df[, size])Standard Student’s t distribution with df degrees of freedom.triangular(left, mode, right[, size])三角形分布uniform([low, high, size])均匀分布vonmises(mu, kappa[, size])von Mises分布wald(mean, scale[, size])瓦尔德（逆高斯）分布weibull(a[, size])Weibull 分布zipf(a[, size])齐普夫分布随机数生成器函数说明RandomStateContainer for the Mersenne Twister pseudo-random number generator.seed([seed])Seed the generator.get_state()Return a tuple representing the internal state of the generator.set_state(state)Set the internal state of the generator from a tuple.参考链接numpy的random模块]]></content>
      <categories>
        <category>Python</category>
        <category>常用模块</category>
      </categories>
      <tags>
        <tag>常用模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之jupyter中dataframe美化]]></title>
    <url>%2Fposts%2F62040.html</url>
    <content type="text"><![CDATA[这篇文章学习了对jupyter中美化dataframe显示的语法，主要包括用于控制显示的dataframe.style.apply()、dataframe.style.applymap()以及控制显示格式的dataframe.style.format()以及一些内置的用法。styling在pandas 0.17.1之后的版本中出现了可以formatting以及displaying dataframe的Styler object，其主要是通过添加css样式达到的目的，接下来就学习一下吧。pandas的apply相关函数pandas中apply(func)可以将函数作用于行或者列的数据，而applymap(func)可以作用于table中的单个数据，在这里也结合了appy相关的函数：Styler.applymap(func) for elementwise stylesStyler.apply(func, axis=0) for columnwise stylesStyler.apply(func, axis=1) for rowwise stylesStyler.apply(func, axis=None) for tablewise styles测试数据1234import pandas as pdimport numpy as npdf=pd.DataFrame(np.random.randn(10,10))通过阈值控制颜色定义函数123def showColor(val): color= 'red' if val &gt;0 else 'green' return 'color:%s' %color应用函数1df.style.applymap(showColor)展示效果只对指定列进行操作注意这里的subset以及pd.IndexSlice的用法：12345678# applymap只作用于前五行的后五列df.style.applymap(showColor,subset=pd.IndexSlice[:5,5:])# applymap只作用于第三行的第5到8列，注意是包括第八列df.style.applymap(showColor,subset=pd.IndexSlice[2,5:8])# applymap作用于第四行的不连续的列df.style.applymap(showColor,subset=pd.IndexSlice[3,[1,3,5,7]])设置背景颜色定义函数123456789101112# 给每一列最低的添加黄色的背景色def show_bg(col): # 涉及到运算符顺序 # 赋值运算符优先级较低 c=col==col.max() return ['background-color:yellow' if v else '' for v in c]# 类似的结果def show_bg_2(col): # np.sign为符号函数，大于0的为1，小于0的为0 s=np.sign(col)==np.sign(col.max()) return ['background-color:blue' if v else 'background-color:red' for v in s]应用函数1df.style.apply(show_bg)展示效果使用内置的函数实现：123# 使用内置的方法实现对最大值上背景色# 默认颜色为黄色，可以通过color设置df.style.highlight_max(color='red')组合上面的颜色以及背景色12# apply函数的subset直接指定列就行df.style.applymap(showColor).apply(show_bg,subset=[3,4,5])实现百分比显示12345# 默认的bar显示df.style.bar()# 自定义的bar显示df.style.bar(subset=['A', 'B'], align='mid', color=['#d65f5f', '#5fba7d'])设置数据格式和上面的使用df.style.apply等不同，这里使用df.style.format进行格式的控制，具体对格式的控制参考format函数:123# 百分比显示，小数点后保留两位# 但是不能写到文件df.style.format("&#123;:.2%&#125;")更多的用法还支持想excel中的色阶操作以及鼠标滑动上去之后方法显示数据的效果等，具体请参考官方文档参考链接官方文档jupyter notebook中美化pandas中DataFrame的输出format函数]]></content>
      <categories>
        <category>Python</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jupyter进一步配置和使用]]></title>
    <url>%2Fposts%2F21776.html</url>
    <content type="text"><![CDATA[这篇文章主要记录关于jupyter的一下小工具，包括ipywidgets、qgrid、输出矢量图、管理conda环境、markdown设置锚定、加载网页源代码或者本地python程序、运行本地python程序等.ipywidgets作用可以实现 jupyter notebook 笔记本的交互式控件操作，个人觉得在于matplotlib进行画图配合上具有比较好的效果。安装1234567# 直接使用conda安装conda install -c conda-forge ipywidgets# jupyter安装在base的server# kernel安装在py36conda install -n base -c conda-forge widgetsnbextensionconda install -n py36 -c conda-forge ipywidgets使用官方文档上面有很多使用的示例，个人感觉这个插件与matplotlib结合起来进行绘图可能是比较好的选择，以下是一些示例：通过调整w来调整图像的显示范围123456789101112131415from ipywidgets import *import numpy as npimport matplotlib.pyplot as plt%matplotlib inlinex = np.linspace(0, 2 * np.pi)## 通过调整w来调整图像的显示范围def update(w = 1.0): fig = plt.figure() ax = fig.add_subplot(1, 1, 1) ax.plot(x, np.sin(w * x)) fig.canvas.draw()interact(update);调整直线的斜率和截距1234567891011121314151617%matplotlib inlinefrom ipywidgets import interactiveimport matplotlib.pyplot as pltimport numpy as npdef f(m, b): plt.figure(2) x = np.linspace(-10, 10, num=1000) plt.plot(x, m * x + b) plt.ylim(-5, 5) plt.show()interactive_plot = interactive(f, m=(-2.0, 2.0), b=(-3, 3, 0.5)) # m代表范围output = interactive_plot.children[-1]output.layout.height = '350px'interactive_plot多个选框，包括颜色、线宽、grid等12345678@widgets.interact_manual( color=['blue', 'red', 'green'], lw=(1., 10.))def plot(freq=1., color='blue', lw=2, grid=True): t = np.linspace(-1., +1., 1000) fig, ax = plt.subplots(1, 1, figsize=(8, 6)) ax.plot(t, np.sin(2 * np.pi * freq * t), lw=lw, color=color) ax.grid(grid)相关链接官方文档Jupyter notebook最简原型界面设计 - ipywidgets与lineup_widgetgithub官网知乎展示qgrid作用主要针对的是pandas的dataframe，可以通过直观的滚动、排序和过滤控件来探索DataFrame，以及通过双击单元格来编辑DataFrame。安装12# 直接使用conda安装conda install qgrid安装之后在python中调用发现ModuleNotFoundError: No module named &#39;qgrid&#39;，然后使用pip重新安装：1pip install qgrid然后调用发现AttributeError: module &#39;numpy&#39; has no attribute &#39;__version__&#39;，搜索得知是numpy的问题，重新安装或者升级numpy：1pip install --upgrade pip numpy设置在nbextension中使用：123jupyter nbextension enable --py --sys-prefix qgrid Enabling notebook extension qgrid/extension... - Validating: OK配置完成之后可以尝试如下示例：12345678910111213import numpy as npimport pandas as pdimport qgridrandn = np.random.randndf_types = pd.DataFrame(&#123; 'A' : pd.Series(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04', '2013-01-05', '2013-01-06', '2013-01-07', '2013-01-08', '2013-01-09'],index=list(range(9)),dtype='datetime64[ns]'), 'B' : pd.Series(randn(9),index=list(range(9)),dtype='float32'), 'C' : pd.Categorical(["washington", "adams", "washington", "madison", "lincoln","jefferson", "hamilton", "roosevelt", "kennedy"]), 'D' : ["foo", "bar", "buzz", "bippity","boppity", "foo", "foo", "bar", "zoo"] &#125;)df_types['E'] = df_types['D'] == 'foo'qgrid_widget = qgrid.show_grid(df_types, show_toolbar=True)qgrid_widget如果没有显示可以刷新jupyter。使用示例默认情况下，jupyter的dataframe不会显示全部的dataframe，使用qgrid之后可以显示全部的数据，并且可以设置显示的数目，防止占据太大的空间，具体的各种示例集合。参考链接官方github官方文档输出矢量图默认情况下jupyter会得到png，看着非常不清晰，为了克服这种情况，可以使用如下配置，将输出设置为svg格式的矢量图(放大不会使其模糊)：12345678910# jupyter中输出矢量图import matplotlibimport matplotlib.pyplot as plt%matplotlib inline%config InlineBackend.figure_format = 'svg'# 保存为矢量图plt.savefig('tmp.pdf', bbox_inches='tight')plt.show()管理conda环境使用的包为nb_conda，官方的介绍：Provides Conda environment and package access extension from within Jupyter.作用将使用conda创建的环境与Jupyter Notebook相关联，便于在Jupyter Notebook中使用不同的虚拟环境可以在线管理(增加、删除、复制)虚拟环境以及安装package安装1conda install nb_conda使用使用界面和简要功能：卸载使用下面的命令卸载nb_conda包：1canda remove nb_conda参考链接Jupyter Notebook介绍、安装及使用教程Markdown在文中设置链接并定位在使用Markdown编辑文档时，难免会遇到需要在文中设定链接跳转查看，定位在文档中的其他位置便于查看，因为Markdown可以完美的兼容html语法，因此这种功能可以通过html语法当中“a标签”的索引用法来实现：12345678# 在跳转部位和和插入链接一样的形式# 不过链接修改为锚定的形式[添加链接的正文](#自定义索引词)# 在需要跳转到的位置添加a标签# id和前面的锚定#后面的相同&lt;a id=自定义索引词&gt;跳转提示&lt;/a&gt;加载指定网页源代码或本地python文件加载网页源代码1%load URL加载本地python文件1%load Python文件的绝对路径注意：Python文件的后缀为.py%load后跟的是Python文件的绝对路径输入命令后，可以按CTRL 回车来执行命令第一次执行，是将本地的Python文件内容加载到单元格内。此时，Jupyter Notebook会自动将%load命令注释掉（即在前边加井号#），以便在执行已加载的文件代码时不重复执行该命令；第二次执行，则是执行已加载文件的代码直接运行本地python文件123456789%run Python文件的绝对路径# 使用shell命令的形式# python3!python3 Python文件的绝对路径# python2!python Python文件的绝对路径参考链接如何优雅地使用 Jupyter？Jupyter DashBoards 另类全家桶Jupyter Notebook介绍、安装及使用教程]]></content>
      <categories>
        <category>Python</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pv-命令执行的进度信息]]></title>
    <url>%2Fposts%2F6226.html</url>
    <content type="text"><![CDATA[这篇文章学习了linux中用于显示命令执行进度信息的命令pv，这个命令需要安装；该命令主要起到管道的作用，标准输入或文件流入，然后流出到标准输出，在这个过程中统计进度信息；主要学习了-L、-n、匀速打印字符、结合gzip、结合grep、结合wc等。pv命令简介pv命令 Pipe Viewer 的简称，由Andrew Wood 开发，其作用是通过管道显示数据处理进度的信息，这些信息包括已经耗费的时间、完成的百分比(通过进度条显示)、当前的速度、全部传输的数据以及估计剩余的时间等。为了实现上述功能需要将该命令插入到两个进程之间的管道中，并佐以合适的选项，它的标准输入经由它到达其标准输出, 同时进度信息会显示在标准错误上，pv依次拷贝FILE中的数据到其标准输出( - 表示标准输入)，如果FILE未提供仅仅拷贝标准输入。该命令行的行为与cat类似。pv安装12# 在root目录下使用yum安装yum install pvpv命令格式123456789101112131415161718# 官方Usage: pv [OPTION] [FILE]...Concatenate FILE(s), or standard input, to standard output,with monitoring.# 总结# 查看文件，并显示进度pv filepv [options] file# 拷贝文件进度pv file &gt; output_filename# 查看command进行的进度pv [options] | commandpv [options] | command &gt; output_filenamecommand1| pv | command2pv命令参数信息显示开关参数完整参数说明-p--progress显示进度条-t--timer打开计时器，这将显示pv的总耗用时间-e--eta预测完成需要多长时间-r--rate显示当前的数据传输速率-a--average-rate显示当前的平均数据传输速率-b--bytes显示到目前为止传输的数据总量-F--format FORMAT设置输出样式-n--numeric每行显示一个数字百分比(不带百分号)，用来替代通常的可视进度条，注意，如果使用-n，则不需要-f-q--quiet不显示任何传输信息输出修饰符参数完整参数说明-W--wait等到第一个字节被转移后，才显示进展信息或计算任何ETAs-s--size SIZE假设在计算百分比和ETAs时要传输的数据总量是SIZE字节-l--line-mode不是计数字节，而是计数行(换行字符)-i--interval SEC隔多久更新一次，默认设置是每秒钟更新一次，注意，这可以是小数，比如0.1-w--width WIDTH设置终端宽-H--height HEIGHT设置终端行高-N--name NAME使用NAME作为输出信息的前缀-f--force强制输出-c--cursor使用游标定位转义序列而不是仅使用回车符数据传输修饰符参数完整参数说明-L--rate-limit RATE设置每秒传输最大字节数-B--buffer-size BYTES设置传输缓冲区大小-E--skip-errorsskip read errors in input-S--stop-at-size传输指定的大小后停止传输-R--remote PID如果PID是已经在运行的pv的一个实例，那么-R PID将使该实例可以接收新的参数设置pv退出状态退出状态说明0没有问题1-R或-P选项存在问题2无法访问4输入文件与输出文件相同8关闭文件或移动到下一个文件时发生内部错误16一个或多个输入文件传输数据时出错32捕获的信号导致提前退出64内存分配失败pv使用实例默认使用实际上pv命令就是相当于把文件打开，然后输出到标准输出，进入后面的管道：12pv B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart &gt;../rsync/test.txt 258MiB 0:00:00 [1.13GiB/s] [=======================================================================================================================&gt;] 100%默认情况下：-p --progress：带进度条的完成比例-t --timer：已消耗时间-e --eta：预估剩余时间-r --rate：已传输总量-b --bytes：数据量总量-W --wait：等到第一个字节被转移后，才显示进展信息或计算任何ETAs-L-传输限速上面默认的传输速率是1.13GiB/s，很快，这里将其限制为1m/s:12pv -L 1m B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart &gt;../rsync/test.txt 20MiB 0:00:20 [1.01MiB/s] [=======&gt; ] 7% ETA 0:03:58-n-每行显示一个数字百分比默认情况下会显示传输进度条，如果不想显示传输进度条可以使用-n参数来输出传输的整数百分比，不带百分号的：1234567pv -n -L 1m B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart &gt;../rsync/test.txt 0 0 1 1 1 2匀速打印字符123# 设置每秒打印5个字符，而不是一次全部显示echo "Tecmint[dot]com is a community of Linux Nerds and Geeks" | pv -qL 5 Tecmint[dot]com is a community of Linux Nerds and Geeks结合gzip显示压缩进度：12pv B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart |gzip - &gt;test.log 127MiB 0:00:06 [21.6MiB/s] [==========================================================&gt; ] 49% ETA 0:00:06使用管道的好处在于：不用指定参数来保留原始文件，因为处理的是标准输入而不是原始文件结合grep查找内容时，对于较大的文件，可能会比较慢，并且没有任何输出也不知道进行了多少，加上pv命令可以显示查找进度：1234samtools view LJ_mt_677_1_paired.bam |pv |grep "ST-E00243:634:HYCT5CCXY:3:2117:20202:10996" ST-E00243:634:HYCT5CCXY:3:2117:20202:10996 .......... YS:i:-16 YT:Z:CP ST-E00243:634:HYCT5CCXY:3:2117:20202:10996 .......... YS:i:0 YT:Z:CP 3.5GiB 0:00:44 [79.7MiB/s] [ &lt;=&gt; ]结合wc1234# 显示统计行数的进度samtools view LJ_mt_677_1_paired.bam |pv |wc -l 3.5GiB 0:00:44 [79.9MiB/s] [ &lt;=&gt; ] 8981682参考链接pv 通过管道监控数据的进度如何使用 pv 命令监控 linux 命令的执行进度Linux 命令 PV 显示当前在命令行执行的进度信息，管道查看器利用pv命令监视数据的处理进度Linux：使用pv命令显示执行进度]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[获取时间日期格式和延时]]></title>
    <url>%2Fposts%2F52406.html</url>
    <content type="text"><![CDATA[这篇文章学习了linux中用于获取时间日期格式和延时的两个命令date和sleep；主要学习了date命令中的-d、-u、-s、自定义显示日期和时间、-n，sleep命令中的常规用法、不同时间尺度的混用、浮点型时间设置以及usleep进行微秒级休眠。date命令date命令简介date用于获取和设置操作系统的时间和日期，同时也能自定义日期和时间的显示格式。date命令格式12345# 自定义格式Usage: date [OPTION]... [+FORMAT]# 使用已有的格式 or: date [-u|--utc|--universal] [MMDDhhmm[[CC]YY][.ss]]Display the current time in the given FORMAT, or set the system date.date命令参数参数完整参数说明-d--date=STRING显示字符串所指的日期与时间，字符串前后必须加上双引号-f--file=DATEFILE和-d类似，一次读取DATEFILE的一行-s--set=STRING根据字符串来设置日期与时间，字符串前后必须加上双引号-u--utc、--universal显示或设置世界标准时间-r--reference=FILE显示文件的最后修改时间-R--rfc-2822输出RFC 2822格式日期或时间，格式为：星期, 日-月-年, 小时:分钟:秒 时区-I[TIMESPEC]--iso-8601[=TIMESPEC]显示ISO 8601格式的日期或时间date自定义格式字段&nbsp;符号意义描述年%y年(后两位)last two digits of year (00..99)%Y年year月%m月month (01..12)%h、%b月的简称month (Jan..Dec)%B月的全称month (January..December)&nbsp;日%j年中天day of year (001..366)%d月中天day of month (如01)%w周中天day of week (0..6); 0 is Sunday%u周中天day of week (1..7); 1 is Monday%a周中天,星期的简称day of week (Sun..Sat)%A周中天,星期的全称day of week (Sunday..Saturday)周%U年中周(00-53)week number of year with Sunday as first day%W年中周(00-53)week number of year with Monday as first day时%H时(24时制)hour (00..23)%I时(12时制)hour (01..12)%k时(24时制)hour (0..23)%l时(12时制)hour (1..12)分%M分minute (00..59)秒%S秒second (00..60)%N纳秒ns of current minute%s秒从1970-01-01到目前时间的秒数总数上午下午%p显示出AM或PM显示出AM或PM完整格式%T完整时间time; same as %H:%M:%S%r完整时间，12小时制time; same as hh:mm:ss %p%x、%D日期完整格式date; same as %m/%d/%y%F日期完整格式date; same as %Y-%m-%d日期和时间%c显示日期和时间Tue Nov 20 14:12:58 2012时区%Z显示时区，日期域CST、EST特殊格式%n换行a newline%ttab键a tabdate使用实例-u-显示世界标准时间12date -u Fri May 3 23:15:35 UTC 2019-d-显示指定的日期和时间-d参数可以用来描述获取什么时候的时间，描述的方式非常开放，但不能使用”now”关键字，其他的如3天前”3 days ago”，3天后”3 days”，昨天”yesterday”，下周一”next Monday”等等：123456789101112131415161718192021222324252627# 显示一天之前的此刻时间date -d "1 day ago" Thu May 2 18:45:08 EDT 2019# 显示一天之后的此刻时间date -d "1 day" Sat May 4 18:47:44 EDT 2019# 2秒之后的时间date &amp;&amp; date -d "2 seconds" Fri May 3 18:46:43 EDT 2019 Fri May 3 18:46:45 EDT 2019# 2秒之前的时间date &amp;&amp; date -d "2 seconds ago" Fri May 3 18:47:16 EDT 2019 Fri May 3 18:47:14 EDT 2019# 指定时间之前的时间date -d "2018-02-19 3 days ago" Fri Feb 16 00:00:00 EST 2018date -d "2018-02-19 - 3 days" Fri Feb 16 00:00:00 EST 2018# 指定时间之后的时间date -d "2018-02-19 3 days" Thu Feb 22 00:00:00 EST 2018date -d "2018-02-19 + 3 days" Thu Feb 22 00:00:00 EST 2018-s-设置时间和日期1234567891011121314# 设置当前时间，只有root权限才能设置，其他只能查看date -s # 设置成20120523，这样会把具体时间设置成空00:00:00date -s 20120523 # 设置具体时间，不会对日期做更改date -s 01:01:01 # 这样可以设置全部时间date -s "01:01:01 2012-05-23" date -s "01:01:01 20120523" date -s "2012-05-23 01:01:01" date -s "20120523 01:01:01"自定义输出格式date [OPTION] [+format]，其中+表示从前面的时间中获取其中的格式部分，如date -d &quot;yesterday&quot; +&quot;%Y&quot;获取的是昨天的年份部分：结合-d123456789101112# %F:%Y-%m-%ddate -d "3 days ago" +%F 2019-04-30# %c：日期和时间# 其中的时间是%rdate -d "3 days ago" +%c Tue 30 Apr 2019 07:02:03 PM EDT# %r：显示时间，12小时制（hh:mm:ss %p）date -d "3 days ago" +%r 07:03:07 PM-n-换行显示1234# 显示完时间之后，日期换行显示date -d "2018-02-19 3 days" +"%T%n%D" 00:00:00 02/22/18直接定义12345date +"%F %T" 2019-05-03 19:11:15date +"%Y-%m-%d %H:%M:%S" 2019-05-03 19:10:58实战使用给定一个日期，计算该日期所在星期的星期一是几月几号，例如，2018-05-12是星期六，那么星期一是2018-05-07:12345678#!/bin/bashsrc_date="2018-05-12"# 先判断给定的日期是星期几src_weekday=`date -d $src_date +%w`# src_weekday=6Mon_date=`date -d "$src_date - $(( src_weekday - 1 )) days" +%F`echo $Mon_date# 2018-05-07sleep命令sleep命令简介sleep命令可以用来将目前动作延迟一段时间，默认情况下，sleep 的进程是不占用 CPU 时间的.sleep命令格式12Usage: sleep NUMBER[SUFFIX]... or: sleep OPTIONsuffix:s：表示秒m：表示分钟h：表示小时d：表示天最大支持的休眠单位为天，如果需要更大的单位如月，需要用天转化NUMBER可以是浮点型的数值，例如0.003s、0.1m表示的是6ssleep使用实例常规使用123456789# 休眠1sdate ; sleep 1s ;date Fri May 3 20:35:43 EDT 2019 Fri May 3 20:35:44 EDT 2019# 休眠1分钟date ; sleep 1m ;date Fri May 3 20:36:19 EDT 2019 Fri May 3 20:37:19 EDT 2019时间混用1234# 休眠1分钟30sdate ; sleep 1m 30s;date Fri May 3 20:37:46 EDT 2019 Fri May 3 20:39:16 EDT 2019不同的时间尺度连用时需要注意时间尺度之间一定要有空格隔开浮点型的时间12345# 休眠半分钟# 和30s的效果是相同的date ; sleep 0.5m;date Fri May 3 20:41:24 EDT 2019 Fri May 3 20:41:54 EDT 2019usleep-微秒级的休眠命令12# 休眠1000微秒，即1毫秒usleep 1000参考链接date命令每天一个linux命令（37）：date命令Linux date命令 - 显示和设置系统日期与时间date、sleep和usleep命令sleep命令_Linux sleep命令：让程序暂停或休眠一段时间]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[du-显示目录或文件大小]]></title>
    <url>%2Fposts%2F30062.html</url>
    <content type="text"><![CDATA[这篇文章学习了linux中用于统计目录或文件大小的命令du，主要学习了：-h、-S、-s、-c、-a、--exclude、--max-depth、结合sort命令、-t、关于单位名称、与ls输出结果的差别原因。du命令简介du 命令，全称是 disk usage，用来展示文件或者文件夹磁盘使用量的统计信息.du命令格式123Usage: du [OPTION]... [FILE]... or: du [OPTION]... --files0-from=FSummarize disk usage of each FILE, recursively for directories.du命令参数参数完整参数说明-a-all显示目录中单个文件的大小，而不是笼统的显示目录大小-b--bytes显示目录或文件大小时，以byte为单位-c--total除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和-s--summarize仅显示总计，只列出最后加总的值-k以KB(1024bytes)为单位输出-m以MB为单位输出-h--human-readable以K、M、G为单位，提高信息的可读性--si与-h参数相同，但是K、M、G是以1000为换算单位-P--no-dereference不显示所有符号链接的源文件大小，这么默认情况-L--dereference显示所有符号链接的源文件大小-D--dereference-args显示指定符号链接的源文件大小-S--separate-dirs显示个别目录的大小时，并不含其子目录的大小--exclude=PATTERN排除指定的目录或文件-X--exclude-from=FILE从文件中读取排除的规则-d--max-depth=N统计指定深度的目录大小，当--max-depth=0时，效果同-s相同-t---threshold=SIZE只输出大小大于某个特定值的文件du命令使用实例目录信息123456789ls -alh total 259M drwxrwxr-x. 3 user user 4.0K May 3 13:24 . drwxrwxr-x. 4 user user 4.0K May 3 00:27 .. -rw-rw-r--. 1 user user 259M May 2 13:59 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart drwxrwxr-x. 3 user user 24 May 3 13:25 backup -rw-rw-r--. 1 user user 14K May 3 00:16 test1.txt -rw-rw-r--. 1 user user 11K May 3 00:17 test2.txt -rw-rw-r--. 1 user user 69 May 2 13:32 test.txt默认用法12345678910111213141516# 统计当前文件夹的大小du .# 默认是以K为单位 264768 ./backup/backup_test 264768 ./backup 529572 .# 统计指定文件大小du test1.txt 16 test1.txt# 统计多个文件大小du test1.txt test2.txt 16 test1.txt 12 test2.txt默认会显示文件夹以及子文件夹大小，不会具体显示文件夹中文件的大小-h-人性化显示大小和ls命令一样，du命令也可以使用-h参数来以人类可读的形式展示磁盘使用量的单位名称(K、M、G)：12345# 以人类可读的形式显示大小du -h . 259M ./backup/backup_test 259M ./backup 518M .-S-统计目录但不包括子目录的大小默认情况下，du统计的目录大小会包括子目录的大小，这就会造成一种重复统计大小的情况，如果想只显示当前目录中除子目录以外文件的大小的大小，可以使用-S参数：123456# 可以与上面默认的情况对比# backup目录只能自由子目录backup_test，所以除去子目录大小后，其大小为0du -Sh . 259M ./backup/backup_test 0 ./backup 259M .-s-只显示总和大小12345678910# 与默认显示每个文件夹以及子文件夹的大小不同# 只显示了总的大小du -sh . 518M .# 显示给定的文件大小# 这个和默认的情况没啥区别du -sh B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart test2.txt 259M B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart 12K test2.txt-c-所有目录以及总大小12345678910111213141516171819# 显示当前目录所有目录以及总大小du -ch . 259M ./backup/backup_test 259M ./backup 518M . 518M total# 显示给定的文件总和大小du -ch B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart test2.txt 259M B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart 12K test2.txt 259M total# 显示给定文件和目录的总和大小du -ch backup/ test1.txt 259M backup/backup_test 259M backup/ 16K test1.txt 259M total-c参数相当于是一个加和的操作，先得到给定的文件或者目录的大小，然后将这些大小加和起来得到total-a-显示所有文件和目录大小默认情况下，du后面如果跟着文件夹，统计的只有文件夹或者子文件夹的大小，如果想要查看所有文件和文件夹的大小，可以使用-a参数：12345678910# 查看所有文件和目录大小du -ah . 4.0K ./test.txt 16K ./test1.txt 12K ./test2.txt 259M ./B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart 259M ./backup/backup_test/B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart.test 259M ./backup/backup_test 259M ./backup 518M .–exclude-排除统计文件或目录如果使用了-a参数，那么指定目录下所有的文件和子目录大小都会显示，即使是隐藏文件或文件夹(以.开头)，如果不想显示这些文件，可以使用–exclude进行规则的限制：1234567891011121314151617181920# 显示所有的文件和目录大小du -ah . 6.8M ./wordpress-4.4.1.tar.gz 3.4M ./curl-7.34.0.tar.gz 980K ./soft/redis-2.6.16.tar.gz 40M ./soft/go1.1.2.Linux-amd64.tar.gz 120K ./soft/.abc 0 ./.bbc/ddd 0 ./.bbc/.ccc 51M . # 用--exclude结合通配符# 将以.开头的文件或目录大小排除在外 du -ah --exclude="*/.*" . 6.8M ./wordpress-4.4.1.tar.gz 3.4M ./curl-7.34.0.tar.gz 980K ./soft/redis-2.6.16.tar.gz 40M ./soft/go1.1.2.Linux-amd64.tar.gz 41M ./soft 51M .–max-depth-限制统计深度文件夹是可以嵌套的，有的时候，我们只想展示第一级或第二级子文件夹的信息，而不希望 du 统计的层次太深，那么我们可以用 --max-depth 选项来进行控制：12345678910111213141516171819202122# 结合-c参数，--max-depth=0# 相当于使用了-s参数du --max-depth=0 -ch . 518M . 518M total# 结合-c参数，--max-depth=1# 只会显示当前和子目录，不会显示子目录的子目录du --max-depth=1 -ch . 259M ./backup 518M . 518M total# 结合-a参数，--max-depth=1# 显示了当前目录下所有的文件大小以及子目录大小du --max-depth=1 -ah . 4.0K ./test.txt 16K ./test1.txt 12K ./test2.txt 259M ./B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart 259M ./backup 518M .结合sort命令按照文件或文件夹大小进行降序：123456789du -ah . |sort -hr 518M . 259M ./backup/backup_test/B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart.test 259M ./backup/backup_test 259M ./backup 259M ./B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart 16K ./test1.txt 12K ./test2.txt 4.0K ./test.txt关于sort -n和-h参数的区别：-n选项，按数值进行比较，只会傻傻地比较数字，它会认为 98 K大于 2G-h选项，会更加聪明，先优先比较单位（G&gt;M&gt;K），然后再对数值进行比较-t-只输出大小大于某个特定值的文件1234567# 只输出大于100m的文件du -ah . -t 100m 259M ./B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart 259M ./backup/backup_test/B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart.test 259M ./backup/backup_test 259M ./backup 518M .关于单位名称默认的单位是K，当然也可以通过指定-b、-k、-m来分别设置以bytes、KB、MB为单位，其实这些-k、-m对单位的设置都是通过--block-size来控制的：--block-size=1(-b)，则表示使用bytes为单位--block-size=1K(-k)，则表示使用KB为单位--block-size=1M(-m)，则表示使用MB为单位du和ls结果的差异12345678910111213141516#有一个文件, 里面只输入了a、b两个英文字母cat &lt;&lt; EOF &gt;test3.txt &gt; ab &gt; EOF#用下面的方法, 我们可以把文件中的控制字符也展示出来, 发现除了a、b外还包括了一个结尾符cat -E test3.txt ab$ #用ls来查看大小, 发现展示的是3字节ls -alh test3.txt -rw-rw-r--. 1 user user 3 May 3 17:06 test3.txt #用du来查看大小, 竟然展示的是4KB字节du -h test3.txt 4.0K test3.txtdu 命令的作者也太粗心了吧，竟然连字母个数都数不清么？冤枉啊！其实，du 和 ls 在展示文件大小时，是存在着本质区别的：du 展示的是磁盘空间占用量ls 展示的是文件内容的大小可能这两句话还不足以让你理解两者的区别，我们举一个形象的例子。中秋节时，中国人走亲访友时都会购买月饼礼盒，月饼的体积可以认为是文件内容大小，而加上包装礼盒的总体积可以认为是磁盘空间使用量。那么，在 Linux 的世界里，每个文件也要有包装么？要想解答这个问题，我们就要简单介绍下 Linux 文件系统的原理了：文件系统进驻磁盘之初，就会将磁盘按照固定数据块（block）大小进行分隔切块，通常情况下每一个固定数据块大小会被设定为 4096bytes，也就是 4KB，与此同时，大部分文件系统规定：一个数据块中最多存放一个文件的内容，当没存满时，剩余的空间不得被其他文件使用当一个文件的内容较大时，则可以存储到多个数据块中文件 test3.txt 中只有三个字符，两个可见字符（ab）和一个控制字符（$），因此，这个文件的内容大小就是 3bytes，但是由于 Linux 文件系统的限制，它需要占用一个数据块来存储这个文件，因此这个文件实际占用的磁盘空间就是 4KB 了。参考链接du命令_Linux du命令：查看文件夹和文件的磁盘占用情况Linux命令行查看目录及子目录大小 - du]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pgrep-使用进程名直接查找pid等信息]]></title>
    <url>%2Fposts%2F22799.html</url>
    <content type="text"><![CDATA[这篇文章学习了linux中直接通过进程名查找pid以及进程名和完整命令行的命令pgrep，其是ps结合awk、grep命令查找信息的一个简写命令；主要学习了-l、-a、-f、-x等。pgrep命令简介pgrep命令以名称为依据从运行进程队列中查找进程，并显示查找到的进程id。每一个进程ID以一个十进制数表示，通过一个分割字符串和下一个ID分开，默认的分割字符串是一个新行。前面学习了查看静态进程信息的命令ps，在实际使用中经常会遇到需要查看某个任务的pid信息，这个时候如果使用ps命令就需要结合awk和grep等命令，显得比较繁琐，如查看jupyterhub相关名称的pid需要使用ps -auxf |grep &quot;jupyterhub&quot; |grep -v &quot;grep&quot; |awk &#39;{print $2}&#39;，这么长的命令写着不是很方便，那么有没有可以简化的方法呢？pgrep就是为了解决这一问题而生的，pgrep相当于ps -eo pid,cmd | awk &#39;{print $1,$2}&#39; | grep KeyWord，可以直接得到命令的pid。pgrep是根据进程名来查找得到pid，并且其对匹配的字符数目也有限制，默认只能匹配进程的前15个字符:ps aux includes the full command line (path and parameters), while pgrep only looks at the first 15 characters of the executable’s names这个可以结合后面的参数-f进行全字符的匹配与pgrep相对应的还有一个pkill命令，和pgrep用法完全相同，不过个人感觉还是使用pgrep查找到想要的pid之后结合xargs和kill进行操作比较好。pgrep命令格式12Usage: pgrep [options] &lt;pattern&gt;pgrep命令参数选项说明--d定义输出的多个进程之间的分隔符（默认使用换行符）-l列出pid 和 进程名-a列出pid 和 完整的命令-v否定匹配，即列出除了查找的进程以外的其他进程-w列出所有的TID-c统计匹配到的所有进程数量-f用进程全名去匹配，包括参数-g匹配列出的进程组ID-G其后跟着一组group id，该命令在搜索时，仅考虑group列表中的进程。-n表示如果该程序有多个进程正在运行，则仅查找最新的，即最后启动的。-o表示如果该程序有多个进程正在运行，则仅查找最老的，即最先启动的（多个进程时即父进程PID）。-P根据父进程PID，找出所有子进程的pid-s匹配会话ID-t通过控制终端匹配-u其后跟着一组有效用户ID(effetive user id)，该命令在搜索时，仅考虑该effective user列表中的进程。-U其后跟着一组实际用户ID(real user id)，该命令在搜索时，仅考虑该real user列表中的进程。-x表示进程的名字必须完全匹配, 以上的选项均可以部分匹配。-F从文件中读取PID-L如果PID文件未锁定，则失败pgrep使用实例ps查看命令信息1234ps -auxf |grep "jupyterhub" |grep -v "grep" user2+ 17668 0.0 0.1 292476 55356 ? Ssl Apr29 0:00 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub-singleuser --port=54460 --notebook-dir="/" --NotebookApp.default_url="/tree/home/user2" root 30495 0.0 0.1 272996 49736 ? Sl Apr30 1:06 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub -f /etc/jupyterhub/jupyterhub_config.py user+ 30529 0.0 0.1 476772 86504 ? Ssl Apr30 0:23 \_ /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub-singleuser --port=60783 --notebook-dir="/" --NotebookApp.default_url="/tree/home/user"可以发现输出结果中第三个为子进程。默认使用1234# 默认情况下只会显示pidpgrep jupyterhub 17668 30495这里只会显示父进程的信息，不会显示子进程的pid-l-列出pid和进程名12345# 列出pid和进程名# 但没有列出命令信息，不是很完善pgrep -l jupyterhub 17668 jupyterhub-sing 30495 jupyterhub这里只会显示父进程的信息，不会显示子进程的pid-a-列出pid和完整命令1234# 显示了pid和完整的命令，信息较全pgrep -a jupyterhub 17668 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub-singleuser --port=54460 --notebook-dir="/" --NotebookApp.default_url="/tree/home/user2" 30495 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub -f /etc/jupyterhub/jupyterhub_config.py这里只会显示父进程的信息，不会显示子进程的pid-f-匹配整个命令行123456# 发现是使用-f参数可以得到三个pid# 也就是包括了子进程的信息pgrep -f "jupyterhub" 17668 30495 30529结合-a使用：1234pgrep -af "jupyterhub" 17668 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub-singleuser --port=54460 --notebook-dir="/" --NotebookApp.default_url="/tree/home/user2" 30495 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub -f /etc/jupyterhub/jupyterhub_config.py 30529 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub-singleuser --port=60783 --notebook-dir="/" --NotebookApp.default_url="/tree/home/user"使用-f参数既可以显示父进程pid，也会显示子进程的pid-x-精确匹配进程名12345678910# 不包括子进程的进程名称# 是模糊匹配pgrep -l "jupyterhub" 17668 jupyterhub-sing 30495 jupyterhub# 精确匹配进程名# 排除了jupyterhub-sing的结果pgrep -ax "jupyterhub" 30495 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub -f /etc/jupyterhub/jupyterhub_config.py参考链接Linux命令——pgrep和pkillpgrep无法匹配问题pgrep命令]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ps-报告当前系统的进程状态]]></title>
    <url>%2Fposts%2F33990.html</url>
    <content type="text"><![CDATA[这篇文章学习了linux中查看静态进程信息的命令ps，主要学习了-A、-u、-N、显示所有进程信息(-ef)、信息更多地显示所有进程信息(-aux)、依据进程信息进行排序、-C、-o、实时监控进程状态等；如果希望直接得到进程的pid、命令行以及进程名等信息，可以直接使用pgrep命令。ps命令简介Linux中的ps命令是Process Status的缩写，用来列出系统中当前运行的那些进程。ps命令列出的是当前那些进程的快照，就是执行ps命令的那个时刻的那些进程，是静态的，如果想要动态的显示进程信息，就可以使用top命令。要对进程进行监测和控制，首先必须要了解当前进程的情况，也就是需要查看当前进程，而 ps 命令就是最基本同时也是非常强大的进程查看命令。使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等。总之大部分信息都是可以通过执行该命令得到的。linux上进程有5种状态以及在ps中对应的状态码：状态说明ps中的状态码运行 runnable (on run queue)正在运行或在运行队列中等待R中断 sleeping休眠中, 受阻, 在等待某个条件的形成或接受到信号S不可中断 uninterruptible sleep (usually IO)收到信号不唤醒和不可运行, 进程必须等待直到有中断发生D僵死 a defunct (”zombie”) process进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放Z停止 traced or stopped进程收到SIGSTOP, SIGTSTP, SIGTTIN, SIGTTOU信号后停止运行运行Tps命令参数参数说明a显示所有进程(with tty)，包括其他其他用户的进程-a显示所有进程(with tty)，但不包括会话的领导进程(session leaders)-A, -e显示所有进程c显示进程的真实名称-N反向选择，相当于！e命令之后显示环境，user、name、path等-f信息全部列出，通常和其他选项联用-H显示树状结构r显示当前终端正在运行的进程T显示当前终端的所有进程-u指定用户的所有进程-k、--sort对进程信息进行排序，+表示升序，-表示降序-C根据command名称进行过滤ps输出结果说明UID、USER：该命令是由哪个用户产生的。PID：进程的ID号。%CPU：该进程占用CPU资源的百分比。%MEM：该进城占用物理内存的百分比。VSZ：该进程占用虚拟内存的大小，单位KB。RSS：该进程占用实际物理内存的大小，单位KB。TTY：该进程在哪个终端中运行。其中tty1-tty7代表本地控制台终端，tty1-tty6是本地字符界面终端，tty7是图形终端。pst/0-255代表虚拟终端。STAT：由两个字符组成的状态码，用于表示当前进程的状态：第一个字符：R：运行S：睡眠T：停止状态Z：僵死第二个字符：s：包含子进程+：位于前台&lt;：进程正以高优先级运行N：进程正以低优先级运行L：进程在内存中存在锁定页面s：进程是会话领导者（session leader）l：进程是多线程的START：该进程的启动时间TIME：该进程占用CPU的运算时间，注意不是系统时间COMMAND：产生此进程的命令ps使用实例-A-显示所有进程信息1234567ps -A PID TTY TIME CMD 1 ? 00:10:40 systemd 2 ? 00:00:01 kthreadd 3 ? 00:00:01 ksoftirqd/0 5 ? 00:00:00 kworker/0:0H 7 ? 00:00:03 migration/0-u-显示指定用户信息1234567891011# 显示root的进程信息ps -u root u USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.0 52096 4584 ? Ss 2018 10:41 /usr/lib/systemd/systemd --system --deserialize 23 root 2 0.0 0.0 0 0 ? S 2018 0:01 [kthreadd] root 3 0.0 0.0 0 0 ? S 2018 0:01 [ksoftirqd/0] root 5 0.0 0.0 0 0 ? S&lt; 2018 0:00 [kworker/0:0H] root 7 0.0 0.0 0 0 ? S 2018 0:03 [migration/0] root 8 0.0 0.0 0 0 ? S 2018 0:00 [rcu_bh] root 9 0.0 0.0 0 0 ? S 2018 0:00 [rcuob/0] root 10 0.0 0.0 0 0 ? S 2018 0:00 [rcuob/1]说明：最后的u参数用来决定以针对用户的格式输出，由User, PID, %CPU, %MEM, VSZ, RSS, TTY, STAT, START, TIME 和 COMMAND这几列组成.-N-反向选择123456789101112# 非root用户的进程信息ps -u root u -N USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND dbus 784 0.0 0.0 35048 1036 ? Ssl 2018 0:50 /bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation polkitd 915 0.0 0.0 632008 2000 ? Ssl 2018 0:13 /usr/lib/polkit-1/polkitd --no-debug user+ 3453 0.0 0.0 145612 2300 ? S May02 0:00 sshd: user@pts/1 user+ 3454 0.0 0.0 115508 2272 pts/1 Ss May02 0:01 -bash user+ 15238 0.0 0.0 145612 2172 ? S 00:31 0:00 sshd: user@pts/2 user+ 15239 0.0 0.0 115508 2228 pts/2 Ss+ 00:31 0:00 -bash user2+ 17668 0.0 0.1 292476 55356 ? Ssl Apr29 0:00 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub-singleuser --port=54460 user+ 17931 0.0 0.0 155268 1860 pts/1 R+ 01:07 0:00 ps -u root u -N rstudio+ 21690 0.0 0.0 212740 5480 ? Ssl Apr10 4:41 /usr/lib/rstudio-server/bin/rserver显示所有进程信息显示完整的命令信息：1234567ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 2018 ? 00:10:40 /usr/lib/systemd/systemd --system --deserialize 23 root 2 0 0 2018 ? 00:00:01 [kthreadd] root 3 2 0 2018 ? 00:00:01 [ksoftirqd/0] root 5 2 0 2018 ? 00:00:00 [kworker/0:0H] root 7 2 0 2018 ? 00:00:03 [migration/0]显示所有进程信息，信息更多1234567891011ps -aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.0 52096 4624 ? Ss 2018 10:40 /usr/lib/systemd/systemd --system --deserialize 23 root 2 0.0 0.0 0 0 ? S 2018 0:01 [kthreadd] root 3 0.0 0.0 0 0 ? S 2018 0:01 [ksoftirqd/0] root 5 0.0 0.0 0 0 ? S&lt; 2018 0:00 [kworker/0:0H] root 7 0.0 0.0 0 0 ? S 2018 0:03 [migration/0] root 8 0.0 0.0 0 0 ? S 2018 0:00 [rcu_bh] root 9 0.0 0.0 0 0 ? S 2018 0:00 [rcuob/0] root 10 0.0 0.0 0 0 ? S 2018 0:00 [rcuob/1] root 11 0.0 0.0 0 0 ? S 2018 0:00 [rcuob/2]与ps -ef相比，ps -aux信息更多，包括了%CPU、%MEM等信息，两者的cmd和command是相同的依据进程信息进行排序参数说明：12# 参数说明k, --sort specify sort order as: [+|-]key[,[+|-]key[,...]]多个key之间使用逗号分隔+表示升序，-表示降序支持的sort key可以查看这个链接中的STANDARD FORMAT SPECIFIERS依据进程的CPU使用排序1234567891011121314151617# 降序排列，+pcpups -aux --sort +pcpu USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND user+ 15072 118 2.5 1890184 1247420 pts/2 R+ 00:28 0:02 sh test.sh root 1 0.0 0.0 52096 4624 ? Ss 2018 10:40 /usr/lib/systemd/systemd --system --deserialize 23 root 2 0.0 0.0 0 0 ? S 2018 0:01 [kthreadd] root 3 0.0 0.0 0 0 ? S 2018 0:01 [ksoftirqd/0] root 5 0.0 0.0 0 0 ? S&lt; 2018 0:00 [kworker/0:0H] root 7 0.0 0.0 0 0 ? S 2018 0:03 [migration/0]# 升序排列，+pcpups -aux --sort +pcpu root 30495 0.0 0.1 272996 49736 ? Sl Apr30 0:54 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub -f /etc/jupyterhub/jupyt root 30508 0.0 0.0 566792 35008 ? Ssl Apr30 0:03 node /usr/bin/configurable-http-proxy --ip 192.168.1.231 --port 8000 --api-ip 127.0.0.1 --api-port 800 user+ 30529 0.0 0.1 476772 86504 ? Ssl Apr30 0:20 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub-singleuser --port=60783 user+ 30575 0.0 0.1 1015552 96128 ? Ssl Apr30 0:06 /home/softwares/anaconda3/bin/python -m ipykernel_launcher -f /home/user/.local/share/jupyter/ru user+ 15072 100 22.5 11214456 11102608 pts/2 R+ 00:28 0:46 sh test.sh依据进程的内存使用排序123456789# 根据内存使用进行降序排列ps -aux --sort -pmem USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND user+ 30575 0.0 0.1 1015552 96128 ? Ssl Apr30 0:06 /home/softwares/anaconda3/bin/python -m ipykernel_launcher -f /home/user/.local/share/jupyter/ru user+ 30529 0.0 0.1 476772 86504 ? Ssl Apr30 0:20 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub-singleuser --port=60783 user2+ 17668 0.0 0.1 292476 55356 ? Ssl Apr29 0:00 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub-singleuser --port=54460 root 30495 0.0 0.1 272996 49736 ? Sl Apr30 0:54 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub -f /etc/jupyterhub/jupyt root 30508 0.0 0.0 566792 35008 ? Ssl Apr30 0:03 node /usr/bin/configurable-http-proxy --ip 192.168.1.231 --port 8000 --api-ip 127.0.0.1 --api-port 800 root 15933 0.0 0.0 341804 13380 ? Ssl 2018 0:01 /usr/bin/python -Es /usr/sbin/firewalld --nofork --nopid-C-通过command名称过滤使用 -C 参数，后面跟你要找的进程的名字:12ps -fC jupyterhub root 30495 1 0 Apr30 ? 00:00:54 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub -f /etc/jupyterhub/jupyterhub_config.py参数是带有顺序的，不能使用-Cf，使用-fC是正确的-o-指定输出字段12345# 指定输出字段ps -o pid,ppid,pgrp,session,tpgid,comm PID PPID PGRP SESS TPGID COMMAND 3454 3453 3454 3454 13946 bash 13946 3454 13946 3454 13946 ps支持的输出字段可以查看这个链接中的STANDARD FORMAT SPECIFIERS实时监控进程状态ps 命令会显示你系统当前的进程状态，但是这个结果是静态的，如果我们需要像上面提到的通过CPU和内存的使用率来筛选进程，并且我们希望结果能够每秒刷新一次，我们可以将ps命令和watch命令结合起来：12345678910111213# 每10秒更新一次watch -n 10 'ps -aux --sort -pmem | head -n 20' Every 10.0s: ps -aux --sort -pmem | head -n 20 Fri May 3 00:53:36 2019 USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND user+ 30575 0.0 0.1 1015552 96128 ? Ssl Apr30 0:06 /home/softwares/anaconda3/bin/python -m ipykernel_launcher -f /home/user/.local/share/jupyter/ru user+ 30529 0.0 0.1 476772 86504 ? Ssl Apr30 0:20 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub-singleuser --port=60783 user2+ 17668 0.0 0.1 292476 55356 ? Ssl Apr29 0:00 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub-singleuser --port=54460 root 30495 0.0 0.1 272996 49736 ? Sl Apr30 0:54 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub -f /etc/jupyterhub/jupyt root 30508 0.0 0.0 566792 35008 ? Ssl Apr30 0:03 node /usr/bin/configurable-http-proxy --ip 192.168.1.231 --port 8000 --api-ip 127.0.0.1 --api-port 800 root 15933 0.0 0.0 341804 12992 ? Ssl 2018 0:01 /usr/bin/python -Es /usr/sbin/firewalld --nofork --nopid rstudio+ 21690 0.0 0.0 212740 5480 ? Ssl Apr10 4:41 /usr/lib/rstudio-server/bin/rserver root 3448 0.0 0.0 145612 5156 ? Ss May02 0:00 sshd: user [priv]这里的动态查看并不像top或者htop命令一样，使用ps的好处是你能够自定义显示你想查看的字段：12345678910111213141516# 查看指定用户的信息，并按照内存使用进行降序排序watch -n 10 'ps -u user u --sort -pmem | head -n 20' Every 10.0s: ps -u user u --sort -pmem | head -n 20 Fri May 3 00:56:12 2019 USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND user+ 30575 0.0 0.1 1015552 96128 ? Ssl Apr30 0:06 /home/softwares/anaconda3/bin/python -m ipykernel_launcher -f /home/user/.local/share/jupyter/ru user+ 30529 0.0 0.1 476772 86504 ? Ssl Apr30 0:20 /home/softwares/anaconda3/bin/python /home/softwares/anaconda3/bin/jupyterhub-singleuser --port=60783 user+ 17081 0.0 0.0 157560 2528 pts/1 S+ 00:55 0:00 watch -n 10 ps -U user -u --sort -pmem | head -n 20 user+ 3453 0.0 0.0 145612 2300 ? S May02 0:00 sshd: user@pts/1 user+ 3454 0.0 0.0 115508 2272 pts/1 Ss May02 0:01 -bash user+ 15239 0.0 0.0 115508 2228 pts/2 Ss+ 00:31 0:00 -bash user+ 15238 0.0 0.0 145612 2172 ? S 00:31 0:00 sshd: user@pts/2 user+ 17120 0.0 0.0 155264 1832 pts/1 R+ 00:56 0:00 ps -U user -u --sort -pmem user+ 17119 0.0 0.0 113124 1364 pts/1 S+ 00:56 0:00 sh -c ps -U user -u --sort -pmem | head -n 20 user+ 17118 0.0 0.0 157556 936 pts/1 S+ 00:56 0:00 watch -n 10 ps -U user -u --sort -pmem | head -n 20 user+ 17121 0.0 0.0 107904 672 pts/1 S+ 00:56 0:00 head -n 20说明：最后的u参数用来决定以针对用户的格式输出，由User, PID, %CPU, %MEM, VSZ, RSS, TTY, STAT, START, TIME 和 COMMAND这几列组成.参考链接每天一个linux命令（41）：ps命令4. ps 进程查看器Linux命令-5 ps10个重要的Linux ps命令实战Linux 进程管理（1）- 查看进程：ps,pstree,top,htop,bg,fg,jobs如何在Linux中查看所有正在运行的进程进程管理技巧]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rsnyc-远程数据同步]]></title>
    <url>%2Fposts%2F8376.html</url>
    <content type="text"><![CDATA[这篇文章学习了linux中进行远程数据同步的命令rsync，相比于功能相近的scp命令，其可以实现增量同步；主要学习了本地目录之间的同步、本地与远程之间的同步、-t、-a、-r、-R、-l、-L、--backup、--backup-dir、--existing、--ignore-existing、--remove-source-files、--exclude、--delete、--max-size等参数。rsync命令简介rsync是可以实现增量备份的工具。配合任务计划，rsync能实现定时或间隔同步，配合inotify或sersync，可以实现触发式的实时同步。rsync可以实现scp的远程拷贝(rsync不支持远程到远程的拷贝，但scp支持)、cp的本地拷贝、rm删除和&quot;ls -l&quot;显示文件列表等功能。但需要注意的是，rsync的最终目的或者说其原始目的是实现两端主机的文件同步，因此实现的scp/cp/rm等功能仅仅只是同步的辅助手段，且rsync实现这些功能的方式和这些命令是不一样的。本篇文章将简单介绍rsync的使用方法和它常用的功能。rsync同步说明rsync的目的是实现本地主机和远程主机上的文件同步(包括本地推到远程，远程拉到本地两种同步方式)，也可以实现本地不同路径下文件的同步，但不能实现远程路径1到远程路径2之间的同步(scp可以实现)。不考虑rsync的实现细节，就文件同步而言，涉及了源文件和目标文件的概念，还涉及了以哪边文件为同步基准。例如，想让目标主机上的文件和本地文件保持同步，则是以本地文件为同步基准，将本地文件作为源文件推送到目标主机上。反之，如果想让本地主机上的文件和目标主机上的文件保持同步，则目标主机上的文件为同步基准，实现方式是将目标主机上的文件作为源文件拉取到本地。当然，要保持本地的两个文件相互同步，rsync也一样能实现，这就像Linux中cp命令一样，以本地某文件作为源，另一文件作为目标文件，但请注意，虽然rsync和cp能达到相同的目的，但它们的实现方式是不一样的。实际上，如果简单理解的话，可以将其当成复制命令来理解：本地和远程同步，就是将远程的文件复制到本地，覆盖本地原有文件的内容远程和本地同步，就是将本地的文件复制到远程，覆盖远程原有文件的内容既然是文件同步，在同步过程中必然会涉及到源和目标两文件之间版本控制的问题，例如是否要删除源主机上没有但目标上多出来的文件，目标文件比源文件更新(newer than source)时是否仍要保持同步，遇到软链接时是拷贝软链接本身还是拷贝软链接所指向的文件，目标文件已存在时是否要先对其做个备份等等。rsync同步过程中由两部分模式组成：决定哪些文件需要同步的检查模式以及文件同步时的同步模式：检查模式是指按照指定规则来检查哪些文件需要被同步，例如哪些文件是明确被排除不传输的。默认情况下，rsync使用&quot;quick check&quot;算法快速检查源文件和目标文件的大小、mtime(修改时间)是否一致，如果不一致则需要传输。当然，也可以通过在rsync命令行中指定某些选项来改变quick check的检查模式，比如&quot;--size-only&quot;选项表示&quot;quick check&quot;将仅检查文件大小不同的文件作为待传输文件。rsync支持非常多的选项，其中检查模式的自定义性是非常有弹性的。同步模式是指在文件确定要被同步后，在同步过程发生之前要做哪些额外工作。例如上文所说的是否要先删除源主机上没有但目标主机上有的文件，是否要先备份已存在的目标文件，是否要追踪链接文件等额外操作。rsync也提供非常多的选项使得同步模式变得更具弹性。相对来说，为rsync手动指定同步模式的选项更常见一些，只有在有特殊需求时才指定检查模式，因为大多数检查模式选项都可能会影响rsync的性能。rsync命令格式通用命令格式1rsync options source destination本地路径之间的同步12# 本地路径之间的同步Local: rsync [OPTION...] SRC... [DEST]本地和远程的同步1234# 本地和远程的同步 Access via remote shell: Pull: rsync [OPTION...] [USER@]HOST:SRC... [DEST] Push: rsync [OPTION...] SRC... [USER@]HOST:DEST本地和远程的同步(rsync daemon)12345Access via rsync daemon: Pull: rsync [OPTION...] [USER@]HOST::SRC... [DEST] rsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST] Push: rsync [OPTION...] SRC... [USER@]HOST::DEST rsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST前两者的本质是通过管道通信，即使是远程shell；而第三种方式则是让远程主机上运行rsync服务，使其监听在一个端口上，等待客户端的连接。命令中的第一个路径参数一定是源文件路径，即作为同步基准的一方，可以同时指定多个源文件路径。最后一个路径参数则是目标文件路径，也就是待同步方。路径的格式可以是本地路径，也可以是使用user@host:path或user@host::path的远程路径，如果主机和path路径之间使用单个冒号隔开，表示使用的是远程shell通信方式，而使用双冒号隔开的则表示的是连接rsync daemon。另外，连接rsync daemon时，还提供了URL格式的路径表述方式rsync://user@host/path。如果仅有一个SRC或DEST参数，则将以类似于&quot;ls -l&quot;的方式列出源文件列表(只有一个路径参数，总会认为是源文件)，而不是复制文件。另外，使用rsync一定要注意的一点是，源路径如果是一个目录的话，带上尾随斜线和不带尾随斜线是不一样的，不带尾随斜线表示的是整个目录包括目录本身，带上尾随斜线表示的是目录中的文件，不包括目录本身。rsync参数说明参数完整参数说明-v--verbose显示rsync过程中详细信息，可以使用"-vvvv"获取更详细信息-P显示文件传输的进度信息(实际上"-P"="--partial --progress"，其中的"--progress"才是显示进度信息的)-n--dry-run仅测试传输，而不实际传输，常和"-vvvv"配合使用来查看rsync是如何工作的-a--archive归档模式，表示递归传输并保持文件属性，等同于"-rtopgDl"(不带-H,-A,-X)-r--recursive递归-t--times保持mtime属性。强烈建议任何时候都加上"-t"，否则目标文件mtime会设置为系统时间，导致下次更新检查出mtime不同从而导致增量传输无效-o--owner保持owner属性(属主)-g--group保持group属性(属组)-p--perms保持perms属性(权限，不包括特殊权限)-D是"--device --specials"选项的组合，即也拷贝设备文件和特殊文件-l--links如果文件是软链接文件，则会拷贝软链接，默认情况下会忽略链接的同步-L--copy-links如果文件是软链接文件，则会拷贝软链接指向的文件或目录，而不是单纯的保留软链接形式，默认情况下会忽略链接的同步-z传输时进行压缩提高效率-R--relative使用相对路径，意味着将命令行中指定的全路径而非路径最尾部的文件名发送给服务端，包括它们的属性。用法见下文示例--size-only默认算法是检查文件大小和mtime不同的文件，使用此选项将只检查文件大小。-u--update仅在源mtime比目标已存在文件的mtime新时才拷贝，注意，该选项是接收端判断的，不会影响删除行为-d--dirs以不递归的方式拷贝目录本身，默认递归时，如果源为"dir1/file1"，则不会拷贝dir1目录，使用该选项将拷贝dir1但不拷贝file1--max-size限制rsync传输的最大文件大小，可以使用单位后缀，还可以是一个小数值(例如："--max-size=1.5m")--min-size限制rsync传输的最小文件大小。这可以用于禁止传输小文件或那些垃圾文件--exclude指定排除规则来排除不需要传输的文件--delete以SRC为主，对DEST进行同步。多则删之，少则补之。注意"--delete"是在接收端执行的，所以它是在exclude/include规则生效之后才执行的-b--backup对目标上已存在的文件做一个备份，备份的文件名后默认使用"~"做后缀--backup-dir指定备份文件的保存路径，不指定时默认和待备份文件保存在同一目录下-e指定所要使用的远程shell程序，默认为ssh，可以用来指定端口号--port连接daemon时使用的端口号，默认为873端口--password-filedaemon模式时的密码文件，可以从中读取密码实现非交互式。注意，这不是远程shell认证的密码，而是rsync模块认证的密码-W--whole-filersync将不再使用增量传输，而是全量传输，在网络带宽高于磁盘带宽时，该选项比增量传输更高效--existing要求只更新目标端已存在的文件，目标端还不存在的文件不传输。注意，使用相对路径时如果上层目录不存在也不会传输。--ignore-existing要求只更新目标端不存在的文件，和"--existing"结合使用有特殊功能，见下文示例--remove-source-files要求删除源端已经成功传输的文件rsync使用实例本地之间的同步123# 将scp目录下的test.txt同步到当前目录中# 默认是不会显示进度信息的，和scp不同rsync /home/user/learn/linux_learn/scp/test.txt ./注意事项：只要目的端文件内容和源端不一样，就会触发数据同步，rsync会确保两边的文件内容一样默认情况下，rsync不会同步文件的“modify time”，凡是有数据同步的文件，目的端的文件的“modify time”总是会被修改为最新时刻的时间(同步发生的时间)，而默认情况下rsync会检查源文件和目标文件的大小、mtime(修改时间)是否一致，如果不一致则需要传输，这样时间发生改变会使得源文件和目的端文件内容总是不同，导致增量同步无效rsync不会太关注目的端文件的rwx权限，如果目的端没有此文件，那么权限会保持与源端一致；如果目的端有此文件，则权限不会随着源端变更-t-保持mtime属性为了解决默认情况下rsync会将目的端同步文件的modify time修改为当前时间从而导致增量同步无效的问题，可以使用-t来在同步文件时保留mtime属性：1234567891011121314151617181920212223242526272829303132333435# 远程目录-rw-rw-r--. 1 user user 271119851 May 2 13:59 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart-rw-rw-r--. 1 user user 69 May 2 13:32 test.txt# 同步，保留mtime属性rsync -r -v -t /home/user/learn/linux_learn/scp/test ./# 当前目录# 时间和远程文件的保持一致-rw-rw-r--. 1 user user 271119851 May 2 13:59 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart-rw-rw-r--. 1 user user 69 May 2 13:32 test.txt# 再次运行同步# 因为时间戳是相同的，且文件内容也是相同的，所以不会进行再次同步rsync -r -v -t /home/user/learn/linux_learn/scp/test ./sending incremental file listsent 129 bytes received 13 bytes 284.00 bytes/sectotal size is 271119920 speedup is 1909295.21# 如果不使用-t参数rsync -r -v /home/user/learn/linux_learn/scp/test ./# 这里的时间就是当前时间-rw-rw-r--. 1 user user 271119851 May 2 21:50 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart-rw-rw-r--. 1 user user 69 May 2 21:50 test.txt# 再次运行同步# 因为时间戳是不同的，所以还会进行同步rsync -r -v /home/user/learn/linux_learn/scp/test ./sending incremental file listtest/B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.fileparttest/test.txtsent 271153227 bytes received 51 bytes 180768852.00 bytes/sec注意事项：-t参数会保留远程(源端)文件的modify time属性，下次再进行同步时，如果远程文件没有修改，就不会再次同步，真正的增量同步不加-t参数会使得当前文件的modify time为同步操作发生的时间，从而使得远程文件和当前文件的modify time一直不同，重复运行会一直同步，即使远程文件没有修改，这使得增量同步无效为了防止文件时间戳和大小一致，但是内容不一致的情况，可以使用-I参数：don’t skip files that match in size and mod-time，但是这会影响rsync的性能-a-归档模式rsync的-a选项是archive的意思，加了之后有以下作用：递归模式同步软链接同步权限同步时间戳同步属主和属组本地和远程同步和scp命令一样，rsync也是默认使用的是22端口连接远程服务器，如果想要指定服务器端口需要使用-e来指定ssh连接参数，如端口、连接的用户、ssh选项等：12345678# 指定端口为12000rsync -r -v -e "ssh -p 12000 " wangjb@166.111.152.116:/Share/home/wangjb/user/data/test/B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart ./wangjb@166.111.152.116's password: receiving incremental file listB2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepartsent 115306 bytes received 66000 bytes 10988.24 bytes/sectotal size is 271119851 speedup is 1495.37-r-递归同步文件夹内容12# 将scp目录下的test目录及其内容递归地复制到当前目录中的test目录rsync -r /home/user/learn/linux_learn/scp/test ./使用-r选项，rsync会进入到文件夹里去检查，而不会只对文件夹本身做“quick check”的(检查文件夹的大小和时间戳)-R-保留目录结构默认情况下，同步只是针对的最后指定的文件或者目录，上层目录不会进行同步，如果有时需要保留目录结构，可以使用-R参数：1234567# 使用-R会保留目录结构rsync -R -r /home/user/learn/linux_learn/scp/test ./# 不能使用相对路径，如果使用会报错rsync -R -r ../scp/test ./found ".." dir in relative path: ../scp/testrsync error: syntax or usage error (code 1) at flist.c(2130) [sender=3.0.9]输出结果：12# 最终生成的路径/home/user/learn/linux_learn/rsync/(当前目录)home/user/learn/linux_learn/scp/test由于不能使用相对路径，有时候我们并不需要从根目录进行保留目录结构，只希望保留一部分目录结构，这是可以使用.表示保留目录结构的起始位置：12# 从linux_learn开始保留目录结构rsync -R -r /home/user/learn/./linux_learn/scp/test ./输出结果：12# 最终生成的路径/home/user/learn/linux_learn/rsync/(当前目录)linux_learn/scp/test-R参数表示使用相对路径，此相对路径是以目标目录为根的，例如/home/user/learn/linux_learn/scp/test ./表示使用当前目录来替换最开始的/目录-R指定的source目录必须使用绝对路径，不能使用相对路径-R可以指定保留部分目录结构，在完整的绝对路径中想要保留的目录结构之前加上./即可-l-保留原始链接形式12345678910111213141516171819202122232425262728293031323334# 远程文件-rw-rw-r--. 1 user user 271119851 May 2 13:59 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepartlrwxrwxrwx. 1 user user 12 May 2 22:10 test2.txt -&gt; ../test2.txt-rw-rw-r--. 1 user user 69 May 2 13:32 test.txt# 同步rsync -v -t -r /home/user/learn/linux_learn/scp/test ./sending incremental file listtest/test/B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.fileparttest/test.txt# 默认会跳过链接文件skipping non-regular file "test/test2.txt"sent 271153253 bytes received 54 bytes 180768871.33 bytes/sectotal size is 271119932 speedup is 1.00# 同步，保留软连接rsync -v -t -r -l /home/user/learn/linux_learn/scp/test ./sending incremental file listtest/test/B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.fileparttest/test.txt# 保留软链接形式test/test2.txt -&gt; ../test2.txtsent 271153269 bytes received 57 bytes 180768884.00 bytes/sectotal size is 271119932 speedup is 1.00# 远程文件# 得到了和当前文件相同的软连接，相对路径的软连接会失效-rw-rw-r--. 1 user user 271119851 May 2 13:59 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepartlrwxrwxrwx. 1 user user 12 May 2 22:10 test2.txt -&gt; ../test2.txt-rw-rw-r--. 1 user user 69 May 2 13:32 test.txt-L-复制链接指向的文件或目录上述的参数-l虽会保留软链接，但如果不是同一台机器以及链接不是使用的绝对路径都会使得链接失效，较为有效地做法是复制链接指向的文件，可以使用-L参数：1234567891011121314151617# 同步，复制链接指向的文件或目录rsync -v -t -r -L /home/user/learn/linux_learn/scp/test ./sending incremental file listtest/test/B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.fileparttest/test.txt# 直接复制了链接指向的文件test/test2.txtsent 271153307 bytes received 73 bytes 180768920.00 bytes/sectotal size is 271119935 speedup is 1.00# 当前文件# 不再是链接，而是文件-rw-rw-r--. 1 user user 271119851 May 2 13:59 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart-rw-rw-r--. 1 user user 15 May 2 22:09 test2.txt-rw-rw-r--. 1 user user 69 May 2 13:32 test.txt–backup-已存在的目录备份如果在进行同步时希望保留当前的文件，可以使用--backup来进行备份，默认的备份文件使用”~“做后缀，可以使用--suffix指定备份后缀：12# 同步的同时进行备份rsync -r --backup /home/user/learn/linux_learn/scp/test ./输出结果：12345(base) [user@localhost test]$ lltotal 529536# 默认的原始的文件使用了~-rw-rw-r--. 1 user user 271119851 May 2 13:09 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart-rw-rw-r--. 1 user user 271119851 May 2 12:35 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart~指定原始文件的备份后缀：12# 使用--suffix指定备份文件的后缀rsync -r --backup --suffix ".backup" /home/user/learn/linux_learn/scp/test ./输出结果：123456(base) [user@localhost test]$ lltotal 794304# 设置了备份文件后缀为backup-rw-rw-r--. 1 user user 271119851 May 2 13:11 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart-rw-rw-r--. 1 user user 271119851 May 2 12:35 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart~-rw-rw-r--. 1 user user 271119851 May 2 13:09 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart.backup–backup-dir-指定备份目录将当前的文件备份到指定的目录中，而不是默认的当前目录，默认是不会给文件增加后缀的，可以使用--suffix指定备份后缀，注意必须和--backup一同使用：12345# 将当前文件备份到backup目录下，如果目录不存在就创建rsync -r --backup --backup-dir ./backup /home/user/learn/linux_learn/scp/test ./# 指定备份文件后缀rsync -r --backup --backup-dir ./backup --suffix ".test" /home/user/learn/linux_learn/scp/test ./–existing-只更新目标端存在的文件12# 只更新当前目录下存在文件rsync -r --existing /home/user/learn/linux_learn/scp/test ./输出结果：1# 因为当前目录下没有和test目录下共有的文件，所以没有进行同步在当前目录下创建一个和远程目录中相同的文件test.txt，并在远程的test.txt中写入内容，而当前目录的test.txt为空：123456789101112# 当前目录-rw-rw-r--. 1 user user 0 May 2 13:32 test.txt# 远程目录-rw-rw-r--. 1 user user 271119851 May 1 23:59 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart-rw-rw-r--. 1 user user 69 May 2 13:32 test.txt# 同步rsync -r --existing /home/user/learn/linux_learn/scp/test ./# 实现了相同文件的同步-rw-rw-r--. 1 user user 69 May 2 13:35 test.txt–ignore-existing-只更新目标端不存在的文件和上面的--existing参数相反，--ignore-existing只更新当面不存在的文件：12345678910# 当前目录-rw-rw-r--. 1 user user 0 May 2 13:43 test.txt# 同步rsync -r --ignore-existing /home/user/learn/linux_learn/scp/test ./# 当前目录# 已存在的test.txt没有更新-rw-rw-r--. 1 user user 271119851 May 2 13:44 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart-rw-rw-r--. 1 user user 0 May 2 13:43 test.txt–remove-source-files-删除远程文件使用该选项后，远程已经更新成功的文件都会被删除，远程所有未传输或未传输成功的文件都不会被移除。未传输成功的原因有多种，如exclude排除了，&quot;quick check&quot;未选项该文件，传输中断等等。总之，显示在&quot;rsync -v&quot;被传输列表中的文件都会被移除。如下：1234567891011121314151617# 当前目录-rw-rw-r--. 1 user user 0 May 2 13:43 test.txt# 远程目录-rw-rw-r--. 1 user user 271119851 May 1 23:59 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart-rw-rw-r--. 1 user user 69 May 2 13:32 test.txt# 同步# 同步完成之后删除远程已经同步好的文件rsync -r -v --ignore-existing --remove-source-files /home/user/learn/linux_learn/scp/test ./# 当前目录-rw-rw-r--. 1 user user 271119851 May 2 13:50 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart-rw-rw-r--. 1 user user 0 May 2 13:43 test.txt# 远程目录# 同步完成的文件被删除了-rw-rw-r--. 1 user user 69 May 2 13:32 test.txt–exclude-指定排除规则上面使用--existing和--ignore-existing来仅对已经存在或者不存在的文件进行更新，实际上就是一种排除规则，如果希望对某一类文件的同步进行排除可以使用--exclude参数：123456789101112131415161718# 当前目录total 0# 远程目录-rw-rw-r--. 1 user user 271119851 May 2 13:59 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart-rw-rw-r--. 1 user user 69 May 2 13:32 test.txt# 同步# 排除所有txt后缀文件rsync -r -v --exclude "*.txt" /home/user/learn/linux_learn/scp/test ./sending incremental file listtest/B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepartsent 271153093 bytes received 32 bytes 180768750.00 bytes/sectotal size is 271119851 speedup is 1.00# 当前目录-rw-rw-r--. 1 user user 271119851 May 2 14:01 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart一个--exclude只能指定一条规则，要指定多条排除规则，需要使用多个--exclude选项，或者将排除规则写入到文件中，然后使用--exclude-from选项读取该规则文件除了--exclude排除规则，还有--include包含规则，顾名思义，它就是筛选出要进行传输的文件，所以include规则也称为传输规则。它的使用方法和--exclude一样。如果一个文件即能匹配排除规则，又能匹配包含规则，则先匹配到的立即生效，生效后就不再进行任何匹配最重要的一点是它的作用时间。当发送端敲出rsync命令后，rsync将立即扫描命令行中给定的文件和目录(扫描过程中还会按照目录进行排序，将同一个目录的文件放在相邻的位置)，这称为拷贝树(copy tree)，扫描完成后将待传输的文件或目录记录到文件列表中，然后将文件列表传输给接收端。而筛选规则的作用时刻是在扫描拷贝树时，所以会根据规则来匹配并决定文件是否记录到文件列表中(严格地说是会记录到文件列表中的，只不过排除的文件会被标记为hide隐藏起来)，只有记录到了文件列表中的文件或目录才是真正需要传输的内容。换句话说，筛选规则的生效时间在rsync整个同步过程中是非常靠前的，它会影响很多选项的操作对象，最典型的如--delete。rsync中的匹配规则以下是rsync中的规则种类，不解之处请结合下文的--delete分析：exclude规则：即排除规则，只作用于发送端，被排除的文件不会进入文件列表(实际上是加上隐藏规则进行隐藏)include规则：即包含规则，也称为传输规则，只作用于发送端，被包含的文件将明确记录到文件列表中hide规则：即隐藏规则，只作用于发送端，隐藏后的文件对于接收端来说是看不见的，也就是说接收端会认为它不存在于源端show规则：即显示规则，只作用于发送端，是隐藏规则的反向规则protect规则：即保护规则，该规则只作用于接收端，被保护的文件不会被删除掉risk规则：即取消保护规则，是protect的反向规则除此之外，还有一种规则是clear规则，作用是删除include/exclude规则列表–delete-得到和远程目录完全相同的目录使用”–delete”选项后，接收端的rsync会先删除目标目录(当前目录)下已经存在，但源端(远程)目录不存在的文件，也就是”多则删之，少则补之”：1234567891011121314151617181920212223# 当前目录-rw-rw-r--. 1 user user 0 May 2 14:17 test2.txt# 远程目录-rw-rw-r--. 1 user user 271119851 May 2 13:59 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart-rw-rw-r--. 1 user user 69 May 2 13:32 test.txt# 同步# 先删除当前目录中存在但是远程目录不存在的文件，然后进行同步rsync -r --delete -v /home/user/learn/linux_learn/scp/test ./sending incremental file list# 删除操作deleting test/test2.txttest/B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.fileparttest/test.txtsent 271153227 bytes received 51 bytes 108461311.20 bytes/sectotal size is 271119920 speedup is 1.00# 当前目录# test2.txt已经被删除-rw-rw-r--. 1 user user 271119851 May 2 14:19 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart-rw-rw-r--. 1 user user 69 May 2 14:19 test.txt--delete与--exclude联用，--exclude可以将某些文件排除在同步文件之外，而这些文件在被排除在同步文件之外后，当前目录存在的这些被排除的文件会不会被--delete删除是关键？结果是--exclude排除的文件不会被--delete删除：12345678910111213141516171819202122# 当前目录-rw-rw-r--. 1 user user 271119851 May 2 14:19 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart-rw-rw-r--. 1 user user 69 May 2 14:19 test.txt# 远程目录-rw-rw-r--. 1 user user 271119851 May 2 13:59 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart-rw-rw-r--. 1 user user 69 May 2 13:32 test.txt# 同步# 排除所有txt后缀的文件# 也就是说不会对当前目录中的txt文件依据远程文件进行同步rsync -v -r --delete --exclude "*.txt" /home/user/learn/linux_learn/scp/test ./sending incremental file listtest/B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepartsent 271153093 bytes received 32 bytes 180768750.00 bytes/sectotal size is 271119851 speedup is 1.00# 当前目录# 虽然txt文件没有没同步， 但是也没有被删除-rw-rw-r--. 1 user user 271119851 May 2 18:37 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart-rw-rw-r--. 1 user user 69 May 2 14:19 test.txt关于--exclude排除的文件不会被--delete删除的原理请参考这篇文章--delete与--existing和--ignore-existing结合使用时，文件不会被传输，但会删除receiver端额外多出的文件，个人理解其过程可能是先--existing得到的传输文件列表中都是当前文件和远程共有的文件，再次使用--ignore-existing时是仅传输不存在的文件，此时的文件列表不包含当前目录不存在的文件，所以不会进行传输，--delete会进行删除操作：12345678910111213141516171819202122232425# 创建文件$ mkdir a b$ touch a/&#123;1..4&#125;.txt$ touch b/a.log# 使用--delete$ rsync -nrv --delete a/ b/sending incremental file listdeleting a.log1.txt2.txt3.txt4.txt sent 118 bytes received 33 bytes 302.00 bytes/sectotal size is 0 speedup is 0.00 (DRY RUN)# 使用--delete并结合--existing、--ignore-existing$ rsync -nrv --existing --ignore-existing --delete a/ b/sending incremental file list# 只进行了删除操作deleting a.log sent 106 bytes received 21 bytes 254.00 bytes/sectotal size is 0 speedup is 0.00 (DRY RUN)–max-size-不传输大文件12345678910# 不同步大于100M的文件rsync -v -t -r --max-size "100m" /home/user/learn/linux_learn/scp/test ./sending incremental file listtest/test/test.txt# 忽略了链接文件skipping non-regular file "test/test2.txt"sent 267 bytes received 35 bytes 604.00 bytes/sectotal size is 271119932 speedup is 897748.12参考链接第2章 rsync(一)：基本命令和用法rsync命令《rsync同步的艺术》–linux命令五分钟系列之四十二rsync 使用示例]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scp-跨平台复制命令]]></title>
    <url>%2Fposts%2F2539.html</url>
    <content type="text"><![CDATA[这篇文章学习了Linux中用于远程复制命令scp，其主要功能包括：复制远程文件到当前服务器文件或目录、复制远程目录到当前服务器目录、复制当前文件到远程服务器文件或目录、复制当前目录到远程目录，其中重要和常用的参数是-P、-r；需要特别注意scp和cp以及rsnyc命令的区别。scp命令简介scp是secure copy的简写，用于在Linux下进行远程拷贝文件的命令，和它类似的命令有cp，不过 cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。当你服务器硬盘变为只读 read only system时，用scp可以帮你把文件移出来。与scp命令类似的工具有rsync，两者的功能类似，但是区别主要表现在资源占用和速度上：scp消耗资源少，不会提高多少系统负荷，在这一点上，rsync就远远不及它了rsync比scp会快一点，但当小文件多的情况下，rsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用scp命令格式12345scp [参数] [原路径] [目标路径]Usage: scp [-12346BCpqrv] [-c cipher] [-F ssh_config] [-i identity_file] [-l limit] [-o ssh_option] [-P port] [-S program] [[user@]host1:]file1 ... [[user@]host2:]file2scp参数说明参数说明-1强制scp命令使用协议ssh1-2强制scp命令使用协议ssh2-4强制scp命令只使用IPv4寻址-6强制scp命令只使用IPv6寻址-B使用批处理模式（传输过程中不询问传输口令或短语）-C允许压缩。（将-C标志传递给ssh，从而打开压缩功能）-p保留原文件的修改时间，访问时间和访问权限-q不显示传输进度条-r递归复制整个目录-v详细方式显示输出，scp和ssh(1)会显示出整个过程的调试信息，这些信息用于调试连接，验证和配置问题-ccipher 以cipher将数据传输进行加密，这个选项将直接传递给ssh-Fssh_config 指定一个替代的ssh配置文件，此参数直接传递给ssh-iidentity_file 从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh。-llimit 限定用户所能使用的带宽，以Kbit/s为单位-ossh_option 如果习惯于使用ssh_config(5)中的参数传递方式-Sprogram 指定加密传输时所使用的程序。此程序必须能够理解ssh(1)的选项-Pport 注意是大写的P, port是指定数据传输用到的端口号scp具体使用本地到远程复制文件命令形式：123456789101112# 通用形式scp [可选参数] source_file remote_username@remote_ip:target_file_or_folder# 在命令中指定传输目的服务器username# 复制到文件夹，文件名称保持不变$scp local_file remote_username@remote_ip:remote_folder# 复制到文件，复制并改名$scp local_file remote_username@remote_ip:remote_file# 在命令中不指定传输目的服务器username$scp local_file remote_ip:remote_folder$scp local_file remote_ip:remote_file如果在命令中指定了目的服务器的用户名，命令执行后只需要输入对应的用户密码；如果在命令中不指定目的服务器的用户名，命令执行后默认的用户名和当前服务器的用户名相同，输入密码12# 直接这么写会报错scp B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart username@166.111.152.101:/home/username/learn/linux_learn/scp直接按照上面的写法会出错：12ssh: connect to host 166.111.152.101 port 22: Connection refusedlost connection出错原因是没有指定port，而scp默认的port是22，如果端口号不是22的话就会出错，可以使用-P来指定端口号：1234567891011# 使用-P指定端口# 如果端口不是22# 复制到文件夹，文件名称保持不变scp -P 18231 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart username@166.111.152.101:/home/username/learn/linux_learn/scp # 需要输入目的服务器username的密码username@166.111.152.101's password: # 显示传输进度 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart 100% 259MB 8.6MB/s 00:30# 复制到文件，相当于复制并且修改文件名称scp -P 18231 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart username@166.111.152.101:/home/username/learn/linux_learn/scp/test.txt不指定目的服务器的用户名，那么默认目的服务器用户名和当前服务器用户名相同：1234567# 在命令中没有指定用户名scp -P 18231 B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart 166.111.152.101:/home/username/learn/linux_learn/scp/test.txt# 默认的用户名和当前服务器用户名相同local_username@166.111.152.101's password: # local_username和username不同，导致了权限错误scp: /home/username/learn/linux_learn/scp/test.txt: Permission denied复制目录使用-r参数来进行递归复制：12345# 在命令中指定目的服务器的username$scp -r local_folder remote_username@remote_ip:remote_folder# 不在命令中指定目的服务器的username，默认和当前服务器的username相同$scp -r local_folder remote_ip:remote_folder远程到本地123# 通用形式# 其实就是将前面的scp后面接着的远程和本地文件换个位置scp [可选参数] remote_username@remote_ip:source_file target_file_or_folder复制文件12345# 复制到本地目录scp -P 12000 wangjb@166.111.152.116:/Share/home/wangjb/username/data/test/B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart ./# 复制到本地文件，相当于复制并改名scp -P 12000 wangjb@166.111.152.116:/Share/home/wangjb/username/data/test/B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart ./test.txt复制目录12# 使用-r参数来进行递归复制scp -r -P 12000 wangjb@166.111.152.116:/Share/home/wangjb/username/data/test ./参考链接scp 跨机远程拷贝每天一个linux命令（60）：scp命令]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[read-从键盘或文件中获取输入]]></title>
    <url>%2Fposts%2F59492.html</url>
    <content type="text"><![CDATA[read是linux中获取键盘或文件输入并将结果保存在若干变量或数组中的命令，其主要参数包括：-p、-a、-d、-e、-i、-s、-t、-n、-r、-u；需要特别注意这里学习的关于使用管道符读取文件时涉及到的自定义变量生命周期的问题。read命令简介read命令可以获取键盘或者文件输入并赋值给变量或数组。read命令格式1234usage: read [-ers] [-a array] [-d delim] [-i text] [-n nchars] [-N nchars] [-p prompt] [-t timeout] [-u fd] [name ...]read参数说明参数说明-a后跟一个变量，该变量会被认为是个数组，然后给其赋值，默认是以空格为分割符-d后面跟一个标志符，其实只有其后的第一个字符有用，作为结束的标志。-p后面跟提示信息，即在输入前打印提示信息。-e在输入的时候可以使用命令补全功能。-i设置默认用于补全的prefix，必须和前面的-e一同使用才有用-n后跟一个数字，定义输入文本的长度，很实用。-r屏蔽\，如果没有该选项，则\作为一个转义字符(续行)，有的话\就是个正常的字符了。-s安静模式，在输入字符时不在屏幕上显示，例如login时输入密码。-t后面跟秒数，定义输入字符的等待时间。-u后面跟fd，从文件描述符中读入，该文件描述符可以是exec新开启的。read用法实例默认读取123456789101112#!/bin/bash# 默认情况下echo输出内容之后会换行# -n参数可以不换行echo -n "please input your name:"# 读取键盘输入，并保存在name变量中read name# 输出变量并正常退出echo "welcome !!! $name"exit 0输出：123./test.sh please input your name:test welcome !!! test如果在read之后没有使用参数进行接收键盘输入，则读取的值会存放在一个叫作 $REPLY 的环境变量中：123456#!/bin/bash# 没有指定接收键盘输入的变量read -p "please input your name and place:"# 默认会存放在$REPLY中echo "welcome $REPLY"exit 0输出：1234sh test_2.sh # 还是能正常输出please input your name and place:testwelcome test-p-输入提示语上面为了达到输入提示语的效果借助了echo命令，其实read命令的参数-p可以起到输入提示语的效果：12345678#!/bin/bash#echo -n "please input your name:"# 使用-p参数替换echo进行输入提示read -p "please input your name:" nameecho "welcome !!! $name"exit 0输出：1234./test.sh # 效果和使用echo是一样的 please input your name:test welcome !!! test一次读入多个变量变量的数目是根据read定义的变量数目决定的：read后面变量数目等于空格分隔的键盘输入数目1234567#!/bin/bash# read后面有两格变量name和city，所以可以读取两个变量# 使用空格分隔变量read -p "please input your name and city: " name cityecho "welcome !!! $name from $city"exit 0输出：12345./test.sh # 键盘输入两个使用空格分隔的字符# 传递给name和city变量 please input your name and city: test beijing welcome !!! test from beijingread后面变量数目小于空格分隔的键盘输入数目12345./test.sh # 键盘输入三个使用空格分隔的字符# 第一个空格分隔的字符传递给name，剩下的传递给另一个变量please input your name and city: test beijing haidianwelcome !!! test from beijing haidianread后面变量数目大于空格分隔的键盘输入数目12345./test.sh # 键盘输入一个使用空格分隔的字符# 字符传递给第一个变量name，剩下的变量为空please input your name and city: testwelcome !!! test from如果read后面的参数数目等于键盘输入的空格分隔的字符数目，则参数和输入一一对应如果read后面的参数数目大于键盘输入的空格分隔的字符数目，则不足的参数为空如果read后面的参数数目小于键盘输入的空格分隔的字符数目，则多余的空格分隔的字符赋值在最后一个变量-a-数组变量默认情况下，read将读取的字符存储在不同的变量中，如果想要储存在数组中，可以使用-a参数：123456789#!/bin/bash# -a参数后面是指定的存储数组的变量read -p "get var by array: " -a arrayfor i in $&#123;array[*]&#125;do echo "print $i"doneexit 0输出：12345sh a.sh get var by array: as ad af print as print ad print af-d-指定读取结束字符如果希望使用特定的字符来控制读取停止位置，可以使用-d参数，注意之后-d后面指定字符的第一个字符有用：12345678910#!/bin/bash# 这里-d参数指定了end字符# 其实只有开头的e起到作用了read -p "get var by array: " -d end -a arrayfor i in $&#123;array[*]&#125;do echo "print $i"doneexit 0输出：12345sh d.sh # 输入的时候遇到e字符就会停止接收# 然后直接执行后面的输出get var by array: ads ada eprint adsprint ada-t-输入等待时间设置输入等待时间，如果长时间不输入，read命令返回一个非零退出状态，可以结合if命令进行处理：1234567891011121314#!/bin/bashread -t 5 -p "please input your name within 5s:" name# 输出read命令的退出状态echo $?# if命令本来就是判断条件测试语句的退出状态# 如果非零则执行else的结果if read -t 5 -p "please input your name within 5s:" namethen echo "welcome !!! $name"else echo "sorry, too slow"fiexit 0输出：12345./test_t.sh # 不进行输入，返回退出状态为142please input your name within 5s:142# 使用if条件测试进行处理，输出自定义的内容please input your name within 5s:sorry, too slow-s-输入内容不显示默认的read会将输入显示在屏幕上，而在输入时可能会遇到一些信息不希望被人看到，这时可以使用-s参数(实际上，数据是显示的，只是 read 命令将文本颜色设置成与背景相同的颜色)：1234#!/bin/bash# 使用-s参数来不显示屏幕输入内容read -s -p "please input your code:" passwordecho "hehe, your password is $password"输出：123./test_s.sh # 注意这里不会换行please input your code:hehe, your password is test-n-输入字符长度read可以使用-n参数来控制读取的输入字符长度，当输入的字符数目达到预定数目时，自动退出，并将输入的数据赋值给变量：12345678910111213#!/bin/bashread -n 1 -p "Do you want to continue [Y/N]?" answercase $answer inY | y) echo "fine ,continue";;N | n) echo "ok,good bye";;*) echo "error choice";;esacexit 0输出：1234./n.sh # 本来准备输入yes，但是输入y之后就默认指定后面的echo命令# 压根没有给输入yes的可能性Do you want to continue [Y/N]?yfine ,continue输入长度达到-n指定的长度之后立即停止接受输入，并执行后续的命令，不管是不是还在输入.-u-读取文件内容读取文件内容常常使用在循环中：使用文件操作符：12345678910111213141516171819#! /bin/bash# 生成了编号为 3 的文件描述符# 这个编号可以自定义，默认的1和2分别为标准输出和标准错误输出exec 3&lt; test.txt # 使用-u 3来读取文件内容count=0while read -u 3 vardo # 使用了命令计算并赋值 let count=$count+1 echo "Line $count:$var"doneecho "finished"echo "Line no is $count" # 关闭3号文件描述符exec 3&lt;&amp;-输出：123456./u_1.sh Line 1:19248 Line 2:19247 Line 3:19246 finished Line no is 3使用管道：12345678910111213#!/bin/bashcount=1# 这里使用了管道而不是上面的文件描述符# 使用更为简单cat test.txt | while read linedo echo "Line $count:$line" let count=$count+1doneecho "finished"echo "Line no is $count"exit 0输出：1234567sh u_2.sh Line 1:19248 Line 2:19247 Line 3:19246 finished # 注意这里的line的计数为1，而不是3 Line no is 1上面最后输出的line计数为1而不是实际的3是由于管道导致的。我们知道，管道的两边一般需要新建进程，当执行完 while 语句后，新进程也就结束了，而脚本中 count 是新进程中的自定义变量，进程结束后该变量也就消失了（自定义变量的生命周期结束）。当脚本执行 echo 时，显示的 count 变量是脚本中第一行定义的变量的值，而不是 while 语句中的那个 count 变量了，因而输出的结果当然就是 1 了。重定向：为了使用简单(不使用文件描述符)，而又需要避免管道带来的问题，可以使用重定向：1234567891011#!/bin/bashcount=0while read linedo let count=$count+1 echo "Line $count:$line"# 这里使用了重定向，形式为cmd &lt; filedone &lt; test.txtecho "finished"echo "Line no is $count"exit 0输出：123456Line 1:19248Line 2:19247Line 3:19246finished# 这里输出了正确的结果3Line no is 3-r-屏蔽转移和续行常规情况下，在文件中使用\可以表示续行操作，这样在读取文件的时候也会将其当做续行符，从而将多行文本当成一行文本：123456789101112# 修改test.txt文件，加入续行符cat test.txt 19248 \ 19247 \ 19246# 执行前面的读取文件命令sh u_3.sh # 读取的结果都在同一行 Line 1:19248 19247 19246 finished Line no is 1如果需要忽略续行符\，可以使用read的-r参数：123456789101112#!/bin/bashcount=0# 加入-r参数表示忽略续行符while read -r linedo let count=$count+1 echo "Line $count:$line"# 这里使用了重定向，形式为cmd &lt; filedone &lt; test.txtecho "finished"echo "Line no is $count"exit 0输出：12345678sh u_4.sh # 忽略了续行符 # 当做3行读取 Line 1:19248 \ Line 2:19247 \ Line 3:19246 finished Line no is 3-e-输入补全在输入时进行tab补全功能：1234read -e -p "输入文件名:" str 输入文件名:test# 上面输入test之后按下两次tab键就可以输出当前目录下匹配test的文件信息test.sh test_s.sh test_t.sh test.txt-i-设置默认用于补全的prefix如果需要给变量设置默认用于补全的prefix，自动进行填充，需要使用read的-i参数，注意这个必须结合-e参数进行使用：123456789#!/bin/bash# 设置默认的prefix# 自动填充到输入，再结合tab进行补全test="test"# -i必须结合-e参数一同使用read -e -i "$test" -p "please input your name: " nameecho "welcome !!! $name"exit 0输出：1234sh i.sh # 与前面单独使用-e不同的是，这里的test是自动填充的prefixplease input your name: testtest.sh test_s.sh test_t.sh test.txt参考链接Linux read 命令read命令_Linux read命令：读取从键盘或文件输入的数据]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[time-计算命令执行花费的时间]]></title>
    <url>%2Fposts%2F21450.html</url>
    <content type="text"><![CDATA[这篇文章学习了linux中计算命令执行花费的时间的命令time，其输出包括三个时间real、user 和 sys，其中real是最终花费的时间；一般情况下real=user+sys，但如果命令是多核执行，也有可能是real_time&lt;user_time+sys_time，同时由于usr time+sys time不包括其他进程的执行时间和进程阻塞时间的，所以real_time&gt;user_time+sys_time也是非常有可能的；最后前后两次执行同一个命令，输出的时间可能不同，这是因为第一次执行命令系统会建立缓存使得第二次执行的时间缩短。time命令简介time命令用于统计执行指定命令所花费的总时间。time命令格式1time commandtime使用讲解123456time lstest1.txt test2.txtreal 0m0.002suser 0m0.001ssys 0m0.001s执行time ls之后会得到三个输出，real、user 和 sys，它们都代表什么含义呢？哪个才是 ls 命令的执行时间呢？下面我们就一起来看看这三个统计时间：real：从进程 ls 开始执行到完成所耗费的 CPU 总时间。该时间包括 ls 进程执行时实际使用的 CPU 时间，ls 进程耗费在阻塞上的时间（如等待完成 I/O 操作）和其他进程所耗费的时间（Linux 是多进程系统，ls 在执行过程中，可能会有别的进程抢占 CPU）。user：进程 ls 执行用户态代码所耗费的 CPU 时间。该时间仅指 ls 进程执行时实际使用的 CPU 时间，而不包括其他进程所使用的时间和本进程阻塞的时间。sys：进程 ls 在内核态运行所耗费的 CPU 时间，即执行内核系统调用所耗费的 CPU 时间。关于用户态和内核态：在内核态，代码拥有完全的，不受任何限制的访问底层硬件的能力。可以执行任意的CPU指令，访问任意的内存地址。内核态通常情况下，都是为那些最底层的，由操作系统提供的，可信可靠的代码来运行的。内核态的代码崩溃将是灾难性的，它会影响到整个系统。在用户态，代码不具备直接访问硬件或者访问内存的能力，而必须借助操作系统提供的可靠的，底层的APIs来访问硬件或者内存。由于这种隔离带来的保护作用，用户态的代码崩溃（Crash），系统是可以恢复的。我们大多数的代码都是运行在用户态的。现在，我们应该对这三个时间非常清楚了吧。ls 命令的真正执行时间是多少？答案就是 user+sys 的时间，但一般情况下，real=user+sys，因而我们就使用 real 的时间作为 ls 的执行时间了（注意，这里会有几个坑，我们将在后面进行介绍）。几个误区及解释real_time=user_time+sys_time如果你认为上面的等式一定成立的话，那么请你再理解一下前面关于 real、user和 sys 的介绍。在前面的表述中，real time 是包含了其他进程的执行时间和进程阻塞时间的，而 usr time+sys time 显然是不包括其他进程的执行时间和进程阻塞时间的。因此，real_time&gt;user_time+sys_time是非常有可能的。real_time&gt;user_time+sys_time根据上面的分析，这个关系式应该是成立的吧？嘿嘿，不一定哟。一般来说，在单核 CPU 系统中，这个关系式是成立的，但如果我们的系统是多核 CPU 的话，而有些程序是能够同时利用到多核 CPU 的计算能力的，在这种情况下这个关系式就不成立了。程序利用多核 CPU 的计算能力，可以并行地处理多项事务。就像一件工作，原来是一个 CPU 核去做，现在是两个 CPU 核并行做，那么完成同样工作所花费的总时间是 user_time+sys_time，而两个人并行做却能够在更短的时间内完成，耗时为 real_time。因此，这种情况下，便出现了 real_time&lt;user_time+sys_time 的情况。real_time&lt;user_time+sys_time多核情况下，real_time&lt;user_time+sys_time 是成立的，那单核呢？显然real_time&gt;user_time+sys_time是有可能成立的。上面的三个误区有点绕，但结论很重要，就是 real_time 和 user_time+sys_time 的大小关系不是恒久不变的，你需要了解你的 Linux 服务器，是单核，还是多核，这样才能正确地确定它们的关系。前后执行同样命令时间不同123456789101112131415# 第一次执行[roc@roclinux ~]$ time sudo find / -name mysql.sh /etc/profile.d/mysql.sh real 0m6.776s user 0m1.101s sys 0m1.363s# 第二次执行[roc@roclinux ~]$ time sudo find / -name mysql.sh/etc/profile.d/mysql.sh real 0m3.059s user 0m1.189s sys 0m1.435s咦，怎么 real 的时间缩减到了 3.059 秒了，生生少了 3 秒多钟，这又是怎么回事呢？为什么同样的命令在第二次执行时快这么多呢？这个现象跟 Linux 操作系统的运行原理有关，find 命令在第一次执行后，系统会对一些文件做缓存，在第二次执行时，就正好使用到了这些缓存中的数据，因此执行速度就变快了很多。/usr/bin/time—另一个计时命令默认使用123/usr/bin/time sleep 3s 0.00user 0.00system 0:03.00elapsed 0%CPU (0avgtext+0avgdata 2416maxresident)k 0inputs+0outputs (0major+183minor)pagefaults 0swaps通过上述命令可以发现这个命令的输出结果更加完善，不仅包括前面的time输出的user、sys、real等信息，还输出了关于CPU使用、文件读写的情况，所以比time更加实用.自定义输出内容%E: Elapsed real time (in [hours:]minutes:seconds).%e：(Not in tcsh.) Elapsed real time (in seconds).更多参数的说明信息：github123456# 输出时间/usr/bin/time --format='download took %E seconds' sleep 3s download took 0:03.00 seconds/usr/bin/time --format='download took %e seconds' sleep 3s download took 3.00 seconds参考链接time命令_Linux time命令：测量命令的执行时间或者系统资源的使用情况我使用过的Linux命令之time - 测定一个命令的资源使用情况time命令]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xargs-给其他命令传递参数]]></title>
    <url>%2Fposts%2F30003.html</url>
    <content type="text"><![CDATA[这篇文章学习了非常强大的能给其他命令传递参数的命令xargs，需要特别注意的是xargs传递的是后一个命令的参数，而管道符传递的是前一个命令的结果，一个字符串而已；主要学习了-a、-d、-n、-I、-t、-p、-L等参数，同时也学习了其与find命令结合进行很多很强大的操作！xargs命令简介xargs 是给命令传递参数的一个过滤器，也是组合多个命令的一个工具，其能够捕获一个命令的输出，然后传递给另外一个命令xargs 可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据xargs 也可以将单行或多行文本输入转换为其他格式，例如多行变单行，单行变多行xargs 默认的命令是 echo，这意味着通过管道传递给 xargs 的输入将会包含换行和空白，不过通过 xargs 的处理，换行和空白将被空格取代xargs 一般是和管道一起使用xargs和管道符通过上述功能的总结可以发现其实xargs命令和管道符的作用比较类似，两者都能够组合命令，但是两者在有些地方也存在区别或者不适用的地方，下面以cat命令为例：12345678910111213141516cat test1.txt# 测试文件1 I am test1 filecat test2.txt # 测试文件2 I am test2 file# 使用管道查看test1.txt的内容echo test1.txt |cat -# 输出的就是前面echo的结果 test1.txt# 而使用xargsecho test1.txt |xargs cat -# 可以查看test.txt的具体内容 I am test1 file总结一下关于管道符和xargs：管道符：把前一个命令原本要输出到屏幕的标准正常数据当作是后一个命令的标准输入xargs:将前一个命令的标准输出传递给下一个命令，作为它的参数可以发现，两者最主要的区别是，管道符处理的是直接前一个命令的结果(字符串)，而xargs是将前一个命令的结果作为参数，可以通过上面的示例感受一下一些需要处理文件名的命令，如rm、cp、mv等命令就需要使用xargs，而另一些可以直接处理具体文本内容的，就可以直接使用管道符，例如grepxargs命令格式123456Usage: xargs [OPTION]... COMMAND INITIAL-ARGS... # 注意，后面的command是在xargs的参数后面 front-command | xargs -option later-commandRun COMMAND with arguments INITIAL-ARGS and more arguments read from input.xargs命令参数参数完整参数说明-0--nullItems are separated by a null('\0'), not whitespace-a--arg-file=FILE从文件读取参数，而不是标准输入-d--delimiter=CHARACTER自定义参数定界符-E ENDEND出现位置之后的参数都会被忽略-I Rsame as --replace=R (R must be specified)-i--replace=[R]当xargs command 后有多个参数时，调整参数位置，R默认是{}-L,-l--max-lines=MAX-LINES从标准输入一次读取 num 行送给 command 命令-n--max-args=MAX-ARGS指定一次处理的参数个数-P--max-procs=MAX-PROCS修改最大的进程数，默认是1，为0时候为as many as it can-p--interactive当每次执行一个argument的时候询问一次用户-r--no-run-if-empty当xargs的输入为空的时候则停止xargs，不加这个参数会至少执行一次-s--max-chars=MAX-CHARSxargs 后面那个命令的最大命令行字符数(包括命令的长度、参数的长度等)--show-limitsShow limits on command-line length.-t--verbosePrint commands before executing themxargs使用实例-a-从文件中读取参数123echo "" |xargs -a test1.txt # 从文件中读取参数I am test1 file-d-设置参数定界符默认情况下xargs将其标准输入中的内容以空白(包括空格、Tab、回车换行等)分割成多个之后当作命令行参数传递给其后面的命令，也可以通过-d参数指定：1234567891011echo '11@22@33' | xargs# xargs默认命令是echo# 等同于echo '11@22@33' | xargs echo 11@22@33# 设置定界符为@# 注意echo命令要在xargs参数的后面echo '11@22@33' | xargs -d "@" echo11 22 33# 这个会有一个空行，不知道为什么# 如果不加-d参数就不会出现空行-n-每次处理的参数个数默认情况下，xargs后面的命令一次会处理所有的参数，可以通过-n参数指定每次处理的参数个数：12345678910echo "1 2 3 4 5 6 7 8 9" |xargs -n 3# 每次输出3个 1 2 3 4 5 6 7 8 9# 上面的执行过程等价于echo 1 2 3echo 4 5 6echo 7 8 9-E-指定停止解析参数字符1234# 指定停止解析参数字符为33# 包括33在内的后续字符都不会作为参数echo "11 22 33 44" |xargs -E "33" 11 22注意，是完全以-E指定的停止解析字符完全相同才可以：1234567# 包含233以及33，最终会在33的echo "11 22 233 44 33 55 66" |xargs -E "33" 11 22 233 44# 包含332以及33，最终会在33的echo "11 22 332 44 33 55 66" |xargs -E "33" 11 22 332 44注意，如果同时指定了-d参数，则-E参数会失效：12345# 指定-d的同时指定-E# -E失效echo "11 22 33 44 " | xargs -d " " -E "33"11 22 33 44 # 这里会出现一个空行-I-调整参数位置如果xargs后面的命令需要多个参数时，可以使用-I来指定替换字符串，并将其放在合适的位置，这个替换字符串在 xargs 扩展时会被替换掉，当 -I 与 xargs 结合使用，每一个参数命令都会被执行一次，例如将当前目录下所有的文件复制到另一个目录：12345678910111213141516171819202122232425# 首先这个任务直接使用管道符是不能完成的ls *.txt|cp - ../csplit/ cp: cannot stat ‘-’: No such file or directory# 如果直接使用xargs会报错# 默认是将前一个参数的结果放在了最后，而txt不是一个目录# 所以报错ls *.txt|xargs cp ../csplit/ cp: target ‘test2.txt’ is not a directory# 正确的用法# 使用-I参数指定&#123;&#125;为替换字符串# 在cp命令中使用&#123;&#125;指代xargs传递给cp的参数ls *.txt | xargs -I &#123;&#125; cp &#123;&#125; ../csplit/# 指定@为替换字符串ls *.txt | xargs -I @ cp @ ../csplit/# 执行命令之前先显示命令ls *.txt | xargs -t -I @ cp @ ../csplit/cp test1.txt ../csplit/ cp test2.txt ../csplit/# 等同于使用-i，只是-i有默认值，而-I没有默认值，必须要指定# -i默认就是&#123;&#125;，但是使用-I一定要加上&#123;&#125;ls *.txt | xargs -i cp &#123;&#125; ../csplit/还可以使用多次替换符：123456# 给所有的文件重命名# 加上后缀ls *.txt |xargs -I &#123;&#125; mv &#123;&#125; &#123;&#125;.bak# 加上前缀ls *.bak |xargs -I &#123;&#125; mv &#123;&#125; test_&#123;&#125;-I(-i)参数在命令需要多个参数且参数位置有限制时很适用，例如cp、mv命令-I(-i)指定的替换字符串用于表示xargs传递给命令的参数使用的位置-I没有默认值，必须要指定替换字符串，而-i有默认值为{}，可以不用指定当 -I 与 xargs 结合使用，每一个参数命令都会被执行一次，正如上面的ls *.txt | xargs -t -I @ cp @ ../csplit/是进行了两次的cp，而不是一次全部cp-t-在执行命令之前先输出命令1234ls *.txt | xargs -t -I @ cp @ ../csplit/# 显示会执行的命令 cp test1.txt ../csplit/ cp test2.txt ../csplit/-p-执行命令之前询问1234ls *.txt | xargs -p -I @ cp @ ../csplit/# 进行询问 cp test1.txt ../csplit/ ?...y cp test2.txt ../csplit/ ?...y-L-每次读取多少行作为输入123456789101112131415161718cat test1.txt# 测试文件 I am test1 file test2 test2cat test1.txt |xargs -L 1 echo# 每次读取一行作为输入 I am test1 file test2 test2cat test1.txt |xargs -L 2 echo# 每次读取二行作为输入# 两行的文本会合并 I am test1 file test2 test2cat test1.txt |xargs echo# 默认是所有行作为输入 I am test1 file test2 test2注意：-L 和 -n 参数是互相排斥的结合find命令1234567891011121314151617find ./ -name "*.txt"# find命令默认输出结果以\n进行换行 ./test1.txt ./test2.txt# 使用-print0表示在每条结果后面加上 '\0' 而不是换行find ./ -name "*.txt" -print0 ./test1.txt./test2.txt(base) [user@localhost xargs]$ # -print0参数刚好可以与xargs的-0参数对应# -0参数表示使用\0分割参数find ./ -name "*.txt" -print0 |xargs -0 ./test1.txt ./test2.txt# 使用-d参数也能达到一样的效果find ./ -name "*.txt" -print0 |xargs -d "\0" ./test1.txt ./test2.txt指定-print0以及设置-0参数的意义在于：如果查找到的文件名中包含空格，不使用-print0那么find命令会将结果使用\n隔开并输出，而xargs对空白进行分割，换行、空格、tab都属于空白，所以会将find文件名分成两部分，这样会出错；而使用-print0结合-0参数后，前后都是使用&#39;\0&#39;分割不同的文件名，这样可以保证文件名不被分割。下面是一个示例：123456789101112131415161718192021# 我们创建了3个日志文件, 且故意让文件名称中都含有空格[roc@roclinux ~]$ for((i=0;i&lt;3;i++)); do touch "test $&#123;i&#125;.log";done # 我们列出创建的文件[roc@roclinux ~]$ ls -1Ftest 0.logtest 1.logtest 2.log # 我们来运行xargs命令, 发现报错了# 因为xargs将test 0.log文件分割为了test和0.log文件，然后根本不存在这两个文件[roc@roclinux ~]$ find . -name '*.log' -print | xargs rmrm: cannot remove ‘./test’: No such file or directoryrm: cannot remove ‘1.log’: No such file or directoryrm: cannot remove ‘./test’: No such file or directoryrm: cannot remove ‘0.log’: No such file or directoryrm: cannot remove ‘./test’: No such file or directoryrm: cannot remove ‘2.log’: No such file or directory# 使用-print0和-0结合可以完美解决问题find . -name '*.log' -print0 | xargs -0 rm -fxargs 的-0选项不仅可以将分隔符从默认的空格变成 NULL，还会将单引号、双引号、反斜线等统统默认为是普通字符。所以说，-0选项特别适合处理命令参数中含有引号、空格、反斜线的情况。结合rm命令如果一次删除的文件太多，使用rm *.file可能会遇到Argument list too long错误，这是因为rm 可接受的参数长度达到了极限，这其实并非 rm的错，而是系统限制了参数的长度，通过下面的命令可以查看到系统的参数长度限制值：123# 查看系统对参数长度的限制getconf ARG_MAX 2097152解决办法可以是：1find . -name '*.file' -print | xargs rm -rf使用命令在所有文件中查找字符串1find ./ "*.log" |xargs grep -ri "test"参考链接xargs命令详解，xargs与管道的区别xargs命令_Linux xargs命令：一个给其他命令传递参数的过滤器Linux xargs 命令linux 管道传递参数xargs 用法]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[printf-格式化输出字符串]]></title>
    <url>%2Fposts%2F47162.html</url>
    <content type="text"><![CDATA[这篇文章学习了Linux中进行格式化输出字符串的命令printf，除了格式化输出之外还能对其进行修饰，这些修饰包括：指定输出宽度、填充不足位数、指定精度、使用多个格式替换符、对齐输出、输出正负值等。printf命令简介printf命令可以进行格式化输出字符串，这是其与echo命令不同的地方，也是其特征；printf 由 POSIX标准所定义，因此使用 printf 的脚本比使用 echo 移植性好；具体的功能包括：指定输出宽度填充不足位数指定精度使用多个格式替换符对齐输出输出正负值printf命令格式1printf %[输出最少宽度][．精度][类型] 字符或数字1 字符或数字2 ....背景echo可以用来进行字符串的输出，还可以用来输出转义字符，同时还可以用来进行带颜色的文字和背景输出，看到这里不禁要问：echo已经可以进行这么多的输出，为什么这里还要学习printf命令呢？其实原因很简单：学习csplit时，其中的-b参数指定前缀时也需要使用printf的格式输出使用seq命令产生序列时可以指定-f参数来进行格式化的输出这么多命令需要使用printf命令足以见得其重要性，其实printf的主要作用就是用来进行格式化输出，这是其区别于echo的最主要的特征，也是其存在的意义。在有些应用情境下，使用printf比使用echo命令更便捷：1234567891011121314151617# 将多个字符串换行输出# 使用echoecho -e "abc\ndef\nghi\njkl"# 需要在每个字符串后面添加\n转义字符 abc def ghi jkl# 使用printfprintf "%s\n" "abc" "def" "ghi" "jkl"# 可以直接使用"%s\n"为所有的字符串添加相同的格式 abc def ghi jklprintf格式替换符格式替换符的作用前面使用了&quot;%s\n&quot;来对每个输出进行格式化，那么&quot;%s\n&quot;是什么呢，为什么能够用来进行标准化呢？&quot;%s&quot;相当于一个替身演员，我们使用&quot;%s&quot;代替传入的参数，也就是说， &quot;%s&quot;代替了命令3中的abc，代替了def，代替了ghi，代替了每一个传入的参数，在我们指定的”格式”中，它代表了每一个传入的参数，所以，如果我们指定的格式为&quot;%s\n&quot;，当abc被当做参数传入printf命令时，printf就会把&quot;%s\n&quot;中的%s替换成abc，于是，abc就变成了我们指定的格式”abc\n”，最终printf输出的就是格式化后的”abc\n”，以此类推，每一段文本都被当做一个参数传入printf命令，然后按照指定的格式输出了，具体的工作机制可以使用参考下图：了解上面替身演员的作用机制之后，我们可以进行随心所欲的输出格式自定义，例如：123456789printf "(%s)\n" "abc" "def" "ghi" "jkl" (abc) (def) (ghi) (jkl)# 这里需要注意，默认情况下，printf输出的字符不会换行，如需换行需要指定\nprintf "(%s)\t" "abc" "def" "ghi" "jkl"(abc) (def) (ghi) (jkl) (base) [user@localhost seq]而 “替身演员”只是我给&quot;%s&quot;起的一个外号，它的真名叫 “格式替换符”，而printf中，”格式替换符”不只有”%s”一种，“%s”代替了每一个传入的参数，并将他们转化成了”字符串类型”，针对不同的需求，我们可以设置不同的格式替换符，例如，如果需要指定浮点型，可以使用%f，如果需要指定整数，可以使用%d。常用的格式替换符格式替换符说明%s字符串%f浮点格式（也就是我们概念中的float或者double）%e(%E)浮点格式，使用的是科学计数法，大小写e、E区别在于科学计数法的e是大写还是小写%g(%G)浮点数不显无意义的0%d、%i有符号十进制整数%b相对应的参数中包含转义字符时，可以使用此替换符进行替换，对应的转义字符会被转义%cASCII字符，显示相对应参数的第一个字符%o不带正负号的八进制值%u不带正负号的十进制值%x不带正负号的十六进制值，使用a至f表示10至15%X不带正负号的十六进制值，使用A至F表示10至15%%表示"%"本身printf转义字符关于转义字符的内容直接参考echo命令中的转义字符，两者基本上是一样的，具体链接printf格式替换符修饰信息指定输出位数使用形式：&quot;m%f\n&quot;，其中m表示输出的位数1234567891011121314151617181920printf "%f\n" 1 2 3 4# 默认情况下，浮点会保留小数点后6位 1.000000 2.000000 3.000000 4.000000printf "%1f\n" 1 2 3 4# 如果指定位数为1，默认输出还是原始长度 1.000000 2.000000 3.000000 4.000000printf "%10f\n" 1 2 3 4# 如果指定位数为10，则会使用空格填充两个 1.000000 2.000000 3.000000 4.000000通过上面的实例可以得出如下结论：如果指定的位数小于原始输出位数，则会保留原始长度如果指定的位数大于原始输出位数，默认会使用空格填充不足的位数填充不足位数使用形式：&quot;0m%f\n&quot;，其中m表示输出的位数，0表示不足位数使用0填充1234567891011121314151617181920printf "%10f\n" 1 2 3 4# 默认在输出位数没有达到指定时，会使用空格进行填充 1.000000 2.000000 3.000000 4.000000printf "%010f\n" 1 2 3 4# 可以指定使用0来填充不足的位数 001.000000 002.000000 003.000000 004.000000printf "%010s\n" 1 2 3 4# 好像不会对字符串进行填充0 1 2 3 4只能使用0或空格来进行填充对字符串&quot;%s&quot;好像不能使用0填充指定精度使用形式：&quot;.n%f\n&quot;，其中.n表示精度，也就是小数点后保留的位数；&quot;.n%d\n&quot;，如果用在整数上，会使用0填充1234567891011121314printf "%.4f\n" 1 2 3 4# 默认情况是保留六位小数# 这里指定保留四位小数 1.0000 2.0000 3.0000 4.0000# 对整数使用精度则会达到填充0的效果printf "%.4d\n" 1 2 3 4 0001 0002 0003 0004可以和前面的指定输出位数联合使用对整数使用精度则会达到填充0的效果使用多个格式替换符使用形式：&quot;%s %s\n&quot;，多个格式替换符连用，每个格式替换符代表一个参数1234567891011printf "%s %s\n" a b c d e f# 每两个进行一次换行 a b c d e fprintf "%s%s\n" a b c d e f# 每个参数之间的间隔取决于格式替换符之间的间隔 ab cd ef如果指定的”格式”中包含两个”格式替换符”，那么printf每次进行”格式化”操作时，就会传入两个参数，然后前一个参数对应第一个替换符，后一个参数对应第二个替换符，当本次格式化操作完成以后，再传入下一波参数，具体的工作机制如下：对齐输出使用形式：&quot;%-s&quot;，-表示左对齐，不加表示右对齐12345678910111213141516171819202122printf "%s %s %s %s \n" 姓名 性别 年龄 体重 苹果 男 18 60 香蕉 男 18 80# 输出上述信息得到的结果会存在错位现象# 原因：第一行宽度与后面每行对应的宽度不一致# 指定的话需要结合系统编码，utf-8中文是3个字节 姓名 性别 年龄 体重 苹果 男 18 60 香蕉 男 18 80printf "%6s %6s %4s %4s \n" 姓名 性别 年龄 体重 苹果 男 18 60 香蕉 男 18 80# 输出也没有对齐# 第二行的男字节宽度为3，会填补3个空格# 默认是右对齐 姓名 性别 年龄 体重 苹果 男 18 60 香蕉 男 18 80printf "%-6s %-6s %-4s %-4s \n" 姓名 性别 年龄 体重 苹果 男 18 60 香蕉 男 18 80# "-"表示左对齐# 不加的时候表示右对齐 姓名 性别 年龄 体重 苹果 男 18 60 香蕉 男 18 80输出正负值使用形式：&quot;%+d&quot;，+表示在正值前面加上+符号12345678printf "%-6s %-6s %-4s %-4d \n" 苹果 男 18 60 香蕉 男 18 -80苹果 男 18 60 香蕉 男 18 -80printf "%-6s %-6s %-4s %-+4d \n" 苹果 男 18 60 香蕉 男 18 -80# 加了+使得整数会显示+，可以个负数的输出保持对齐苹果 男 18 +60 香蕉 男 18 -80参考链接printf命令详解C语言 printf详解printf命令]]></content>
      <categories>
        <category>Linux</category>
        <category>常用内容总结</category>
      </categories>
      <tags>
        <tag>常用内容总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[seq-产生固定步长整数]]></title>
    <url>%2Fposts%2F1152.html</url>
    <content type="text"><![CDATA[这篇文章学习了linux中常用的用来产生等间隔序列的命令seq，主要参数包括-w、-f、-s。seq命令简介seq命令可以用来产生从指定起始位点到终止位点固定步长的数字序列，这个序列可以是整数也可以是小数，在输出结果时，可以进行等宽输出、格式化输出、指定分隔符输出。seq命令格式1234Usage: seq [OPTION]... LAST or: seq [OPTION]... FIRST LAST or: seq [OPTION]... FIRST INCREMENT LASTPrint numbers from FIRST to LAST, in steps of INCREMENT.seq命令参数参数完整参数说明-f--format=FORMAT使用printf 样式的浮点格式来进行格式化输出，不能和-w一起用-s--separator=STRING指定输出分隔符，默认是换行符\n-w--equal-width输出等宽的结果，默认使用0来补全，不能和-f一起用seq使用实例seq默认行为1234567891011121314151617181920212223242526seq 1 5# 如果给定两个数字，则一个为起始，一个为终止，步长为1 1 2 3 4 5seq 2 1# 没有输出结果，步长还是默认为1# 即使起始大于终止seq 5# 如果只指定一个数字，则这个数字是终止数字，起始和步长都为1 1 2 3 4 5seq 1 0.5 2# 步长可以为小数# 起始和终止都可以为小数 1.0 1.5 2.0可以设置负的INCREMENT：1234seq 2 -1 1# 生成递减的序列 2 1-s-设置序列输出间隔符12345678910seq 1 4# 默认是通过换行符隔开 1 2 3 4seq -s ',' 1 4# 指定分隔符为逗号 1,2,3,4如果想要指定带有特殊意义的字符作为分隔符，就需要结合echo输出转义字符:1234567seq -s "\t" 1 4# 如果直接指定\t，输出结果不能达到理想的效果 1\t2\t3\t4seq -s "$(echo -e "\t")" 1 4# 使用echo -e输出结果进行指定 1 2 3 4指定转义字符时需要借助echo -e进行输出，直接指定会出错-w-设置等宽输出123456789101112131415161718seq 5 10# 默认行为 5 6 7 8 9 10seq -w 5 10# 设置输出的序列等宽# 宽度由最大数字的宽度决定 05 06 07 08 09 10-w参数不能和-f参数连用-f-进行格式化输出123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960seq 1 5# 默认情况# 等同于seq -f "%g" 1 5# %g表示浮点数不显无意义的零"0" 1 2 3 4 5# 而真正的浮点数seq -f "%f" 1 5# 后面有很多没有意义的0 1.000000 2.000000 3.000000 4.000000 5.000000# 科学计数法seq -f "%e" 1 5 1.000000e+00 2.000000e+00 3.000000e+00 4.000000e+00 5.000000e+00# 指定输出位宽seq -f "%3g" 5 10# 输出的位宽为3，宽度不足3的使用空格填充 5 6 7 8 9 10# 使用0填充位宽不足的seq -f "%03g" 5 10# 这个如果将位宽设置为2，就和-w参数相同# 但是-w参数可以自动识别最大宽度 005 006 007 008 009 010# 添加前缀输出seq -f "dir%g" 1 5# 添加前缀为dir dir1 dir2 dir3 dir4 dir5# 结合其他命令使用mkdir $(seq -f 'dir%g' 1 5)更多关于printf格式化输出的内容请参考这篇文章其他可以得到指定步长整数的方法1234567891011121314151617181920for i in &#123;1..5&#125;;do echo $i;done# 使用花括号进行拓展# 默认步长为1 1 2 3 4 5for i in &#123;1..5..2&#125;;do echo $i;done# 指定步长为2 1 3 5for i in &#123;a..f..2&#125;;do echo $i;done# 还可以对字母进行指定步长输出 a c e参考链接seq命令详解seq命令]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shuf-随机打乱文件]]></title>
    <url>%2Fposts%2F50731.html</url>
    <content type="text"><![CDATA[这篇文章学习了linux中对文件以及命令行输入进行随机打乱的命令shuf，主要参数包括-e、-i、-n、-o、-r等。shuf简介shuf命令可以对文件或者命令行输入进行随机打乱并输出到标准输出或者指定的文件中，还可以指定shuf的随机模式(有放回地抽取)shuf命令格式12345Usage: shuf [OPTION]... [FILE] or: shuf -e [OPTION]... [ARG]... or: shuf -i LO-HI [OPTION]...Write a random permutation of the input lines to standard output.shuf参数参数完整参数说明-e--echo将参数作为输入信息进行随机打乱-i--input-range=LO-HI在特定范围内生成随机数-n--head-count=COUNT最大输出行数-o--output=FILE指定输出文件--random-source=FILEget random bytes from FILE-r--repeat有放回地抽取，需要结合-n参数一同使用-z--zero-terminated以0 结束行而非换行符shuf使用实例测试文件1234567891011cat test.txt line1 line2 line3 line4 line5 line6 line7 line8 line9 line10shuf默认行为123456789101112shuf test.txt# 将test.txt随机打乱 line2 line9 line7 line5 line10 line6 line8 line3 line4 line1-e-将参数作为输入信息进行随机打乱12345678910111213shuf -e "abc" "def" "mbc" mbc abc defa=badadb=asdfc=sadfashuf -e $a $b $c# 变量拓展 badad sadfa asdf-i-在指定范围内生成随机数12345678910111213# 生成1-10范围内的随机数# 包括1和10shuf -i 1-10 3 7 4 6 1 9 2 5 10 8-n-最大输出行数12345# 输出随机打乱后结果的其中3行shuf -n 3 test.txt line4 line5 line9-o-指定输出文件123456789101112131415# 随机打乱并将结果输出到shuf.txtshuf test.txt -o shuf.txt# 查看结果cat shuf.txt line7 line1 line4 line6 line2 line9 line3 line5 line8 line10-r-有放回地抽取1234567891011121314151617# 有放回的抽取15行结果shuf -n 15 -r test.txt line6 line9 line6 line9 line8 line1 line6 line1 line2 line1 line10 line7 line10 line10 line8-r参数一定要结合-n参数一同使用，不然会一直运行有放回地抽取，相当于死循环，一直输出参考链接给初学者看的 shuf 命令教程Linux shuf Command Tutorial for Beginners (with Examples)]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell中的float问题]]></title>
    <url>%2Fposts%2F61435.html</url>
    <content type="text"><![CDATA[这篇文章学习了shell中处理浮点比较相关的内容，主要学习了使用awk以及bc命令来进行浮点比较和运算，此前还有一篇相关的文章问题最近在编写shell脚本的时候发现shell中使用浮点的比较会出错：123if [[ 0.1 -lt 1 ]];then echo "yes";fi# 输出 -bash: [[: 0.1: syntax error: invalid arithmetic operator (error token is ".1")原因shell是不支持浮点的，不管是浮点的运算还是浮点的比较解决办法使用awkawk是支持浮点，包括运算以及比较：12345678910# 浮点运算awk 'BEGIN&#123;print 2/3&#125;' 0.666667# 比较awk 'BEGIN&#123;print 2&lt;3&#125;'# 真值返回1 1awk 'BEGIN&#123;print 2&gt;3&#125;'# 假则不输出结果使用bcbc是shell中支持浮点相关方法的命令：123456789101112# 浮点计算，如果结果小于0，会省略0，这里使用方法加上echo 'scale=2;a=2/3;if( length(a) == scale(a) ) print 0;print a ,"\n"' |bc# 输出结果，保留两位小数 0.66# 浮点的比较bc &lt;&lt;&lt; "0.2 &gt;= 0.3"# 假值返回0 0bc &lt;&lt;&lt; "0.2 &lt;= 0.3"# 真值返回1 1注意&lt;&lt;&lt;、&lt;&lt;、&lt;的区别：&lt;：表示从文件file中读取&lt;&lt;：表示从命令行读取到指定的结束字符&lt;&lt;&lt;：读取后面紧接的字符串具体的用法实例参考文章关于浮点运算可以参考之前的文章参考链接Floating Point Comparison in Shell Script]]></content>
      <categories>
        <category>Linux</category>
        <category>常用内容总结</category>
      </categories>
      <tags>
        <tag>常用内容总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据竞赛Top解决方案开源整理]]></title>
    <url>%2Fposts%2F49396.html</url>
    <content type="text"><![CDATA[这篇文章总结了机器学习中一些竞赛获奖者的经验总结或者代码(讲解)。纯数据竞赛2018科大讯飞AI营销算法大赛Rank1：https://zhuanlan.zhihu.com/p/478075442018 IJCAI 阿里妈妈搜索广告转化预测Rank1：https://github.com/plantsgo/ijcai-2018Rank2：https://github.com/YouChouNoBB/ijcai-18-top2-single-mole-solutionhttps://blog.csdn.net/Bryan__/article/details/80600189Rank3: https://github.com/luoda888/2018-IJCAI-top3Rank8: https://github.com/fanfanda/ijcai_2018Rank8: https://github.com/Gene20/IJCAI-18Rank9（第一赛季）：https://github.com/yuxiaowww/IJCAI-18-TIANCHIRank29: https://github.com/bettenW/IJCAI18_Tianchi_Rank29Rank41: https://github.com/cmlaughing/IJCAI-18Rank48: https://github.com/YunaQiu/IJCAI-18alimamaRank53: https://github.com/altmanWang/IJCAI-18-CVRRank60: https://github.com/Chenyaorui/ijcai_2018Rank81: https://github.com/wzp123456/IJCAI_18Rank94: https://github.com/Yangtze121/-IJCAI-18-2018腾讯广告算法大赛Rank3: https://github.com/DiligentPanda/Tencent_Ads_Algo_2018Rank6: https://github.com/nzc/tencent-contestRank7: https://github.com/guoday/Tencent2018_Lookalike_Rank7thRank9: https://github.com/ouwenjie03/tencent-ad-gameRank10: https://github.com/keyunluo/Tencent2018_Lookalike_Rank10thrank10（初赛）: https://github.com/ShawnyXiao/2018-Tencent-LookalikeRank11:https://github.com/liupengsay/2018-Tencent-social-advertising-algorithm-contesthttps://my.oschina.net/xtzggbmkk/blog/1865680Rank26: https://github.com/zsyandjyhouse/TencentAD_contestRank33: https://github.com/John-Yao/Tencent_Social_Ads2018Rank69: https://github.com/BladeCoda/Tencent2018_Final_Phrase_Prest2018高校大数据挑战赛-快手活跃用户预测Rank1：https://github.com/drop-out/RNN-Active-User-Forecasthttps://zhuanlan.zhihu.com/p/42622063Rank4: https://github.com/chantcalf/2018-Rank4-Rank13(初赛 a榜rank2 b榜rank5): https://github.com/luoda888/2018-KUAISHOU-TSINGHUA-Top13-SolutionsRank15: https://github.com/sunwantong/Kuaishou-Active-UserRank20: https://github.com/bigzhao/Kuaishou_2018_rank20thRank28(初赛 a榜rank1 b榜rank2)：https://github.com/YangKing0834131/2018-KUAISHOU-TSINGHUA-Top28-Solutions-https://github.com/FNo0/2018-KUAISHOU-Top282018JDATA 用户购买时间预测Rank9：https://zhuanlan.zhihu.com/p/451417992018 DF风机叶片开裂预警Rank2：https://github.com/SY575/DF-Early-warning-of-the-wind-power-system2018 DF光伏发电量预测Rank1：https://zhuanlan.zhihu.com/p/44755488?utm_source=qq&amp;utm_medium=social&amp;utm_oi=623925402599559168https://mp.weixin.qq.com/s/Yix0xVp2SiqaAcuS6Q049gAI全球挑战者大赛-违约用户风险预测Rank1：https://github.com/chenkkkk/User-loan-risk-prediction2016融360-用户贷款风险预测Rank7：https://github.com/hczheng/Rong3602016 CCF-020优惠券使用预测Rank1: https://github.com/wepe/O2O-Coupon-Usage-Forecast2016 ccf-农产品价格预测Rank2: https://github.com/xing89qs/CCF_ProductRank35: https://github.com/wqlin/ccf-price-prediction2016 ccf-客户用电异常Rank4: https://github.com/AbnerYang/2016CCF-StateGrid2016 ccf-搜狗的用户画像比赛Rank1: https://github.com/hengchao0248/ccf2016_sougouRank3: https://github.com/AbnerYang/2016CCF-SouGouRank5:https://github.com/dhdsjy/2016_CCFsougouhttps://github.com/dhdsjy/2016_CCFsougou2https://github.com/prozhuchen/2016CCF-sougouhttps://github.com/coderSkyChen/2016CCF_BDCI_Sougou2016 ccf-联通的用户轨迹RankX: https://github.com/xuguanggen/2016CCF-unicom2016 ccf-Human or RobotsRank6: https://github.com/pickou/ccf_human_or_robot菜鸟-需求预测与分仓规划Rank6:https://github.com/wepe/CaiNiao-DemandForecast-StoragePlaningRank10: https://github.com/xing89qs/TianChi_CaiNiao_Season2NLP2018 DC达观-文本智能处理挑战Rank1: https://github.com/ShawnyXiao/2018-DC-DataGrand-TextIntelProcessRank4: https://github.com/hecongqing/2018-daguan-competitionRank10: https://github.com/moneyDboat/data_grandRank18: https://github.com/nlpjoe/daguan-classify-2018RankX: https://github.com/yanqiangmiffy/daguan智能客服问题相似度算法设计——第三届魔镜杯大赛rank6：https://github.com/qrfaction/paipaidairank12：https://www.jianshu.com/p/827dd447daf9 https://github.com/LittletreeZou/Question-Pairs-MatchingRank16：https://github.com/guoday/PaiPaiDai2018_rank16Rank29: https://github.com/wangjiaxin24/daguan_NLP2018JD Dialog Challenge 任务导向型对话系统挑战赛Rank3: https://github.com/zengbin93/jddc_solution_4th2018CIKM AnalytiCup – 阿里小蜜机器人跨语言短文本匹配算法竞赛Rank2: https://github.com/zake7749/CloserRank12：https://github.com/Leputa/CIKM-AnalytiCup-2018Rank18: https://github.com/VincentChen525/Tianchi/tree/master/CIKM%20AnalytiCup%202018CVKaggle-TGSRank56：https://github.com/Gary-Deeplearning/TGS-Sal其他资料经验文章介绍featexp 一个帮助理解特征的工具包：http://www.sohu.com/a/273552971_129720Ask Me Anything session with a Kaggle Grandmaster Vladimir I. Iglovikov PDF：https://pan.baidu.com/s/1XkFwko_YrI5TfjjIai7ONQ大佬的Github植物 ：https://github.com/plantsgowepon ：https://github.com/wepeSnake：https://github.com/luoda888Drop-out：https://github.com/drop-out金老师的知乎：https://zhuanlan.zhihu.com/jlbookworm渣大：https://github.com/nzc郭大：https://github.com/guoday其他数据比赛资讯：https://github.com/iphysresearch/DataSciCompApacheCN 的kaggle资料链接：https://github.com/apachecn/kaggleKaggle top方案整理：https://github.com/EliotAndres/kaggle-past-solutions团队联系方式Smile qq:240485545 Email:smile.xuhc@gmail.comPUSH qq:1471386635 Email：1471386635@qq.comdive2space qq: 1124361357 Email:dive2space@qq.com来源链接竞赛|数据竞赛Top解决方案开源整理]]></content>
      <categories>
        <category>机器学习</category>
        <category>竞赛</category>
      </categories>
      <tags>
        <tag>开源代码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[anaconda管理软件和环境]]></title>
    <url>%2Fposts%2F42087.html</url>
    <content type="text"><![CDATA[这里写摘要，显示更好看开始于二级标题印象笔记里面的两篇文章斌斌师兄的脚本看看(里面有2和3兼容的问题)主要想解决的问题：环境备份的问题—多台集群环境如何管理软件冲突时如何将软件安装在另一个环境中，使用的时候是怎么使用的呢？—直接找到环境的bin目录，然后将给软件指定alias指定到这个目录？]]></content>
  </entry>
  <entry>
    <title><![CDATA[csplit-根据文本内容切割文件]]></title>
    <url>%2Fposts%2F1958.html</url>
    <content type="text"><![CDATA[这篇文章学习了Linux常用的按照文件内容来对文件进行分割的命令csplit，前面学习的split主要是根据文件的外部信息进行的分割；主要学习了利用pattern模式分割以及参数使用；patern方面主要学习了INTEGER、/REGEXP/[OFFSET]、{INTEGER}、{*}以及%REGEXP%[OFFSET]；参数主要学习了-f、-b、-n、-z、-k和-s。csplit简介csplit主要是依据文件内容来进行切割文件，与split不同，split只是依据文件外部的信息，包括大小、行数以及分割得到的文件数目来进行限制。csplit命令格式12Usage: csplit [OPTION]... FILE PATTERN...默认输出：每个小文件的字节数目文件名为xx00、xx01这种csplit options参数参数完整参数说明-b-suffix-format=FORMAT预预设的输出格式其文件名称为xx00，xx01等，用户可以通过改变format来改变输出的文件名；-f--prefix=PREFIX设置输出文件名的前缀，替换默认的xx-k--keep-files就算发生错误或者终止运行，也不删除已经输出的文件-n--digits=DIGITS默认输出的文件后缀为两位数字，这个参数可以修改后缀数字的数目，默认为2-s--quiet, --silent静默输出，不显示执行过程-z--elide-empty-files删除(不输出)空的输出文件csplit 匹配模式参数说明INTEGER使用行数来分割文件(不包括指定的行数)/REGEXP/[OFFSET]使用REGEXP来分割文件(不包含REGEXP行)%REGEXP%[OFFSET]跳过REGEXP之前的行，从之后的行开始输出{INTEGER}重复前面的pattern指定的次数{*}尽可能多地重复前面的patterncsplit匹配模式使用实例测试文件12345678910111213141516cat server.log SERVER-1 [con] 10.10.10.1 suc [con] 10.10.10.2 fai [dis] 10.10.10.3 pen [con] 10.10.10.4 suc SERVER-2 [con] 10.10.10.5 suc [con] 10.10.10.6 fai [dis] 10.10.10.7 pen [con] 10.10.10.8 suc SERVER-3 [con] 10.10.10.9 suc [con] 10.10.10.10 fai [dis] 10.10.10.11 pen [con] 10.10.10.12 sucINTEGER-按行划分1234567# 将文件分割为前一行 和 剩余的行# 注意是不包括数字指定的行csplit server.log 2# 输出划分得到的小文件的字节大小 9 273输出内容：123456-rw-rw-r--. 1 user user 9 Apr 13 16:15 xx00-rw-rw-r--. 1 user user 273 Apr 13 16:15 xx01# 不包括第二行cat xx00 SERVER-1也可以指定多个整数来分割：1234567# 指定多行文本进行划分# 分别得到0-1、2-4、5-6、7-最后的文件csplit server.log 2 5 7 9 63 30 180输出结果：12345678910-rw-rw-r--. 1 user user 9 Apr 13 16:20 xx00-rw-rw-r--. 1 user user 63 Apr 13 16:20 xx01-rw-rw-r--. 1 user user 30 Apr 13 16:20 xx02-rw-rw-r--. 1 user user 180 Apr 13 16:20 xx03# server.log的第2、3、4行cat xx01 [con] 10.10.10.1 suc [con] 10.10.10.2 fai [dis] 10.10.10.3 pen/REGEXP/[OFFSET]-匹配分割文件12345# 以SERVER-2为模式进行分割# 不包括模式匹配上的这一行csplit server.log /SERVER-2/ 93 189输出结果：12345678910-rw-rw-r--. 1 user user 93 Apr 13 16:43 xx00-rw-rw-r--. 1 user user 189 Apr 13 16:43 xx01# 不包括SERVER-2这一行cat xx00 SERVER-1 [con] 10.10.10.1 suc [con] 10.10.10.2 fai [dis] 10.10.10.3 pen [con] 10.10.10.4 suc匹配的是pattern第一次出现的位置：12345678910# 将上述测试文件的SERVER-3修改为SERVER-2csplit server.log /SERVER-2/ 93 189# 从第一次出现SERVER的位置分割# 因为SERVER出现在第一行，所以第一个文件大小为0csplit server.log /SERVER*/ 0 282第一次匹配输出结果：123456789101112# 从第一次匹配到SERVER-2的位置进行分割more xx01 SERVER-2 [con] 10.10.10.5 suc [con] 10.10.10.6 fai [dis] 10.10.10.7 pen [con] 10.10.10.8 suc SERVER-2 [con] 10.10.10.9 suc [con] 10.10.10.10 fai [dis] 10.10.10.11 pen [con] 10.10.10.12 suc指定模式之后的偏移：1234567# 以SERVER-2为模式进行分割# 并且向下移一行，这样就包括了模式匹配上的那一行# 偏移+表示向下多输出一行# -表示向上少输出一样csplit server.log /SERVER-2/+1 102 180偏移后的输出结果：123456SERVER-1[con] 10.10.10.1 suc[con] 10.10.10.2 fai[dis] 10.10.10.3 pen[con] 10.10.10.4 sucSERVER-2REGEXP匹配的是第一次出现的位置，只会在第一次出现位置处切割可以设置[OFFSET]来进行匹配行的上下偏移{INTEGER}和{*}-重复前面的pattern前面的/REGEXP/[OFFSET]只会在第一次出现pattern的位置进行切割，如果想要在所有的pattern匹配位置进行切割，可以借助{INTEGER}和{*}分别进行指定次数的重复pattern以及任意次数的重复。12345678910111213141516171819202122# 重复前面的pettern一次# 是重复一次，原本中有2个SERVER-2，只用重复一次即可csplit server.log /SERVER-2/ &#123;1&#125; 93 93 96# 如果设置重复两次会出错# 这种情况不会有结果输出# 可以借助后面的-k参数来保留结果csplit server.log /SERVER-2/ &#123;2&#125; 93 93 csplit: ‘/SERVER-2/’: match not found on repetition 2 96# 重复任意次数# 这样可以避免出现不知道pettern出现几次而出现错误csplit server.log /SERVER-2/ &#123;*&#125; 93 93 96结果输出：123456789101112131415161718(base) [user@localhost csplit]$ cat xx00 SERVER-1 [con] 10.10.10.1 suc [con] 10.10.10.2 fai [dis] 10.10.10.3 pen [con] 10.10.10.4 suc(base) [user@localhost csplit]$ cat xx01 SERVER-2 [con] 10.10.10.5 suc [con] 10.10.10.6 fai [dis] 10.10.10.7 pen [con] 10.10.10.8 suc(base) [user@localhost csplit]$ cat xx02 SERVER-2 [con] 10.10.10.9 suc [con] 10.10.10.10 fai [dis] 10.10.10.11 pen [con] 10.10.10.12 suc{INTEGER}和{*}可以有效解决/REGEXP/[OFFSET]只会对第一次出现的pattern进行分割的问题，重复指定的次数或者任意多次的pattern来对文件进行分割，从而达到将文件从所有出现pattern的位置进行切割的目的；%REGEXP%[OFFSET]-逃过模式之前的行12345# 跳过SERVER-2之前的行# 这里剩下的部分会包含模式这一行# 相当于把按模式分割的前面几个文件给删掉了csplit server.log %SERVER-2% 189输出结果：1234567891011cat xx00 SERVER-2 [con] 10.10.10.5 suc [con] 10.10.10.6 fai [dis] 10.10.10.7 pen [con] 10.10.10.8 suc SERVER-3 [con] 10.10.10.9 suc [con] 10.10.10.10 fai [dis] 10.10.10.11 pen [con] 10.10.10.12 suc这个和前面的/REGEXP/[OFFSET]相同，都可以指定[OFFSET]偏移量。csplit参数使用实例-f-设置输出前缀123# 指定输出文件前缀为test# 以SERVER-2为分割csplit server.log -f test /SERVER-2/输出结果：12345678910-rw-rw-r--. 1 user user 93 Apr 13 16:09 test00-rw-rw-r--. 1 user user 189 Apr 13 16:09 test01cat test00 # 输出内容不包含匹配行 SERVER-1 [con] 10.10.10.1 suc [con] 10.10.10.2 fai [dis] 10.10.10.3 pen [con] 10.10.10.4 suc-b-设置输出文件名称格式12345# 设置输出文件名格式之后加上.log后缀# 设置文件名称等宽，并使用0填充 --&gt; 02dcsplit server.log -f test -b "%02d.log" /SERVER-2/ 93 189输出结果：1234# 默认情况是两位的数字后缀，并且指定输出格式一定要是02d，用0填充# 如果不加0表示用0填充，那么会出现空格填充的情况-rw-rw-r--. 1 user user 93 Apr 13 18:22 test00.log-rw-rw-r--. 1 user user 189 Apr 13 18:22 test01.log-n-设置后缀数字数目123csplit server.log -f test -b "%03d.log" -n 3 /SERVER-2/93189输出结果：12-rw-rw-r--. 1 user user 93 Apr 13 18:28 test000.log-rw-rw-r--. 1 user user 189 Apr 13 18:28 test001.log-k-保留运行错误的结果文件12345678910111213141516# 前面的这个示例# 因为存在错误，所以不会得到结果文件csplit server.log /SERVER-2/ &#123;2&#125; 93 93 csplit: ‘/SERVER-2/’: match not found on repetition 2 96# 加上-k参数来避免这种情况# 依然后提示错误信息# 但是会得到能够正确分割的文件csplit server.log /SERVER-2/ &#123;2&#125; -k 93 93 csplit: ‘/SERVER-2/’: match not found on repetition 2 96输出结果：123-rw-rw-r--. 1 user user 93 Apr 13 18:33 xx00-rw-rw-r--. 1 user user 93 Apr 13 18:33 xx01-rw-rw-r--. 1 user user 96 Apr 13 18:33 xx02-z-不输出空文件12345678# 默认情况下会输出文件大小为0的文件csplit server.log /SERVER/ 0 282# 使用-z参数就不会输出空文件csplit server.log /SERVER/ -z 282参考链接csplit 命令csplit命令]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux查看CPU型号、内存、硬盘、版本等信息]]></title>
    <url>%2Fposts%2F9853.html</url>
    <content type="text"><![CDATA[这篇文章学习和总结了Linux中查看CPU型号、内存、硬盘、版本等信息的命令，便于日常使用查询。查看CPU信息CPU相关的信息都保存在/proc/cpuinfo文件中查看CPU个数1234cat /proc/cpuinfo | grep "physical id" | uniq | wc -l# 输出结果2查看CPU核数1234cat /proc/cpuinfo | grep "cpu cores" | uniq# 输出信息cpu cores : 6查看CPU型号123cat /proc/cpuinfo | grep 'model name' |uniq# 输出信息model name : Intel(R) Xeon(R) CPU E5-2620 v3 @ 2.40GHz查看内存信息内存信息保存在/proc/meminfo中查看内存大小1234cat /proc/meminfo | grep MemTotal# 输出内存大小，Kb为单位# 大小为49GMemTotal: 49219420 kB查看内存条数12345678910111213141516171819dmidecode |grep -A16 "Memory Device$"# 实验室集群安装了6个8G的，还有8个卡槽没有安装内存条 Memory Device Array Handle: 0x002F Error Information Handle: Not Provided Total Width: 72 bits Data Width: 64 bits Size: 8192 MB # 这里安装了一个8G的内存 Form Factor: DIMM Set: None Locator: DIMM1_CPU1 Bank Locator: Not Specified Type: Other Type Detail: Synchronous Speed: 2400 MHz Manufacturer: Undefined Serial Number: 131087AA Asset Tag: DIMM1_CPU1_AssetTag Part Number: KHX2400C15/8G查看硬盘信息查看硬盘大小1234567891011121314151617fdisk -l | grep Disk# 输出的硬盘信息 Disk /dev/sda: 1000.2 GB, 1000204886016 bytes, 1953525168 sectors Disk label type: dos Disk identifier: 0x00097e63 Disk /dev/sdb: 1000.2 GB, 1000204886016 bytes, 1953525168 sectors Disk label type: dos Disk identifier: 0x00091a2b Disk /dev/sdc: 4000.8 GB, 4000787030016 bytes, 7814037168 sectors Disk label type: dos Disk identifier: 0x00000000 Disk /dev/sdd: 2000.4 GB, 2000398934016 bytes, 3907029168 sectors Disk label type: dos Disk identifier: 0x4120a342 Disk /dev/mapper/centos-root: 53.7 GB, 53687091200 bytes, 104857600 sectors Disk /dev/mapper/centos-swap: 8388 MB, 8388608000 bytes, 16384000 sectors Disk /dev/mapper/centos-home: 1937.7 GB, 1937730699264 bytes, 3784630272 sectors其他常用命令查看当前操作系统版本信息12cat /proc/version Linux version 3.10.0-327.18.2.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.3 20140911 (Red Hat 4.8.3-9) (GCC) ) #1 SMP Thu May 12 11:03:55 UTC 2016查看版本当前操作系统内核信息123uname -a# 输出信息Linux localhost.localdomain 3.10.0-327.18.2.el7.x86_64 #1 SMP Thu May 12 11:03:55 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux查看当前操作系统发行信息1234cat /etc/redhat-release# 或cat /etc/centos-release CentOS Linux release 7.2.1511 (Core)查看硬盘使用情况12345678910111213df -hl Filesystem Size Used Avail Use% Mounted on /dev/mapper/centos-root 50G 48G 2.8G 95% / devtmpfs 24G 0 24G 0% /dev tmpfs 24G 0 24G 0% /dev/shm tmpfs 24G 17M 24G 1% /run tmpfs 24G 0 24G 0% /sys/fs/cgroup /dev/mapper/centos-home 1.8T 1.3T 519G 72% /home /dev/sdd1 1.8T 1.6T 156G 92% /datastore_2 /dev/sdc1 3.6T 419G 3.0T 13% /workstation /dev/sda1 494M 172M 323M 35% /boot tmpfs 4.7G 0 4.7G 0% /run/user/0 tmpfs 4.7G 0 4.7G 0% /run/user/1021关于结果：最后一列表示挂载点，也就是哪些目录使用的什么盘，第一个根目录是除了后面几个挂载点之外的剩余目录的大小，这里的比较小只有50G，并且占用比较大，可能经常会出现OSError: [Errno 28] No space left on device的问题，腾点空间就好了。参考链接Linux下查看CPU型号,内存大小,硬盘空间的命令(详解)]]></content>
      <categories>
        <category>Linux</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[split-按大小分割文件]]></title>
    <url>%2Fposts%2F41178.html</url>
    <content type="text"><![CDATA[这篇文章主要学习了linux中用于按照指定的需求(大小、行数、文件数目)拆分文件的命令split，是cat命令合并文件功能的反向操作；主要参数包括：-l、-b(K、M、T，默认是bytes)、-d(--numeric-suffixes=num)、文件前缀、-a(默认为2)、--additional-suffix=str、-n(N、K/N、l/N、l/K/N)、-e等参数；最后可以通过md5sum命令检查split之后cat命令合并得到的文件和原始文件相比是否完整。split简介Linux split命令可以将一个大文件分割成指定大小的很多个小文件，并且拆分速度非常的快，可以看成是cat命令合并文件功能的反操作，其主要特点：可以指定子文件的行数、大小以及子文件的数目指定大小以及子文件数目(默认情况)会对一行甚至是一个单词的内容进行切割，指定子文件数目中可以读这种情况进行调整指定的文件前缀名需要放在split文件之后，不然会报错，前缀默认为x可以指定文件的后缀(数字、字符)以及后缀的数目，后缀默认是从aa开始递增的两位字符可以文件添加统一的后缀(作为文件的拓展名)split命令格式12Usage: split [OPTION]... [INPUT [PREFIX]]Output fixed-size pieces of INPUT to PREFIXaa, PREFIXab, ..default size is 1000 linesdefault PREFIX is ‘x’With no INPUT, or when INPUT is -, read standard inputsplit参数参数完整参数说明-l--lines=NUMBER指定每多少行切成一个小文件-b--bytes=SIZE指定每多少字节切成一个小文件，单位可以是K、M、G-d--numeric-suffixes[=FROM]使用数字作为小文件名称的后缀，默认从0开始(使用from调节)--additional-suffix=SUFFIX小文件名称的后缀，默认从 aa 开始-n--number=CHUNKS分得的文件(CHUNKS)数目-a--suffix-length=N后缀长度，默认是2，也就是按 aa、ab、ac 这样的格式依次编号-C--line-bytes=SIZEput at most SIZE bytes of lines per output file-e--elide-empty-files在使用-n参数的时候不产生空的文件--verbose显示分割进度CHUNKS:参数说明N分割为N个文件K/N将N个文件中的第K个输出到标准输出l/N在不分割行的情况下分割为N个文件l/K/N将在不分割行的情况下得到的N个文件中的第K个输出到标准输出r/Nlike 'l' but use round robin distributionr/K/Nlikewise but only output Kth of N to stdout使用实例-l-指定每个文件的行数123456789101112131415161718192021222324252627282930# 查看文件的行数wc -l test.txt 51 test.txt# 每个文件10行split -l 10 test.txt # 生成6个文件 # 其中最后一个文件只有一行-rw-rw-r--. 1 user user 5779 Apr 12 00:10 test.txt-rw-rw-r--. 1 user user 338 Apr 12 00:12 xaa-rw-rw-r--. 1 user user 1900 Apr 12 00:12 xab-rw-rw-r--. 1 user user 1513 Apr 12 00:12 xac-rw-rw-r--. 1 user user 1523 Apr 12 00:12 xad-rw-rw-r--. 1 user user 432 Apr 12 00:12 xae-rw-rw-r--. 1 user user 73 Apr 12 00:12 xaf# 查看文件内容# 空行也算行# 换行算一行，不进行切割cat -n xac 1 2 In particular, Anaconda Distribution contains re-distributable, run-time, shared-library files from the Intel(TM) Math Kernel Library ("MKL binaries"). You are specifically authorized to use the MKL binaries with your installation of Anaconda Distribution. You are also authorized to redistribute the MKL binaries with Anaconda Distribution or in the conda package that contains them. Use and redistribution of the MKL binaries are subject to the licensing terms located at https://software.intel.com/en-us/license/intel-simplified-software-license. If needed, instructions for removing the MKL binaries after installation of Anaconda Distribution are available at http://www.anaconda.com. 3 4 Anaconda Distribution also contains cuDNN software binaries from NVIDIA Corporation ("cuDNN binaries"). You are specifically authorized to use the cuDNN binaries with your installation of Anaconda Distribution. You are also authorized to redistribute the cuDNN binaries with an Anaconda Distribution package that contains them. If needed, instructions for removing the cuDNN binaries after installation of Anaconda Distribution are available at http://www.anaconda.com. 5 6 7 Anaconda Distribution also contains Visual Studio Code software binaries from Microsoft Corporation ("VS Code"). You are specifically authorized to use VS Code with your installation of Anaconda Distribution. Use of VS Code is subject to the licensing terms located at https://code.visualstudio.com/License. 8 9 Cryptography Notice 10 ===================不足指定行数的也放在一个文件中空行也算行一行文本太长换行的话算一行，不进行切割-b-指定分割文件大小123456789101112131415161718192021# 默认单位是bsplit -b 1000 test.txt# 输出结果# 可以和前面-l的输出结果对比 -rw-rw-r--. 1 user user 1000 Apr 12 00:35 xaa -rw-rw-r--. 1 user user 1000 Apr 12 00:35 xab -rw-rw-r--. 1 user user 1000 Apr 12 00:35 xac -rw-rw-r--. 1 user user 1000 Apr 12 00:35 xad -rw-rw-r--. 1 user user 1000 Apr 12 00:35 xae -rw-rw-r--. 1 user user 779 Apr 12 00:35 xaf# 查看输出文件内容# 会对一行的内容甚至的一个单词进行切割cat xab DING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL ANACONDA, INC. BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Notice of Third Party Software Licenses ======================================= Anaconda Distribution contains open source software packages from third parties. These are available on an "as is" basis and subject to their individual license agreements. These licenses are available in Anaconda Distribution or at http://docs.anaconda.com/anaconda/pkg-docs. Any binary packages of thes不同于-l参数会保留行的完整性，-b参数会对同一行甚至同一个单词进行切割-b参数可以指定的单位包括K、M、G，默认是字节指定文件名前缀1234567891011121314# 文件的前缀需要放在split文件之后# 不然会报错split test -b 1000 test.txt split: cannot open ‘test’ for reading: No such file or directory# 分割得到的文件的前缀为test# 替换默认的前缀xsplit -b 1000 test.txt test -rw-rw-r--. 1 user user 1000 Apr 12 00:38 testaa -rw-rw-r--. 1 user user 1000 Apr 12 00:38 testab -rw-rw-r--. 1 user user 1000 Apr 12 00:38 testac -rw-rw-r--. 1 user user 1000 Apr 12 00:38 testad -rw-rw-r--. 1 user user 1000 Apr 12 00:38 testae -rw-rw-r--. 1 user user 779 Apr 12 00:38 testaf-d-指定数字后缀1234567891011121314151617181920# 默认的后缀的aa开始的# 这里指定以数字作为后缀# 默认后缀从0开始split -b 1000 -d test.txt -rw-rw-r--. 1 user user 1000 Apr 12 00:45 x00 -rw-rw-r--. 1 user user 1000 Apr 12 00:45 x01 -rw-rw-r--. 1 user user 1000 Apr 12 00:45 x02 -rw-rw-r--. 1 user user 1000 Apr 12 00:45 x03 -rw-rw-r--. 1 user user 1000 Apr 12 00:45 x04 -rw-rw-r--. 1 user user 779 Apr 12 00:45 x05# 设置后缀从10开始# 注意这里只能使用完整的参数形式，不能使用-d这种简写的split -b 1000 --numeric-suffixes=10 test.txt -rw-rw-r--. 1 user user 1000 Apr 12 00:49 x10 -rw-rw-r--. 1 user user 1000 Apr 12 00:49 x11 -rw-rw-r--. 1 user user 1000 Apr 12 00:49 x12 -rw-rw-r--. 1 user user 1000 Apr 12 00:49 x13 -rw-rw-r--. 1 user user 1000 Apr 12 00:49 x14 -rw-rw-r--. 1 user user 779 Apr 12 00:49 x15-a-设置后缀的长度12345678# 设置数字后缀的长度为3split -b 1000 -a 3 -d test.txt -rw-rw-r--. 1 user user 1000 Apr 12 00:47 x000 -rw-rw-r--. 1 user user 1000 Apr 12 00:47 x001 -rw-rw-r--. 1 user user 1000 Apr 12 00:47 x002 -rw-rw-r--. 1 user user 1000 Apr 12 00:47 x003 -rw-rw-r--. 1 user user 1000 Apr 12 00:47 x004 -rw-rw-r--. 1 user user 779 Apr 12 00:47 x005在文件名最后添加额外的后缀这里额外的后缀和前面的数字和默认字符串后缀不同，这个后缀是统一的(可以用来指定文件格式)，所有文件的都相同，而前面的数字和默认字符串后缀会随着文件数目而变化：12345678# 指定额外的后缀为testsplit -b 1000 --numeric-suffixes=10 --additional-suffix='.txt' test.txt -rw-rw-r--. 1 user user 1000 Apr 12 01:33 x10.txt -rw-rw-r--. 1 user user 1000 Apr 12 01:33 x11.txt -rw-rw-r--. 1 user user 1000 Apr 12 01:33 x12.txt -rw-rw-r--. 1 user user 1000 Apr 12 01:33 x13.txt -rw-rw-r--. 1 user user 1000 Apr 12 01:33 x14.txt -rw-rw-r--. 1 user user 779 Apr 12 01:33 x15.txt-n-设置文件的数目N-分割为N个文件以文件大小为依据平均分割为N个文件：1234567891011121314151617181920212223# 指定分割的文件数目为10# 注意和前面的-b、-l区分，这里的数目是固定的# 每个文件的大小是相同的，最后一个文件可能大或者小split -n 10 test.txt -rw-rw-r--. 1 user user 577 Apr 12 00:55 xaa -rw-rw-r--. 1 user user 577 Apr 12 00:55 xab -rw-rw-r--. 1 user user 577 Apr 12 00:55 xac -rw-rw-r--. 1 user user 577 Apr 12 00:55 xad -rw-rw-r--. 1 user user 577 Apr 12 00:55 xae -rw-rw-r--. 1 user user 577 Apr 12 00:55 xaf -rw-rw-r--. 1 user user 577 Apr 12 00:55 xag -rw-rw-r--. 1 user user 577 Apr 12 00:55 xah -rw-rw-r--. 1 user user 577 Apr 12 00:55 xai -rw-rw-r--. 1 user user 586 Apr 12 00:55 xaj# 查看其中一个文件内容，发现有些行被中间截断了cat xaf n are available at http://www.anaconda.com. Anaconda Distribution also contains cuDNN software binaries from NVIDIA Corporation ("cuDNN binaries"). You are specifically authorized to use the cuDNN binaries with your installation of Anaconda Distribution. You are also authorized to redistribute the cuDNN binaries with an Anaconda Distribution package that contains them. If needed, instructions for removing the cuDNN binaries after installation of Anaconda Distribution are available at http://www.anaconda.com. Anaconda Distribution also contains Visual Studio Code softw前面的-l、-b参数是按照指定行数或者大小来分割文件，文件数目不可控；而-n指定分割得到的文件数目，数目多少是可控的，并且除最后一个文件外，大小是相同的；-n参数会依据文件大小严格分割得到n个文件，可能会对同一行甚至是一个单词的内容进行切割，这个和-b参数类似;K/N-将N个文件中的第K个输出到标准输出12345678910111213141516# 直接在屏幕输出分割得到的10个文件中的第1个# 不会得到分割的文件# 还是会对行进行分割split -n 1/10 test.txt =================================== Anaconda End User License Agreement =================================== Copyright 2015, Anaconda, Inc. All rights reserved under the 3-clause BSD License: Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and thel/N-在不分割行的情况下分割为N个文件1234567891011121314# 在不分割行的情况下分割为10个文件# 分割得到10个文件，保持了行的连续性# 可能会得到大小为0的文件，不一定在最后split -n l/10 test.txt -rw-rw-r--. 1 user user 674 Apr 12 01:21 xaa -rw-rw-r--. 1 user user 940 Apr 12 01:21 xab -rw-rw-r--. 1 user user 624 Apr 12 01:21 xac -rw-rw-r--. 1 user user 691 Apr 12 01:21 xad -rw-rw-r--. 1 user user 0 Apr 12 01:21 xae -rw-rw-r--. 1 user user 781 Apr 12 01:21 xaf -rw-rw-r--. 1 user user 535 Apr 12 01:21 xag -rw-rw-r--. 1 user user 650 Apr 12 01:21 xah -rw-rw-r--. 1 user user 378 Apr 12 01:21 xai -rw-rw-r--. 1 user user 506 Apr 12 01:21 xaj-n l/N：在指定分割得到的文件数目的同时保留了每个文件中行的完整性-e-在使用-n参数的时候不产生空的文件123456789101112# 不输出空的文件# 对比前面的-n l/10，这里不产生空的文件(前面的xae)split -n l/10 -e test.txt -rw-rw-r--. 1 user user 674 Apr 12 01:30 xaa -rw-rw-r--. 1 user user 940 Apr 12 01:30 xab -rw-rw-r--. 1 user user 624 Apr 12 01:30 xac -rw-rw-r--. 1 user user 691 Apr 12 01:30 xad -rw-rw-r--. 1 user user 781 Apr 12 01:30 xae -rw-rw-r--. 1 user user 535 Apr 12 01:30 xaf -rw-rw-r--. 1 user user 650 Apr 12 01:30 xag -rw-rw-r--. 1 user user 378 Apr 12 01:30 xah -rw-rw-r--. 1 user user 506 Apr 12 01:30 xail/K/N-将在不分割行的情况下得到的N个文件中的第K个输出到标准输出12345678910111213141516# 类似于前面的K/N# 直接在屏幕输出分割得到的10个文件中的第1个# 只是保留了行的完整性split -n l/1/10 test.txt =================================== Anaconda End User License Agreement =================================== Copyright 2015, Anaconda, Inc. All rights reserved under the 3-clause BSD License: Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.cat合并并校验文件12345678910111213141516# 首先拆分为3个文件split -n 3 test.txt -rw-rw-r--. 1 user user 1926 Apr 12 09:37 xaa -rw-rw-r--. 1 user user 1926 Apr 12 09:37 xab -rw-rw-r--. 1 user user 1927 Apr 12 09:37 xac# 查看原始的md5值md5sum test.txt 27272b6fb8e9e0b22f8f0f5afc6e1346 test.txt# 合并文件cat xa&#123;a..c&#125; &gt;merged.txt# 查看合并后文件的md5值md5sum merged.txt 27272b6fb8e9e0b22f8f0f5afc6e1346 merged.txt对split之后的文件进行cat操作得到的文件md5值和原始文件相同参考链接split命令_Linux split命令：切割（拆分）文件]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[paste-合并文件]]></title>
    <url>%2Fposts%2F22454.html</url>
    <content type="text"><![CDATA[这篇文章学习了Linux中常用的合并文件命令paste，主要参数包括-s、-d，这个参数与cut命令的功能相反；与cat命令相比，paste默认按行合并，如果指定-s参数之后进行先在一个文件内部按指定的分隔符将所有的行合并，然后在所有的文件之间按列合并。paste简介paste命令主要用来将多个文件的内容合并(按行或者按列合并)，与cut命令完成的功能刚好相反。特点：可以指定分隔符可以先在一个文件内部按指定的分隔符将所有的行合并，然后在所有的文件之间按列合并注意与cat命令合并文件的区别：cat只能按列合并文件paste默认按行合并，如果指定-s参数之后进行先在一个文件内部按指定的分隔符将所有的行合并，然后在所有的文件之间按列合并paste命令格式12Usage: paste [OPTION]... [FILE]...Write lines consisting of the sequentially corresponding lines from each FILE, separated by TABs, to standard output.With no FILE, or when FILE is -, read standard input.paste命令参数参数完整参数说明-d--delimiters=LIST设置分割字符，默认为tab-s--serial先在文件内部按指定的分隔符合并行，然后所有的文件之间按列合并使用实例测试文件cat test1.txt123cat test2.txtabccat test3.txtdefgcat test4.txtacb默认连接文件123456# 默认情况下以tab分隔两个不同的文件内容paste test1.txt test2.txt |cat -T# cat -T显示tab为^I 1^Ia 2^Ib 3^Ic-d-设置分隔符12345# 设置分隔符为$paste -d '$' test1.txt test2.txt1$a2$b3$c-s-设置按列合并-s参数相当于先将每一个文件内部按照指定的分隔符进行合并，然后再和另一个文件按列进行合并：12345678paste -d '$' -s test1.txt test2.txt # 先在文件内部合并为一行，然后两个文件按列合并 1$2$3 a$b$c# 单独的一个文件内部合并为一行paste -d '$' -s test1.txt 1$2$3行数不同1234567# 用于合并的文件如果行数不同，则会空行# 不会报错paste test1.txt test3.txt 1 d 2 e 3 f g文件未排序12345paste test1.txt test4.txt # 文件未排序也能正常合并 1 a 2 c 3 bcat-按列合并12345678cat test1.txt test2.txt # 按列合并 1 2 3 a b c标准输出的特殊用法1234567891011[user@localhost paste]$ cat test1.txt |paste -123# 一个-表示从前面读取一行用于合并# 可以将一行看做一个文件[user@localhost paste]$ cat test1.txt |paste - -1 23 [user@localhost paste]$ cat test1.txt |paste - - -1 2 3]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows和Linux下使用tree命令]]></title>
    <url>%2Fposts%2F15686.html</url>
    <content type="text"><![CDATA[tree命令可以以树的形式显示文件夹的结构，便于观察，这里记录了在windows和linux平台上安装和使用tree命令的过程。windows下简便用法在git bash中使用命令：1cmd //c tree输出结果：1234567891011文件夹 PATH 列表卷序列号为 AC83-2977D:.├─docs│ ├─css│ ├─img│ ├─js│ ├─projects│ ├─resource│ └─software└─site注意：这个在cmd中不能使用windows下安装使用从这个链接中下载tree-1.5.2.2-setup.exe文件，然后进行常规的安装步骤，得到tree.exe文件;然后将安装得到的tree.exe文件复制到Git的安装目录：C:\Program Files\Git\usr\bin，注意一定要是usr下的这个目录，不能直接放在git下的bin目录;最后在git bash下就可以使用tree命令了，cmd下在执行tree-1.5.2.2-setup.exe安装之后就可以使用，不过使用局限较大，只有两个参数，默认显示所有的文件夹，可以使用/F显示所有的文件:12345678910111213141516171819# cmd下使用# 不加参数，直接指定文件夹tree chIA-drop 文件夹 PATH 列表 卷序列号为 CC05-4904 C:\USERS\user\DESKTOP\CHIA-DROP └─scripts# cmd下查看命令帮助tree /?以图形显示驱动器或路径的文件夹结构。TREE [drive:][path] [/F] [/A]# 可以发现cmd下只有两个参数 /F 显示每个文件夹中文件的名称。 /A 使用 ASCII 字符，而不使用扩展字符。# git bash下可以正常使用Linux下安装使用12# 需要管理员权限yum install tree -y常用参数12345678910111213141516171819202122tree命令行参数：-a 显示所有文件和目录。-A 使用ASNI绘图字符显示树状图而非以ASCII字符组合。-C 在文件和目录清单加上色彩，便于区分各种类型。-d 显示目录名称而非内容。-D 列出文件或目录的更改时间。-f 在每个文件或目录之前，显示完整的相对路径名称。-F 在执行文件，目录，Socket，符号连接，管道名称名称，各自加上"*","/","=","@","|"号。-g 列出文件或目录的所属群组名称，没有对应的名称时，则显示群组识别码。-i 不以阶梯状列出文件或目录名称。-I 不显示符合范本样式的文件或目录名称。-l 如遇到性质为符号连接的目录，直接列出该连接所指向的原始目录。-n 不在文件和目录清单加上色彩。-N 直接列出文件和目录名称，包括控制字符。-p 列出权限标示。-P 只显示符合范本样式的文件或目录名称。-q 用"?"号取代控制字符，列出文件和目录名称。-s 列出文件或目录大小。-t 用文件和目录的更改时间排序。-u 列出文件或目录的拥有者名称，没有对应的名称时，则显示用户识别码。-x 将范围局限在现行的文件系统中，若指定目录下的某些子目录，其存放于另一个文件系统上，则将该子目录予以排除在寻找范围外。参考链接Linux tree commandtree(1) - Linux man page]]></content>
      <categories>
        <category>折腾</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[科学上网]]></title>
    <url>%2Fposts%2F43102.html</url>
    <content type="text"><![CDATA[这篇文章主要记录了使用xx-net进行科学上网的过程，包括安装、配置以及在使用中遇到的问题和解决；最后采取的科学上网策略是在蓝灯流量没使用完之前先使用蓝灯，蓝灯流量用完之后再使用xx-net。工具XX-net：下载地址：地址使用chrome浏览器的配置：Chrome优点：免费操作简单速度还可以比较稳定蓝灯：下载地址：地址优点：稳定速度很快缺点：免费的只有500M流量每个月专业版的每年要差不多180RMB(好贵。。。)所以可以先使用蓝灯(快)啊，然后等蓝灯流量用完之后再使用xx-net(免费、慢)，感觉自己有点小机灵~~~~接下来主要介绍自己安装配置xx-net的步骤和遇到的问题，蓝灯的使用非常简单，直接下载安装就可以使用了。安装配置过程运行start.bat通过执行start.bat来完成xx-net的相关配置，我在这一步遇到了运行之后浏览器不能上网，并且出现错误，具体的解决方案见出现的问题及解决章节。正常运行完成之后就会得到一个XX-NET的快捷方式，以后只用双击这个快捷方式就可以运行xx-net。设置ipv6按照xx-net的说明，其主要有GAE_proxy和X-Tunnel，其中的GAE_proxy是免费的，有免费的当然使用免费的呀，但是其需要开启IPV6，可以按照官方给定的教程来来开启，官方提供了mac、windows(7、10)、Linux的不同开启说明，我这里选择了win10教程，其中有个简单的开启方法：运行code\default\gae_proxy\local\ipv6_tunnel目录下的enable_ipv6.bat文件即可开启，当然也可以手动开启，具体按照上面的教程。设置自动代理ipv6开启之后再按照官方设置代理教程的简单方法就可以访问谷歌等国外网站，但是这的缺点是：访问国内网站(不用科学上网的网站)也会很慢，这个时候就可以使用谷歌的浏览器插件来进行自动代理切换，这个在官方的设置代理教程中也有给出。具体步骤建议在谷歌浏览器插件中下载安装Proxy SwitchyOmega出现的问题以及解决启动start.bat之后浏览器不能上网，并且出现错误错误信息如下：首先，解决浏览器不能上网：chrome浏览器设置—&gt;高级设置—&gt;系统(打开代理设置)—&gt;局域网(LAN)设置按下图修改接下来，修改xx-net配置文件：XX-Net-3.13.1\data\launcher\config.yaml123456789modules: gae_proxy: &#123;auto_start: 1&#125; launcher: &#123;allow_remote_connect: 0, control_port: 8085, last_run_version: 3.13.1, proxy: pac&#125; smart_router: &#123;auto_start: 1&#125; # 将这里的1改为0 x_tunnel: &#123;auto_start: 1&#125;update: &#123;last_path: 'C:\Users\user\Desktop\XX-Net-3.13.1\XX-Net-3.13.1\code\default\launcher', postUpdateStat: noChange, uuid: a58ace84-79fb-4dd5-bcc8-8c36e7cde706&#125;然后再次执行start.bat即可其他工具和方法youtube上的这个视频介绍了一种使用shadowsocks的方法，使用免费的ip和密码来实现翻墙，具体的视频链接]]></content>
      <categories>
        <category>折腾</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之subprocess-子进程管理]]></title>
    <url>%2Fposts%2F57519.html</url>
    <content type="text"><![CDATA[这篇文章主要学习了Python常用模块subprocess，这是一个子进程管理的模块，用来在Python代码中执行操作系统级别的命令(如linux下的命令行命令)；主要学习了其中的两大API：subprocess.run()和subprocess.Popen()，学习了如何传递要执行的命令、如何获取命令的退出状态码(returncode)、输出(stdout)、错误(stderr)以及如何与进程交互等。subprocess模块简介subprocess模块主要用于创建子进程，并连接它们的输入、输出和错误管道，获取它们的返回状态。通俗地说就是通过这个模块，你可以在Python的代码里执行操作系统级别的命令，比如ipconfig、du -sh等等。subprocess模块替代了一些老的模块(os模块)和函数，比如：1234import osos.systemos.spawn*subprocess过去版本中的call()，check_call()和check_output()已经被run()方法取代了，run()方法为3.5版本新增。大多数情况下，推荐使用run()方法调用子进程，执行操作系统命令。在更高级的使用场景，你还可以使用Popen接口。其实run()方法在底层调用的就是Popen接口。运行外部命令-subprocess.run()命令形式123456import subprocesssubprocess.run(args, *, stdin=None, input=None,\ stdout=None, stderr=None, shell=False, \ timeout=None, check=False, \ encoding=None, errors=None)功能执行args参数所表示的命令，等待命令结束，并返回一个CompletedProcess实例，可以获取其属性的值。常用参数args：表示要执行的命令，必须是一个字符串或者字符串参数列表；推荐使用字符串列表的形式，这样可以处理任何必要的转义和引用参数(例如，允许文件名中的空格)，如果传递单个字符串，则shell必须为True，或者字符串必须简单地命名要执行的程序而不指定任何参数stdin、stdout和stderr：子进程的标准输入、输出和错误；其值可以是：subprocess.PIPE：表示为子进程创建新的管道subprocess.DEVNULL：表示使用os.devnull，类似于Linux下的/dev/nulls一个已经存在的文件描述符已经打开的文件对象None，这是默认的设置，表示什么都不做，结果输出到父进程上(如控制台)另外，stderr可以合并到stdout里一起输出timeout：设置命令超时时间；如果命令执行时间超时，子进程将被杀死，并弹出TimeoutExpired异常check：如果该参数设置为True，并且进程退出状态码不是0，则弹出CalledProcessError异常encoding：如果指定了该参数，则stdin、stdout和stderr可以接收或输出字符串数据，并以该编码方式编码，否则只接收或输出bytes类型的数据shell：如果该参数为True，将通过操作系统的shell执行指定的命令关于文件描述符和文件对象的区别：文件描述符是Linux内核为了高效管理已被打开的文件或其他输入输出资源所创建的索引，其是一个非负整数(通常是小整数)，用于指代被打开的文件或其他输入输出资源，所有执行I/O操作的系统调用都通过文件描述符；常见的，0(标准输入)、1(标准输出)、2(标准错误输出)都是文件描述符(程序开始时这三个就已经存在，然后打开的第一个文件的文件描述符就是3)。(In Unix and related computer operating systems, a file descriptor (FD, less frequently fildes) is an abstract indicator (handle) used to access a file or other input/output resource, such as a pipe or network socket.)每一个文件描述符会与一个打开文件相对应，同时，不同的文件描述符也会指向同一个文件。相同的文件可以被不同的进程打开也可以在同一个进程中被多次打开。系统为每一个进程维护了一个文件描述符表，该表的值都是从0开始的，所以在不同的进程中你会看到相同的文件描述符，这种情况下相同文件描述符有可能指向同一个文件，也有可能指向不同的文件。文件对象是在文件被打开时创建的一个file结构组成，Python的open()方法就是打开并创建一个文件对象使用实例args参数使用-字符串和字符串列表args参数表示要执行的命令，必须是一个字符串或者字符串参数列表；推荐使用字符串列表的形式，这样可以避免转义以及其他会被 shell 解析的特殊字符，如果传递单个字符串，则shell必须为True，或者字符串必须简单地命名要执行的程序而不指定任何参数:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import subprocess# 使用单个字符串subprocess.run("ls") test1.txt test2.txt test3.txt test4.txt test5.txt CompletedProcess(args='ls', returncode=0)subprocess.run('ls') test1.txt test2.txt test3.txt test4.txt test5.txt CompletedProcess(args='ls', returncode=0)# 当单个字符串中间有空格时会出错# 这样会导致命令不能传递参数subprocess.run('ls -l') or subprocess.run("ls -l") Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/home/user/miniconda3/envs/learn/lib/python3.7/subprocess.py", line 472, in run with Popen(*popenargs, **kwargs) as process: File "/home/user/miniconda3/envs/learn/lib/python3.7/subprocess.py", line 775, in __init__ restore_signals, start_new_session) File "/home/user/miniconda3/envs/learn/lib/python3.7/subprocess.py", line 1522, in _execute_child raise child_exception_type(errno_num, err_msg, err_filename) FileNotFoundError: [Errno 2] No such file or directory: 'ls -l': 'ls -l'# 使用单个字符串传递参数，并且制定shell=True# 就可以传递参数了subprocess.run("ls -l",shell=True) total 0 -rw-rw-r-- 1 user user 0 Apr 4 10:44 test1.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test2.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test3.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test4.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test5.txt CompletedProcess(args='ls -l', returncode=0)# 如果使用的是字符串列表，针对上面不能传递参数的行为就可以改善# 避免转义引号以及其他会被 shell 解析的特殊字符# 如果需要传递参数不需要指定shell=Truesubprocess.run(["ls", "-l"]) total 0 -rw-rw-r-- 1 user user 0 Apr 4 10:44 test1.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test2.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test3.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test4.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test5.txt CompletedProcess(args=['ls', '-l'], returncode=0)# 如果在使用字符串列表之后还指定了shell=True# 只会执行字符串列表的第一个# 字符串列表剩余部分会被舍弃subprocess.run(["ls", "-l"],shell=True) # 只输出了ls的结果 test1.txt test2.txt test3.txt test4.txt test5.txt CompletedProcess(args=['ls', '-l'], returncode=0)# 上面的返回结果都是CompletedProcess 实例，包含进程退出码以及输出等信息# 可以通过属性的方式获取其值test=subprocess.run("ls -l",shell=True) total 0 -rw-rw-r-- 1 user user 0 Apr 4 10:44 test1.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test2.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test3.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test4.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test5.txt# 获取命令的退出状态码test.returncode 0总结一下args参数的用法：如果命令是字符串，并且中间存在空格(给命令传递了参数)，必须加上参数shell=True，不然运行会出错，或者就是运行不加参数的命令(命令不能带空格)命令是字符串列表时，可以使用带参数的命令，这个时候就不能添加参数shell=True，如果加上了不会出错，但是参数就会失效，只会运行单独的命令在不加shell=True参数运行命令时，字符串不能存在空格(如[&quot;ls&quot; &quot;-l &quot;]、&quot;ls &quot;)，运行会报错以上均为linux上的情况，windows下使用更加随意，subprocess.run(&quot;ls -l&quot;)、subprocess.run(&quot;ls -l&quot;,shell=True)、subprocess.run([&quot;ls&quot;,&quot;-l&quot;])、subprocess.run([&quot;ls&quot;,&quot;-l&quot;],shell=True)运行结果都是一样的，都是正确答案。stdin、stdout和stderr-控制子进程的输入、输出和错误stdin、stdout和stderr：子进程的标准输入、输出和错误；其值可以是：subprocess.PIPE：表示为子进程创建新的管道subprocess.DEVNULL：表示使用os.devnull一个已经存在的文件描述符已经打开的文件对象None，这是默认的设置，表示什么都不做，结果输出到父进程上另外，stderr可以合并到stdout里一起输出默认情况下，由 run() 启动的进程的标准输入输出渠道绑定在了父进程上，那就意味着调用程序不能捕获命令的输出(前面实例中直接输出在控制台上)，给 stdout 和 stderr 参数传递 PIPE 可以捕获输出用于后续处理:123456789101112131415161718192021222324252627282930313233343536import subprocess# 为子进程创建新的管道completed = subprocess.run(['ls', '-1'],stdout=subprocess.PIPE)completed # 看到返回的这个实例中间的stdout中有结果 CompletedProcess(args=['ls', '-1'], returncode=0, stdout=b'test1.txt\ntest2.txt\ntest3.txt\ntest4.txt\ntest5.txt\n')# 不创建管道作为对比completed = subprocess.run(['ls', '-1']) test1.txt test2.txt test3.txt test4.txt test5.txtcompleted # 这个返回的实例中不包含结果，结果被输出在上面的屏幕上 CompletedProcess(args=['ls', '-1'], returncode=0)# 如果需要输出子进程的返回值# 同样是通过获取属性的值completed.stdout # 可以看到返回的结果是byte类型的 # 这是以为我们没有设置encoding参数 b'test1.txt\ntest2.txt\ntest3.txt\ntest4.txt\ntest5.txt\n'# 使用utf-8进行解码completed.stdout.decode('utf-8')) 'test1.txt\ntest2.txt\ntest3.txt\ntest4.txt\ntest5.txt\n'# 直接设置encoding参数就不用进行decode操作completed = subprocess.run(['ls', '-1'],stdout=subprocess.PIPE,encoding="utf-8")completed.stdout # 直接返回字符串，不用进行decode操作 'test1.txt\ntest2.txt\ntest3.txt\ntest4.txt\ntest5.txt\n'stdin-使用文件与进程交互前面提到stdin可以传入一个文件对象，这里将需要执行的命令写入文件，从而达到与进程通信的目的：123456789import subprocess# Linux下，先进入Python环境，然后执行文件中的命令fd = open("cmd.txt",'r')ret = subprocess.run("python", stdin=fd, stdout=subprocess.PIPE,shell=True)print(ret.stdout) # 输出结果 b'hello world\\!\n'fd.close()check-检查退出码check：如果该参数设置为True，并且进程退出状态码(CompletedProcess 的 returncode 属性)不是0，则弹出CalledProcessError异常:123456789101112131415161718192021222324import subprocess# 如果不使用check=True，即使命令错误了，也不会报错subprocess.run(['false']) # 命令执行不成功，返回状态码为1 CompletedProcess(args=['false'], returncode=1)# 增加check=True# 会对命令的执行状态码进行检查，如果执行失败(不为0)，就报错subprocess.run(['false'], check=True) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/home/user/miniconda3/envs/learn/lib/python3.7/subprocess.py", line 487, in run output=stdout, stderr=stderr) subprocess.CalledProcessError: Command '['false']' returned non-zero exit status 1.# 异常处理try: subprocess.run(['false'], check=True)except subprocess.CalledProcessError as err: print('ERROR:', err) # 输出 ERROR: Command '['false']' returned non-zero exit status 1.encoding-输入、输出、错误编码方式encoding：如果指定了该参数，则stdin、stdout和stderr可以接收或输出字符串数据，并以该编码方式编码，否则只接收或输出bytes类型的数据:123456789101112131415161718192021import subprocess# 为子进程创建新的管道completed = subprocess.run(['ls', '-1'],stdout=subprocess.PIPE)# 如果需要输出子进程的返回值# 同样是通过获取属性的值completed.stdout # 可以看到返回的结果是byte类型的 # 这是以为我们没有设置encoding参数 b'test1.txt\ntest2.txt\ntest3.txt\ntest4.txt\ntest5.txt\n'# 使用utf-8进行解码completed.stdout.decode('utf-8')) 'test1.txt\ntest2.txt\ntest3.txt\ntest4.txt\ntest5.txt\n'# 直接设置encoding参数就不用进行decode操作completed = subprocess.run(['ls', '-1'],stdout=subprocess.PIPE,encoding="utf-8")completed.stdout # 直接返回字符串，不用进行decode操作 'test1.txt\ntest2.txt\ntest3.txt\ntest4.txt\ntest5.txt\n'CompletedProcess类run()方法的返回值，表示一个进程结束了，CompletedProcess类有下面这些属性：属性说明args进程运行的命令，通常是个字符串列表或字符串returncode进程结束状态返回码，0表示命令成功状态，非0表示不成功stdout获取子进程的stdout，通常为bytes类型序列(可以通过ecoding参数调整)，None表示没有捕获值。如果在调用run()方法时，设置了参数stderr=subprocess.STDOUT，则错误信息会和stdout一起输出，此时stderr的值是Nonestderr获取子进程的错误信息，通常为bytes类型序列，None表示没有捕获值check_returncode()用于检查返回码。如果返回状态码不为零，弹出CalledProcessError异常subprocess.DEVNULL-抑制输出某些情况下，输出不应该被展示和捕获，使用 subprocess.DEVNULL 抑制输出流(Linux下的/dev/null)：1234567891011121314151617import subprocess# 'echo to stdout; echo to stderr 1&gt;&amp;2; exit 1'# 上述命令会有一个错误输出to stderrtry: completed = subprocess.run( 'echo to stdout; echo to stderr 1&gt;&amp;2; exit 1', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, )except subprocess.CalledProcessError as err: print('ERROR:', err)else: print('returncode:', completed.returncode) print('stdout is &#123;!r&#125;'.format(completed.stdout)) print('stderr is &#123;!r&#125;'.format(completed.stderr))输出结果：12345# 运行结果不会输出到控制台，应为设置了stdout和stderr# 同时也不会被捕获，因为设置的值为subprocess.DEVNULL，相当于是无底洞returncode: 1stdout is Nonestderr is Nonesubprocess.STDOUT-合并标准错误和输出12345678910111213try: completed = subprocess.run( 'echo to stdout; echo to stderr 1&gt;&amp;2; exit 1', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, )except subprocess.CalledProcessError as err: print('ERROR:', err)else: print('returncode:', completed.returncode) print('stdout is &#123;!r&#125;'.format(completed.stdout)) print('stderr is &#123;!r&#125;'.format(completed.stderr))输出结果：12345678# CompletedProcess类CompletedProcess(args='echo to stdout; echo to stderr 1&gt;&amp;2; exit 1', returncode=1, stdout=b'to stdout\nto stderr\n')returncode: 1# stdout合并了stderr的输出stdout is b'to stdout\nto stderr\n'# 输出在了stdout中，所以这里就成了空值stderr is None注意：错误输出合并输出在了stdout中之后，CompletedProcess实例中的 stderr属性就成了空值更高级的使用场景-subprocess.Popen()命令形式123456789import subprocesssubprocess.Popen(args, bufsize=-1, executable=None, \ stdin=None, stdout=None, stderr=None, preexec_fn=None, \ close_fds=True, shell=False, cwd=None, env=None, \ universal_newlines=None, startupinfo=None, \ creationflags=0, restore_signals=True, \ start_new_session=False, pass_fds=(), *, \ encoding=None, errors=None, text=None)功能功能与run()方法基本类同，但是它的返回值是一个Popen实例，而不是CompletedProcess实例常用参数大部分的参数都和subprocess.run()中的用法相同，这里列出几个这里特有的参数：cwd： 如果该参数值不是None，则该函数将会在执行这个子进程之前改变当前工作目录env： 用于指定子进程的环境变量，如果env=None，那么子进程的环境变量将从父进程中继承；如果env!=None，它的值必须是一个映射对象可调用方法方法描述Popen.poll()用于检查子进程（命令）是否已经执行结束，没结束返回None，结束后返回状态码Popen.wait(timeout=None)等待子进程结束，并返回状态码；如果在timeout指定的秒数之后进程还没有结束，将会抛出一个TimeoutExpired异常Popen.communicate(input=None, timeout=None)该方法可用来与进程进行交互，比如发送数据到stdin，从stdout和stderr读取数据，直到到达文件末尾Popen.send_signal(signal)发送指定的信号给这个子进程Popen.terminate()停止该子进程Popen.kill()杀死该子进程关于Popen.communicate()方法的说明：该方法中的可选参数 input 应该是将被发送给子进程的数据，或者如没有数据发送给子进程，该参数应该是None。input参数的数据类型必须是字节串，如果universal_newlines参数值为True(或者设置encoding参数)，则input参数的数据类型必须是字符串该方法返回一个元组(stdout_data, stderr_data)，这些数据将会是字节串或字符串(如果universal_newlines的值为True,或者设置encoding参数)如果在timeout指定的秒数后该进程还没有结束，将会抛出一个TimeoutExpired异常，捕获这个异常，然后重新尝试通信不会丢失任何输出的数据，但是超时之后子进程并没有被杀死，为了合理的清除相应的内容，一个好的应用应该手动杀死这个子进程来结束通信需要注意的是，这里读取的数据是缓冲在内存中的，所以，如果数据大小非常大或者是无限的，就不应该使用这个方法使用实例获取命令结果12345678910111213141516171819p = subprocess.Popen('ls -l', stdout=subprocess.PIPE, shell=True)p = subprocess.Popen(["ls","-l"], stdout=subprocess.PIPE)# 返回的p和前面的不同p &lt;subprocess.Popen object at 0x7fcddff8a710&gt;# 使用属性的read方法获取结果# read()只能读取一次，再读取一次结果就为空(读取一遍后文件指针到最后了)p.stdout.read() b'total 4\n-rw-rw-r-- 1 user user 23 Apr 4 15:26 cmd.txt\n-rw-rw-r-- 1 user user 0 Apr 4 10:44 test1.txt\n-rw-rw-r-- 1 user user 0 Apr 4 10:44 test2.txt\n-rw-rw-r-- 1 user user 0 Apr 4 10:44 test3.txt\n-rw-rw-r-- 1 user user 0 Apr 4 10:44 test4.txt\n-rw-rw-r-- 1 user user 0 Apr 4 10:44 test5.txt\n'# 使用decode将输出的字节串解码为utf-8，并输出结果print(p.stdout.read().decode("utf-8")) total 4 -rw-rw-r-- 1 user user 23 Apr 4 15:26 cmd.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test1.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test2.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test3.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test4.txt -rw-rw-r-- 1 user user 0 Apr 4 10:44 test5.txt修改工作目录cwd： 如果该参数值不是None，则该函数将会在执行这个子进程之前改变当前工作目录：123456p=subprocess.Popen('ls -l', stdout=subprocess.PIPE, shell=True,cwd="./test")# 使用decode将输出的字节串解码为utf-8，并输出结果print(p.stdout.read().decode("utf-8")) total 0 -rw-rw-r-- 1 user user 0 Apr 4 17:46 cwd1.txt -rw-rw-r-- 1 user user 0 Apr 4 17:46 cwd2.txtPopen.communicate()使用该方法返回一个元组(stdout_data, stderr_data)，这些数据将会是字节串或字符串(如果universal_newlines的值为True,或者设置encoding参数)与进程交互实例一：12345678910111213141516171819202122232425262728293031323334353637383940414243obj = subprocess.Popen(["python"], stdin=subprocess.PIPE, \ stdout=subprocess.PIPE, stderr=subprocess.PIPE)obj.stdin.write('print(1)') # 直接输入字符会报错 # 只能输入字节串 Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: a bytes-like object is required, not 'str'# 使用encoding或者universal_newlinesobj = subprocess.Popen(["python"], stdin=subprocess.PIPE, \ stdout=subprocess.PIPE, stderr=subprocess.PIPE,\ encoding="utf-8")obj = subprocess.Popen(["python"], stdin=subprocess.PIPE, \ stdout=subprocess.PIPE, stderr=subprocess.PIPE,\ universal_newlines=True)# 使用obj.stdin.write来传递命令obj.stdin.write('print(1)') # 输出写入的字符长度，Python3新增的功能 8obj.stdin.write('print(2)') # 输出写入的字符长度，Python3新增的功能 8obj.stdin.write('print(3)') # 输出写入的字符长度，Python3新增的功能 8# 获取返回的输出值和错误out,err = obj.communicate()out '1\n2\n'err ''# 使用obj.communicate()的input参数来传递命令out,err = obj.communicate(input='print(1)')out # 输出 '1\n'err ''与进程交互实例二：12345678910111213141516171819202122232425import subprocess# 'cat -; echo "to stderr" 1&gt;&amp;2'# 获取标准输入# 并且得到标准错误输出proc = subprocess.Popen( 'cat -; echo "to stderr" 1&gt;&amp;2', shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,)# 前面没有设置encoding参数以及universal_newlines参数# 这使用encode来将字符串编码为字节串msg = 'through stdin to stdout'.encode('utf-8')stdout_value, stderr_value = proc.communicate(msg)# 使用decode来将字节串解码为字符串print('pass through:', repr(stdout_value.decode('utf-8'))) # 输出标准输出，cat -的运行结果 pass through: 'through stdin to stdout'print('stderr :', repr(stderr_value.decode('utf-8'))) # 输出标准错误，echo "to stderr" 1&gt;&amp;2的运行结果 # 1&gt;&amp;2将标准输出重定向到标准错误输出 stderr : 'to stderr\n'实现shell中管道符的实例：123456789import subprocessp1 = subprocess.Popen(['ls', '-l'], stdout=subprocess.PIPE)# 这里设置p2的输入为p1的输出p2 = subprocess.Popen(['grep', 'cmd'], stdin=p1.stdout, stdout=subprocess.PIPE)out,err = p2.communicate()out b'-rw-rw-r-- 1 user user 23 Apr 4 15:26 cmd.txt\n'err总结如果不想将结果输出在控制台上，可以设置stdout和stderr来捕获输出如果希望命令的运行不成功(退出状态码不为0)就爆出异常，可以设置check=True以及异常捕获在使用字符串与进程通信以及输出结果的时候，需要注意设置encoding以及universal_newlines参数，不然命令会报错或者输出得到的是字节串参考链接subprocess — Subprocess managementsubprocessPython之系统交互（subprocess）11.2. subprocess — 生成多余进程Python标准库06 子进程 (subprocess包)]]></content>
      <categories>
        <category>Python</category>
        <category>常用模块</category>
      </categories>
      <tags>
        <tag>常用模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之字符串与字符编码(转载)]]></title>
    <url>%2Fposts%2F59082.html</url>
    <content type="text"><![CDATA[这是一篇转载的文章，围绕Python中的字符串与字符编码比较了Python2和Python3在字节与字符串默认行为上的不同、结合Python源代码执行过程讲解了设置字符编码的作用以及不同字符编码之间的转换，是一篇非常实用和重要的文章。前言Python中的字符编码是个老生常谈的话题，同行们都写过很多这方面的文章。有的人云亦云，也有的写得很深入。近日看到某知名培训机构的教学视频中再次谈及此问题，讲解的还是不尽人意，所以才想写这篇文字。一方面，梳理一下相关知识，另一方面，希望给其他人些许帮助。Python2的 默认编码 是ASCII，不能识别中文字符，需要显式指定字符编码；Python3的 默认编码 为Unicode，可以识别中文字符。相信大家在很多文章中都看到过类似上面这样“对Python中中文处理”的解释，也相信大家在最初看到这样的解释的时候确实觉得明白了。可是时间久了之后，再重复遇到相关问题就会觉得貌似理解的又不是那么清楚了。如果我们了解上面说的默认编码的作用是什么，我们就会更清晰的明白那句话的含义。相关概念字符与字节一个字符不等价于一个字节，字符是人类能够识别的符号，而这些符号要保存到计算的存储中就需要用计算机能够识别的字节来表示。一个字符往往有多种表示方法，不同的表示方法会使用不同的字节数。这里所说的不同的表示方法就是指字符编码，比如字母A-Z都可以用ASCII码表示（占用一个字节），也可以用UNICODE表示（占两个字节），还可以用UTF-8表示（占用一个字节）。字符编码的作用就是将人类可识别的字符转换为机器可识别的字节码，以及反向过程。UNICDOE才是真正的字符串，而用ASCII、UTF-8、GBK等字符编码表示的是字节串 。关于这点，我们可以在Python的官方文档中经常可以看到这样的描述&quot;Unicode string&quot; , &quot; translating a Unicode string into a sequence of bytes&quot;我们写代码是写在文件中的，而字符是以字节形式保存在文件中的，因此当我们在文件中定义个字符串时被当做字节串也是可以理解的。但是，我们需要的是字符串，而不是字节串。一个优秀的编程语言，应该严格区分两者的关系并提供巧妙的完美的支持。JAVA语言就很好，以至于了解Python和PHP之前我从来没有考虑过这些不应该由程序员来处理的问题。遗憾的是，很多编程语言试图混淆“字符串”和“字节串”，他们把字节串当做字符串来使用，PHP和Python2都属于这种编程语言。最能说明这个问题的操作就是取一个包含中文字符的字符串的长度：对字符串取长度，结果应该是所有字符的个数，无论中文还是英文对字符串对应的字节串取长度，就跟编码(encode)过程使用的字符编码有关了(比如：UTF-8编码，一个中文字符需要用3个字节来表示；GBK编码，一个中文字符需要2个字节来表示)注意：Windows的cmd终端字符编码默认为GBK，因此在cmd输入的中文字符需要用两个字节表示123456789101112&gt;&gt;&gt; # Python2&gt;&gt;&gt; a = 'Hello,中国' # 字节串，长度为字节个数 = len('Hello,')+len('中国') = 6+2*2 = 10&gt;&gt;&gt; b = u'Hello,中国' # 字符串，长度为字符个数 = len('Hello,')+len('中国') = 6+2 = 8&gt;&gt;&gt; c = unicode(a, 'gbk') # 其实b的定义方式是c定义方式的简写，都是将一个GBK编码的字节串解码（decode）为一个Uniocde字符串&gt;&gt;&gt; &gt;&gt;&gt; print(type(a), len(a))(&lt;type 'str'&gt;, 10)&gt;&gt;&gt; print(type(b), len(b))(&lt;type 'unicode'&gt;, 8)&gt;&gt;&gt; print(type(c), len(c))(&lt;type 'unicode'&gt;, 8)&gt;&gt;&gt;Python3中对字符串的支持做了很大的改动，具体内容会在下面介绍。编码与解码先做下科普：UNICODE字符编码，也是一张字符与数字的映射，但是这里的数字被称为代码点(code point), 实际上就是十六进制的数字。Python官方文档中对Unicode字符串、字节串与编码之间的关系有这样一段描述：Unicode字符串是一个代码点（code point）序列，代码点取值范围为0到0x10FFFF（对应的十进制为1114111）。这个代码点序列在存储（包括内存和物理磁盘）中需要被表示为一组字节(0到255之间的值)，而将Unicode字符串转换为字节序列的规则称为编码。这里说的编码不是指字符编码，而是指编码的过程以及这个过程中所使用到的 Unicode字符的代码点与字节的映射规则 。这个映射不必是简单的一对一映射，因此编码过程也不必处理每个可能的Unicode字符，例如：将Unicode字符串转换为ASCII编码的规则很简单–对于每个代码点：如果代码点数值&lt;128，则每个字节与代码点的值相同如果代码点数值&gt;=128，则Unicode字符串无法在此编码中进行表示（这种情况下，Python会引发一个UnicodeEncodeError异常）将Unicode字符串转换为UTF-8编码使用以下规则：如果代码点数值&lt;128，则由相应的字节值表示（与Unicode转ASCII字节一样）如果代码点数值&gt;=128，则将其转换为一个2个字节，3个字节或4个字节的序列，该序列中的每个字节都在128到255之间。简单总结：编码(encode) ：将Unicode字符串（中的代码点)转换特定字符编码对应的字节串的过程和规则解码(decode) ：将特定字符编码的字节串转换为对应的Unicode字符串(中的代码点)的过程和规则可见，无论是编码还是解码，都需要一个重要因素，就是 特定的字符编码 。因为一个字符用不同的字符编码进行编码后的字节值以及字节个数大部分情况下是不同的，反之亦然。Python中的默认编码Python源代码文件的执行过程我们都知道，磁盘上的文件都是以二进制格式存放的，其中文本文件都是以某种特定编码的字节形式存放的。对于程序源代码文件的字符编码是由编辑器指定的，比如我们使用Pycharm来编写Python程序时会指定工程编码和文件编码为UTF-8，那么Python代码被保存到磁盘时就会被转换为UTF-8编码对应的字节（encode过程）后写入磁盘。当执行Python代码文件中的代码时，Python解释器在读取Python代码文件中的字节串之后，需要将其转换为UNICODE字符串（decode过程）之后才执行后续操作。上面已经解释过，这个转换过程（decode，解码）需要我们指定文件中保存的字节使用的字符编码是什么，才能知道这些字节在UNICODE这张万国码和统一码中找到其对应的代码点是什么。这里指定字符编码的方式大家都很熟悉，如下所示：12# 用来指示Python解释器使用什么字符编码来将读取的字节串如何转化为字符串# -*- coding:utf-8 -*-默认编码那么，如果我们没有在代码文件开始的部分指定字符编码，Python解释器就会使用哪种字符编码把从代码文件中读取到的字节转换为UNICODE代码点呢？就像我们配置某些软件时，有很多默认选项一样，需要在Python解释器内部设置默认的字符编码来解决这个问题，这就是文章开头所说的“默认编码”。因此大家所说的Python中文字符问题就可以总结为一句话： 当无法通过默认的字符编码对字节进行转换时，就会出现解码错误(UnicodeEncodeError) 。Python2和Python3的解释器使用的默认编码是不一样的，我们可以通过sys.getdefaultencoding()来获取默认编码：123456789&gt;&gt;&gt; # Python2&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.getdefaultencoding()'ascii'&gt;&gt;&gt; # Python3&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.getdefaultencoding()'utf-8'因此，对于Python2来讲，Python解释器在读取到中文字符的字节码尝试解码操作时，会先查看当前代码文件头部是否有指明当前代码文件中保存的字节码对应的字符编码是什么。如果没有指定则使用默认字符编码&quot;ASCII&quot;进行解码导致解码失败，导致如下错误：1SyntaxError: Non-ASCII character '\xc4' in file xxx.py on line 11, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details对于Python3来讲，执行过程是一样的，只是Python3的解释器以&quot;UTF-8&quot;作为默认编码，但是这并不表示可以完全兼容中文问题。比如我们在Windows上进行开发时，Python工程及代码文件都使用的是默认的GBK编码，也就是说Python代码文件是被转换成GBK格式的字节码保存到磁盘中的。Python3的解释器执行该代码文件时，试图用UTF-8进行解码操作时，同样会解码失败，导致如下错误：1SyntaxError: Non-UTF-8 code starting with '\xc4' in file xxx.py on line 11, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details最佳实践创建一个工程之后先确认该工程的字符编码是否已经设置为UTF-8(编辑器设置中设置) —&gt;用于指示代码会使用什么字符编码方式保存为字节串为了兼容Python2和Python3，在代码头部声明字符编码：-*- coding:utf-8 -*- —&gt;用于指示Python解释器使用什么字符编码将读取的字节串转化为字符串另外地，在读写文件内容的时候也需要指定正确的文件字符的编码方式，这部分在Python系列之文件读写(转载)中有所讲解。Python2与Python3中对字符串的支持其实Python3中对字符串支持的改进，不仅仅是更改了默认编码，而是重新进行了字符串的实现，而且它已经实现了对UNICODE的内置支持，从这方面来讲Python已经和JAVA一样优秀。下面我们来看下 Python2与Python3中对字符串的支持有什么区别：Python2Python2中对字符串的支持由以下三个类提供:123class basestring(object) class str(basestring) class unicode(basestring)执行help(str)和help(bytes)会发现结果都是str类的定义，这也说明Python2中 str就是字节串，而后来的 unicode对象对应才是真正的字符串。12345678#!/usr/bin/env python# -*- coding:utf-8 -*-a = '你好'b = u'你好'print(type(a), len(a))print(type(b), len(b))输出结果：12(&lt;type 'str'&gt;, 6)(&lt;type 'unicode'&gt;, 2)Python3Python3中对字符串的支持进行了实现类层次的上简化，去掉了unicode类，添加了一个bytes类。从表面上来看，可以认为Python3中的str和unicode合二为一了。12class bytes(object)class str(object)实际上，Python3中已经意识到之前的错误，开始明确的区分字符串与字节。因此Python3中的 str已经是真正的字符串，而字节是用单独的bytes类来表示。也就是说，Python3默认定义的就是字符串，实现了对UNICODE的内置支持，减轻了程序员对字符串处理的负担。12345678910#!/usr/bin/env python# -*- coding:utf-8 -*-a = '你好'b = u'你好'c = '你好'.encode('gbk')print(type(a), len(a))print(type(b), len(b))print(type(c), len(c))输出结果：123&lt;class 'str'&gt; 2&lt;class 'str'&gt; 2&lt;class 'bytes'&gt; 4字符编码转换上面提到，UNICODE字符串可以与任意字符编码的字节进行相互转换，如图：那么大家很容易想到一个问题，就是不同的字符编码的字节可以通过Unicode相互转换吗？答案是肯定的。Python2中的字符串进行字符编码转换转换过程：1字节串--&gt;decode('原来的字符编码')--&gt;Unicode字符串--&gt;encode('新的字符编码')--&gt;字节串转换实例：123456789#!/usr/bin/env python# -*- coding:utf-8 -*-# Python2中的utf_8_a为字节串utf_8_a = '我爱中国'# 先将字节串decode为字符串，然后再将字符串encode为字节串gbk_a = utf_8_a.decode('utf-8').encode('gbk')# 再使用decode转化为字符串输出print(gbk_a.decode('gbk'))输出结果：1我爱中国Python3中的字符串进行字符编码转换因为Python3中定义的字符串默认就是unicode，因此不需要先解码，可以直接编码成新的字符编码，其过程为：1字符串--&gt;encode('新的字符编码')--&gt;字节串转换实例：1234567#!/usr/bin/env python# -*- coding:utf-8 -*-utf_8_a = '我爱中国'gbk_a = utf_8_a.encode('gbk')print(gbk_a.decode('gbk'))输出结果：1我爱中国最后需要说明的是，Unicode不是有道词典，也不是google翻译器，它并不能把一个中文翻译成一个英文。正确的字符编码的转换过程只是把同一个字符的字节表现形式改变了，而字符本身的符号是不应该发生变化的，因此并不是所有的字符编码之间的转换都是有意义的。怎么理解这句话呢？比如GBK编码的“中国”转成UTF-8字符编码后，仅仅是由4个字节变成了6个字节来表示，但其字符表现形式还应该是“中国”，而不应该变成“你好”或者“China”。文章来源Python中的字符串与字符编码]]></content>
      <categories>
        <category>Python</category>
        <category>其他技巧整理</category>
      </categories>
      <tags>
        <tag>其他技巧整理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之覆盖之前输出的内容]]></title>
    <url>%2Fposts%2F38536.html</url>
    <content type="text"><![CDATA[这篇文章学习了使用Python输出时进行覆盖输出(覆盖上一次的运行结果)，关键点在于：在要输出的字符前加上carriage return symbol &#39;\r&#39;、写入操作的时候不能有换行操作、字符串后增加一定的空格字符。问题来源在学习sys模块中的sys.stdout.write()方法时，看别人的博客提供了一个实现百分比进度条的程序，其实现如下：12345678910111213141516import sysimport timedef bar(num, total): rate = num / total rate_num = int(rate * 100) r = '\r[%s%s]%d%%' % ("="*num, " "*(100-num), rate_num, ) sys.stdout.write(r) # 使用flush将缓存区数据立即写入 sys.stdout.flush()if __name__ == '__main__': for i in range(0, 101): time.sleep(0.1) bar(i, 100)结果输出：123# 结果在输出的时候后面的输出会覆盖之前的输出# 而不是重新一行显示[====================================================================================================]100%而当我使用print()进行输出时：12345678910111213def bar(num, total): rate = num / total rate_num = int(rate * 100) r = '\r[%s%s]%d%%' % ("="*num, " "*(100-num), rate_num, ) print(r) # 使用flush将缓存区数据立即写入 sys.stdout.flush()if __name__ == '__main__': for i in range(0, 101): time.sleep(0.1) bar(i, 100)输出结果：123# 发现没有进行覆盖，虽然功能差不多，但是这样很占空间[ ]0%[= ]1%鉴于上述两种输出模式的差别，我就想知道是什么控制了这种覆盖的输出。问题的原因问题的原因在于：r = &#39;\r[%s%s]%d%%&#39; % (&quot;=&quot;*num, &quot; &quot;*(100-num), rate_num, )中的\r写入操作的时候没有换行：sys.stdout.write(r)最后没有+&#39;\n&#39;字符串后增加一定的空格字符解释：Prefix your output with carriage return symbol ‘\r’ and do not end it with line feed symbol ‘\n’. This will place cursor at the beginning of the current line, so output will overwrite previous its content. Pad it with some trailing blank space to guarantee overwrite：12sys.stdout.write('\r' + str(hpi) + ' ' * 20)sys.stdout.flush() # important所以我上面直接使用print(r)的错误在于写入操作的时候有了换行操作，这是 print()的默认行为，关于print()请参考这篇文章正确写法：123456789101112131415161718import sysimport timedef bar(num, total): rate = num / total rate_num = int(rate * 100) r = '\r[%s%s]%d%%' % ("="*num, " "*(100-num), rate_num, ) # sys.stdout.write(r) # 或者使用 print(r,end='') # 使用flush将缓存区数据立即写入 sys.stdout.flush()if __name__ == '__main__': for i in range(0, 101): time.sleep(0.1) bar(i, 100)参考链接python overwrite previous line]]></content>
      <categories>
        <category>Python</category>
        <category>其他技巧整理</category>
      </categories>
      <tags>
        <tag>其他技巧整理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之Python3的sys.stdout.write()返回字符长度]]></title>
    <url>%2Fposts%2F23402.html</url>
    <content type="text"><![CDATA[这篇文章主要记录了自己在Python3中使用sys.stdout.write()时发现会返回写入的字符长度，进而了解到Python3中文件对象的写入操作File.write()都会返回写入的字符长度，同时针对这种问题提出了自己的解决方法，将字符长度赋值给另一个变量，不让其输出即可。问题来源在学习sys模块中的sys.stdout.write()方法时，看别人的博客提供了一个实现百分比进度条的程序，其实现如下：1234567891011121314151617181920import sysimport timedef bar(num, total): rate = num / total rate_num = int(rate * 100) # \r会影响flush() # 不加的话输出结果不会显示在同一行，也不会对齐 r = '\r[%s%s]%d%%' % ("="*num, " "*(100-num), rate_num, ) # 这里使用的是sys.stdout.write(r) # 也可以使用print(i,end='') sys.stdout.write(r) # 使用flush将缓存区数据立即写入 sys.stdout.flush()if __name__ == '__main__': for i in range(0, 101): time.sleep(0.1) bar(i, 100)输出结果：1[====================================================================================================]100%我觉得有些复杂，想将其改为不使用函数的形式，具体如下：12345for num in range(0, 101): time.sleep(0.1) r = '\r[%s%s]%d%%' % ("="*num, " "*(100-num), num) sys.stdout.write(r) sys.stdout.flush()结果输出如下：1[= ]1%105发现后面多了一个105，想了半天，发现这个原来就是输出的字符的长度：100 + 4 + 1(\r)，关于这个\r的作用在另一篇文章中有所讲解。也就是说我在输出我想打印的字符时还显示了这个字符的长度！问题的原因后来发现这是Python3的sys.stdout.write()以及sys.stderr.write()的(准确的说是File.write())新功能，可以返回写入的字符数目：12345678910111213&gt;&gt;&gt; f=open('./test.txt','w')&gt;&gt;&gt; f.write('hello world!')12# 上面就返回了写入的字符的数目&gt;&gt;&gt; f.close()# 使用sys.stdout.write()和sys.stderr.write()也是一样的效果&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.stdout.write("foo")foo3&gt;&gt;&gt; sys.stderr.write("bar")3bar注意：Python2中File.write()的返回值是None问题解决找到问题的原因之后解决起来就非常简单了，只需要将返回的值赋值给另一个变量，不让它直接输出即可：12345for num in range(0, 101): time.sleep(0.1) r = '\r[%s%s]%d%%' % ("="*num, " "*(100-num), num) test=sys.stdout.write(r) sys.stdout.flush()输出结果：1[============== ]14%参考链接Strange behavior in Python 3 using the sys module]]></content>
      <categories>
        <category>Python</category>
        <category>其他技巧整理</category>
      </categories>
      <tags>
        <tag>其他技巧整理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之文件读写(转载)]]></title>
    <url>%2Fposts%2F57951.html</url>
    <content type="text"><![CDATA[这是一篇转载的文章，主要包括I/O操作概述、文件读写实现原理与操作步骤、文件打开模式及其区别、Python文件操作步骤示例、Python文件读取相关方法以及 文件读写与字符编码。I/O操作概述I/O在计算机中是指Input/Output，也就是Stream(流)的输入和输出。这里的输入和输出是相对于内存来说的，Input Stream(输入流)是指数据从外(磁盘、网络)流进内存，Output Stream是数据从内存流出到外面(磁盘、网络)。程序运行时，数据都是在内存中驻留，由CPU这个超快的计算核心来执行，涉及到数据交换的地方(通常是磁盘、网络操作)就需要IO接口。那么这个IO接口是由谁提供呢？高级编程语言中的IO操作是如何实现的呢？操作系统是个通用的软件程序，其通用目的如下：硬件驱动进程管理内存管理网络管理安全管理I/O管理操作系统屏蔽了底层硬件，向上提供通用接口。因此，操作I/O的能力是由操作系统的提供的，每一种编程语言都会把操作系统提供的低级C接口封装起来供开发者使用，Python也不例外。文件读写实现原理与操作步骤文件读写实现原理文件读写就是一种常见的IO操作。那么根据上面的描述，可以推断python也应该封装操作系统的底层接口，直接提供了文件读写相关的操作方法。事实上，也确实如此，而且Java、PHP等其他语言也是。那么我们要操作的对象是什么呢？我们又如何获取要操作的对象呢？由于操作I/O的能力是由操作系统提供的，且现代操作系统不允许普通程序直接操作磁盘，所以读写文件时需要请求操作系统打开一个对象(通常被称为文件描述符–file descriptor, 简称fd)，这就是我们在程序中要操作的文件对象。通常高级编程语言中会提供一个内置的函数，通过接收”文件路径”以及“文件打开模式”等参数来打开一个文件对象，并返回该文件对象的文件描述符。因此通过这个函数我们就可以获取要操作的文件对象了。这个内置函数在Python中叫open(), 在PHP中叫fopen(),文件读写操作步骤不同的编程语言读写文件的操作步骤大体都是一样的，都分为以下几个步骤：123451)打开文件，获取文件描述符2)操作文件描述符--读/写3)关闭文件只是不同的编程语言提供的读写文件的api是不一样的，有些提供的功能比较丰富，有些比较简陋。需要注意的是： 文件读写操作完成后，应该及时关闭 。一方面，文件对象会占用操作系统的资源；另外一方面，操作系统对同一时间能打开的文件描述符的数量是有限制的，在Linux操作系统上可以通过ulimit -n 来查看这个显示数量。如果不及时关闭文件，还可能会造成数据丢失。因为我将数据写入文件时，操作系统不会立刻把数据写入磁盘，而是先把数据放到内存缓冲区异步写入磁盘。当调用close方法时，操作系统会保证把没有写入磁盘的数据全部写到磁盘上，否则可能会丢失数据。文件打开模式我们先来看下在Python、PHP和C语言中打开文件的函数定义Python1234# Python2open(name[, mode[, buffering]])# Python3open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)PHP1resource fopen ( string $filename , string $mode [, bool $use_include_path = false [, resource $context ]] )C语言1int open(const char * pathname, int flags);会发现以上3种编程语言内置的打开文件的方法接收的参数中，除了都包含一个“文件路径名称”，还会包含一个mode参数(C语言的open函数中的flags参数作用相似)。这么mode参数定义的是打开文件时的模式，常见的文件打开模式有：只读、只写、可读可写、只追加。不同的编程语言中对文件打开模式的定义有些微小的差别，我们来看下Python中的文件打开模式有哪些。table th:first-of-type{width:20%}table th:nth-of-type(2){width:80%}文件打开模式描述r以只读模式打开文件，并将文件指针指向文件头；如果文件不存在会报错w以只写模式打开文件，并将文件指针指向文件头；如果文件存在则将其内容清空，如果文件不存在则创建a以只追加可写模式打开文件，并将文件指针指向文件尾部；如果文件不存在则创建r+在r的基础上增加了可写功能w+在w的基础上增加了可读功能a+在a的基础上增加了可读功能b读写二进制文件(默认是t，表示文本)，需要与上面几种模式搭配使用，如ab，wb, ab, ab+(POSIX系统，包括Linux都会忽略该字符)思考1： r+、w+和a+都可以实现对文件的读写，那么他们有什么区别呢？r+会覆盖当前文件指针所在位置的字符，如原来文件内容是”Hello，World“，打开文件后写入”hi“则文件内容会变成”hillo, World“(因为 r模式打开文件时文件指针指向文件头)w+与r+的不同是，w+在打开文件时就会先将文件内容清空，不知道它有什么用(感觉和单独的使用w模式没什么差别)a+与r+的不同是，a+只能写到文件末尾(无论当前文件指针在哪里)思考2： 为什么要定义这些模式呢？为什么不能像我们用word打开一篇文档一样既可以读，又可以写，还可修改呢？关于这个问题，我查了很多资料，也没找到很权威的说明。在跟同行朋友交流过程中，发现大家主要有两种观点：跟安全有关 ，有这种观点的大部分是做运维的朋友，他们认为这就像linux上的rwx(读、写、执行)权限。跟操作系统内核管理I/O的机制有关 ，有这种观点的大部分是做C开发的，特别是与内核相关的开发人员。为了提高读写速度，要写入磁盘的数据会先放进内存缓冲区，之后再回写。由于可能会同时打开很多文件，当要回写数据时，需要遍历以打开的文件判断是否需要回写。他们认为如果打开文件时指定了读写模式，那么需要回写时，只要去查找以“可写模式”打开的文件就可以了。Python文件操作步骤示例我们来读取这样一个文本文件：song.txt，该文件的字符编码为utf-8。1234匆匆那年我们 究竟说了几遍 再见之后再拖延可惜谁有没有 爱过不是一场 七情上面的雄辩匆匆那年我们 一时匆忙撂下 难以承受的诺言只有等别人兑现菜鸟实现(只是实现功能)Python3实现：12345678# 第一步：(以只读模式)打开文件f = open('song.txt', 'r', encoding='utf-8')# 第二步：读取文件内容print(f.read())# 第三步：关闭文件f.close()这里说下Python2的实现12345678# 第一步：(以只读模式)打开文件f = open('song.txt', 'r')# 第二步：读取文件内容print(f.read().decode('utf-8'))# 第三步：关闭文件f.close()说明：Python3中已经内置对Unicode的支持，字符串str已经是真正的Unicode字符串。也就是说Python3中的文件读取方法已经自动完成了解码处理，因此无需再手动进行解码，可以直接将读取的文件中的内容进行打印；Python2中的字符串str是字节串，读取文件得到的也是字节串，在打印之前应该手动将其解码成Unicode字符串。关于这部分的说明，可以参考之前这篇文章&lt;&gt;。中级实现在实现基本功能的前提下，考虑一些可能的意外因素。因为文件读写时都有可能产生IO错误(IOError)，一旦出错，后面包括f.close()在内的所有代码都不会执行了。因此我们要保证文件无论如何都能被关闭。那么可以用try...finally来实现，这实际上就是try...except..finally的简化版(我们只用Python3来进行示例演示)：123456789f = ''try: f = open('song.txt', 'r', encoding='utf-8') print(f.read()) num = 10 / 0finally: print('&gt;&gt;&gt;&gt;&gt;&gt;finally') if f: f.close()输出结果：12345678匆匆那年我们 究竟说了几遍 再见之后再拖延可惜谁有没有 爱过不是一场 七情上面的雄辩匆匆那年我们 一时匆忙撂下 难以承受的诺言只有等别人兑现&gt;&gt;&gt;&gt;&gt;&gt;finallyTraceback (most recent call last): File "&lt;stdin&gt;", line 4, in &lt;module&gt;ZeroDivisionError: division by zero输出结果说明，尽管with代码块中出现了异常，但是”&gt;&gt;&gt;&gt;&gt;&gt;finally“ 信息还是被打印了，说明finally代码块被执行，即文件关闭操作被执行。但是结果中错误信息还是被输出了，因此还是建议用一个完成的try...except...finally语句对异常信息进行捕获和处理。最佳实践为了避免忘记或者为了避免每次都要手动关闭文件，我们可以使用with语句(一种语法糖，语法糖语句通常是为了简化某些操作而设计的)。with语句会在其代码块执行完毕之后自动关闭文件。因此我们可以这样来改写上面的程序：123with open('song.txt', 'r', encoding='utf-8') as f: print(f.read())print(f.closed)输出结果：12345匆匆那年我们 究竟说了几遍 再见之后再拖延可惜谁有没有 爱过不是一场 七情上面的雄辩匆匆那年我们 一时匆忙撂下 难以承受的诺言只有等别人兑现True是不是变得简介多了，代码结构也比较清晰了。with之后打印的f.closed属性值为True，说明文件确实被关闭了。思考:with语句会帮我们自动处理异常信息吗？要回答这个问题就要提到“上下文管理器” 和 with语句的工作流程。with语句不仅仅可以用于文件操作，它实际上是一个很通用的结构，允许使用所谓的上下文管理器(context manager)。上下文管理器是一种支持__enter__()和__exit__()这两个方法的对象。__enter__()方法不带任何参数，它在进入with语句块的时候被调用，该方法的返回值会被赋值给as关键字之后的变量。__exit__()方法带有3个参数：type(异常类型), value(异常信息), trace(异常栈)，当with语句的代码块执行完毕或执行过程中因为异常而被终止都会调用__exit__()方法。正常退出时该方法的3个参数都为None，异常退出时该方法的3个参数会被分别赋值。如果__exit__()方法返回值(真值测试结果)为True则表示异常已经被处理，命令执行结果中就不会抛出异常信息了；反之，如果__exit__()方法返回值(真值测试结果)为False，则表示异常没有被处理并且会向外抛出该异常。现在我们应该明白了，异常信息会不会被处理是由with后的语句返回对象的__exit__()方法决定的。文件可以被用作上下文管理器。它的__enter__方法返回文件对象本身，__exit__方法会关闭文件并返回None。我们看下file类中关于这两个方法的实现：1234567def __enter__(self): # real signature unknown; restored from __doc__ """ __enter__() -&gt; self. """ return self def __exit__(self, *excinfo): # real signature unknown; restored from __doc__ """ __exit__(*excinfo) -&gt; None. Closes the file. """ pass可见，file类的__exit__()方法的返回值为None，None的真值测试结果为False，因此用于文件读写的with语句代码块中的异常信息还是会被抛出来，需要我们自己去捕获并处理。123with open('song.txt', 'r', encoding='utf-8') as f: print(f.read()) num = 10 / 0输出结果：1234567匆匆那年我们 究竟说了几遍 再见之后再拖延可惜谁有没有 爱过不是一场 七情上面的雄辩匆匆那年我们 一时匆忙撂下 难以承受的诺言只有等别人兑现Traceback (most recent call last): File "&lt;stdin&gt;", line 3, in &lt;module&gt;ZeroDivisionError: division by zero注意： 上面所说的__exit__()方法返回值(真值测试结果)为True则表示异常已经被处理，指的是with代码块中出现的异常。它对于with关键字之后的代码中出现的异常是不起作用的，因为还没有进入上下文管理器就已经发生异常了。因此，无论如何，还是建议在必要的时候在with语句外面套上一层try...except来捕获和处理异常。有关“上下文管理器”这个强大且高级的特性的更多信息，请参看Python参考手册中的上下文管理器部分。或者可以在Python库参考中查看上下文管理器和contextlib部分。Python文件读取相关方法我们知道，对文件的读取操作需要将文件中的数据加载到内存中，而上面所用到的read()方法会一次性把文件中所有的内容全部加载到内存中。这明显是不合理的，当遇到一个几个G的的文件时，必然会耗光机器的内存。这里我们来介绍下Python中读取文件的相关方法：方法描述read()一次读取文件所有内容，返回一个strread(size)每次最多读取指定长度的内容，返回一个str；在Python2中size指定的是字节长度，在Python3中size指定的是字符长度readlines()一次读取文件所有内容，按行返回一个listreadline()每次只读取一行内容此外，还要两个与文件指针位置相关的方法:方法描述seek(n)将文件指针移动到指定字节的位置tell()获取当前文件指针所在字节位置下面来看下操作实例读取指定长度的内容Python212with open('song.txt', 'r') as f: print(f.read(12).decode('utf-8'))输出结果：1匆匆那年结果说明：Python2中read(size)方法的size参数指定的要读取的字节数，而song.txt文件是UTF-8编码的内容，一个汉字占3个字节，因此12个字节刚好是4个汉字。Python312with open('song.txt', 'r', encoding='utf-8') as f: print(f.read(12))输出结果：1匆匆那年我们 究竟说结果说明：Python3中read(size)方法的size参数指定的要读取的字符数，这与文件的字符编码无关，就是返回12个字符。读取文件中的一行内容Python212with open('song.txt', 'r', encoding='utf-8') as f: print(f.readline())Python312with open('song.txt', 'r') as f: print(f.readline().decode('utf-8'))输出结果都一样：1匆匆那年我们 究竟说了几遍 再见之后再拖延遍历打印一个文件中的每一行这里我们只以Python3来进行实例操作，Python2仅仅是需要在读取到内容后进行手动解码而已，上面已经有示例。方式一：先一次性读取所有行到内存，然后再遍历打印123with open('song.txt', 'r', encoding='utf-8') as f: for line in f.readlines(): print(line)输出结果：1234567891011121314151617匆匆那年我们 究竟说了几遍 再见之后再拖延可惜谁有没有 爱过不是一场 七情上面的雄辩匆匆那年我们 一时匆忙撂下 难以承受的诺言只有等别人兑现``` 这种方式的缺点与read()方法是一样的，都是会消耗大量的内存空间。**方式二：通过迭代器一行一行的读取并打印**```pythonwith open('song.txt', 'r', encoding='utf-8', newline='') as f: for line in f: print(line)输出结果：1234567匆匆那年我们 究竟说了几遍 再见之后再拖延可惜谁有没有 爱过不是一场 七情上面的雄辩匆匆那年我们 一时匆忙撂下 难以承受的诺言只有等别人兑现另外，发现上面的输出结果中行与行之间多了一个空行。这是因为文件每一行的默认都有换行符，而print()方法也会输出换行，因此就多了一个空行。去掉空行也比较简单：可以用line.rstrip()去除字符串右边的换行符，也可以通过print(line, end=’’)避免print方法造成的换行。将缓存区数据立刻写入文件-flush()flush()方法的主要作用是刷新缓冲区数据，将缓冲区中的数据立刻写入文件或控制台；在我们平常当调用write()进行文件写入操作时，默认情况下，并没有立即将信息写入文件，而是先写入了缓冲区，当缓冲区满了以后才会写到文件中(这样可以保护磁盘，如果每次执行write就直接对磁盘进行操作，会缩短磁盘的寿命)，这就涉及到一个问题就是如果缓冲区没写满那存在缓冲区的数据怎么办？一种方法是直接调用flush()方法，将缓冲区的数据写入磁盘；另一种方法是执行文件的close()操作(前面的文件操作步骤也有提及)，这样可以把没有写入磁盘的数据全部写到磁盘上，这种方法实质上也是调用了flush()刷新缓存区数据。接下来结合print()实例来对flush()进行进一步的学习，在学习之前还需要介绍一下Python的print()函数：其完整形式是print(value, ..., sep=&#39; &#39;, end=&#39;\n&#39;, file=sys.stdout, flush=False)其中的end参数表示在字符串末尾增加的字符，默认情况下使用的是&#39;\n&#39;，也就是换行* 默认的输出位置是sys.stdout也就是控制台，可以将其设置为文件对象，那就是将结果输出到文件对象默认情况下是不刷新缓存区数据的，即flush=False所以实际上，在Python中使用print()输出到控制台实际上就是使用了sys.stdout.write(str+&#39;\n&#39;)(注意这里的+&#39;\n&#39;是和print的end是一致参数的)，其中也使用了write()方法，这也就说明其也涉及到了缓冲区(事实上print()还专门有flush参数).使用实例：12345678910# -*- encoding: utf-8 -*-import timeimport sys for i in range(5): # 实时刷新，因为print输出的字符串以\n结束 # sys.stdout检测到缓冲区内容以换行符结尾，它就会直接将缓冲区内容输出 print (i) time.sleep(1)理想情况下，上述实例开始并不会输出任何内容，而在程序运行完成之后会一次性输出0、1、2、3、4(程序正常结束，刷新缓冲区)，但是实际上在程序运行过程中就会刷新，这是因为sys.stdout检测到缓冲区内容以换行符结尾，它就会直接将缓冲区内容输出，不需要显式调用sys.stdout.flush()方法；接下来我们将print的end设置为空或者其他字符：12345678910# -*- encoding: utf-8 -*-import timeimport sys for i in range(5): # 设置字符串在结尾为不添加换行符 # 防止自动刷新缓冲区 print (i,end='') time.sleep(1)这次和预想的一样，在程序运行完成之后才会刷新缓冲区，一次性输出0、1、2、3、4，接下来设置sys.stdout.flush()进行强制的刷新缓冲区：12345678910# -*- encoding: utf-8 -*-import timeimport sys for i in range(5): print (i,end='') # 强制刷新缓冲区 sys.stdout.flush() time.sleep(1)这此和预期的结果也是相同的，随着程序的运行，一步一步的输出0、1、2、3、4.总结一下缓冲区刷新的方式：flush()强制刷新缓存区缓冲区满时，自动刷新文件关闭或者是程序结束自动刷新缓冲区中遇到换行符(\n)也会刷新file类的其他方法方法描述flush()刷新缓冲区数据，将缓冲区中的数据立刻写入文件next()返回文件下一行，这个方法也是file对象实例可以被当做迭代器使用的原因truncate([size])截取文件中指定字节数的内容，并覆盖保存到文件中，如果不指定size参数则文件将被清空; Python2无返回值，Python3返回新文件的内容字节数write(str)将字符串写入文件，没有返回值writelines(sequence)向文件写入一个字符串或一个字符串列表，如果字符串列表中的元素需要换行要自己加入换行符fileno()返回一个整型的文件描述符，可以用于一些底层IO操作上(如，os模块的read方法)isatty()判断文件是否被连接到一个虚拟终端，是则返回True，否则返回False文件读写与字符编码前面已经写过一篇介绍Python中字符编码的相关文件&lt;&gt; 里面花了很大的篇幅介绍Python中字符串与字符编码的关系以及转换过程。其中谈到过两个指定的字符编码的地方，及其作用：PyCharm等IDE开发工具指定的项目工程和文件的字符编码： 它的主要作用是告诉Pycharm等IDE开发工具保存文件时应该将字符转换为怎样的字节表示形式，以及打开并展示文件内容时应该以什么字符编码将字节码转换为人类可识别的字符。Python源代码文件头部指定的字符编码，如*-* coding:utf-8 -*-： 它的主要作用是告诉Python解释器当前python代码文件保存时所使用的字符编码，Python解释器在执行代码之前，需要先从磁盘读取该代码文件中的字节然后通过这里指定的字符编码将其解码为unicode字符。Python解释器执行Python代码的过程与IDE开发工具是没有什么关联性的。那么这里为什么又要谈起字符编码的问题呢？或者换个问法，既然从上面已经指定了字符编码，为什么对文件进行读写时还要指定字符编码呢？从前面的描述可以看出：上面两个地方指定的是Python代码文件的字符编码，是给Python解释器和Pycharm等程序软件用的；而被读写文件的字符编码与Python代码文件的字符编码没有必然联系，读写文件时指定的字符编码是给我们写的程序软件用的。这是不同的主体和过程，希望我说明白了。读写文件时怎样指定字符编码呢？上面解释了读写文件为什么要指定字符编码，这里要说下怎样指定字符编码(其实这里主要讨论是读取外部数据时的情形)。这个问题其实在上面的文件读取示例中已经使用过了，这里我们再详细的说一下。首先，再次看一下Python2和Python3中open函数的定义：1234# Python2open(name[, mode[, buffering]])# Python3open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)可以看到，Python3的open函数中多了几个参数，其中包括一个encoding参数。是的，这个encoding就是用来指定被操作文件的字符编码的。1234567# 读操作with open('song.txt', 'r', encoding='utf-8') as f: print(f.read())# 写操作with open('song.txt', 'w', encoding='utf-8') as f: print(f.write('你好'))那么Python2中怎样指定呢？Python2中的对文件的read和write操作都是字节，也就说Python2中文件的read相关方法读取的是字节串(如果包含中文字符，会发现len()方法的结果不等于读取到的字符个数，而是字节数)。如果我们要得到正确的字符串，需要手动将读取到的结果decode(解码)为字符串；相反，要以特定的字符编码保存要写入的数据时，需要手动encode(编码)为字节串。这个encode()和decode()函数可以接收一个字符编码参数。Python3中read和write操作的都是字符串，实际上是Python解释器帮我们自动完成了写入时的encode(编码)和读取时的decode(解码)操作，因此我们只需要在打开文件(open函数)时指定字符编码就可以了。123456789# 读操作with open('song.txt', 'r') as f: print(f.read().decode('utf-8'))# 写操作with open('song2.txt', 'w') as f: # f.write(u'你好'.encode('utf-8')) # f.write('你好'.decode('utf-8').encode('utf-8')) f.write('你好')文件读写时有没有默认编码呢？Python3中open函数的encoding参数显然是可以不指定的，这时候就会用一个“默认字符编码”。看下Python3中open函数文档对encoding参数的说明：1234encoding is the name of the encoding used to decode or encode thefile. This should only be used in text mode. The default encoding isplatform dependent, but any encoding supported by Python can bepassed. See the codecs module for the list of supported encodings.也就是说，encoding参数的默认值是与平台有关的，比如Window上默认字符编码为GBK，Linux上默认字符编码为UTF-8。而对于Python2来说，在进行文件写操作时，字节会被直接保存；在进行文件读操作时，如果不手动进行来decode操作自然也就用不着默认字符编码了。但是这时候在不同的字符终端打印的时候，会用当前平台的字符编码自动将字节解码为字符，此时可能会出现乱码。如song.txt文件时UTF-8编码的，在windows(字符编码为GBK)的命令行终端进行如下操作就会出现乱码：1234567&gt;&gt;&gt; with open('song.txt', 'r') as f:... print(f.read())...鍖嗗寙閭ｅ勾鎴戜滑 绌剁珶璇翠簡鍑犻亶 鍐嶈涔嬪悗鍐嶆嫋寤?鍙儨璋佹湁娌℃湁 鐖辫繃涓嶆槸涓€鍦?涓冩儏涓婇潰鐨勯泟杈?鍖嗗寙閭ｅ勾鎴戜滑 涓€鏃跺寙蹇欐拏涓?闅句互鎵垮彈鐨勮瑷€鍙湁绛夊埆浜哄厬鐜我们应该尽可能的获取被操作文件的字符编码，并明确指定encoding参数的值。文章来源Python之文件读写]]></content>
      <categories>
        <category>Python</category>
        <category>其他技巧整理</category>
      </categories>
      <tags>
        <tag>其他技巧整理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之sys-程序与python解释器的交互]]></title>
    <url>%2Fposts%2F38877.html</url>
    <content type="text"><![CDATA[这篇文章主要学习了Python的sys模块，其作用是程序与python解释器的交互；主要学习了其中的sys.argv、sys.modules、sys.path、sys.platform、sys.stdin、sys.stdout(附带一个实现百分比进度条的实例)以及sys.exit()sys模块简介sys模块主要是针对与Python解释器相关的变量和方法，不是主机操作系统(与os模块不同)。主要属性和方法属性及方法使用说明sys.argv获取命令行参数列表，第一个元素是程序本身sys.exit(n)退出Python程序，exit(0)表示正常退出。当参数非0时，会引发一个SystemExit异常，可以在程序中捕获该异常sys.version获取Python解释程器的版本信息sys.maxsize最大的Int值，64位平台是2**63 - 1sys.path返回模块的搜索路径，初始化时使用PYTHONPATH环境变量的值sys.platform返回操作系统平台名称sys.stdin输入相关sys.stdout输出相关sys.stderr错误相关sys.exc_info()返回异常信息三元元组sys.getdefaultencoding()获取系统当前编码，默认为utf-8sys.setdefaultencoding()设置系统的默认编码sys.getfilesystemencoding()获取文件系统使用编码方式，默认是utf-8sys.modules以字典的形式返回所有当前Python环境中已经导入的模块sys.builtin_module_names返回一个列表，包含所有已经编译到Python解释器里的模块的名字sys.copyright当前Python的版权信息sys.flags命令行标识状态信息列表。只读。sys.getrefcount(object)返回对象的引用数量sys.getrecursionlimit()返回Python最大递归深度，默认1000sys.getsizeof(object[, default])返回对象的大小sys.getswitchinterval()返回线程切换时间间隔，默认0.005秒sys.setswitchinterval(interval)设置线程切换的时间间隔，单位秒sys.getwindowsversion()返回当前windwos系统的版本信息sys.hash_info返回Python默认的哈希方法的参数sys.implementation当前正在运行的Python解释器的具体实现，比如CPythonsys.thread_info当前线程信息常用属性和方法实例脚本参数-sys.argv12345# -*- encoding: utf-8 -*-import sysfor index,arg in enumerate(sys.argv): print ("第%d个参数是：%s" %(index,arg))输出结果：12345678python argv.py 1 2 3 4 5 6 第0个参数是：argv.py 第1个参数是：1 第2个参数是：2 第3个参数是：3 第4个参数是：4 第5个参数是：5 第6个参数是：6该方法已经被argparse方法替换，argparse更加强大和简单易用，关于argparse可以参考这篇文章不过这个获取任意数目参数的方法也还挺实用的，在argparse中可以使用nargs=argparse.REMAINDER将剩余的参数利用列表收集起来查看已经导入的模块-sys.modulessys.modules保存有当前Python环境中已经导入的模块记录，这是一个全局字典，当Python启动后就加载在内存中。每当导入新的模块，sys.modules将自动记录该模块，当第二次试图再次导入该模块时，Python会先到这个字典中查找是否曾经导入过该模块，是则忽略，否则导入，从而加快了程序运行的速度。同时，它拥有字典的基本方法，例如sys.modules.keys()查看字典的所有键，sys.modules.values()查看字典的所有值，sys.modules[&#39;sys&#39;]查看sys键对应的值。1234567891011121314151617181920212223import sys# 查看所有已经导入的模块sys.modules # 输出结果中会有很多模块，但是我只导入了sys模块 # 可能是在python启动时就已经默认导入了很多必须的模块 &#123;'builtins': &lt;module 'builtins' (built-in)&gt;, 'sys': &lt;module 'sys' (built-in)&gt;, '_frozen_importlib': &lt;module '_frozen_importlib' (frozen)&gt;, ....&#125;# 得到所有的模块名sys.modules.keys() # 输出模块名 dict_keys(['builtins', 'sys', '_frozen_importlib', '_imp', '_warnings', '_thread', '_weakref', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'zipimport', 'encodings', 'codecs', '_codecs'...&#125;# 得到所有模块信息sys.modules.values() # 返回所有的模块信息 dict_values([&lt;module 'builtins' (built-in)&gt;, &lt;module 'sys' (built-in)&gt;, &lt;module '_frozen_importlib' (frozen)&gt;, &lt;module '_imp' (built-in)&gt;, &lt;module '_warnings' (built-in)&gt;, &lt;module '_thread' (built-in)&gt;, ...&#125;# 得到具体某个模块的信息sys.modules['sys'] # 查看sys模块的信息 &lt;module 'sys' (built-in)&gt;模块搜索路径-sys.path12345import syssys.path # 得到模块搜索路径 ['', '/home/user/miniconda3/lib/python36.zip', '/home/user/miniconda3/lib/python3.6', '/home/user/miniconda3/lib/python3.6/lib-dynload', '/home/user/miniconda3/lib/python3.6/site-packages']sys.path本质上是一个列表，可以进行append、insert、pop、remove等各种列表相关的操作，但通常都进行append操作，添加自己想要的查找路径.操作系统平台名称-sys.platform操作系统返回值Linux'linux'Windows'win32'Windows/Cygwin'cygwin'Mac OS X'darwin'交互式输入-sys.stdinsys.stdin返回一个”文件类型”对象，支持read()、readline()和readlines()等与文件读取相关的操作，就像使用open()打开的文件对象一样。1234567891011import sys# 使用ctrl + d结束输入&gt;&gt;&gt; s=sys.stdin.read()asdfaasdfasdaf&gt;&gt;&gt; s'asdfa\nasdfasd\naf\n\n\n'sys.stdin 与 input()：当我们用input(&#39;Please input something！&#39;)时，事实上是先输出提示信息，然后捕获输入。 以下两组等价：12345678910import sys# 直接使用inputs = input('Please input something！')# 使用sys.stdinprint('Please input something！') # -1 可以抛弃输入流中的'\n' 换行符# 默认s = sys.stdin.readline()[:-1]打印输出-sys.stdoutsys.stdout 与 print():当我们print(obj)的时候，事实上是调用了sys.stdout.write(obj+&#39;\n&#39;)，将内容打印到控制台（默认是显示器），然后追加一个换行符。12345import sys# 以下两种方式等价的sys.stdout.write('hello'+'\n') print('hello')从控制台重定向到文件：默认情况下sys.stdout指向控制台，如果把文件对象赋值给sys.stdout，那么 print ()调用的就是文件对象的write()方法。123456789101112import sys# 创建文件对象f_handler = open('out.log', 'w') # 将文件对象赋值给sys.stdoutsys.stdout = f_handler # 调用print()实际上就是sys.stdout.write('hello'+'\n') # 从而直接写入了文件中print('hello')# 你无法在屏幕上看到hello# 因为它被写到out.log文件里了如果你还想同时在控制台打印的话，最好先将原始的控制台对象引用保存下来，向文件中打印之后再恢复 sys.stdout：12345__console__ = sys.stdout # 保存控制台# redirection start # # 去干点别的，比如写到文件里... # redirection end # 干完别的了，恢复原来的控制台sys.stdout = __console__利用sys.stdout实现百分比进度条1234567891011121314151617181920import sysimport timedef bar(num, total): rate = num / total rate_num = int(rate * 100) # \r会影响flush() # 不加的话输出结果不会显示在同一行，也不会对齐 r = '\r[%s%s]%d%%' % ("="*num, " "*(100-num), rate_num, ) # 这里使用的是sys.stdout.write(r) # 也可以使用print(r,end='') sys.stdout.write(r) # 使用flush将缓存区数据立即写入 sys.stdout.flush()if __name__ == '__main__': for i in range(0, 101): time.sleep(0.1) bar(i, 100)输出结果：123456789101112# 使用sys.stdout.write(r)# 或者print(i,end='')[====================================================================================================]100%# 如果使用print(i)# sys.stdout.write(i+'\n') [ ]0%[= ]1%[== ]2%# 上述两种输出结果的区别是换行和不换行的问题，print会默认打印换行，也就是end='\n'这里涉及到了一个flush()的用法，具体讲解参考这篇文章还涉及到Python3的sys.stdout.write()返回字符长度问题也涉及到了Python覆盖之前输出的内容的问题程序退出状态-sys.exit(n)sys.exit(0)：表示程序正常退出sys.exit(n)：其中n不等于0表示程序非正常退出大部分的系统都要求n的取值范围是0-127执行到主程序末尾，解释器自动退出(正常退出sys.exit(0))；但是如果遇到异常需要中途退出程序，可以调用sys.exit(n)函数(其中的n不为0)，比如在运行之前先进行检查参数，如果不满足要求直接sys.exit(1)退出程序；如果不是遇到异常，而是普通的终止程序，可以使用sys.exit(0)正常退出程序。注意：可以传递给sys.exit()不仅仅是数字，None可以对应于上面的0，而其他可以输出内容或者标准错误输出的都可以对应于上面的1，例如 sys.exit(&quot;some error message&quot;)。参考链接syspython之sys模块详解]]></content>
      <categories>
        <category>Python</category>
        <category>常用模块</category>
      </categories>
      <tags>
        <tag>常用模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之glob-文件名规则匹配]]></title>
    <url>%2Fposts%2F24468.html</url>
    <content type="text"><![CDATA[这篇文章学习了Python中的常用模块glob，其作用是查找特定目录中符合匹配规则的文件(或目录)，主要包括三个函数：glob.glob()、glob.iglob()和glob.escape()，其中最主要的函数是glob.glob()，glob.iglob()和glob.glob()功能相似，但是返回的不再是列表而是迭代器对象，而glob.escape()主要是用来生成特殊字符匹配的pattern；在使用中需要注意通配符和正则表达式的区别。glob模块简介glob模块是使用 Unix shell 规则去查找匹配模式的文件，返回的结果是无序的；在进行匹配时使用的是shell的通配符而不是正则表达式，关于正则表达式与通配符的区别，之前有过一篇文章，如果忘记的话可以查看一下。glob模块其实也可以看做是os模块的补充，os模块中的os.listdir()可以列出某个目录下所有的文件和目录，但是这种列出是没有筛选性的，这在某些情况下并不是很适用，比如我想挑选出符合某个命名规则的文件，而glob模块就可以达到这个目的。通配符规则这里列出了glob模块支持的通配符规则(和shell的通配符规则有细微差别)：table th:first-of-type{width:15%}table th:nth-of-type(2){width:35%}table th:nth-of-type(3){width:50%}字符含义实例*匹配 0 或多个字符a*b：a与b之间可以有任意长度的任意字符, 也可以一个也没有, 如aabcb, axyzb, a012b, ab?匹配任意一个字符a?b：a与b之间必须也只能有一个字符, 可以是任意字符, 如aab, abb, acb, a0b[char]匹配原始字符char，相当于转义操作a[?]b：a与b之间只有一个字符且为?,此时的?已经不再具有匹配任意一个字符的功能 如: a?b.txt[list]匹配 list 中的任意单一字符a[xyz]b：a与b之间必须也只能有一个字符, 但只能是 x 或 y 或 z, 如: axb, ayb, azb[!list]匹配 除list 中的任意单一字符(一定要有一个)a[!0-9]b：a与b之间必须也只能有一个字符, 但不能是阿拉伯数字, 如axb, aab, a-b[c1-c2]匹配 c1-c2 中的任意单一字符 如：[0-9] [a-z]a[0-9]b：0与9之间必须也只能有一个字符 如a0b, a1b… a9b返回所有匹配文件名-glob.glob()命令：glob.glob(pathname, *, recursive=False)参数说明：pathname：绝对路径或者相对路径，可以包含通配符recursive：如果recursive是True，模式`会匹配任何文件以及0个或多个目录和子目录**；如果模式是os.sep`，只有目录和子目录会被匹配；可以用于递归匹配目录和子目录的内容与os模块对比使用123456789101112131415import osimport glob# 使用os模块列出所有的文件os.listdir('full_path') ['a?c.txt', 'abc.txt', 'acc.txt', 'adc.txt', 'a[*]c.txt']# 使用glob模块列出所有的文件glob.glob('full_path/') # 没得到正确结果 ['full_path/']glob.glob('full_path/*') ['full_path/a?c.txt', 'full_path/abc.txt', \ 'full_path/acc.txt', 'full_path/adc.txt', 'full_path/a[*]c.txt']通过上面的示例我们可以看出glob.glob()和os.listdir()在使用和返回结果的区别：使用方面：os.listdir()更为简单，只需要列出路径即可；而glob.glob()还需要设置通配符来达到匹配的目的返回结果方面：os.listdir()返回文件名称(不带路径)，而glob.glob()会返回文件名称+路径(和指定的路径相同模式，指定时使用绝对路径，返回结果前也是绝对路径，指定时使用相对路径，返回结果前也是相对路径)*-匹配任意一个或多个字符1234567import osimport glob# 匹配任意一个或多个字符glob.glob('./a*c.txt') # 返回只要是以a开头、以c结尾的文件名，具体中间字符的数量没有限制 ['./a?c.txt', './abc.txt', './acc.txt', './adc.txt', './abbc.txt']?-匹配任意单个字符12345678import osimport glob# 匹配任意单个字符glob.glob('./a?c.txt') # 如果不想输出以a开头、以c结尾并且中间包含两个以上字符的文件名，可以使用? # 表示中间只有任意一个字符，abbc.txt就不符合条件了 ['./a?c.txt', './abc.txt', './acc.txt', './adc.txt'][]-匹配特殊字符1234567891011121314151617181920212223import osimport glob# 匹配单个特殊字符glob.glob('./a[?]c.txt') # 如果文件名中含有特殊字符，比如这里的? # 对其进行匹配可以使用[] ['./a?c.txt']glob.glob('./a\?c.txt') # 不同于shell可以使用\进行转义，这里转义后不能正确匹配 []# 注意这里是单个字符，不能匹配得到多个的情况# 如果需要匹配多个，可以重复使用glob.glob('./a[?][?]c.txt') ['./a??c.txt']# 匹配得到单个和多个特殊字符的glob.glob('./a[?]*c.txt') # 注意这的*不是任意多个前一个字符(正则表达式中的定义) # 因为*可以匹配任意字符，?也不例外，前面使用了[?]作为限制 ['./a?c.txt', './a??c.txt'][]-匹配字符范围1234567891011import osimport glob# 匹配字符范围，同样是单个字符glob.glob('./a[b-d]c.txt') # a和c之间存在一个字符，且该字符的范围是b-d ['./abc.txt', './acc.txt', './adc.txt']# 如果不能表示为范围，可以单独列出字符的范围glob.glob('./a[bcd]c.txt') ['./abc.txt', './acc.txt', './adc.txt'][!char]-排除字符1234567import osimport glob# 匹配中间字符不为b的文件glob.glob('./a[!b]c.txt') # 排除了abc.txt ['./a?c.txt', './acc.txt', './adc.txt']递归匹配子目录内容上述方法都是常用的匹配当前目录文件名的方法，如果还想要匹配子目录的内容，上述方法是显然不行的：1234567891011121314151617181920212223242526# 创建子目录sub_dir，包含如下几个文件abbc.txt abc.txt acc.txt# 如果也想匹配出上面列出的文件# 单纯的使用如下命令是不行的glob.glob('./*') ['./a?c.txt', './abc.txt', './acc.txt', './adc.txt', './abcd.txt', './wre.txt', './abbc.txt', './a??c.txt', './sub_dir']# 同样使用如下命令也不行glob.glob('./*/*', recursive=True) # 只会得到子目录下的文件 ['./sub_dir/abc.txt', './sub_dir/acc.txt', './sub_dir/abbc.txt']# 这是真正的做法就需要使用前面提到的recursive参数glob.glob('./**', recursive=True) # 得到当前目录和子目录下所有文件 ['./', './a?c.txt', './abc.txt', './acc.txt', './adc.txt', './abcd.txt', './wre.txt', './abbc.txt', './a??c.txt', './sub_dir', './sub_dir/abc.txt', './sub_dir/acc.txt', './sub_dir/abbc.txt']glob.glob('./**/a[b-d]c.txt', recursive=True) # 得到当前目录和子目录下所有符合pattern的文件 ['./abc.txt', './acc.txt', './adc.txt', './sub_dir/abc.txt', './sub_dir/acc.txt']# 得到所有的目录和子目录glob.glob('./**/', recursive=True) ['./', './sub_dir/'].开头文件的匹配如果目录中包含以.开头的文件，默认情况下不会对其进行匹配(使用*也达不到目的)，如果想要匹配需要显式指定.。12345678import globglob.glob('*.gif') # 不会匹配出.开头的 ['card.gif']glob.glob('.c*') # 显式指定.，匹配出以.开头的文件 ['.card.gif']返回所有匹配文件名的迭代器-glob.iglob()命令：glob.iglob(pathname, *, recursive=False)参数：和前面的glob.glob()相同使用实例：12345678910111213141516171819202122import glob# 和glob的用法相同，只是会返回一个迭代器glob.iglob('./*.txt') # 输出一个迭代器对象 &lt;generator object _iglob at 0x7fa8dd9022b0&gt;# 得到具体的结果可以使用循环f=glob.iglob('./*.txt') for i in f: # 遍历这个迭代器对象 print (i)# 输出 ./a?c.txt ./abc.txt ./acc.txt ./adc.txt ./abcd.txt ./wre.txt ./abbc.txt ./a??c.txt其他用法参考glob.glob()。转义元字符-glob.escape()前面提到了如果想要匹配一些特殊字符，如?可以使用[]将其括起来的方式表示原始字符，不进行通配，这里glob还专门提供了一个方法glob.escape()来达到上述的目的，其返回的是一个构造好的pattern，其中的特殊字符都会被[]括起来。特殊的字符主要包括三个：?、*和[使用实例：1234567891011import glob# 返回构造好的patternglob.escape('./a?c.txt') # 和自己加[]效果是一样的 './a[?]c.txt'pattern=glob.escape('./a?c.txt')glob.glob(pattern) # 输出 ['./a?c.txt']参考链接glob — Unix style pathname pattern expansion7.4. glob — 文件名规则匹配[Python] glob 模块(查找文件路径)]]></content>
      <categories>
        <category>Python</category>
        <category>常用模块</category>
      </categories>
      <tags>
        <tag>常用模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之shutil-高级文件操作]]></title>
    <url>%2Fposts%2F51574.html</url>
    <content type="text"><![CDATA[这篇文章主要学习了Python中用来进行高级文件操作的模块shutil，其主要包括文件或者目录的赋值、删除、剪切以及压缩和解压缩操作，是对上一个学习的os模块功能的补充。shutil简介前面已经学习了os模块中的常用目录及文件操作，虽然其中有很多非常强大的功能，但是其中也有一些需要补足的地方，比如删除非空文件夹(这个是os模块不能直接做到的)、文件复制等，基于上述的补足，这里学习一下Python中高级文件操作的模块shutil，注意高级文件操作是Python官方给的名称，不是我直接编出来的，所以可见这个模块的强大。从主要功能上来看shutil模块是对os模块的补充，主要针对文件的拷贝、删除、移动、压缩和解压操作。高级文件目录管理复制文件内容到另一个文件命令：shutil.copyfileobj(fsrc, fdst[, length=16*1024])，其中的fsrc和fdst都是file-like object(使用open()方法打开后的文件对象)。功能：copy文件内容(部分或全部)到另一个文件(从fsrc复制到fdst中)，可以copy指定大小的内容，默认的大小为16*1024；如果length设置为负值，则会读取整个文件内容，而不是以块的方式进行迭代读取；fdst文件是清空重写还是追加写入需要开文件的打开模式程序的源码：12345678def copyfileobj(fsrc, fdst, length=16*1024): """copy data from file-like object fsrc to file-like object fdst""" while 1: # 程序的核心是这个read() buf = fsrc.read(length) if not buf: break fdst.write(buf)看了上述源码，发现很多问题就很简单了，包括从什么写入什么，read()参数的理解等等，所以说看源码才是王道啊！使用实例：1234567891011121314151617181920212223242526272829# source文件内容this is source file!# destination文件内容this is destination file!import shutil# source文件使用mode r读取打开s =open('source.txt','r')# destination文件使用mode w写入打开# w模式打开会清空文件内容# 如果需要写入文件，可以使用a模式打开d=open('target.txt','w')# 执行复制操作，从source文件复制到destination文件shutil.copyfileobj(s,d,length=16*1024)# 得到的destination文件内容# 由于前面使用了w模式打开文件，所以文件内容被清空了this is source file!# 使用追加模式打开destination文件d=open('target.txt','a')shutil.copyfileobj(s,d,length=16*1024)# 得到的destination文件内容# 由于前面使用了a模式打开文件，所以source文件内容是追加在后面this is target file!this is source file!部分或者全部复制：Note that if the current file position of the fsrc object is not 0, only the contents from the current file position to the end of the file will be copied.fdst文件是清空重写(w模式)还是追加写入(a模式)需要开文件的打开模式复制整个文件内容到另一个文件命令：shutil.copyfile(src, dst)，和上一个命令比较相似，不同于上一个命令的是src和dst是字符串形式的文件路径而不是文件对象，也就是说使用之前不用open()。功能：拷贝整个文件(src)内容到另一个文件(dst)；如果source文件和destination文件是相同的，则会产生错误，同时destination文件必须是可写的，不然也会报错；同时需要注意如果目标文件destination中有内容，执行操作后会覆盖。源码：12345678910111213141516171819202122232425262728293031def copyfile(src, dst, *, follow_symlinks=True): """Copy data from src to dst. If follow_symlinks is not set and src is a symbolic link, a new symlink will be created instead of copying the file it points to. """ # 判断文件是否相同，如果相同就报错 if _samefile(src, dst): raise SameFileError("&#123;!r&#125; and &#123;!r&#125; are the same file".format(src, dst)) for fn in [src, dst]: try: st = os.stat(fn) except OSError: # File most likely does not exist pass else: # XXX What about other special files? (sockets, devices...) if stat.S_ISFIFO(st.st_mode): raise SpecialFileError("`%s` is a named pipe" % fn) if not follow_symlinks and os.path.islink(src): os.symlink(os.readlink(src), dst) else: with open(src, 'rb') as fsrc: # 这里的打开模式需要注意，会清空原始的target的文件内容 with open(dst, 'wb') as fdst: # 调用了前面提到的shutil.copyfileobj copyfileobj(fsrc, fdst) return dst使用实例：12345678910111213141516# source文件内容this is source file!# destination文件内容this is destination file!import shutilimport os# 先修改工作目录os.chdir(r"c:\FastFolder\learn_test")# 执行复制操作，从source文件复制到destination文件shutil.copyfile('source.txt','target.txt')# 得到的destination文件内容# 可见原始的文件内容被清空了this is source file!全部复制，目标文件的原有内容会被清空，可以从源码中文件的打开模式看出传递的是表示文件地址的字符串，而不是像前面的shutil.copyfileobj(fsrc, fdst[, length=16*1024])传递的是文件对象仅复制权限命令：shutil.copymode(src, dst)：仅拷贝权限，内容、组、用户均不变；src和dst是字符串形式的文件路径而不是文件对象仅复制状态信息命令：shutil.copystat(src, dst)：仅复制所有的状态信息，包括权限，组，用户，修改时间等；src和dst是字符串形式的文件路径而不是文件对象复制文件内容和权限命令：shutil.copy(src,dst)：同时复制文件的内容以及权限相当于先copyfile()然后copymode()如果dst是一个目录，一个和src文件的basename相同的文件会被创建(或重写)；src和dst是字符串形式的文件路径而不是文件对象源码：123456789101112131415161718def copy(src, dst, *, follow_symlinks=True): """Copy data and mode bits ("cp src dst"). Return the file's destination. The destination may be a directory. If follow_symlinks is false, symlinks won't be followed. This resembles GNU's "cp -P src dst". If source and destination are the same file, a SameFileError will be raised. """ # 判断，如果dst是一个目录，就使用src的basename创建文件 if os.path.isdir(dst): dst = os.path.join(dst, os.path.basename(src)) copyfile(src, dst, follow_symlinks=follow_symlinks) copymode(src, dst, follow_symlinks=follow_symlinks) return dst使用实例：123456789import shutilimport os# 先修改工作目录os.chdir(r"c:\FastFolder\learn_test")# 执行复制操作，其中的dst为目录shutil.copy('source.txt','old_name')# 在old_name目录下生成了source.txt文件，和src名称相同，而且内容也相同复制文件内容和状态命令：shutil.copy2(src, dst)：与copy函数功能大部分一致，只是会把所有的文件元数据()都复制(copymode-&gt;copystat)；同时复制文件的内容以及文件的所有状态信息；相当于先copyfile()后copystat()；元数据的复制是通过shutil.copystat(src, dst)来完成；补充(元数据的定义)：主要是描述数据属性(property)的信息，用来支持如指示存储位置、历史数据、资源查找、文件记录等功能，是一种数据的数据，更多关于元数据可以看这篇文章。排除指定的文件命令：shutil.ignore_patterns(*patterns)：接收一个或多个通配符字符串，然后创建一个可以被传递给shutil.copytree()方法的’ignore’参数的函数；当文件名与指定的通配符匹配时，则不会被赋值，也就是排除指定的文件。递归复制目录和子目录命令：shutil.copytree(src, dst, symlinks=False, ignore=None)：递归地复制src目录及其子目录的文件和状态信息到目标目录dst目标目录dst必须是不存在的如果目标目录的父目录不存在，则会一同创建目录的权限和时间通过shutil.copystat()来拷贝，单个文件通过shutil.copy2()来拷贝参数：symlinks参数：指定是否复制软链接(小心陷入死循环)，如果为true，则以链接的形式进行复制；如果为false或者默认情况下，则会将链接文件的内容进行复制ignore参数：指定不参与复制的文件，其值应该是一个ignore_patterns()方法；也是递归的ignore，每个目录下的符合ignore的都会被忽略，因为这个参数是传递给copytree的，而copytree是递归调用的源码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192def copytree(src, dst, symlinks=False, ignore=None, copy_function=copy2, ignore_dangling_symlinks=False): """Recursively copy a directory tree. The destination directory must not already exist. If exception(s) occur, an Error is raised with a list of reasons. If the optional symlinks flag is true, symbolic links in the source tree result in symbolic links in the destination tree; if it is false, the contents of the files pointed to by symbolic links are copied. If the file pointed by the symlink doesn't exist, an exception will be added in the list of errors raised in an Error exception at the end of the copy process. You can set the optional ignore_dangling_symlinks flag to true if you want to silence this exception. Notice that this has no effect on platforms that don't support os.symlink. The optional ignore argument is a callable. If given, it is called with the `src` parameter, which is the directory being visited by copytree(), and `names` which is the list of `src` contents, as returned by os.listdir(): callable(src, names) -&gt; ignored_names Since copytree() is called recursively, the callable will be called once for each directory that is copied. It returns a list of names relative to the `src` directory that should not be copied. The optional copy_function argument is a callable that will be used to copy each file. It will be called with the source path and the destination path as arguments. By default, copy2() is used, but any function that supports the same signature (like copy()) can be used. """ # names中存储了目录所有文件的列表---不能区分文件或者目录 names = os.listdir(src) if ignore is not None: ignored_names = ignore(src, names) else: ignored_names = set() # 这里是os.makedirs，所以是递归创建目录的，也就是可以创建父目录 os.makedirs(dst) errors = [] for name in names: # 判断是不是复制ignore的条件，符合就直接进行下一轮循环 if name in ignored_names: continue srcname = os.path.join(src, name) dstname = os.path.join(dst, name) try: if os.path.islink(srcname): linkto = os.readlink(srcname) # 函数传递的参数 if symlinks: # We can't just leave it to `copy_function` because legacy # code with a custom `copy_function` may rely on copytree # doing the right thing. os.symlink(linkto, dstname) copystat(srcname, dstname, follow_symlinks=not symlinks) else: # ignore dangling symlink if the flag is on if not os.path.exists(linkto) and ignore_dangling_symlinks: continue # otherwise let the copy occurs. copy2 will raise an error if os.path.isdir(srcname): # 这部分是递归复制 copytree(srcname, dstname, symlinks, ignore, copy_function) else: copy_function(srcname, dstname) elif os.path.isdir(srcname): copytree(srcname, dstname, symlinks, ignore, copy_function) else: # Will raise a SpecialFileError for unsupported file types copy_function(srcname, dstname) # catch the Error from the recursive copytree so that we can # continue with other files except Error as err: errors.extend(err.args[0]) except OSError as why: errors.append((srcname, dstname, str(why))) try: copystat(src, dst) except OSError as why: # Copying file access times may fail on Windows if getattr(why, 'winerror', None) is None: errors.append((src, dst, str(why))) if errors: raise Error(errors) return dst使用实例：123456789from shutil import copytree, ignore_patterns# 忽略pyc文件和tmp文件# 注意destination肯定是不存在的copytree(source, destination, ignore=ignore_patterns('*.pyc', 'tmp*'))copytree('folder1', 'folder2', ignore=ignore_patterns('*.pyc', 'tmp*'))# 复制链接，不是复制链接指向文件的内容copytree('f1', 'f2', symlinks=True, ignore=ignore_patterns('*.pyc', 'tmp*'))递归删除命令：shutil.rmtree(path[, ignore_errors[, onerror]])，递归地删除目录(path，不能为链接目录)及子目录内的文件。注意！该方法不会询问yes或no，被删除的文件也不会出现在回收站里，请务必小心！参数：path：指定目录，但不能是链接指向的目录，传递的是字符串形式的文件路径而不是文件对象ignore_errors：设置为true，删除过程中的出错不会被抛出，会被忽略；如果为false或者忽略这个参数，删除过程中的错误会调用onerror中的错误处理方式进行处理，如果onerror中没有定义处理方式，就会抛出错误。onerror：一旦提供这个参数，就必须有三个参数function、path和excinfo.function：抛出异常的函数，是os.path.islink()、os.listdir()、 os.remove()或者os.rmdir()path：传递给function参数的path名excinfo：sys.exc_info()返回的异常信息onerror的异常不会被捕获使用实例：12345678910import os, statimport shutildef remove_readonly(func, path, _): # 去除文件的只读属性，尝试再次删除 os.chmod(path, stat.S_IWRITE) # 这里的func是针对前面抛出异常的操作 func(path)shutil.rmtree(directory, onerror=remove_readonly)需要注意的方面：删除路径的最后一个目录，而不是整个路径，例如shutil.rmtree(&#39;user/tester/noob&#39;)只会删除最后的noob目录的所有内容，而不会将整个路径&#39;user/tester/noob&#39;包含的文件夹都删除，参考这个链接。剪切目录命令：shutil.move(src, dst)，递归地移动文件或者目录，类似mv命令；如果destination是一个已经存在的目录，src会直接移动到这个目录中；如果destination已经存在但不是一个目录，destination将会被重写；如果是同一个文件或者目录，重命名。查找文件路径命令：which(cmd, mode=os.F_OK | os.X_OK, path=None)，返回文件路径，类似Linux的which命令参数讲解：cmd：需要查找的内容-字符串形式mode：查找内容的权限，默认情况os.F_OK：path是否存在以及os.X_OK：path是否可执行path：在指定路径中查找使用场景：典型的使用场景是在环境变量 PATH 定义的路径中查找可执行程序的位置，如果没有找到文件，which() 返回 None归档操作查看支持的压缩文件格式命令：shutil.get_archive_formats()使用实例：1234567891011import shutilfor format, description in shutil.get_archive_formats(): print('&#123;:&lt;5&#125;: &#123;&#125;'.format(format, description))# 输出结果 bztar: bzip2'ed tar-file gztar: gzip'ed tar-file tar : uncompressed tar file xztar: xz'ed tar-file zip : ZIP file创建归档或压缩文件命令：shutil.make_archive(base_name, format[, root_dir[, base_dir[, verbose[, dry_run[, owner[, group[, logger]]]]]]])参数说明：base_name：压缩后的文件名(不包含拓展名)；如果不指定绝对路径，则压缩文件保存在当前目录下；这个参数必须指定format：压缩格式，可以是zip、tar、bztar(tar.bz2)、gztar(tar.gz)、xztar中的一种；这个参数也必须指定root_dir：设置压缩包里的根目录，即在创建归档之前先切换到它指定的目录，一般使用默认值，不特别指定base_dir：要进行压缩的源文件或目录，如果没有提供则对root_dir目录下的所有文件进行归档压缩dry_run：如果值为Ture表示不会创建归档，但是操作输出会被记录到logger中，可用于测试owner：用户，默认当前用户group：组，默认当前组logger：用于记录日志，通常是logging.Logger对象使用实例：1234567891011121314151617181920212223242526import shutil# 提供base_dirshutil.make_archive(base_name="test", format="gztar", base_dir="./cat") # 返回 'test.tar.gz'# 输出结果# 注意文件中显示的路径，如果前面设置的是全路径，会创建全路径的文件夹 drwxrwxr-x user/user 0 2019-03-22 18:29 ./cat/ -rw-rw-r-- user/user 13 2019-03-22 17:28 ./cat/test1.txt -rw-rw-r-- user/user 7 2019-03-22 18:05 ./cat/test2.txt -rw-rw-r-- user/user 20 2019-03-22 18:05 ./cat/test3.txt -rw-rw-r-- user/user 8 2019-03-22 18:14 ./cat/filename -rw-rw-r-- user/user 8 2019-03-22 18:29 ./cat/test4.txt# 如果只提供root_dirshutil.make_archive(base_name="test2", format="gztar", root_dir="./cat") # 返回 'absolute_path/test2.tar.gz'# 输出结果 drwxrwxr-x user/user 0 2019-03-22 18:29 ./ -rw-rw-r-- user/user 13 2019-03-22 17:28 ./test1.txt -rw-rw-r-- user/user 7 2019-03-22 18:05 ./test2.txt -rw-rw-r-- user/user 20 2019-03-22 18:05 ./test3.txt -rw-rw-r-- user/user 8 2019-03-22 18:14 ./filename -rw-rw-r-- user/user 8 2019-03-22 18:29 ./test4.txt设置base_dir之后会在压缩的文件中会出现设置的base_dir路径(保留了原始路径信息)，这个需要特别注意，如果设置的是全路径指向某一个文件，解压的结果中也会包含那个全路径；如果设置的是root_dir，不设置base_dir，默认对root_dir中的进行压缩，则不会有上述麻烦，生成的文件解压后直接可以看到内容，不会出现全路径。解压缩后缀与格式的对应命令：shutil.get_unpack_formats()使用实例：12345678910111213import shutilfor format, exts, description in shutil.get_unpack_formats(): print('&#123;:&lt;5&#125;: &#123;&#125;, names ending in &#123;&#125;'.format( format, description, exts))# 输出 bztar: bzip2'ed tar-file, names ending in ['.tar.bz2', '.tbz2'] gztar: gzip'ed tar-file, names ending in ['.tar.gz', '.tgz'] tar : uncompressed tar file, names ending in ['.tar'] xztar: xz'ed tar-file, names ending in ['.tar.xz', '.txz'] zip : ZIP file, names ending in ['.zip']解压缩或解包源文件命令：shutil.unpack_archive(filename[, extract_dir[, format]])参数说明：filename：是压缩文档的完整路径extract_dir：是解压缩路径，默认为当前目录format：是压缩格式，默认使用文件后缀名代码的压缩格式，可以是zip、tar、bztar(tar.bz2)、gztar(tar.gz)、xztar中的一种；如果不提供这个参数，程序会根据filename的后缀名来自动选择方法。使用实例：123import shutil# filename是全路径shutil.unpack_archive("full_path/test.tar.gz", "./test", 'gztar')参考链接shutilPython之文件与目录操作（os、zipfile、tarfile、shutil）shutil — High-level file operations实例教程]]></content>
      <categories>
        <category>Python</category>
        <category>常用模块</category>
      </categories>
      <tags>
        <tag>常用模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之os-使用操作系统相关功能]]></title>
    <url>%2Fposts%2F24368.html</url>
    <content type="text"><![CDATA[这篇文章主要学习了Python使用操作系统相关功能的os模块，其主要功能包括：系统相关、目录及文件操作、执行命令和管理进程，这里主要学习了常用的目录及文件操作，其中涉及到的功能非常多，需要时可以查看使用，最后还学习了系统相关中的查看和新增环境变量操作，较为实用。os模块简介os模块是Python标准库中的一个用于访问操作系统相关功能的模块，os模块提供了一种可移植的使用操作系统功能的方法使用os模块中提供的接口，可以实现跨平台访问，但是，并不是所有的os模块中的接口在全平台都通用，有些接口的实现是依赖特定平台的，比如linux相关的文件权限管理和进程管理os模块的主要功能：系统相关、目录及文件操作、执行命令和管理进程在使用os模块的时候，如果出现了问题，会抛出OSError异常，表明无效的路径名或文件名，或者路径名(文件名)无法访问，或者当前操作系统不支持该操作目录及文件操作因为平常使用os模块一般也就是文件以及目录操作，所以这里先学习文件及目录相关操作的命令。os模块中包含了一系列文件操作相关的函数，其中有一部分是Linux平台专用方法(Linux是用C写的，底层的libc库和系统调用的接口都是C API，Python的os模块中包括了对这些接口的Python实现，通过Python的os模块，可以调用Linux系统的一些底层功能，进行系统编程，关于Linux的相关方法，内容较为复杂，可根据需要自行查阅官方文档），这里只介绍一些常用的，各平台通用的方法(包括了os模块和os.path模块):方法和变量用途os.getcwd()获取当前工作目录，即当前python脚本工作的目录路径os.chdir("dirname")改变当前脚本工作目录；相当于shell下cdos.curdir返回当前目录: ('.')os.pardir获取当前目录的父目录字符串名：('..')os.makedirs('dir1/dir2')可生成多层递归目录os.removedirs(‘dirname1’)递归删除空目录（要小心）os.mkdir('dirname')生成单级目录os.rmdir('dirname')删除单级空目录，若目录不为空则无法删除并报错os.listdir('dirname')列出指定目录下的所有文件和子目录，包括隐藏文件os.scandir('dirname')更详细地列出所有文件和子目录，相当于os.listdir('dirname')的升级版os.remove('filename')删除一个文件os.rename("oldname","new")重命名文件/目录os.stat('path/filename')获取文件/目录信息os.access(path, mode)检测文件或目录的访问权限os.chmod(path, mode)修改文件权限os.walk(top, topdown=True, onerror=None, followlinks=False)遍历整个目录结构，对每一个目录都返回一个三元元组(dirpath, dirnames, filenames)os.path.abspath(path)返回path规范化的绝对路径os.path.split(path)将path分割成目录和文件名二元组返回os.path.splitext(path)分割路径为后缀名(eg:.txt)和之前部分os.path.dirname(path)返回path的目录。其实就是os.path.split(path)的第一个元素os.path.basename(path)返回path最后的文件名。如果path以／或\结尾，那么就会返回空值。os.path.exists(path或者file)如果path存在，返回True；如果path不存在，返回Falseos.path.isabs(path)如果path是绝对路径，返回Trueos.path.isfile(path)如果path是一个存在的文件，返回True。否则返回Falseos.path.isdir(path)如果path是一个存在的目录，则返回True。否则返回Falseos.path.join(path1[, path2[, ...]])将多个路径组合后返回，第一个绝对路径之前的参数将被忽略os.path.getatime(path)返回path所指向的文件或者目录的最后存取时间os.path.getmtime(path)返回path所指向的文件或者目录的最后修改时间os.path.relpath(path, start)返回path相对于start(比如os.curdir)的相对路径,start默认为根目录os.path.realpath(path)获取path的真实、绝对路径(可用于获取软链接文件指向的文件路径)os.path.samefile(path1, path2)判断path1和path2是否为同一个文件os.path.getsize(filename)返回文件包含的字符数量获取当前工作目录-os.getcwd()1234import os# 返回当前工作目录print (os.getcwd())输出：123456# Python文件地址：# "c:\FastFolder\learn_test\os_learn.py"# 输出工作目录而不是python文件所在的目录# 如果需要得到文件所在目录，后续有专门的命令c:\FastFolder改变当前工作目录-os.chdir()123456# 改变工作目录# 将工作目录改变到py文件所在的目录os.chdir(r"c:\FastFolder\learn_test")# 改变工作目录之后输出当前工作目录print (os.getcwd())输出：12# 发现此时的工作目录已经改变c:\FastFolder\learn_test创建单层目录-os.mkdir()12345678910# 先返回当前目录print (os.getcwd())# 创建单层目录-相对路径mk_dir='test_single_dir'os.mkdir(mk_dir)# 创建单层目录-绝对路径mk_dir=r'c:\FastFolder\learn_test\python_test\test_single_dir'os.mkdir(mk_dir)os.mkdir()还可以设置创建的目录的mode权限，具体参考这个链接删除单层空目录-os.rmdir()123456# 删除单层目录，相对路径和绝对路径均可os.rmdir(mk_dir)# 如果目录非空会报错# OSError: [WinError 145] 目录不是空的。os.rmdir(mk_dir)递归创建目录-os.makedirs()12345678910# 先返回当前目录print (os.getcwd())# 递归创建目录-相对路径mk_dirs='test_dir/test'os.makedirs(mk_dirs)# 递归创建目录-绝对路径mk_dirs=r'c:\FastFolder\learn_test\python_test\test_dir\test'os.makedirs(mk_dirs)输出结果：12345# 当前工作目录'c:\FastFolder'# 在当前目录创建了test_dir/test目录# 在指定的绝对路径下创建了test_dir/test目录os.makedirs()还可以设置创建的目录的mode权限，具体参考这个链接递归删除多级空目录-os.removedirs()1234567# 递归删除多级目录-绝对或者相对路径均可os.removedirs(mk_dirs)# 递归删除也需要# 如果目录非空会报错：# OSError: [WinError 145] 目录不是空的。: 'test_dir'os.removedirs('test_dir')关于创建和删除单层、多层目录：创建单层和删除单层可以使用：os.mkdir()、os.rmdir()创建多层和删除多层可以使用：os.makedirs()、os.removedirs()两者之间不仅仅是dirs和dir的区别，还有make和mk、remove和rm的区别Python删除目录os.removedirs()的过程：If the leaf directory is succesfully removed, removedirs tries to successively remove every parent directory displayed in path.列出所有文件和子目录-os.listdir()123456789# 列出当前目录下的所有文件和目录，返回列表# 不会显示子目录内容os.listdir('.')os.listdir()# 列出指定目录下的所有文件和目录，返回列表# 这里使用了相对路径，使用绝对路径也是可以的os.listdir('./python_test')os.listdir('python_test')输出结果：12345# 当前目录下所有文件和目录，返回列表# python_test为目录，os_learn.py为文件['os_learn.py', 'python_test']['all.log', 'argparse_parent_with_group.py', 'argparse_test.py', 'error.log', 'log.txt', 'logging_learn.py', 'main', 'my.log', 'myapp.log', 'test_dir', '__pycache__']os.listdir()的缺点在于返回值为字符串组成的列表，不能从返回值中分辨它们是文件、目录还是符号连接更详细地列出所有文件和子目录-os.scandir()针对上面os.listdir()不能从返回值中分辨它们是文件、目录还是符号连接，使用os.scandir()扫描目录时，返回目录中每一个项目 DirEntry 实例的序列，这种对象有几种属性和方法(是否为目录、文件或者链接)，可以用于访问文件的元数据：1234567891011121314151617os.chdir(r"c:\FastFolder\learn_test")for entry in os.scandir(): # 判断是否为目录 if entry.is_dir(): typ = 'dir' # 判断是否为文件 elif entry.is_file(): typ = 'file' # 判断是否为链接 elif entry.is_symlink(): typ = 'link' else: typ = 'unknown' print('&#123;name&#125; &#123;typ&#125;'.format( name=entry.name, typ=typ, ))输出结果：12345new_name.txt fileold_name diros_learn.py filepython_test dirtempCodeRunnerFile.py file删除文件-os.remove()12345# 删除当前目录下的文件os.remove('to_remove.txt')# 删除指定目录下的文件os.remove(r"c:\FastFolder\learn_test\to_remove.txt")重命名文件或目录-os.rename()12345678910111213# 列出当前目录所有文件os.listdir() # old_name为文件夹，old_name.txt为文件 ['old_name', 'old_name.txt', 'os_learn.py', 'python_test']# 重命名目录os.rename('old_name','new_name') # 不管目录是否为空，都可以正常重命名 ['new_name', 'old_name.txt', 'os_learn.py', 'python_test']# 重命令文件os.rename('old_name.txt','new_name.txt') ['new_name', 'new_name.txt', 'os_learn.py', 'python_test']获取文件或目录信息-os.stat()123# 与os.listdir()不同，必须要指定目录os.stat('.') os.stat_result(st_mode=16895, st_ino=1688849860706458, st_dev=3422898436, st_nlink=1, st_uid=0, st_gid=0, st_size=0, st_atime=1554014658, st_mtime=1554014658, st_ctime=1553005707)检测文件或目录的访问权限-os.access(path, mode)123456789import os# __file__：当前脚本的路径print('Testing:', __file__)print('Exists:', os.access(__file__, os.F_OK))print('Readable:', os.access(__file__, os.R_OK))print('Writable:', os.access(__file__, os.W_OK))print('Executable:', os.access(__file__, os.X_OK))# 返回结果为True或者Falsemode包含F_OK、R_OK、W_OK和X_OK：os.F_OK：作为access()的mode参数，测试path是否存在os.R_OK：包含在access()的mode参数中 ， 测试path是否可读os.W_OK：包含在access()的mode参数中 ， 测试path是否可写os.X_OK：包含在access()的mode参数中 ，测试path是否可执行修改文件权限-os.chmod(path, mode)12345678910111213141516171819202122232425import osimport statfilename = 'os_stat_chmod_example.txt'if os.path.exists(filename): os.unlink(filename)with open(filename, 'wt') as f: f.write('contents')# 使用 stat 函数判断文件当前的权限# stat.S_IMODE：返回文件权限的chmod格式existing_permissions = stat.S_IMODE(os.stat(filename).st_mode)# 得到的是类似438这种的codeif not os.access(filename, os.X_OK): print('Adding execute permission') # stat.S_IXUSR：拥有者具有执行权限 new_permissions = existing_permissions | stat.S_IXUSRelse: print('Removing execute permission') # 使用 xor 异或清除用户的执行权限 # 异或操作：属于A或B，但不属于A交B---&gt;(A-B)∪(B-A) new_permissions = existing_permissions ^ stat.S_IXUSRos.chmod(filename, new_permissions)权限分组(分为三组)：第一组：文件或目录所有者的权限第二组：与文件或目录所有者同一组的用户的权限第三组：不与文件或目录所有者同组的其他用户(系统中其他用户)的权限使用Python的os.chmod修改权限时需要注意进制转换：如果像在Linux中修改权限为664(八进制)，在Python中需要为0664，原因：If you’re wondering why that leading zero is important, it’s because permissions are set as an octal integer(八进制整数), and Python automagically treats any integer with a leading zero as octal(Python会将带0的视为八进制数). So os.chmod(“file”, 436) (in decimal-十进制)would give the same result.进制转换参考这个链接关于stat模块和os.stat()参考这个链接返回绝对路径-os.path.abspath()12345678# 返回绝对路径# 注意和os.stat()相同，必须要指定目录os.path.abspath('.') 'c:\\FastFolder\\learn_test'# 返回文件的绝对路径os.path.abspath('./new_name.txt') 'c:\\FastFolder\\learn_test\\new_name.txt'分割路径为目录和文件名-os.path.split()1234567891011121314151617181920212223# 如果指定的path是相对路径，目录则会返回相对路径os.path.split('./new_name.txt') # 返回元组，第一个元素为目录，第二个元素为文件名 ('.', 'new_name.txt')# 如果最后是以/结尾，返回的文件名为空os.path.split('./') ) ('.', '')# 如果指定的路径为绝对路径，返回绝对路径的目录和文件名os.path.split('c:\\FastFolder\\learn_test\\new_name.txt') # 返回元组，第一个元素为目录，第二个元素为文件名 ('c:\\FastFolder\\learn_test', 'new_name.txt')# 如果最后是以/结尾，返回的文件名为空os.path.split('c:\\FastFolder\\learn_test\\') ('c:\\FastFolder\\learn_test', '')# 感觉应该就是直接从最后一个/号进行了分割，前面的返回目录，后面的作为文件名# 如果path中没有/，则目录会为空，文件名不为空os.path.split('test.sh') ('', 'test.sh')感觉应该就是直接从最后一个/号进行了分割，前面的返回目录，后面的作为文件名如果最后是以/结尾，返回的文件名为空如果path中没有/，则目录会为空，文件名不为空分割路径为后缀名(eg:.txt)和之前部分-os.path.splitext()123456789101112131415161718192021222324# 基本和上面的os.path.split()差不多# 唯一的区别是返回的二元组是后缀名和前部分# 相对路径os.path.splitext("./new_name.txt") # 返回的元组是后缀名和前部分 ('./new_name', '.txt')# 绝对路径os.path.splitext('c:\\FastFolder\\learn_test\\new_name.txt') # 返回的元组是后缀名和前部分 ('c:\\FastFolder\\learn_test\\new_name', '.txt')# 如果没有后缀名，返回空字符# 相对路径os.path.splitext("./new_name") # 没有后缀，返回的是空字符 ('./new_name', '')# 绝对路径os.path.splitext('c:\\FastFolder\\learn_test\\new_name') # 没有后缀，返回的是空字符 ('c:\\FastFolder\\learn_test\\new_name', '')# 不含\也和上面相同os.path.splitext('test.sh') ('test', '.sh')得到路径的目录-os.path.dirname()123456789# 相对路径得到的也是相对路径os.path.dirname('./new_name.txt') '.'# 绝对路径得到的也是绝对路径os.path.dirname('c:\\FastFolder\\learn_test\\new_name.txt') 'c:\\FastFolder\\learn_test'# 相当于就是上面os.path.split()得到的元组的第一个元素返回文件名-os.path.basename()12345678910111213# 相当于就是上面os.path.split()得到的元组的第二个元素os.path.basename('./new_name.txt') 'new_name.txt' os.path.basename('./') ''# 相当于就是上面os.path.split()得到的元组的第二个元素os.path.basename('c:\\FastFolder\\learn_test\\new_name.txt') 'new_name.txt'os.path.basename('c:\\FastFolder\\learn_test\\') ''判断文件和目录是否存在-os.path.exists()1234567891011# 判断文件是否存在os.path.exists('c:\\FastFolder\\learn_test\\new_name.txt') Trueos.path.exists('./new_name.txt') True# 判断目录是否存在os.path.exists('c:\\FastFolder\\learn_test\\') True判断是否为绝对路径-os.path.isabs()1234567891011# 相对路径返回falseos.path.isabs('./') Falseos.path.isabs('./new_name.txt') False# 绝对路径返回trueos.path.isabs('c:\\FastFolder\\learn_test\\') Trueos.path.isabs('c:\\FastFolder\\learn_test\\new_name.txt') True判断是否为存在的文件-os.path.isfile()1234567# 存在的文件返回trueos.path.isfile("./new_name.txt") True# 不存在的文件返回falseos.path.isfile("./new_namdsfae.txt") False判断是否为存在的目录-os.path.isdir()12345os.path.isdir("c:\\FastFolder\\learn_test") True# os.path.isfile()和os.path.isdir()感觉可以使用os.path.exists()替换# 特殊情况，比如通过判断是文件和目录来进行选择性的删除所有的文件，保留目录连接目录与文件名或目录-os.path.join()1234567891011121314# 将若干个目录或文件连接起来# 不管目录或文件存不存在os.path.join('c:\\FastFolder\\learn_test','test','test2') 'c:\\FastFolder\\learn_test\\test\\test2'# 如果根目录在第二个或者更后面，之前的路径将会忽略掉os.path.join('/root', '/usr/local', 'test.sh') # 因为第二个参数'/usr/local'是从根目录开始，第一个/root会被忽略 '/usr/local/test.sh'# 作为对比os.path.join('/root', 'usr/local', 'test.sh') #作为对比，第二个参数'usr/local'没有从根目录开始 # 最后的结果中会包含第一个参数的内容，不管第一个参数是不是从根目录开始 '/root/usr/local/test.sh'遍历整个文件结构-os.walk()walk方法是os模块中非常重要和强大的一个方法(os.walk(top, topdown=True, onerror=None, followlinks=False))。可以帮助我们非常便捷地以递归方式**自顶向下或者自底向上的方式遍历目录树，对每一个目录都返回一个三元元组(dirpath, dirnames, filenames)**:dirpath：遍历所在目录树的位置，是一个字符串对象dirnames：目录树中的子目录组成的列表，不包括(“.”和”..”)filenames：目录树中的文件组成的列表如果可选参数topdown = True或者没有指定，则采用自顶向下的方式进行目录遍历，也就是从父目录向子目录逐步深入遍历，如果topdown = False，则采用自底向上的方式遍历目录，也就是先打印子目录再打印父目录的方式。如果可选参数onerror被指定，则onerror必须是一个函数，该函数有一个OSError实例的参数，这样可以允许在运行的时候即使出现错误的时候不会打断os.walk()的执行，或者抛出一个异常并终止os.walk()的运行。通俗的讲，就是定义这个参数用于指定当发生了错误时的处理方法。默认情况下，os.walk()遍历的时候不会进入符号链接，如果设置了可选参数followlinks = True，则会进入符号链接。注意，这可能会出现遍历死循环，因为符号链接可能会出现自己链接自己的情况，而os.walk()没有那么高的智商，无法发现这一点。只遍历输出根目录：12345678910os.chdir(r"c:\FastFolder\learn_test")try: for root, dirs, files in os.walk(r"./"): print(root) # for directory in dirs: # print( directory) # for file in files: # print(file)except OSError as ex: print(ex)输出：1234567# 在遍历过程中，所有的目录都可能成为根目录././old_name./python_test./python_test\main./python_test\main\__pycache__./python_test\__pycache__遍历输出根目录及其下面的目录：1234567891011os.chdir(r"c:\FastFolder\learn_test")try: for root, dirs, files in os.walk(r"./"): print(root) for directory in dirs: print( directory) # for file in files: # print(file)except OSError as ex: print(ex)输出：1234567891011./old_namepython_test./old_name./python_testmain__pycache__./python_test\main__pycache__./python_test\main\__pycache__./python_test\__pycache__总结以及注意事项除了os.listdir()和os.scandir()可以不指定path表示当前目录之外，基本所有的都必须要指定path，即使是当前目录，也要用类似&#39;.&#39;的方法指定，如果不指定会报错，所以保险起见，还是都指定path吧，以免出错。使用windows的文件路径时一定要小心，比如你要引用d盘下的1.txt文件，那么路径要以字符串的形式写成&#39;d:\\1.txt&#39;或者r&#39;d:\1.txt‘。前面的方式是使用windwos的双斜杠作为路径分隔符，后者是使用原生字符串的形式，以r开始的字符串都被认为是原始字符串，表示字符串里所有的特殊符号都以本色出演，不进行转义，此时可以使用普通windows下的路径表示方式。这两种方法使用哪种都可以，但不可混用。os.path.exists()可以判断文件或者目录是否存在，而具体的os.path.isfile()和os.path.isdir()可以分别判断文件和目录是否存在，从而进行单独的操作，如删除所有目录中的文件，保留目录。os.rmdir()、os.removedirs()都只能删除空的目录，而os.remove()只能删除单个的文件，所以如果需要删除一个带文件的目录需要结合os.listdir() os.remove() os.rmdir()等，比较麻烦。Python删除目录os.removedirs()的过程：If the leaf directory is succesfully removed, removedirs tries to successively remove every parent directory displayed in path.系统相关系统相关的一系列命令在实际使用中用的比较少，所以这里只是列出，便于在后面使用时查询，并不进行深入的学习，后续需要时再学习。os模块提供了一些操作系统相关的变量，可以在跨平台的时候提供支持，便于编写移植性高，可用性好的代码。所以在涉及操作系统相关的操作时，请尽量使用本模块提供的方法，而不要使用当前平台特定的用法或格式，否则一旦移植到其他平台，可能会造成难以解决的困扰。方法和变量用途os.name查看当前操作系统的名称。windows平台下返回‘nt’，Linux则返回‘posix’。os.environ获取系统环境变量os.sep当前平台的路径分隔符。在windows下，为‘\’，在POSIX系统中，为‘/’。os.altsep可替代的路径分隔符，在Windows中为‘/’。os.extsep文件名和文件扩展名之间分隔的符号，在Windows下为‘.’。os.pathsepPATH环境变量中的分隔符，在POSIX系统中为‘:’，在Windows中为‘;’。os.linesep行结束符。在不同的系统中行尾的结束符是不同的，例如在Windows下为‘\r\n’。os.devnull在不同的系统上null设备的路径，在Windows下为‘nul’，在POSIX下为‘/dev/null’。os.defpath当使用exec函数族的时候，如果没有指定PATH环境变量，则默认会查找os.defpath中的值作为子进程PATH的值。环境变量-os.environ()123456789101112131415161718192021222324252627282930313233343536import os# 得到目前的环境变量# 返回类似字典的具有映射关系的对象print(os.environ)# 检查HOME是不是在环境变量中if 'HOME' in os.environ: print('HOME environment variable is already defined. Value =', os.environ['HOME'])else: print('HOME environment variable is not defined.')# 设置环境变量，和操作字典类似# 注意环境变量的值必须要是字符串，不能为数字或其他os.environ['MYSQL_VERSION'] = '5.7.18'# 获取环境变量的值# 可以使用常规的这种字典操作的方式# 这种方式存在的问题是如果环境变量中不存在这个MYSQL_VERSION，则会报错，显示KeyErroros.environ['MYSQL_VERSION'] Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "C:\Users\14910\Anaconda3\lib\os.py", line 678, in __getitem__ raise KeyError(key) from None KeyError: 'MYSQL_VERSION'# 可以使用另一种方式get()print (os.environ.get('DATA')) # 环境变量不存在，返回None None# 还可以设置环境变量不存在时候的默认值print(os.environ.get('DATA', 'TXT')) # 环境变量不存在，返回默认值 TXT执行命令和管理进程在早期的Python版本中，通常使用os模块的system或者popen等方法执行操作系统的命令。但是，最近Python官方逐渐弃用了这些命令，而是改用内置的subprocess模块执行操作系统相关命令。鉴于上述原因，这里就不对这个方面进行更深入的学习，以后详细学习subprocess模块。该部分主要包括两个命令：os.system(command)：运行操作系统命令，直接显示结果；但返回值是0或-1，不能获得显示在屏幕上的数据；command是要执行的命令字符串；除非显式在后台运行该命令，否则 system() 的调用将阻塞，直到它完成.os.popen(command, [mode, [bufsize]])：该方法返回一个文件对象，可以对这个文件对象进行读或写，取决于参数mode，如果mode指定了只读，那么只能对文件对象进行读，如果mode参数指定了只写，那么只能对文件对象进行写操作。简而言之，popen也可以运行操作系统命令，并通过read()方法将命令的结果返回，不像system只能看不能存，这个能存！参考链接很详细的教程使用实例教程Python之文件与目录操作（os、zipfile、tarfile、shutil）os — Miscellaneous operating system interfacespython os.stat() 和 stat模块详解]]></content>
      <categories>
        <category>Python</category>
        <category>常用模块</category>
      </categories>
      <tags>
        <tag>常用模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux中常用的解压缩命令]]></title>
    <url>%2Fposts%2F29022.html</url>
    <content type="text"><![CDATA[这篇文章学习和总结了Linux中常用的解压缩命令，主要针对tar.gz、tar.bz2、gz、bz2和zip文件格式进行解压，分别学习了tar命令(打包命令)、gzip命令、bzip2命令以及zip命令和对应的解压命令来完成对上述文件格式的解压。tar命令tar命令是打包命令而不是解压命令，所谓的打包是指可以把一大堆的文件和目录全部打包成一个文件，这对于备份文件或将几个文件组合成为一个文件以便于网络传输是非常有用的。我们在平常使用时都是使用tar结合相应参数对文件进行解压，但实际上其并不是解压缩命令，其实现解压需要结合特定的参数。这里我们很有必要了解一下打包和解压的区别：打包是指将一大堆文件或目录变成一个总的文件压缩则是将一个大的文件通过一些压缩算法变成一个小文件我们平常解压时面对的文件名大多是tar.gz格式文件，其产生过程和原因是：Linux中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar命令），然后再用压缩程序进行压缩（gzip、bzip2命令）。打包在学习如何解压tar.gz格式文件之前，先学习使用tar命令进行打包并进行压缩，知道来源再去学习针对性的解压命令.命令格式：123Usage: # 输入文件可以有多个，将其统一打包成输出文件 tar option out_file in_file in_file_2相关参数说明：-c：建立新的打包文件-v：显示指令执行过程-r：向已经打包的文件中追加**文件(不能向已经压缩的bz2、gz文件中添加，需要和-f参数一同使用**)-u：更新已经打包的文件中的文件(不能向已经压缩的bz2、gz文件中添加，需要和-f参数一同使用)-A：将tar文件中的文件**追加到已经打包的文件(tar文件)中**，相当于是文件的追加，而不是将整个tar文件追加进去-f：指定打包文件，-f参数一定要在最后，紧接着文件的-z：通过gzip指令处理打包文件-j：通过bzip2指令处理打包文件打包实例：12345678910111213141516171819202122232425262728293031323334# 仅打包，不压缩tar -cvf Homo_sapiens.GRCh38.95.chr.gff3.tar Homo_sapiens.GRCh38.95.chr.gff3 test.txt # 生成tar格式文件，tar格式文件比原始文件大 # 原始文件依旧保留 Homo_sapiens.GRCh38.95.chr.gff3.tar # 向上述打包的文件中添加test2.txt文件tar -rvf Homo_sapiens.GRCh38.95.chr.gff3.tar test2.txt # 生成的还是原来的tar文件，只是其中多了test2.txt Homo_sapiens.GRCh38.95.chr.gff3.tar # 向上述打包的文件中更新test2.txt文件tar -uvf Homo_sapiens.GRCh38.95.chr.gff3.tar test2.txt # tar文件中的test2.txt已经更新了 Homo_sapiens.GRCh38.95.chr.gff3.tar # 向上述打包的文件中添加tar打包文件tar -Avf Homo_sapiens.GRCh38.95.chr.gff3.tar Homo_sapiens.GRCh38.95.chr.gff3_2.tar # 生成的还是原来的tar文件，只是将tar中的文件追加到前面的tar文件中 # 不是将整个tar文件追加进去，如果使用-r选项就是将整个tar文件追加进去 Homo_sapiens.GRCh38.95.chr.gff3.tar # 打包后，以 gzip 压缩 tar -zcvf Homo_sapiens.GRCh38.95.chr.gff3.tar.gz Homo_sapiens.GRCh38.95.chr.gff3 test.txt # 生成tar.gz格式文件 # 原始文件依旧保留 Homo_sapiens.GRCh38.95.chr.gff3.tar.gz# 打包后，以 bzip2 压缩(这个花费时间较长) tar -jcvf Homo_sapiens.GRCh38.95.chr.gff3.tar.bz2 Homo_sapiens.GRCh38.95.chr.gff3 test.txt # 生成tar.bz2格式文件 # 原始文件依旧保留 Homo_sapiens.GRCh38.95.chr.gff3.tar.bz2打包参数是-cvfbz2格式的文件对应的参数就是j，打包所需时间长，压缩包的大小比较小，压缩比高gz格式的文件对应的参数就是z，打包所需时间较短，压缩包的大小比较大，压缩比低tar格式文件比原始文件大上述的文件格式和参数的对应关系很关键，在接下来的所有命令中，只要是针对这两种不同格式的包都需要加上对应的参数。查看包的内容相关参数说明：-t：列出打包文件内容-v：显示指令执行过程-f：指定打包文件，-f参数一定要在最后，紧接着文件的-z：通过gzip指令处理打包文件-j：通过bzip2指令处理打包文件查看包的内容实例：1234567891011121314151617# 查看打包文件tar -tvf Homo_sapiens.GRCh38.95.chr.gff3.tar # 输出包的内容 -rw-rw-r-- user/user 430456714 2019-03-30 18:07 Homo_sapiens.GRCh38.95.chr.gff3 -rw-rw-r-- user/user 0 2019-03-30 18:07 test.txt# 查看tar.gz格式文件内容tar -ztvf Homo_sapiens.GRCh38.95.chr.gff3.tar.gz # 输出tar.gz格式文件内容 -rw-rw-r-- user/user 430456714 2019-03-30 18:07 Homo_sapiens.GRCh38.95.chr.gff3 -rw-rw-r-- user/user 0 2019-03-30 18:07 test.txt# 查看tar.bz2格式文件内容tar -jtvf Homo_sapiens.GRCh38.95.chr.gff3.tar.bz2 # 输出tar.bz2格式文件内容 -rw-rw-r-- user/user 430456714 2019-03-30 18:07 Homo_sapiens.GRCh38.95.chr.gff3 -rw-rw-r-- user/user 0 2019-03-30 18:07 test.txt查看包的基础参数是-tvfbz2格式的文件对应的参数就是jgz格式的文件对应的参数就是z解压相关参数说明：-x：提取(解压)打包文件内容-v：显示指令执行过程-f：指定打包文件，-f参数一定要在最后，紧接着文件的-z：通过gzip指令处理打包文件-j：通过bzip2指令处理打包文件-C：指定解压文件的输出目录解压整个文件12345678910111213141516# 提取tar格式文件内容tar -xvf Homo_sapiens.GRCh38.95.chr.gff3.tar # 输出在当前文件夹下，tar格式文件依旧保留# 提取tar.gz格式文件内容tar -zxvf Homo_sapiens.GRCh38.95.chr.gff3.tar.gz # 输出在当前文件夹下，tar.gz格式文件依旧保留# 提取tar.bz2格式文件内容tar -jxvf Homo_sapiens.GRCh38.95.chr.gff3.tar.bz2 # 输出在当前文件夹下，tar.bz2格式文件依旧保留# 指定解压的输出文件夹tar -zxvf Homo_sapiens.GRCh38.95.chr.gff3.tar.gz -C test # 解压的文件输出在test目录中 # test目录必须存在，不然会报错解压部分文件12345678910# 提取tar.gz格式文件中的test.txt文件tar -zxvf Homo_sapiens.GRCh38.95.chr.gff3.tar.gz test.txt# 提取tar.bz2格式文件中的test.txt文件tar -jxvf Homo_sapiens.GRCh38.95.chr.gff3.tar.bz2 test.txt# 指定解压的输出文件夹tar -zxvf Homo_sapiens.GRCh38.95.chr.gff3.tar.gz test.txt -C test # 解压的文件输出在test目录中 # test目录必须存在，不然会报错tar可解压压缩文件的部分内容，所以可以先通过-t来查看压缩包内容，然后选取自己需要的进行解压，或者直接解压整个包。可以使用-C参数指定解压文件的输出目录gz文件这个没啥可以说的，就是使用gzip命令压缩得到的文件(默认情况下压缩后会使原文件消失)，对于这个命令的解压可以使用：1234567891011121314# 查看压缩文件信息# -l：list compressed file contentsgzip -l Homo_sapiens.GRCh38.95.chr.gff3.gz compressed uncompressed ratio uncompressed_name 38793139 430456714 91.0% Homo_sapiens.GRCh38.95.chr.gff3# gzip -d解压# -d：decompressgzip -d Homo_sapiens.GRCh38.95.chr.gff3.gz # 解压缩后原始的gz格式文件将不会存在# gunzip解压gunzip Homo_sapiens.GRCh38.95.chr.gff3.gz # 解压缩后原始的gz格式文件将不会存在如果想保留原始文件就需要使用-c参数：123456789101112# -c：--stdout write on standard output, keep original files unchanged# -c：将文件输出到标准输出，并且保留原始gz格式文件不变# 输出到标准输出，然后进行重定向到文件# 压缩过程如果想保留原始文件也可以使用-c参数gzip -c Homo_sapiens.GRCh38.95.chr.gff3 &gt;Homo_sapiens.GRCh38.95.chr.gff3.gz# gunzip进行解压缩并保留原始文件gunzip -c Homo_sapiens.GRCh38.95.chr.gff3.gz &gt;Homo_sapiens.GRCh38.95.chr.gff3# gzip -d解压并保留原始文件gzip -d -c Homo_sapiens.GRCh38.95.chr.gff3.gz &gt;Homo_sapiens.GRCh38.95.chr.gff3bz2文件bz2是由bzip2命令压缩得到的文件，默认情况下和gzip相同bzip2也不会保留解压缩前的原始文件，对这种格式的文件进行解压缩可以使用如下命令:12345678910# 和gzip不同，bzip2命令没有能够列出压缩文件内容的选项# bzip2 -d进行解压# -d：--decompress force decompressionbzip2 -d Homo_sapiens.GRCh38.95.chr.gff3.bz2 # 解压缩后原始的bz2格式文件将不会存在# bunzip2解压bunzip2 Homo_sapiens.GRCh38.95.chr.gff3.bz2 # 解压缩后原始的bz2格式文件将不会存在如果想保留原始文件就需要使用-k参数：123456789101112# -k：--keep keep (don't delete) input files# -k：保留原始的输入文件# 这里bzip2也有-c选项，但是也专门提供了-k选项来保留原始文件，所以就不需要进行-c然后重定向# 压缩时保留原始文件bzip2 -k Homo_sapiens.GRCh38.95.chr.gff3# bunzip2解压并保留原始文件bunzip2 -k Homo_sapiens.GRCh38.95.chr.gff3.bz2 # bzip2 -d进行解压并保留原始文件bzip2 -d -k Homo_sapiens.GRCh38.95.chr.gff3.bz2zip格式文件zip格式文件是通过zip命令压缩得到的文件，对其的解压使用unzip命令即可：12345678910111213# 使用zip命令进行压缩，与前面两个gzip和bzip2不同的是可以保留原始文件# 需要自定义输出文件名zip Homo_sapiens.GRCh38.95.chr.gff3.zip Homo_sapiens.GRCh38.95.chr.gff3# 更新zip文件中的问价，使用-u参数zip -u Homo_sapiens.GRCh38.95.chr.gff3.zip test.txt# 将文件添加到zip文件中，使用-m参数zip -m Homo_sapiens.GRCh38.95.chr.gff3.zip test.txt# 使用unzip进行解压# 解压也和前面的gzip和bzip2不同，能够保留原始文件unzip Homo_sapiens.GRCh38.95.chr.gff3.zip总结关于tar命令tar可解压压缩文件的部分内容，所以可以先通过-t来查看压缩包内容，然后选取自己需要的进行解压，或者直接解压整个包。可以使用-C参数指定解压文件的输出目录-f参数一定要在最后，紧接着文件的关于压缩比bzip2的压缩比最高、其次是gzip、接着是zip、最后是打包tar，可以看看这个示例：原始文件tar和zip都会保留原始文件bzip2和gzip都不会保留原始文件gzip需要使用-c参数将结果输出到标准输出，然后重定向来保留文件(解压或者压缩)bzip2可以使用-k参数来直接保留原始文件(解压或者压缩)，也可以使用上面的-c参数其他tar和zip进行压缩或者打包时都是先跟着输出文件(tar、zip格式文件)，再跟着输入的需要打包和压缩的文件，这个需要注意一下bzip2和gzip直接跟着需要压缩的文件即可bzip2和gzip只能针对文件，不能针对目录tar可以支持对目录和文件的打包zip命令需要使用-r参数来支持对目录的压缩参考链接tar命令gzip命令bzip2命令zip命令]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之打印彩色字符串]]></title>
    <url>%2Fposts%2F9708.html</url>
    <content type="text"><![CDATA[这篇文章是Linux中使用echo -e进行彩色输出的后续，Python也可以进行输出样式更改，包括字体颜色、背景颜色、其他输出样式更改(字体闪烁、下划线和加粗等)。效果展示昨天学习了Linux中使用echo命令来进行彩色字符串的输出，后来发现Python也可以进行彩色字符串的输出，但是需要注意的是只能在服务器上使用才可以，在Python IDE或者cmd中支持都不是很完善(IDE压根不能输出而CMD不会出现闪烁效果)，具体的展示效果如下：语法格式和echo命令中学习的相同，控制颜色输出的由两部分构成：\033[xx;xxm和\033[0m(ANSI控制码)：123# 打印红色字体# 31m表示红色print ("\033[31mTEST\033[0m")\033[xxxm：表示开始样式(字体、背景、闪烁等)渲染，m前面可以跟着多种样式渲染的数字表示(不同类型以分号;分隔，不用再加m，否则会出错)，例如：print (&quot;\033[42;37mTEST\033[0m&quot;)可正确输出绿底白字，而print (&quot;\033[42m;37mTEST\033[0m&quot;)输出结果和正确的存在差异\033[0m表示样式(字体、背景、闪烁等)渲染结束，这个不管是在什么样式输出情况下都是固定的字体颜色和echo命令中学习的相同，只需要将echo -e替换为print()即可，具体颜色表格对照:颜色代码颜色完整命令30黑色print ("\033[30mTEST\033[0m")31红色print ("\033[31mTEST\033[0m")32绿色print ("\033[32mTEST\033[0m")33黄色print ("\033[33mTEST\033[0m")34蓝色print ("\033[34mTEST\033[0m")35紫色print ("\033[35mTEST\033[0m")36浅蓝色print ("\033[36mTEST\033[0m")37白色print ("\033[37mTEST\033[0m")输出效果展示：背景颜色具体背景颜色表格对照:颜色代码背景颜色完整命令(字体颜色为红色)40黑色print ("\033[40;31mTEST\033[0m")41红色print ("\033[41;31mTEST\033[0m")42绿色print ("\033[42;31mTEST\033[0m")43黄色print ("\033[43;31mTEST\033[0m")44蓝色print ("\033[44;31mTEST\033[0m")45紫色print ("\033[45;31mTEST\033[0m")46浅蓝色print ("\033[46;31mTEST\033[0m")47白色print ("\033[47;31mTEST\033[0m")输出效果展示：ansi控制码总结ansi控制码中不仅有控制颜色的控制码，还有一些提供其他功能的控制码，如闪烁、加粗、下划线等，我们来总结一下：ANSI控制码说明完整命令示例\033[0m关闭所有属性，也就是说此控制码前面的控制码将会失效。print ("\033[31;0;42mTEST\033[0m")\033[1m设置高亮度(加粗)print ("\033[1;31;42mTEST\033[0m")\033[4m下划线print ("\033[4;31;42mTEST\033[0m")\033[5m闪烁print ("\033[5;31;42mTEST\033[0m")\033[7m反显，撞色显示，显示为白底黑字，或者显示为黑底白字，也可以和字体、背景颜色搭配print ("\033[7mTEST\033[0m")\033[8m消隐，字符颜色将会与背景颜色相同，忽略设置的字体颜色print ("\033[8;31;42mTEST\033[0m")\033[30m--\33[37m设置字符颜色print ("\033[31mTEST\033[0m")\033[40m--\33[47m设置背景色print ("\033[41mTEST\033[0m")实际效果：]]></content>
      <categories>
        <category>Python</category>
        <category>其他技巧整理</category>
      </categories>
      <tags>
        <tag>其他技巧整理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[echo-字符串的输出]]></title>
    <url>%2Fposts%2F39761.html</url>
    <content type="text"><![CDATA[这篇文章主要学习了Linux中非常常用的输出字符串命令echo，包括使用参数-n来不换行输出、使用参数-e来支持各种转义字符、字符串不加或加单或加双引号的区别和使用范围以及最后还学习了非常强大的使用-e参数来进行输出样式更改(字体颜色、背景颜色、字体闪烁、下划线和加粗等)。命令 echo 是用来将字符串写到标准输出，在平时工作中非常常用，这里对其进行详细的学习。echo命令格式123Usage: echo [选项] [输出内容]# echo默认会在最后一个字符后面添加换行符注意单引号、双引号在变量替换、字符拓展以及转义符解析等方面的区别，同样适用于echo命令：双引号允许变量和命令替换，以及转义符的解析，保护特殊元字符和通配符不被shell解析单引号不允许任何变量、元字符、通配符、转义符的解析字符串加不加引号的问题:不加引号：变量替换和命令替换可以正常进行，但是转义字符解析就不可以了，默认会将转义字符直接去掉(可以用来保留原始字符，去除其后紧跟的元字符或通配符的特殊意义)，例如echo -e hello\nworld输出结果为hellonworld，直接把转义字符\去掉了，但是n还是保留了下来(这种可以适用于输出原本字符，比如echo \&quot;hello\&quot;就可以保留双引号输出&quot;hello&quot;)根据上面的分析建议：尽量使用双引号将字符包围起来(一般情况下肯定也不会希望字符不允许任何解析)平常使用，如变量替换、命令替换这种简单的可以使用不加引号的方法，简单，同时也可支持简单的转义(保留原始字符，去除其后紧跟的元字符或通配符的特殊意义)，比如echo \&quot;hello\&quot;就可以保留双引号输出&quot;hello&quot;，实例可见下面字体颜色中的代码。echo支持的选项-e：输出转义字符（具体参见下表）-n：取消输出后行末的换行符号（内容输出后不换行）变量替换注意单引号、双引号特殊字符的作用：12345678x=10# 单引号防止任何变量替换、通配符拓展、转移符解析等echo '$x' $x# 双引号允许变量和命令替换，以及转义符的解析echo "$x" 10命令替换在实际使用过程中经常需要进行命令替换也就是打印出命令执行的结果，但是需要注意打印出来的格式和真实格式是否一致：不使用引号，格式发生改变：12echo `cmp --help` Usage: cmp [OPTION]... FILE1 [FILE2 [SKIP1 [SKIP2]]] Compare two files byte by byte. -b --print-bytes Print differing bytes. -i SKIP --ignore-initial=SKIP Skip the first SKIP bytes of input. -i SKIP1:SKIP2 --ignore-initial=SKIP1:SKIP2 Skip the first SKIP1 bytes of FILE1 and the first SKIP2 bytes of FILE2. -l --verbose Output byte numbers and values of all differing bytes. -n LIMIT --bytes=LIMIT Compare at most LIMIT bytes. -s --quiet --silent Output nothing; yield exit status only. -v --version Output version info. --help Output this help. SKIP1 and SKIP2 are the number of bytes to skip in each file. SKIP values may be followed by the following multiplicative suffixes: kB 1000, K 1024, MB 1,000,000, M 1,048,576, GB 1,000,000,000, G 1,073,741,824, and so on for T, P, E, Z, Y. If a FILE is `-' or missing, read standard input. Report bugs to &lt;bug-gnu-utils@gnu.org&gt;.使用引号，格式没有发生改变：12345678910111213141516171819202122echo "`cmp --help`" Usage: cmp [OPTION]... FILE1 [FILE2 [SKIP1 [SKIP2]]] Compare two files byte by byte. -b --print-bytes Print differing bytes. -i SKIP --ignore-initial=SKIP Skip the first SKIP bytes of input. -i SKIP1:SKIP2 --ignore-initial=SKIP1:SKIP2 Skip the first SKIP1 bytes of FILE1 and the first SKIP2 bytes of FILE2. -l --verbose Output byte numbers and values of all differing bytes. -n LIMIT --bytes=LIMIT Compare at most LIMIT bytes. -s --quiet --silent Output nothing; yield exit status only. -v --version Output version info. --help Output this help. SKIP1 and SKIP2 are the number of bytes to skip in each file. SKIP values may be followed by the following multiplicative suffixes: kB 1000, K 1024, MB 1,000,000, M 1,048,576, GB 1,000,000,000, G 1,073,741,824, and so on for T, P, E, Z, Y. If a FILE is `-' or missing, read standard input. Report bugs to &lt;bug-gnu-utils@gnu.org&gt;.-n-不换行输出取消最后行末尾末尾的换行符(每行末尾会自动添加换行符)：1234567891011121314151617181920212223# 正常输出，默认在"hello world"后面有换行echo "hello world" hello world [user@C-login04 echo]$# 不换行输出echo -n "hello world" hello world[user@C-login04 echo]$# 正常使用echo "hello world" ;echo "hello c" hello world hello c [user@C-login04 echo]$# 添加第一个-necho -n "hello world" ;echo "hello c" hello worldhello c [user@C-login04 echo]$# 添加两个-necho -n "hello world" ;echo -n "hello c" hello worldhello c[user@C-login04 echo]$可以与read命令相结合使用，具体的示例查看read命令-e-输出转义字符命令 echo 加上-e参数能够输出如下转义字符:字符转换说明\字符输出字符本身\a输出警告音(输出时叮咚一声)\b退格键，也就是向左删除一个字符\c所有跟在\c序列后的字符都被忽略，同时取消输出行末的换行符\f换行，但是换行后的新行的开头位置连接着上一行的行尾\n换行符\r使用\r后面的字符覆盖\r之前的同等长度的字符\t制表符，也就是Tab键\v垂直制表符(和-f相同)\0nnn按照八进制 ASCII 码表输出字符，其中 0 为数字 0，nnn 是三位八进制数\xhh按照十六进制 ASCH 码表输出字符，其中 hh 是两位十六进制数\字符-输出字符123456789101112131415# 输出\本身echo -e "hello\\world" hello\world# 输出双引号 echo -e "\"helloworld\"" "helloworld"# 当然这里不加-e选项也能正确输出echo "\\helloworld\"" \helloworld"# 不加双引号也能正确输出echo \\helloworld\" \helloworld"\b-退格键12345678910111213# 只有当\b后面存在字符的时候才会删除前一个字符，否则不会删除echo -e "hello\b" hello # 向左删除一个echo -e "hello\bworld" # 删除了字母o hellworld# \b可以叠加使用，向前删除多个echo -e "hello\b\bworld" # 删除了字母o和l helworld\c-去掉后续字符和换行符12345# 去掉\c后续的字符和换行符echo -e "hello\cworld" hello[user@C-login04 echo]$# 当\c后面不存在字符时，相当于echo -n\f和\v-换行并缩进123456789# \f换行缩进echo -e "hello\fworld" hello world# \v换行缩进echo -e "hello\vworld" hello world\n-换行符1234# 换行echo -e "hello\nworld" hello world\t-制表符123# 制表符echo -e "hello\tworld"hello world\r-等长覆盖使用\r后面的字符覆盖\r之前的同等长度的字符：123456789101112131415# 等长覆盖，前后长度相同echo -e "hello\rworld" world# 等长覆盖，前面长于后面字符echo -e "hellooo\rworld" worldoo# 等长覆盖，前面短于后面字符()echo -e "heo\rworld" world# \r后没字符，不被覆盖echo -e "hello\r" hello-e-彩色输出使用echo命令的-e选项，除了能够输出转义字符，还能够在命令行中输出彩色的字符，或者带有彩色背景的字符，先来一个示例感受一下:12# 打印红色字体echo -e "\033[31mTEST\033[0m"输出结果见下图：不仅可以显示红色，还可以设置背景、闪烁灯效果，是不是觉得很炫酷，接下来就对这个用法进行学习。颜色输出命令格式如果排除上述命令中的需要红色标注的字串TEST，可以发现控制颜色输出的由两部分构成：\033[31m和\033[0m(ANSI控制码)，完整代码见下：1echo -e "\033[31mTEST\033[0m"具体两部分的作用：\033[31m表明开始对字符进行颜色渲染\033[0m表明停止对字符进行渲染，如果不加的话后续的整个终端都会变成红色字体颜色通过上面的学习，我们已经知道是什么在控制颜色的输出，然而在实际应用中肯定也不会只想输出红色的内容，当然bash shell也允许更多颜色的支持，接下来我们就来了解什么控制了具体的字体颜色以及支持的字体颜色包括哪些。还是前面用到的命令，其中31m中的31是用来控制颜色输出的，表明输出字体为红色：1echo -e "\033[31mTEST\033[0m"具体各个字体颜色：123456789#bin/bashfor i in 3&#123;0..7&#125;do # 输出原始命令，注意不能使用单引号，不能进行变量替换 # 也不能使用双引号，不然直接输出颜色了 # 刚好不加引号可以进行简单的转义以及变量替换 echo echo -e \"\\033[$&#123;i&#125;mTEST\\033[0m\" echo -e "\033[$&#123;i&#125;mTEST\033[0m"done输出结果：具体颜色表格对照:颜色代码颜色完整命令30黑色echo -e "\033[30mTEST\033[0m"31红色echo -e "\033[31mTEST\033[0m"32绿色echo -e "\033[32mTEST\033[0m"33黄色echo -e "\033[33mTEST\033[0m"34蓝色echo -e "\033[34mTEST\033[0m"35紫色echo -e "\033[35mTEST\033[0m"36浅蓝色echo -e "\033[36mTEST\033[0m"37白色echo -e "\033[37mTEST\033[0m"背景颜色除了能够修改字体颜色之外，bash shell还支持对背景颜色的修改以及与字体颜色的组合：12# 黄色背景，红色字体echo -e "\033[43;31mTEST\033[0m"具体各个背景颜色(固定字体为红色)：123456789# 先使用sed命令将之前的代码注释sed -i '2,$s/^/#/' color.sh#bin/bashfor i in 4&#123;0..7&#125;do echo echo -e \"\\033[$&#123;i&#125;\;31mTEST\\033[0m\" echo -e "\033[$&#123;i&#125;;31mTEST\033[0m"done输出结果：具体背景颜色表格对照:颜色代码背景颜色完整命令(字体颜色为红色)40黑色echo -e "\033[40;31mTEST\033[0m"41红色echo -e "\033[41;31mTEST\033[0m"42绿色echo -e "\033[42;31mTEST\033[0m"43黄色echo -e "\033[43;31mTEST\033[0m"44蓝色echo -e "\033[44;31mTEST\033[0m"45紫色echo -e "\033[45;31mTEST\033[0m"46浅蓝色echo -e "\033[46;31mTEST\033[0m"47白色echo -e "\033[47;31mTEST\033[0m"上述的字体颜色固定为了红色，实际使用过程中背景颜色和字体颜色可以组合，形成多种输出样式。ansi控制码总结ansi控制码中不仅有控制颜色的控制码，还有一些提供其他功能的控制码，如闪烁、加粗、下划线等，我们来总结一下：ANSI控制码说明完整命令示例\033[0m关闭所有属性，也就是说此控制码前面的控制码将会失效。echo -e "\033[31;0;42mTEST\033[0m"\033[1m设置高亮度(加粗)echo -e "\033[1;31;42mTEST\033[0m"\033[4m下划线echo -e "\033[4;31;42mTEST\033[0m"\033[5m闪烁echo -e "\033[5;31;42mTEST\033[0m"\033[7m反显，撞色显示，显示为白底黑字，或者显示为黑底白字，也可以和字体、背景颜色搭配echo -e "\033[7mTEST\033[0m"\033[8m消隐，字符颜色将会与背景颜色相同，忽略设置的字体颜色echo -e "\033[8;31;42mTEST\033[0m"\033[30m--\33[37m设置字符颜色echo -e "\033[31mTEST\033[0m"\033[40m--\33[47m设置背景色echo -e "\033[41mTEST\033[0m"实际效果：上述是常用的ansi控制码总结，还有一些与光标相关(位置、移动和显隐)以及清屏相关的ansi控制码个人感觉用的很少就没有在这里列出，需要的话后续在补充学习，可以参考这个链接。参考链接echo命令详解 （一） 真的很详细echo命令详解 （二） 真的很详细]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[未完成-screen-远程会话管理工具]]></title>
    <url>%2Fposts%2F33882.html</url>
    <content type="text"><![CDATA[这里写摘要，显示更好看开始于二级标题参考链接linux 技巧：使用 screen 管理你的远程会话SSH远程会话管理工具 - screen使用教程Linux 技巧：让进程在后台可靠运行的几种方法]]></content>
  </entry>
  <entry>
    <title><![CDATA[nohup、disown和&-任务管理]]></title>
    <url>%2Fposts%2F19305.html</url>
    <content type="text"><![CDATA[这篇文章主要围绕任务管理，包括不挂断地运行(nohup命令)、补救命令(disown命令)和&amp;后台运行，学习了如何使用nohup、在没使用nohup的情况下如何补救、如何将任务放在后台运行以及前后台切换相关操作。nohup简介背景问题：我们经常会碰到这样的问题，用 telnet/ssh 登录了远程的 Linux 服务器，运行了一些耗时较长的任务， 结果却由于网络的不稳定导致任务中途失败。如何让命令提交后不受本地关闭终端窗口/网络断开连接的干扰呢？原因：当用户注销(logout)或者网络断开时，终端会收到 HUP(hangup)信号从而关闭其所有子进程；对应到上面的背景问题，当本地终端窗口关闭或者网络连接断开后，终端收到信号导致所有的任务(子进程)都被关闭，具体的过程如下：用户退出 session(终端)系统向该 session 发出HUP信号session 将HUP信号发给所有子进程子进程收到HUP信号后，自动退出解决办法：针对上面的问题和原因，很容易想到如果我们可以让终端忽略HUP(hangup)信号是不是就可以完美解决本地终端窗口关闭或者网络连接断开对任务的影响，这正是今天要学习的命令nohup的功能。nohup虽然一直在使用，但是关于其和&amp;的关系一直有些困惑，这里对nohup命令进行详细的学习，希望能够解决我的困惑。nohup用法12Usage: nohup COMMAND [ARG]... or: nohup OPTIONRun COMMAND, ignoring hangup signals.nohup命令具体作用：阻止HUP信号发到session下的子进程关闭标准输入，该进程不再能够接收任何输入，即使运行在前台重定向标准输出和标准错误到文件nohup.out(默认，可以指定)nohup实例默认用法12345# 忽略挂起信号nohup ./test.sh # 默认情况下，会将标准输出和标准错误结果重定向到当前文件夹下的nohup.out中nohup: ignoring input and appending output to `nohup.out'nohup只是可以忽略挂起信号，也就是不管终端或者网络是不是正常，都会继续运行(退出终端然后重新登录可发现nohup.out文件大小还在变大，程序还在运行)，但是仍然是在前台运行，当前的窗口会一直等待命令运行结束才会允许输入下一个命令。既然忽略挂起信号之后，退出终端命令还可以执行，那这和后台的区别在哪里呢？后台仅仅是解放了当前窗口吗？—&gt;后面会有解答输出重定向123# 输出重定向# 标准输出重定向到文件test.log，标准错误输出(2)重定向等同于标准输出(1)nohup ./test.sh &gt;test.log 2&gt;&amp;1终端进程与其子进程12345678910# 忽略挂起信息nohup ./test.sh # 查找通过top得到的nohup命令的pid# 第二列为命令的pid，第三列为命令的父进程号(这里是终端)# 由于nhup命令是在一个终端上提交的，而grep是在另一个终端上执行的# 所以两个命令的第三列不同，有不同的父进程号，两者属于不同的父进程ps -ef|grep 72502 user 72502 68858 98 17:34 pts/2 00:00:33 /bin/sh ./test.sh user 72568 68932 0 17:35 pts/3 00:00:00 grep 72502通过上面的命令可以知道，如果终端关闭(也就是第三列的父进程关闭)，该父进程所有的子进程(也就是第二列，在该终端上执行的所有命令)都会被关闭。nohup之后命令还是随终端退出这个问题我也没遇到过，但是学习的时候发现有人遇到过类似的问题，为了方便以后可能问题的解决，这里记录一下：有时候在nohup会有问题，当把终端关闭后，进程会自动被关闭，察看nohup.out可以看到在关闭终端瞬间服务自动关闭；咨询红旗Linux工程师后，他也不得其解，在我的终端上执行后，他启动的进程竟然在关闭终端后依然运行；在第二遍给我演示时，我才发现我和他操作终端时的一个细节不同：他是在当shell中提示了nohup成功后还需要按终端上键盘任意键退回到shell输入命令窗口，然后通过在shell中输入exit来退出终端；而我是每次在nohup执行成功后直接点关闭程序按钮关闭终端.。所以这时候会断掉该命令所对应的session，导致nohup对应的进程被通知需要一起shutdown。另一种方式前面提到的终端收到 HUP(hangup)信号从而关闭其所有子进程关闭，一种解决方法是使用nohup让终端忽略HUP(hangup)信号，另一种想法就是让提交的任务不属于当前终端的子进程(相当于上面的第三列不同)，这种做法对应的命令是setsid，但是感觉这是治标不治本的方法，并不是很实用，如果想了解可查看这个链接。nohup和&amp;命令的困惑困惑来源：放在后台之后命令即使关闭了当前的终端，命令还是可以在后台运行，这是为啥？针对上述困惑，我在网上查找了各种资源，大多都是说nohup负责忽略挂起信号，而&amp;负责将命令放在后台运行，这与我的实际实践不符合(感觉网上很多资源都是相互复制，并没有做到自己实践，当然也有可能和自己的服务器配置相关)，随后我查找了英文资料，根据文中提示的命令shopt | grep hupon发现我的服务器的设置为huponexit off，按照文中的说法是不会将HUP(hangup)信号发给所有子进程，但是前面自己实践发现退出终端后命令会直接停止，表明还是有将HUP(hangup)信号发给所有子进程，基于此，我只能继续查找资料，发现区别在于前台和后台：前台任务会随着 session 的退出而退出：因为它收到了HUP(hangup)信号(参考文章开头的流程)后台任务是否也会收到HUP(hangup)信号才是由上面的命令shopt | grep hupon决定的，也就是huponexit off，不会收到这个信号自此，困惑我许久的问题得到了解决，感觉真好(网上资料非常多，自己还是要实践才能辨别好坏啊！！)补救措施问题背景：经过前面的学习，我们已经知道了事先在命令前加上 nohup 或者 setsid 就可以避免 HUP 信号的影响，但是如果我们未加任何处理就已经提交了命令，该如何补救才能让它避免 HUP 信号的影响呢？解决方法：针对上面的问题，可以使用Linux的disown命令disown用法12Usage: disown [-h] [-ar] [jobspec ...]Without options, each jobspec is removed from the table of active jobs.If the -h option is given, each jobspec is not removed from the table, but is marked so that SIGHUP is not sent to the job if the shell receives a SIGHUP.If no jobspec is present, and neither the -a nor the -r option is supplied, the current job is used.If no jobspec is supplied, the -a option means to remove or mark all jobs; the -r option without a jobspec argument restricts operation to running jobs.The return value is 0 unless a jobspec does not specify a valid job.通过上面英文的说明，我们可以这么使用：用disown -h jobspec来使某个作业忽略HUP信号用disown -ah 来使所有的作业都忽略HUP信号用disown -rh 来使正在运行的作业忽略HUP信号需要注意的是：当使用过 disown 之后，会将把目标作业从作业列表中移除，我们将不能再使用jobs来查看它，但是依然能够用ps -ef查找到它。但是还有一个问题，这种方法的操作对象是作业，如果我们在运行命令时在结尾加了&quot;&amp;&quot;来使它成为一个作业并在后台运行，那么就万事大吉了，我们可以通过jobs命令来得到所有作业的列表。但是如果并没有把当前命令作为作业来运行，如何才能得到它的作业号呢？答案就是用 CTRL-z(按住Ctrl键的同时按住z键)了！CTRL-z 的用途就是将当前进程挂起(Suspend)，然后我们就可以用jobs命令来查询它的作业号，再用bg jobspec来将它放入后台并继续运行，需要注意的是，如果挂起会影响当前进程的运行结果，请慎用此方法。使用实例命令已在后台运行1234567891011121314151617# 命令先放在后台运行# 按照前面对我困惑的解答，其实这里已经不需要在将其设置nohup了# 但是为了以防万一，以及严谨性，还是学习一番./test.sh &gt;test.log 2&gt;&amp;1 &amp; [1] 101367# 使用jobs查看后台命令jobs [1]+ Running ./test.sh &gt; test.log 2&gt;&amp;1 &amp;# 再使用disown命令disown -h %1# 查看进程ID和父进程IDps -ef |grep 101367 user 101367 91326 96 00:15 pts/4 00:00:45 bash user 101426 91326 0 00:16 pts/4 00:00:00 grep 101367命令未放在后台如果提交命令时未使用&amp;将命令放入后台运行，可使用 CTRL-z 和bg jobspec将其放入后台，再结合jobs使用disown:12345678910111213141516171819202122# 不放在后台的命令./test.sh &gt;test.log 2&gt;&amp;1# CTRL-z挂起^Z [1]+ Stopped ./test.sh &gt; test.log 2&gt;&amp;1# 放在后台bg %1 [1]+ ./test.sh &gt; test.log 2&gt;&amp;1 &amp;# 查看后台任务jobs[1]+ Running ./test.sh &gt; test.log 2&gt;&amp;1 &amp;# 再使用disown命令disown -h %1# 查看进程ID和父进程IDps -ef |grep 101496 user 101496 91326 88 00:17 pts/4 00:00:27 bash user 101508 91326 0 00:17 pts/4 00:00:00 grep 101496screen命令screen命令也可以让进程免受 HUP 信号的影响，与上面不同的是如果有大量这种命令需要在稳定的后台里运行，其可避免对每条命令都做这样的操作。由于screen命令是一个功能非常强大的命令，这里很难将其搞清楚，后续会专门学习这个命令，具体请参考screen-远程会话管理工具总结现在几种方法已经介绍完毕，我们可以根据不同的场景来选择不同的方案：nohup/setsid 无疑是临时需要时最方便的方法disown 能帮助我们来事后补救当前已经在运行了的作业screen 则是在大批量操作时不二的选择了&amp;后台运行前面其实已经提到和使用过后台运行任务的用法：在命令之后增加&amp;，同时也解决了我再nohup和&amp;之间存在的困惑，这里就再对&amp;进行更加全面的学习。之所以需要学习后台运行任务的命令，是因为当我们在终端或控制台工作时，不希望由于运行一个作业而占住了屏幕，而常规的添加或者不添加nohup都会使得任务占据当前终端或控制台，想要进行下一步操作只能等待当前工作结束，这个非常耽误时间，而使用&amp;来将任务放入后台后，就可在当前终端或工作台进行更多的操作，非常方便(需要注意如果没有使用nohup、并且没有将输出重定向，屏幕会显示大量输出结果)：123456789101112# 使用nohup不挂断地运行任务，并将输出重定向到默认的nohup.outnohup ./test.sh# 后台运行，输出结果显示在屏幕上(那种正在操作其他命令，忽然输出结果的这种)./test.sh &amp;# 后台运行，指定输出重定向文件(屏幕不再有输出内容)./test.sh &gt;test.log 2&gt;&amp;1 &amp;# 使用nohup加上&amp;#其实根据我上面困惑的解答，在我这台服务器上对于后台任务使不使用nohup都可以nohup ./test.sh &gt;test.log 2&gt;&amp;1 &amp;后台任务的两个特点继承当前 session (对话)的标准输出(stdout)和标准错误(stderr)，因此，后台任务的所有输出依然会同步地在命令行下显示不再继承当前 session 的标准输入(stdin)，你无法向这个任务输入指令了，如果它试图读取标准输入，就会暂停执行(halt)后台任务与前台任务的本质区别只有一个：是否继承标准输入监控杀死后台任务前面提交后台任务之后会返回得到任务的进程号，依据这个进程号我们可以监控(ps -ef |grep job进程号)或者杀死(kill -9 job进程号或者kill %job序号)后台的任务：123456789101112131415161718# 提交后台任务nohup ./test.sh &gt;test.log 2&gt;&amp;1 &amp; [1] 138837# 监控后台任务ps -ef |grep 138837 songyb 138837 91326 96 09:19 pts/4 00:00:16 /bin/sh ./test.sh songyb 138912 91326 0 09:20 pts/4 00:00:00 grep 138837# 杀掉任务kill -9 138837jobs [1]+ Killed nohup ./test.sh &gt; test.log 2&gt;&amp;1# 杀掉任务kill %1jobs[1]+ Terminated nohup ./test.sh &gt; test.log 2&gt;&amp;1如果当时没有记下进程号，可以使用echo $!得到当前终端提交的最后一个后台任务的进程号，注意是当前终端，不能在其他终端进行查找切换前后台相关命令ctrl+z：將前台任务丟到后台中暂停，配合bg %job序号使用jobs：查看后台的工作状态bg %job序号：将任务放到后台中去处理fg %job序号：将后台的任务拿到前台来处理12345678910111213141516171819202122# 首先提交一个前台的任务，终端会等待命令运行结束./test.sh &gt;test.log 2&gt;&amp;1# ctrl+z挂起命令，將前台任务丟到后台中暂停^Z [1]+ Stopped ./test.sh &gt; test.log 2&gt;&amp;1# jobs查看工作状态jobs [1]+ Stopped ./test.sh &gt; test.log 2&gt;&amp;1# bg %job序号：将任务放入后台bg %1 [1]+ ./test.sh &gt; test.log 2&gt;&amp;1 &amp;# 再次查看任务状态jobs [1]+ Running ./test.sh &gt; test.log 2&gt;&amp;1 &amp;# fg %job序号：将后台的任务拿到前台来处理fg %1 ./test.sh &gt; test.log 2&gt;&amp;1job序号就是使用jobs命令查看的当前终端的任务序号，如[1]+ Stopped ./test.sh &gt; test.log 2&gt;&amp;1中的[1]，而不是通过top查看的进程号参考链接Linux 技巧：让进程在后台可靠运行的几种方法-讲解非常好[Linux] Linux 守护进程的启动方法-背后的原理]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[wget-命令行下载工具]]></title>
    <url>%2Fposts%2F44952.html</url>
    <content type="text"><![CDATA[这篇文章学习了Linux的命令行下载命令wget，其可以实现断点续传、代理下载、批量下载以及下载整个网站等强大的功能；这里主要学习的参数包括-O、-q、-o、-c、-b、用户名和密码登录、下载限速、测试下载链接、-t、-i、下载整个网站、镜像下载、-R、-A、-w、-U、-Q，其他参数可以查看帮助文档。wget简介wget是linux上的命令行的下载工具。这是一个GPL许可证下的自由软件。Linux wget支持HTTP和FTP协议，支持代理服务器和断点续传功能，能够自动递归远程主机的目录，找到合乎条件的文件并将其下载到本地硬盘上；如果必要，Linux wget将恰当地转换页面中的超级链接以在本地生成可浏览的镜像。由于没有交互式界面，Linux wget可在后台运行，截获并忽略HANGUP信号，因此在用户退出登录以后，仍可继续运行。通常，Linux wget用于成批量地下载Internet网站上的文件，或制作远程网站的镜像。wget最大的缺点是单线程，不支持多线程下载wget用法12Usage: wget [OPTION]... [URL]...由于wget的参数较多，而平常对于其使用要求也不是很高，所以这里就结合实例进行学习，对其参数不做细致学习，需要的时候可以使用wget --help查看帮助文档。wget实例学习默认-使用wget下载单个文件1wget ftp://ftp.ensembl.org/pub/release-95/gff3/homo_sapiens/Homo_sapiens.GRCh38.95.chr.gff3.gz以下的例子是从网络下载一个文件并保存在当前目录，在下载的过程中会显示如下信息：正在下载的文件的名称显示下载百分比的进度条已下载文件的大小当前下载速度剩余下载时间(下载完成之后会显示下载用时)默认情况下保存的文件为下载的文件名，如上述的Homo_sapiens.GRCh38.95.chr.gff3.gz-O-指定保存文件名如上所述，wget默认会以最后一个/的后面的字符来命名下载的文件，这对于动态链接的下载通常会是错误的：12# 下载动态链接内容(这里的示例不是很好，知道有这个情况即可)wget https://blog.csdn.net/chenbang110/article/details/7854384使用上述命令下载结束后会在当前目录得到名为7854384的文件，而实际上该文件是个html文件。为了解决上面出现的问题，可以使用-O指定输出文件名来解决：12# 指定输出文件名wget https://blog.csdn.net/chenbang110/article/details/7854384 -O test.html使用上述命令之后会在当前目录得到名为test.html的文件，下载到本地打开可以得到刚刚显示的博客内容，说明原本是html格式，但是仍然会以最后一个/的后面的字符来命名，忽略文件格式。个人感觉除了在动态链接下使用这个 -O(大写的)之外，正常情况下还是使用默认的文件名吧，这样下载的文件的后缀是正确的，自己指定可能会出错，导致文件不能正确打开。-q-无提示下载默认情况下，下载的时候会显示很多信息(比如链接状态、正在下载的文件的名称、下载速度等)，如果不想显示这些内容可以使用-q参数来达到静默下载的目的：12# 启动静默下载，不显示任何信息，包括网络的连接信息wget -q ftp://ftp.ensembl.org/pub/release-95/gff3/homo_sapiens/Homo_sapiens.GRCh38.95.chr.gff3.gz-o-保存下载日志文件使用上面的-q进行无提示下载虽然使得屏幕上没有了杂乱的信息，但是自己也不知道下载的具体情况，所以这个时候就希望可以将下载信息输出到下载日志文件，wget支持使用-o命令来指定日志文件名称：123# 指定日志文件# -o, --output-file=FILE log messages to FILE.wget -o test.log ftp://ftp.ensembl.org/pub/release-95/gff3/homo_sapiens/Homo_sapiens.GRCh38.95.chr.gff3.gz指定-o后下载过程不会显示信息，所有的下载信息都会被保存到指定的日志文件中-c-断点续传在下载加大文件的情况下，可能会出现下载中断的情况，为了应对这种问题，wget也支持使用-c来进行断点续传：123456789# 开始使用默认的下载方式wget ftp://ftp.ensembl.org/pub/release-95/gff3/homo_sapiens/Homo_sapiens.GRCh38.95.chr.gff3.gz# 但是下载到36%下载就中断了# 36% [======================================&gt; ] 14,005,056 1.20M/s eta 31s# 接下来进行断点续传wget -c ftp://ftp.ensembl.org/pub/release-95/gff3/homo_sapiens/Homo_sapiens.GRCh38.95.chr.gff3.gz# 会接着上次下载的位置(36%)进行下载，并使用+表示之前下载的部分，=表示现在下载的部分# 41% [+++++++++++++++++++++++++++++++++++++++====&gt; ] 15,987,368 299K/s eta 1m 57s-b-后台下载如果当前需要下载的文件比较大，直接放在前台下载有点耽误工作，wget支持使用-b参数启动后台下载：1234567# 启动后台下载wget -b ftp://ftp.ensembl.org/pub/release-95/gff3/homo_sapiens/Homo_sapiens.GRCh38.95.chr.gff3.gz# 启动后台下载之后会返回pid以及下载的日志文件wget-log# 还可以结合tail命令查看下载进度tail wget-logContinuing in background, pid 190363.Output will be written to “wget-log”.用户名和密码认证下载上面使用ftp下载时，默认是匿名登录进行下载，如果需要登录用户名和密码的话需要使用--ftp-user和--ftp-password指定，具体如下：1234# 默认匿名登录：Logging in as anonymous ... Logged in!# ftp下载时设置用户名和密码登录wget --ftp-user=USERNAME --ftp-password=PASSWORD ftp://ftp.ensembl.org/pub/release-95/gff3/homo_sapiens/Homo_sapiens.GRCh38.95.chr.gff3.gz上述是使用ftp进行下载，如果是使用HTTP下载，和上面类似，不过是使用--http-user=USER和--http-password=PASS来分别指定用户名和密码：12# HTTP下载时设置用户名和密码登录wget --http-user=USER --http-password=PASS urlwget还支持使用--user=USER和--password=PASS来统一进行用户名和密码的输入，不用区分http或者ftp下载，但是设置ftp和http的用户名和密码之后会覆盖这个设置的内容：12# 统一设置用户名和密码登录wget --user=USER --password=PASS url如果担心密码泄露，不想直接指定密码，可以使用--ask-password选项来提示输入密码：123# 提示输入密码# --ask-password prompt for passwords.wget --user=USER --ask-password url–limit-rate-限速下载当执行wget的时候，它默认会占用全部可能的宽带下载。但是当你准备下载一个大文件，而你还需要下载其它文件时就有必要限速了，wget支持使用形如--limit-rate=300k的参数进行限速：12# 限速下载wget --limit-rate=300k ftp://ftp.ensembl.org/pub/release-95/gff3/homo_sapiens/Homo_sapiens.GRCh38.95.chr.gff3.gz–spider-测试下载链接当你打算进行定时下载，你应该在预定时间测试下载链接是否有效，wget支持使用--spider参数进行链接有效性的检查：12# 测试下载链接wget --spider ftp://ftp.ensembl.org/pub/release-95/gff3/homo_sapiens/Homo_sapiens.GRCh38.95.chr.gff3.gz输出内容：123456789101112131415161718--2019-03-27 23:34:37-- ftp://ftp.ensembl.org/pub/release-95/gff3/homo_sapiens/Homo_sapiens.GRCh38.95.chr.gff3.gz =&gt; “Homo_sapiens.GRCh38.95.chr.gff3.gz.3”Resolving ftp.ensembl.org... 193.62.193.8Connecting to ftp.ensembl.org|193.62.193.8|:21... connected.Logging in as anonymous ... Logged in!==&gt; SYST ... done. ==&gt; PWD ... done.==&gt; TYPE I ... done. ==&gt; CWD (1) /pub/release-95/gff3/homo_sapiens ... done.==&gt; SIZE Homo_sapiens.GRCh38.95.chr.gff3.gz ... 38793139==&gt; PASV ... done. --2019-03-27 23:34:39-- ftp://ftp.ensembl.org/pub/release-95/gff3/homo_sapiens/Homo_sapiens.GRCh38.95.chr.gff3.gz =&gt; “.listing”==&gt; CWD (1) /pub/release-95/gff3/homo_sapiens ... done.==&gt; PASV ... done. ==&gt; LIST ... done. [ &lt;=&gt; ] 3,175 --.-K/s in 0s Removed “.listing”.# 显示文件存在File “Homo_sapiens.GRCh38.95.chr.gff3.gz” exists.如果文件不存在的话：123456789101112131415161718--2019-03-27 23:36:58-- ftp://ftp.ensembl.org/pub/release-95/gff3/homo_sapiens/Homo_sapiens.GRCh38.95.chr.gff3adsfa.gz =&gt; “Homo_sapiens.GRCh38.95.chr.gff3adsfa.gz”Resolving ftp.ensembl.org... 193.62.193.8Connecting to ftp.ensembl.org|193.62.193.8|:21... connected.Logging in as anonymous ... Logged in!==&gt; SYST ... done. ==&gt; PWD ... done.==&gt; TYPE I ... done. ==&gt; CWD (1) /pub/release-95/gff3/homo_sapiens ... done.==&gt; SIZE Homo_sapiens.GRCh38.95.chr.gff3adsfa.gz ... done.==&gt; PASV ... done. --2019-03-27 23:37:00-- ftp://ftp.ensembl.org/pub/release-95/gff3/homo_sapiens/Homo_sapiens.GRCh38.95.chr.gff3adsfa.gz =&gt; “.listing”==&gt; CWD (1) /pub/release-95/gff3/homo_sapiens ... done.==&gt; PASV ... done. ==&gt; LIST ... done. [ &lt;=&gt; ] 3,175 --.-K/s in 0.004s Removed “.listing”.# 显示文件不存在No such file “Homo_sapiens.GRCh38.95.chr.gff3adsfa.gz”.你可以在以下几种情况下使用--spider参数：定时下载之前进行检查间隔检测网站是否可用检查网站页面的死链接-t-增加重试次数如果网络不稳定或者其他原因导致连接出现问题，wget支持使用-t(--tries=NUMBER)参数来设置重试的次数：123# 设置重试次数为40次# set number of retries to NUMBER (0 unlimits)wget --tries=40 ftp://ftp.ensembl.org/pub/release-95/gff3/homo_sapiens/Homo_sapiens.GRCh38.95.chr.gff3.gz参数-t设置为0的时候是不对重试次数进行限制-i-下载多个文件如果需要下载多个链接，可以将多个链接写入文件，然后使用-i参数进行文件链接的下载：123456789# 使用cat命令创建并输入链接文件cat &gt; filelist.txturl1url2url3url4# 使用-i进行文件链接的下载wget -i filelist.txt递归下载整个网站比如在学习中我们遇到一个很好的网站，里面有很多自己需要的东西，一个一个下载太麻烦，这个时候就可以使用下面的命令直接下载整个网站(感觉不是很道德。。。)：12# 下载整个网站wget --restrict-file-name=ascii -r -p -np -k http://xxx.com/xxx参数解读：--restrict-file-name=ascii：防止出现中文乱码的问题，这个链接中给出了改名字的程序，需要的时候可以看看-r(--recursive)：specify recursive download.（指定递归下载）-k(--convert-links)：make links in downloaded HTML point to local files.（将下载的HTML页面中的链接转换为相对链接即本地链接）-p(--page-requisites)：get all images, etc. needed to display HTML page.（下载所有的图片等页面显示所需的内容）-np(--no-parent): 不追溯至父级目录 don’t ascend to the parent directory.镜像下载当要下载一个完整站点并实现本地浏览的时候，可以使用如下命令进行下载：12# 开启镜像下载wget --mirror -p -k -np -P ./LOCAL URL参数解读：-m(--miror)：开户镜像下载-p：下载所有的图片等页面显示所需的内容-k(--convert-links): make links in downloaded HTML point to local files.（将下载的HTML页面中的链接转换为相对链接即本地链接）-P ./LOCAL：保存所有文件和目录到本地指定目录-np(--no-parent): 不追溯至父级目录 don’t ascend to the parent directory.-R-过滤指定格式文件在下载的过程中，如果不想要下载后缀为.png的图片文件，可以使用--reject=png进行限制：123# 过滤下载，使用逗号分隔不同格式# -R, --reject=LIST comma-separated list of rejected extensions.wget --restrict-file-name=ascii -r -p -np -k -R '*.html','*.css' http://xxx.com/xxx-A-指定下载文件格式上面讲解了使用-R进行过滤排除文件格式，当然也可以指定下载文件的格式，wget支持使用-A来指定下载文件格式：123# 指定文件格式下载# -A, --accept=LIST comma-separated list of accepted extensions.wget --restrict-file-name=ascii -r -p -np -k -A '*.html','*.css' http://xxx.com/xxx-w-设置下载等待时间上面在下载整个网站的时候，下载过快可能会导致ip被封禁，为了避免这种情况，可以使用-w设置两次下载之间的等待时间：123# 设置两次下载之间的等待时间# -w, --wait=SECONDS wait SECONDS between retrievals.wget -w 20 --restrict-file-name=ascii -r -p -np -k http://xxx.com/xxx-U-设置header下载有些网站可能会通过代理名称来判断是不是浏览器，从而可能拒绝下载请求，为了避免请求被拒绝，wget支持使用-U(--user-agent)参数来进行伪装：12# 启动代理进行伪装wget --user-agent="Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16" --restrict-file-name=ascii -r -p -np -k http://xxx.com/xxx越来越有种爬虫的感觉。。。。。-Q-限制总下载文件大小前面提到的下载整个网站虽然很好，但是如果网站太大，对下载的数据量不进行限制，很多能导致自己的服务器存储不够，这时可使用wget的-Q来指定总下载文件大小：12345678# 指定总下载文件大小# -Q, --quota=NUMBER set retrieval quota to NUMBER.# 注意其对单个文件的下载不起效，以下命令可正常下载wget -Q 5m ftp://ftp.ensembl.org/pub/release-95/gff3/homo_sapiens/Homo_sapiens.GRCh38.95.chr.gff3.gz# 对递归下载起效(也可以说链接不止一个)wget -Q 10k --restrict-file-name=ascii -r -p -np -k http://xxx.com/xxx下载超过设置值时会提示：123xxxxxDownload quota of 10K EXCEEDED!xxxx实战Linux上下载迅雷内容参考这个链接参考链接wget命令-实例讲解Linux wget命令实例讲解最后列出了参数，可以看看]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[more和less-查看文本内容]]></title>
    <url>%2Fposts%2F57059.html</url>
    <content type="text"><![CDATA[这篇文章学习了Linux查看文本内容的常用命令more以及less，两个命令很多地方都很相似，但是less更加强大；分别学习了more和less的参数以及命令，其中less部分的参数和命令 只学习了常用的部分(less的功能很强大，对应的参数和命令很多，但是很多用不上，这里就没学习，后学如果有用在补上)。more命令more会以一页一页的显示方便使用者逐页阅读，而最基本的指令就是按空白键(space)就往下一页显示，按 b 键就会往回(back)一页显示，而且还有搜寻字串(直接跳转行)的功能,使用中按h可以查看说明文件 。more命令从前向后读取文件，因此在启动时就加载整个文件。more命令用法more命令格式12usage: more [-dflpcsu] [+linenum | +/pattern] name1 name2 ...more options说明table th:first-of-type{width:20%}table th:nth-of-type(2){width:80%}参数说明+n从笫n行开始显示-n定义屏幕大小为n行+/pattern在每个档案显示前搜寻该字串(pattern)，然后从该字串前两行之后开始显示-c清屏显示-d提示使用者，在内容下方显示 [Press space to continue, &#39;q&#39; to quit.] 如果按错键，则会显示 [Press &#39;h&#39; for instructions.] 而不是 ‘哔’ 声-l忽略Ctrl+l(换页)字符-p通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似-s把连续的多个空行显示为一行-u把文件内容中的下画线去掉-f计算行数时，以实际上的行数，而非自动换行过后的行数(有些单行字数太长的会被扩展为两行或两行以上),可以和-n连用more常用操作命令命令说明空格(space)向下滚动一屏z向下滚动一屏enter(return)向后滚动n行，默认为1q or Q or &lt;interrupt&gt;退出moreb or ctrl-B返回上一屏=输出当前行的行号：f输出文件名和当前行的行号V调用vi编辑器!命令调用Shell，并执行命令.重复上一个命令!命令:输入的命令不能输错，输错了删不了；输出结果和文本内容之间使用------分割：f：使用时是按下:同时按下f，不能先按下:松手后再按f参数和命令的关系参数决定了显示的内容(起始行、页面显示行数、换页是清屏还是滚动)，而命令决定了怎么去显示(翻页、滚动等)，以-p参数为例，规定了是清屏进行翻页，具体的翻页动作需要使用空格键操作，同时需要注意，其只规定的是换页是清屏的，如果使用enter进行显示下一行，仍然是滚动的方式，而不是清屏.more命令实例+n-从第n行开始显示12# n的索引是从1开始的more +3 test.log-n-每屏显示n行12# 每屏显示4行，可结合空格进行翻页more -4 test.log+/pattern-搜寻字串123# 查找第一个出现"liu"字符串的行，并从该处前两行开始显示输出# 输出第一行会显示...skippingmore +/liu test.log第一次出现字符串出现字符串的前两行-c-清屏显示12345678# 在不使用参数的情况下，如果文件行数大于屏幕可以显示的数目，也会清屏显示more test.log# 如果使用了-n选项，仍然符合上面的规则，如果-n小于屏幕可以显示的数目more -4 test.log# 使用-c参数之后，先清屏之后再显示(不管指定的每页显示行数为多少)more -c -4 test.log-d-提示信息12345more -d test.log# 在显示文本下方显示# --More--(0%)[Press space to continue, 'q' to quit.# 按错命令按键则会出现# [Press 'h' for instructions.]-f-计算实际行数123# 每页显示30行(实际行数)# 如果不加-f参数的话(也就是默认情况下)显示的不是实际行数(一行太长，换行会当2行算)more -f -30 test.log-p-清屏换页通过清屏来换页，而不是通过滚动页面(在同一个页面，内容增加，右侧出现滚动滑块)，和-c参数基本是一样的:12# 这个结合翻页很好用，只会在页面顶端的4行显示内容，不会叠加在同一个页面more -p -4 test.logless命令less工具也是对文件或其它输出进行分页显示的工具，应该说是linux正统查看文件内容的工具，功能极其强大。less的用法比起more更加的有弹性:在more的时候，我们并没有办法向前面翻，只能往后面看(b或者ctrl+b只是向前翻页，不能像less一样单行单行的向前滚动显示)，但若使用了 less，就可以使用pageup、pagedown等按键的功能来往前往后翻看文件，更容易用来查看一个文件的内容在 less 里头可以拥有更多的搜索功能，不止可以向下搜，也可以向上搜，more只能搜素后面的，输出的内容不在搜索范围内less命令格式12Usage: less [参数] 文件less options说明less的功能非常强大，包含很多方面，对应的参数也非常堵，需要的可以使用less --help查看，这里只列出常用的参数和功能：参数说明-m显示类似more命令的百分比-N显示每行的行号-M显法读取文件的百分比、行区间及总行数-e当文件显示结束后，自动退出-SChop long lines(在单行显示较长的内容，而不换行显示)-x &lt;数字&gt;将TAB字符显示为指定个数的空格字符less常用操作命令命令说明enter(回车)向下移动一行y向上移动一行pagedown向下移动一行pageup向上移动一行b向上滚动一屏空格键向下滚动一屏g跳到第一行G跳到最后一行p n%跳到n%，比如 10%，也就是说比整个文件内容的10%处开始显示w n可以指定显示哪行开始显示，是从指定数字的下一行显示；比如指定的n是6，那就从第7行显示!命令调用Shell，并执行命令q退出lessmore和less的区别在more的时候，我们并没有办法向前面翻，只能往后面看(b或者ctrl+b只是向前翻页，不能像less一样单行单行的向前滚动显示)，但若使用了 less，就可以使用pageup、pagedown等按键的功能来往前往后翻看文件，更容易用来查看一个文件的内容在 less 里头可以拥有更多的搜索功能，不止可以向下搜，也可以向上搜，more只能搜素后面的，输出的内容不在搜索范围内less使用退出之后屏幕不会留下显示的内容，而more退出之后屏幕会留下当前显示的内容less不必读整个文件，加载速度会比more更快参考链接Linux中more和less命令用法每天一个linux命令(12):more命令]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[未完成-Python系列之setup.py]]></title>
    <url>%2Fposts%2F33963.html</url>
    <content type="text"><![CDATA[这里写摘要，显示更好看开始于二级标题参考链接python的构建工具setup.py关于python中的setup.pypython的setup问题]]></content>
      <categories>
        <category>Python</category>
        <category>常用模块</category>
      </categories>
      <tags>
        <tag>常用模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python爬虫之Selenium-自动化测试]]></title>
    <url>%2Fposts%2F50111.html</url>
    <content type="text"><![CDATA[这篇文章将自己在使用Selenium过程中遇到的好文章进行了汇总和整理，便于后续继续使用这个工具时能尽快找到好的参考，节省时间！Selenium简介selenium 是一套完整的web应用程序测试系统，包含了测试的录制（selenium IDE）,编写及运行（Selenium Remote Control）和测试的并行处理（Selenium Grid）。Selenium的核心Selenium Core基于JsUnit，完全由JavaScript编写，因此可以用于任何支持JavaScript的浏览器上。selenium可以模拟真实浏览器，自动化测试工具，支持多种浏览器，爬虫中主要用来解决JavaScript渲染问题。selenium用法用python写爬虫的时候，主要用的是selenium的Webdriver，我们可以通过下面的方式先看看Selenium.Webdriver支持哪些浏览器执行结果如下，从结果中我们也可以看出基本山支持了常见的所有浏览器：这里要说一下比较重要的PhantomJS,PhantomJS是一个而基于WebKit的服务端JavaScript API,支持Web而不需要浏览器支持，其快速、原生支持各种Web标准：Dom处理，CSS选择器，JSON等等。PhantomJS可以用用于页面自动化、网络监测、网页截屏，以及无界面测试声明浏览器对象上面我们知道了selenium支持很多的浏览器，但是如果想要声明并调用浏览器则需要：1234from selenium import webdriver# 打开浏览器，注意需要提前下载浏览器驱动以及将其写入环境变量browser = webdriver.Chrome()browser = webdriver.Firefox()这里只写了两个例子，当然了其他的支持的浏览器都可以通过这种方式调用。可能遇到的问题：123456789browser = webdriver.Chrome()Traceback (most recent call last): File "C:\Users\14910\Anaconda3\lib\site-packages\selenium\webdriver\common\service.py", line 76, in start stdin=PIPE) File "C:\Users\14910\Anaconda3\lib\subprocess.py", line 769, in __init__ restore_signals, start_new_session) File "C:\Users\14910\Anaconda3\lib\subprocess.py", line 1172, in _execute_child startupinfo)FileNotFoundError: [WinError 2] 系统找不到指定的文件。这是因为没有将浏览器驱动以及没有将浏览器驱动添加到环境变量：12345678910111213# 驱动下载地址http://npm.taobao.org/mirrors/chromedriver/# 下载对应的chrome版本之后将压缩包解压，我下载的是chromedriver_win32.zip# 发现32位的也能用，关键是只提供了32位的# 解压上述包，然后将exe文件写入环境变量，可将exe文件放在C:\Program Files (x86)\Google\Chrome\Application目录下# 添加环境变量(可能需要重启电脑才会生效)之后直接输入chromedriver.exeStarting ChromeDriver 72.0.3626.69 (3c16f8a135abc0d4da2dff33804db79b849a7c38) on port 9515Only local connections are allowed.Please protect ports used by ChromeDriver and related test frameworks to prevent access by malicious code.访问页面12345678910from selenium import webdriver# 打开浏览器browser = webdriver.Chrome()# 打开网站browser.get("http://www.baidu.com")# 输入网站源码print(browser.page_source)# 关闭浏览器browser.close()上述代码运行后，会自动打开Chrome浏览器，并登陆百度打印百度首页的源代码，然后关闭浏览器查找元素单个元素查找123456789101112131415from selenium import webdriverbrowser = webdriver.Chrome()browser.get("http://www.taobao.com")# 使用id查找input_first = browser.find_element_by_id("q")# 使用css_selector查找input_second = browser.find_element_by_css_selector("#q")# 使用xpath查找input_third = browser.find_element_by_xpath('//*[@id="q"]')print(input_first)print(input_second)print(input_third)browser.close()这里我们通过三种不同的方式去获取响应的元素，第一种是通过id的方式，第二个中是CSS选择器，第三种是xpath选择器，结果都是相同的。结果如下：这里列举一下常用的查找元素方法：find_element_by_namefind_element_by_idfind_element_by_xpathfind_element_by_link_textfind_element_by_partial_link_textfind_element_by_tag_namefind_element_by_class_namefind_element_by_css_selector下面这种方式是比较通用的一种方式：这里需要记住By模块所以需要导入from selenium.webdriver.common.by import By12345678910from selenium import webdriverfrom selenium.webdriver.common.by import Bybrowser = webdriver.Chrome()browser.get("http://www.taobao.com")# 设置查找的方法以及查找的对象input_first = browser.find_element(By.ID,"q")print(input_first)browser.close()当然这种方法和上述的方式是通用的，browser.find_element(By.ID,&quot;q&quot;)这里By.ID中的ID可以替换为其他几个多个元素查找其实多个元素和单个元素的区别，举个例子：find_elements,单个元素是find_element,其他使用上没什么区别，通过其中的一个例子演示：12345678910111213from selenium import webdriverbrowser = webdriver.Chrome()browser.get("http://www.taobao.com")# 执行查找lis = browser.find_elements_by_css_selector('.service-bd li')# 使用通用的方法实现from selenium.webdriver.common.by import Bylis = browser.find_elements(By.CSS_SELECTOR,'.service-bd li')print(lis)browser.close()这样获得就是一个列表同样的在单个元素中查找的方法在多个元素查找中同样存在：find_elements_by_namefind_elements_by_idfind_elements_by_xpathfind_elements_by_link_textfind_elements_by_partial_link_textfind_elements_by_tag_namefind_elements_by_class_namefind_elements_by_css_selector元素交互操作对于获取的元素调用交互方法:123456789101112131415161718from selenium import webdriverimport timebrowser = webdriver.Chrome()browser.get("http://www.taobao.com")input_str = browser.find_element_by_id('q')# 发送信息input_str.send_keys("ipad")time.sleep(1)input_str.clear()input_str.send_keys("MakBook pro")button = browser.find_element_by_class_name('btn-search')button.click()运行的结果可以看出程序会自动打开Chrome浏览器并打开淘宝输入ipad,然后删除，重新输入MakBook pro，并点击搜索Selenium所有的api文档交互动作将动作附加到动作链中串行执行：123456789101112131415from selenium import webdriverfrom selenium.webdriver import ActionChainsbrowser = webdriver.Chrome()url = "http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable"browser.get(url)browser.switch_to.frame('iframeResult')source = browser.find_element_by_css_selector('#draggable')target = browser.find_element_by_css_selector('#droppable')actions = ActionChains(browser)actions.drag_and_drop(source, target)actions.perform()更多操作参考执行JavaScript这是一个非常有用的方法，这里就可以直接调用js方法来实现一些操作，下面的例子是 通过登录知乎然后通过js翻到页面底部，并弹框提示123456from selenium import webdriverbrowser = webdriver.Chrome()browser.get("http://www.zhihu.com/explore")browser.execute_script('window.scrollTo(0, document.body.scrollHeight)')browser.execute_script('alert("To Bottom")')获取元素属性-get_attribute(‘class’)12345678910from selenium import webdriverbrowser = webdriver.Chrome()url = 'https://www.zhihu.com/explore'browser.get(url)logo = browser.find_element_by_id('zh-top-link-logo')print(logo)print(logo.get_attribute('class'))获取文本值-text12345678from selenium import webdriverbrowser = webdriver.Chrome()url = 'https://www.zhihu.com/explore'browser.get(url)input = browser.find_element_by_class_name('zu-top-add-question')print(input.text)获取ID、位置、标签名idlocationtag_namesize1234567891011from selenium import webdriverbrowser = webdriver.Chrome()url = 'https://www.zhihu.com/explore'browser.get(url)input = browser.find_element_by_class_name('zu-top-add-question')print(input.id)print(input.location)print(input.tag_name)print(input.size)Frame在很多网页中都是有Frame标签，所以我们爬取数据的时候就涉及到切入到frame中以及切出来的问题，通过下面的例子演示这里常用的是switch_to.from()和switch_to.parent_frame():123456789101112131415161718192021import timefrom selenium import webdriverfrom selenium.common.exceptions import NoSuchElementExceptionbrowser = webdriver.Chrome()url = 'http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable'browser.get(url)browser.switch_to.frame('iframeResult')source = browser.find_element_by_css_selector('#draggable')print(source)try: logo = browser.find_element_by_class_name('logo')except NoSuchElementException: print('NO LOGO')browser.switch_to.parent_frame()logo = browser.find_element_by_class_name('logo')print(logo)print(logo.text)等待当使用了隐式等待执行测试的时候，如果 WebDriver没有在 DOM中找到元素，将继续等待，超出设定时间后则抛出找不到元素的异常, 换句话说，当查找元素或元素并没有立即出现的时候，隐式等待将等待一段时间再查找 DOM，默认的时间是0隐式等待到了一定的时间发现元素还没有加载，则继续等待我们指定的时间，如果超过了我们指定的时间还没有加载就会抛出异常，如果没有需要等待的时候就已经加载完毕就会立即执行123456789from selenium import webdriverbrowser = webdriver.Chrome()# 设置隐式等待browser.implicitly_wait(10)browser.get('https://www.zhihu.com/explore')input = browser.find_element_by_class_name('zu-top-add-question')print(input)显示等待指定一个等待条件，并且指定一个最长等待时间，会在这个时间内进行判断是否满足等待条件，如果成立就会立即返回，如果不成立，就会一直等待，直到等待你指定的最长等待时间，如果还是不满足，就会抛出异常，如果满足了就会正常返回常用的判断条件：title_is 标题是某内容title_contains 标题包含某内容presence_of_element_located 元素加载出，传入定位元组，如(By.ID, ‘p’)visibility_of_element_located 元素可见，传入定位元组visibility_of 可见，传入元素对象presence_of_all_elements_located 所有元素加载出text_to_be_present_in_element 某个元素文本包含某文字text_to_be_present_in_element_value 某个元素值包含某文字frame_to_be_available_and_switch_to_it frame加载并切换invisibility_of_element_located 元素不可见element_to_be_clickable 元素可点击staleness_of 判断一个元素是否仍在DOM，可判断页面是否已经刷新element_to_be_selected 元素可选择，传元素对象element_located_to_be_selected 元素可选择，传入定位元组element_selection_state_to_be 传入元素对象以及状态，相等返回True，否则返回Falseelement_located_selection_state_to_be 传入定位元组以及状态，相等返回True，否则返回Falsealert_is_present 是否出现Alert实例讲解，以来自这篇文章：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#coding=utf-8from selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver.support.wait import WebDriverWaitbase_url = "http://www.baidu.com"driver = webdriver.Firefox()# 定义等待时间，这是隐式等待，当隐式等待和显示等待都存在时，超时时间取二者中较大的，显示等待是sleep(10)这种driver.implicitly_wait(5)# 使用# 定义查找位置locator = (By.ID,'kw')driver.get(base_url)# 判断title,返回布尔值WebDriverWait(driver,10).until(EC.title_is(u"百度一下，你就知道"))# 判断title，返回布尔值WebDriverWait(driver,10).until(EC.title_contains(u"百度一下"))# 判断某个元素是否被加到了dom树里，并不代表该元素一定可见，如果定位到就返回WebElementWebDriverWait(driver,10).until(EC.presence_of_element_located((By.ID,'kw')))# 判断某个元素是否被添加到了dom里并且可见，可见代表元素可显示且宽和高都大于0WebDriverWait(driver,10).until(EC.visibility_of_element_located((By.ID,'su')))# 判断元素是否可见，如果可见就返回这个元素WebDriverWait(driver,10).until(EC.visibility_of(driver.find_element(by=By.ID,value='kw')))# 判断是否至少有1个元素存在于dom树中，如果定位到就返回列表WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR,'.mnav')))# 判断是否至少有一个元素在页面中可见，如果定位到就返回列表WebDriverWait(driver,10).until(EC.visibility_of_any_elements_located((By.CSS_SELECTOR,'.mnav')))# 判断指定的元素中是否包含了预期的字符串，返回布尔值WebDriverWait(driver,10).until(EC.text_to_be_present_in_element((By.XPATH,"//*[@id='u1']/a[8]"),u'设置'))# 判断指定元素的属性值中是否包含了预期的字符串，返回布尔值WebDriverWait(driver,10).until(EC.text_to_be_present_in_element_value((By.CSS_SELECTOR,'#su'),u'百度一下'))# 判断该frame是否可以switch进去，如果可以的话，返回True并且switch进去，否则返回False，注意这里并没有一个frame可以切换进去WebDriverWait(driver,10).until(EC.frame_to_be_available_and_switch_to_it(locator))# 判断某个元素在是否存在于dom或不可见,如果可见返回False,不可见返回这个元素，注意#swfEveryCookieWrap在此页面中是一个隐藏的元素WebDriverWait(driver,10).until(EC.invisibility_of_element_located((By.CSS_SELECTOR,'#swfEveryCookieWrap')))# 判断某个元素中是否可见并且是enable的，代表可点击WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.XPATH,"//*[@id='u1']/a[8]"))).click()driver.find_element_by_xpath("//*[@id='wrapper']/div[6]/a[1]").click()WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.XPATH,"//*[@id='wrapper']/div[6]/a[1]"))).click()# 等待某个元素从dom树中移除，这里没有找到合适的例子#WebDriverWait(driver,10).until(EC.staleness_of(driver.find_element(By.ID,'su')))# 判断某个元素是否被选中了,一般用在下拉列表WebDriverWait(driver,10).until(EC.element_to_be_selected(driver.find_element(By.XPATH,"//*[@id='nr']/option[1]")))# 判断某个元素的选中状态是否符合预期WebDriverWait(driver,10).until(EC.element_selection_state_to_be(driver.find_element(By.XPATH,"//*[@id='nr']/option[1]"),True))# 判断某个元素的选中状态是否符合预期WebDriverWait(driver,10).until(EC.element_located_selection_state_to_be((By.XPATH,"//*[@id='nr']/option[1]"),True))driver.find_element_by_xpath(".//*[@id='gxszButton']/a[1]").click()# 判断页面上是否存在alert,如果有就切换到alert并返回alert的内容instance = WebDriverWait(driver,10).until(EC.alert_is_present())print instance.textinstance.accept()driver.close()关于显式等待和隐式等待具体的讲解可以参考这篇文章更多操作参考浏览器的前进和后退back()forward()12345678910111213import timefrom selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.baidu.com/')browser.get('https://www.taobao.com/')browser.get('https://www.python.org/')browser.back()time.sleep(1)browser.forward()browser.close()cookie操作get_cookies()delete_all_cookes()add_cookie()1234567891011from selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.zhihu.com/explore')print(browser.get_cookies())browser.add_cookie(&#123;'name': 'name', 'domain': 'www.zhihu.com', 'value': 'zhaofan'&#125;)print(browser.get_cookies())browser.delete_all_cookies()print(browser.get_cookies())选项卡管理通过执行js命令实现新开选项卡window.open()不同的选项卡是存在列表里browser.window_handles通过browser.window_handles[0]就可以操作第一个选项卡12345678910111213141516import timefrom selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.baidu.com')browser.execute_script('window.open()')print(browser.window_handles)browser.switch_to_window(browser.window_handles[1])browser.get('https://www.taobao.com')time.sleep(1)browser.switch_to_window(browser.window_handles[0])browser.get('https://python.org')异常处理异常比较复杂，官网的参考地址，这里只进行简单的演示，查找一个不存在的元素1234567891011121314from selenium import webdriverfrom selenium.common.exceptions import TimeoutException, NoSuchElementExceptionbrowser = webdriver.Chrome()try: browser.get('https://www.baidu.com')except TimeoutException: print('Time Out')try: browser.find_element_by_id('hello')except NoSuchElementException: print('No Element')finally: browser.close()实战无界面模式浏览器：opt=webdriver.ChromeOptions()# 把chrome设置成无界面模式，不论windows还是linux都可以，自动适配对应参数opt.set_headless()#无界面self.driver=webdriver.Chrome(options=opt)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131from selenium import webdriverimport lxmlfrom lxml import etreeimport reimport timeimport pymysqlimport urllib.requestimport requestsfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver.common.by import Byclass LagouSpider(object): def __init__(self): opt=webdriver.ChromeOptions() # 把chrome设置成无界面模式，不论windows还是linux都可以，自动适配对应参数 opt.set_headless()#无界面 self.driver=webdriver.Chrome(options=opt) self.url="https://www.lagou.com/zhaopin/Python/" def run(self): self.driver.get(self.url) while True: source = self.driver.page_source #此句话大致意思，执行driver 时间不超过20s 什么时候加载到xpath定位的位置神魔时候停止开始执行页面 内容爬去 WebDriverWait(driver=self.driver,timeout=20).until(EC.presence_of_all_elements_located(By.XPATH,'//*[@id="s_position_list"]/div[2]/div/a[6]')) # WebDriverWait(driver=self.driver, timeout=20).until( # EC.presence_of_element_located((By.XPATH, '//*[@id="s_position_list"]/div[2]/div/a[6]')) # ) self.parse_list_page(source) # 点“下一页” next_btn=self.driver.find_element_by_xpath( '//*[@id="s_position_list"]/div[2]/div/a[6]') # 提取下一页的按钮，注意class的值中有空格不可用。 if "pager_next_disabled" in next_btn.get_attribute("class"): break else: next_btn.click() time.sleep(1) # next_btn = self.driver.find_element_by_xpath( # '//*[@id="s_position_list"]/div[2]/div/a[6]') # if "pager_next_disabled" in next_btn.get_attribute("class"): # break # else: # next_btn.click() # time.sleep(1) # source=self.driver.page_source # #print(source) # self.parse_list_page(source) #职位url列表 def parse_list_page(self,source): #t通过etree调用xpath html=etree.HTML(source) links=html.xpath('//*[@id="s_position_list"]/ul/li/div[1]/div[1]/div[1]/a/@href') for link in links: self.request_detail_page(link) # print(link) #time.sleep(1) #执行提取的url def request_detail_page(self,url): #self.driver.get(url) #打开新的页面 self.driver.execute_script("window.open('%s')"%url) #切换句柄进入新打开的页面 self.driver.switch_to.window((self.driver.window_handles[1])) # self.driver.execute_script("window.open('%s')" % url) # self.driver.switch_to.window(self.driver.window_handles[1]) #加载出来工作名开始爬取 WebDriverWait(driver=self.driver, timeout=20).until( EC.presence_of_element_located((By.XPATH, "//div[@class='job-name']/span[@class='name']")) ) source=self.driver.page_source self.parse_detail_page(source) # 关闭当前详情页，并且切换到列表页 self.driver.close() self.driver.switch_to.window(self.driver.window_handles[0]) #self.parse_list_page(source) #提取具体信息 def parse_detail_page(self,source): html=etree.HTML(source) positionName=html.xpath("//div[@class='position-head']/div/div[1]/div/span/text()")[0] job_request_spans=html.xpath("//div[@class='position-head']/div/div[1]/dd/p[1]/span") salary=job_request_spans[0].xpath(".//text()")[0].strip() city=job_request_spans[1].xpath('.//text()')[0].strip() #city = re.match(r'&lt;span class="xh-highlight"&gt;/(.*?) /&lt;/span&gt;',city) city = re.sub(r"[\s/]", "", city)#此处将"/"替换为空"" work_years = job_request_spans[2].xpath('.//text()')[0].strip() work_years = re.sub(r"[\s/]", "", work_years) education = job_request_spans[3].xpath('.//text()')[0].strip() education = re.sub(r"[\s/]", "", education) content = "".join(html.xpath("//dd[@class='job_bt']//text()")).strip() #print(positionName) #mysql=MySQLPipeline() #mysql.process_item(positionName,salary,city,work_years,education,content) ''' 语法： 'sep'.join(seq) 参数说明 sep：分隔符。可以为空 seq：要连接的元素序列、字符串、元组、字典 上面的语法即：以sep作为分隔符，将seq所有的元素合并成一个新的字符串 返回值：返回一个以分隔符sep连接各个元素后生成的字符串 '''class MySQLPipeline(object): def __init__(self): self.conn = pymysql.connect(host="localhost",user="root",password="root",db="lagou", charset='utf8') self.cursor = self.conn.cursor() def process_item(self,positionName,salary,city,work_years,education,content): insert_sql = ''' insert into lagou_table(positionName,salary,city,work_years,education,content) values(%s,%s,%s,%s,%s,%s) ''' self.cursor.execute(insert_sql,(positionName,salary,city,work_years,education,content)) self.conn.commit() def close_spider(self,spider): #TypeError: close_spider() takes 1 positional argument but 2 were given self.cursor.close() self.conn.close()if __name__=="__main__": spider=LagouSpider() spider.run()参考链接本文框架来源显示等待WebDriverWait与条件判断expected_conditions实例实战项目来源Selenium中的“显示等待”和“隐式等待”]]></content>
      <categories>
        <category>Python</category>
        <category>常用模块</category>
      </categories>
      <tags>
        <tag>常用模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之logging-日志]]></title>
    <url>%2Fposts%2F56982.html</url>
    <content type="text"><![CDATA[这篇文章依照这篇博客对Python的常用模块logging进行了学习，主要学习了日志的作用、不同开发环境设置不同的日志输出、使用logging模块的日志级别函数直接记录日志；也学习了logging模块的高级用法，包括使用logging模块的四大组件进行日志记录(主要用于满足多种需求，如将结果同时输出到文件和屏幕)、配置logging的几种方式、向日志输出上下文信息等；最后也总结了一些实战技巧。日志相关概念日志是一种可以追踪某些软件运行时所发生事件的方法。软件开发人员可以向他们的代码中调用日志记录相关的方法来表明发生了某些事情。一个事件可以用一个可包含可选变量数据的消息来描述。此外，事件也有重要性的概念，这个重要性也可以被称为严重性级别（level）。日志的作用通过log的分析，可以方便用户了解系统或软件、应用的运行情况；如果你的应用log足够丰富，也可以分析以往用户的操作行为、类型喜好、地域分布或其他更多信息；如果一个应用的log同时也分了多个级别，那么可以很轻易地分析得到该应用的健康状况，及时发现问题并快速定位、解决问题，补救损失。简单来讲就是，我们通过记录和分析日志可以了解一个系统或软件程序运行情况是否正常，也可以在应用程序出现故障时快速定位问题。比如，做运维的同学，在接收到报警或各种问题反馈后，进行问题排查时通常都会先去看各种日志，大部分问题都可以在日志中找到答案。再比如，做开发的同学，可以通过IDE控制台上输出的各种日志进行程序调试。对于运维老司机或者有经验的开发人员，可以快速的通过日志定位到问题的根源。可见，日志的重要性不可小觑。日志的作用可以简单总结为以下3点：程序调试了解软件程序运行情况，是否正常软件程序运行故障分析与问题定位如果应用的日志信息足够详细和丰富，还可以用来做用户行为分析，如：分析用户的操作行为、类型喜好、地域分布以及其它更多的信息，由此可以实现改进业务、提高商业利益。日志的等级我们先来思考下下面的两个问题：作为开发人员，在开发一个应用程序时需要什么日志信息？在应用程序正式上线后需要什么日志信息？作为应用运维人员，在部署开发环境时需要什么日志信息？在部署生产环境时需要什么日志信息？在软件开发阶段或部署开发环境时，为了尽可能详细的查看应用程序的运行状态来保证上线后的稳定性，我们可能需要把该应用程序所有的运行日志全部记录下来进行分析，这是非常耗费机器性能的。当应用程序正式发布或在生产环境部署应用程序时，我们通常只需要记录应用程序的异常信息、错误信息等，这样既可以减小服务器的I/O压力，也可以避免我们在排查故障时被淹没在日志的海洋里。那么，怎样才能在不改动应用程序代码的情况下实现在不同的环境记录不同详细程度的日志呢？这就是日志等级的作用了，我们通过配置文件指定我们需要的日志等级就可以了。不同的应用程序所定义的日志等级可能会有所差别，分的详细点的会包含以下几个等级(具体的级别高低在后面会有讲解)：DEBUGINFONOTICEWARNINGERRORCRITICALALERTEMERGENCY日志字段信息与日志格式本节开始问题提到过，一条日志信息对应的是一个事件的发生，而一个事件通常需要包括以下几个内容：事件发生时间事件发生位置事件的严重程度–日志级别事件内容上面这些都是一条日志记录中可能包含的字段信息，当然还可以包括一些其他信息，如进程ID、进程名称、线程ID、线程名称等。日志格式就是用来定义一条日志记录中包含哪些字段的，且日志格式通常都是可以自定义的。输出一条日志时，日志内容和日志级别是需要开发人员明确指定的(必须的)。对于而其它字段信息，只需要是否显示在日志中就可以了。日志功能的实现几乎所有开发语言都会内置日志相关功能，或者会有比较优秀的第三方库来提供日志操作功能，比如：log4j，log4php等。它们功能强大、使用简单。Python自身也提供了一个用于记录日志的标准库模块–logging。logging模块简介logging模块定义的函数和类为应用程序和库的开发实现了一个灵活的事件日志系统。logging模块是Python的一个标准库模块，由标准库模块提供日志记录API的关键好处是所有Python模块都可以使用这个日志记录功能。所以，你的应用日志可以将你自己的日志信息与来自第三方模块的信息整合起来。logging模块的日志级别logging模块默认定义了以下几个日志等级，它允许开发人员自定义其他日志级别，但是这是不被推荐的，尤其是在开发供别人使用的库时，因为这会导致日志级别的混乱。table th:first-of-type{width:20%}table th:nth-of-type(2){width:20%}table th:nth-of-type(3){width:60%}日志等级数值描述DEBUG10最详细的日志信息，典型应用场景是问题诊断INFO20信息详细程度仅次于DEBUG，通常只记录关键节点信息，用于确认一切都是按照我们预期的那样进行工作WARNING30当某些不期望的事情发生时记录的信息（如，磁盘可用空间较低），但是此时应用程序还是正常运行的ERROR40由于一个更严重的问题导致某些功能不能正常运行时记录的信息CRITICAL50当发生严重错误，导致应用程序不能继续运行时记录的信息上面列表中的日志等级是从上到下依次升高(按照数值的大小排序)的，即：DEBUG &lt; INFO &lt; WARNING &lt; ERROR &lt; CRITICAL，而日志的信息量是依次减少的；logging模块可以指定日志记录器的日志级别，只有级别大于或等于该指定日志级别的日志记录才会被输出，小于该等级的日志记录将会被丢弃；开发应用程序或部署开发环境时，可以使用DEBUG或INFO级别的日志获取尽可能详细的日志信息来进行开发或部署调试；应用上线或部署生产环境时，应该使用WARNING或ERROR或CRITICAL级别的日志来降低机器的I/O压力和提高获取错误日志信息的效率；日志级别的指定通常都是在应用程序的配置文件中进行的。logging模块的使用方式介绍logging模块提供了两种记录日志的方式：第一种方式是使用logging提供的日志级别的函数第二种方式是使用Logging日志系统的四大组件其实，logging所提供的模块级别的日志记录函数也是对logging日志系统相关类的封装而已logging模块定义的日志级别的常用函数:函数说明logging.debug(msg, *args, **kwargs)创建一条级别为DEBUG的日志记录logging.info(msg, *args, **kwargs)创建一条级别为INFO的日志记录logging.warning(msg, *args, **kwargs)创建一条级别为WARNING的日志记录logging.error(msg, *args, **kwargs)创建一条级别为ERROR的日志记录logging.critical(msg, *args, **kwargs)创建一条级别为CRITICAL的日志记录logging.log(level, *args, **kwargs)创建一条级别为level的日志记录logging.basicConfig(**kwargs)对root logger进行一次性配置其中logging.basicConfig(**kwargs)函数用于指定要记录的日志级别、日志格式、日志输出位置、日志文件的打开模式等信息，其他几个都是用于记录各个级别日志的函数。logging模块的四大组件组件说明loggers提供应用程序代码直接使用的接口handlers用于将日志记录发送到指定的目的位置filters提供更细粒度的日志过滤功能，用于决定哪些日志记录将会被输出（其它的日志记录将会被忽略）formatters用于控制日志信息的最终输出格式logging模块提供的模块级别的那些函数实际上也是通过这几个组件的相关实现类来记录日志的，只是在创建这些类的实例时设置了一些默认值。使用日志级别函数记录日志回顾下前面提到的几个重要信息：可以通过logging模块定义的日志级别方法去完成简单的日志记录只有级别大于或等于日志记录器指定级别的日志记录才会被输出，小于该级别的日志记录将会被丢弃最简单的日志输出使用各种具体级别的函数：1234567import logginglogging.debug("this is a debug log.")logging.info("this is a info log.")logging.warning("this is a warning log.")logging.error("this is a error log.")logging.critical("this is a critical log.")也可以使用统一设置级别的函数：1234567import logginglogging.log(logging.DEBUG, "This is a debug log.")logging.log(logging.INFO, "This is a info log.")logging.log(logging.WARNING, "This is a warning log.")logging.log(logging.ERROR, "This is a error log.")logging.log(logging.CRITICAL, "This is a critical log.")输出结果：1234567WARNING:root:this is a warning log.ERROR:root:this is a error log.CRITICAL:root:this is a critical log.================================WARNING:root:This is a warning log.ERROR:root:This is a error log.CRITICAL:root:This is a critical log.第二种写法显然没有第一种写法简单，以后还是使用第一种写法吧简单日志输出的结果分析为什么前面两条日志没有被打印出来？这是因为logging模块提供的日志记录函数所使用的日志器设置的日志级别是WARNING(logging的默认日志级别是warning)，因此只有WARNING级别的日志记录以及大于等于它的ERROR和CRITICAL级别的日志记录被输出了，而小于它的DEBUG和INFO级别的日志记录被丢弃了。日志信息中各字段含义？为什么会这样输出？上面输出结果中每行日志记录的各个字段含义分别是：1日志级别:日志器名称:日志内容之所以会这样输出，是因为logging模块提供的日志记录函数所使用的日志器设置的日志格式默认是BASIC_FORMAT，其值为：1"%(levelname)s:%(name)s:%(message)s"如果将日志记录输出到文件中，而不是打印到控制台？因为在logging模块提供的日志记录函数所使用的日志器设置的处理器所指定的日志输出位置默认为:sys.stderr.我是怎么知道这些的？查看这些日志记录函数的实现代码，可以发现：当我们没有提供任何配置信息的时候，这些函数都会去调用logging.basicConfig(**kwargs)方法，且不会向该方法传递任何参数。继续查看basicConfig()方法的代码就可以找到上面这些问题的答案了。查看源码：12345678# 先导入模块import logginghelp(logging.basicConfig)The default behaviour is to create a StreamHandler which writes to sys.stderr, set a formatter using the BASIC_FORMAT format string, and add the handler to the root logger.BASIC_FORMAT = "%(levelname)s:%(name)s:%(message)s"怎么修改这些默认设置呢？其实很简单，在我们调用上面这些日志记录函数之前，手动调用一下basicConfig()方法，把我们想设置的内容以参数的形式传递进去就可以了。logging.basicConfig()函数说明经过上述对简单日志输出的结果分析，发现如果我们想修改输出的信息(默认设置)就需要在调用日志记录函数之前，手动调用一下basicConfig()方法，所以这里来对logging.basicConfig()函数进行一定的学习。该方法用于为logging日志系统做一些基本配置，方法定义如下：1logging.basicConfig(**kwargs)该函数可接收的关键字参数如下：参数名称描述filename指定日志输出目标文件的文件名，指定该设置项后日志信息就不会被输出到控制台了filemode指定日志文件的打开模式，默认为a。需要注意的是，该选项要在filename指定时才有效format指定日志格式字符串，即指定日志输出时所包含的字段信息以及它们的顺序。logging模块定义的格式字段下面会列出。datefmt指定日期/时间格式。需要注意的是，该选项要在format中包含时间字段%(asctime)s时才有效level指定日志器的日志级别stream指定日志输出目标stream，如sys.stdout、sys.stderr以及网络stream。需要说明的是，stream和filename不能同时提供，否则会引发 ValueError异常stylePython 3.2中新添加的配置项。指定format格式字符串的风格，可取值为%、{和$，默认为%handlersPython 3.3中新添加的配置项。该选项如果被指定，它应该是一个创建了多个Handler的可迭代对象，这些handler将会被添加到root logger。需要说明的是：filename、stream和handlers这三个配置项只能有一个存在，不能同时出现2个或3个，否则会引发ValueError异常。格式字符串字段(format)这里列出了logging.basicConfig()函数中的日志格式字符串(format)包含的字段：字段/属性名称使用格式描述asctime%(asctime)s日志事件发生的时间–人类可读时间，如：2003-07-08 16:49:45,896created%(created)f日志事件发生的时间–时间戳，就是当时调用time.time()函数返回的值relativeCreated%(relativeCreated)d日志事件发生的时间相对于logging模块加载时间的相对毫秒数（目前还不知道干嘛用的）msecs%(msecs)d日志事件发生事件的毫秒部分levelname%(levelname)s该日志记录的文字形式的日志级别(‘DEBUG’, ‘INFO’, ‘WARNING’, ‘ERROR’, ‘CRITICAL’)levelno%(levelno)s该日志记录的数字形式的日志级别(10, 20, 30, 40, 50)name%(name)s所使用的日志器名称，默认是’root’，因为默认使用的是 rootLoggermessage%(message)s日志记录的文本内容，通过 msg % args计算得到的pathname%(pathname)s调用日志记录函数的源码文件的全路径filename%(filename)spathname的文件名部分，包含文件后缀module%(module)sfilename的名称部分，不包含后缀lineno%(lineno)d调用日志记录函数的源代码所在的行号funcName%(funcName)s调用日志记录函数的函数名process%(process)d进程IDprocessName%(processName)s进程名称，Python 3.1新增thread%(thread)d线程IDthreadName%(thread)s线程名称定义format的形式：BASIC_FORMAT = &quot;%(levelname)s:%(name)s:%(message)s&quot;这是官方的默认形式，不同字段间使用:分割，分割符可以自定义自定义输出日志信息level-自定义日志级别1234567891011import loggingprint ("=====change level=====")## 自定义日志器的日志级别logging.basicConfig(level=logging.DEBUG)logging.debug("this is a debug log.")logging.info("this is a info log.")logging.warning("this is a warning log.")logging.error("this is a error log.")logging.critical("this is a critical log.")输出信息：123456=====change level=====DEBUG:root:this is a debug log.INFO:root:this is a info log.WARNING:root:this is a warning log.ERROR:root:this is a error log.CRITICAL:root:this is a critical log.filename &amp; format-设置日志输出目标文件和日志格式filename：指定日志输出目标文件的文件名，指定该设置项后日志信心就不会被输出到控制台了format：指定日志格式字符串，即指定日志输出时所包含的字段信息以及它们的顺序。%(asctime)s：日志事件发生的时间–人类可读时间，如：2003-07-08 16:49:45,896%(levelname)s：该日志记录的文字形式的日志级别(&#39;DEBUG&#39;, &#39;INFO&#39;, &#39;WARNING&#39;, &#39;ERROR&#39;, &#39;CRITICAL&#39;)%(message)s：日志记录的文本内容，通过 msg % args计算得到的示例代码如下：1234567891011print ("=====change out file and format=====")# 设置输出的format，中间的字段分隔符可以自定义LOG_FORMAT="%(asctime)s - %(levelname)s - %(message)s"# 设置日志输出文件名以及formatlogging.basicConfig(filename='my.log',level=logging.DEBUG,format=LOG_FORMAT)logging.debug("this is a debug log.")logging.info("this is a info log.")logging.warning("this is a warning log.")logging.error("this is a error log.")logging.critical("this is a critical log.")输出结果：123456cat my.log 2019-03-23 00:01:29,910 - DEBUG - this is a debug log. 2019-03-23 00:01:29,910 - INFO - this is a info log. 2019-03-23 00:01:29,910 - WARNING - this is a warning log. 2019-03-23 00:01:29,910 - ERROR - this is a error log. 2019-03-23 00:01:29,910 - CRITICAL - this is a critical log.datefmt-设置日期/时间格式时间格式同time.strftime()，具体信息可以本文最后的补充信息该选项要在format中包含时间字段%(asctime)s时才有效12345678910LOG_FORMAT = "%(asctime)s - %(levelname)s - %(message)s"DATE_FORMAT = "%m/%d/%Y %H:%M:%S %p"logging.basicConfig(filename='my.log', level=logging.DEBUG, format=LOG_FORMAT, datefmt=DATE_FORMAT)logging.debug("This is a debug log.")logging.info("This is a info log.")logging.warning("This is a warning log.")logging.error("This is a error log.")logging.critical("This is a critical log.")输出结果：1234567891011cat my.log 2019-03-23 00:01:29,910 - DEBUG - this is a debug log. 2019-03-23 00:01:29,910 - INFO - this is a info log. 2019-03-23 00:01:29,910 - WARNING - this is a warning log. 2019-03-23 00:01:29,910 - ERROR - this is a error log. 2019-03-23 00:01:29,910 - CRITICAL - this is a critical log. 03/23/2019 00:18:15 AM - DEBUG - This is a debug log. 03/23/2019 00:18:15 AM - INFO - This is a info log. 03/23/2019 00:18:15 AM - WARNING - This is a warning log. 03/23/2019 00:18:15 AM - ERROR - This is a error log. 03/23/2019 00:18:15 AM - CRITICAL - This is a critical log.从上面输出结果可以发现，前面几行是上一步生成的日志文件，下面几行是这步生成的文件，这是因为默认的filemode是a也就是追加的意思，所以没有清空原始文件的信息。filemode-指定日志文件的打开模式该选项默认为a需要注意的是，该选项要在filename指定时才有效1234567891011LOG_FORMAT = "%(asctime)s - %(levelname)s - %(message)s"DATE_FORMAT = "%m/%d/%Y %H:%M:%S %p"# 将文件打开模式更改为w，如果存在就清空然后写入，如果不存在就创建logging.basicConfig(filename='my.log', level=logging.DEBUG, format=LOG_FORMAT, datefmt=DATE_FORMAT,filemode='w')logging.debug("This is a debug log.")logging.info("This is a info log.")logging.warning("This is a warning log.")logging.error("This is a error log.")logging.critical("This is a critical log.")输出结果：123456cat my.log 03/23/2019 00:23:36 AM - DEBUG - This is a debug log. 03/23/2019 00:23:36 AM - INFO - This is a info log. 03/23/2019 00:23:36 AM - WARNING - This is a warning log. 03/23/2019 00:23:36 AM - ERROR - This is a error log. 03/23/2019 00:23:36 AM - CRITICAL - This is a critical log.可以发现前一步的输出结果已经被覆盖掉了，只生成了这一步的输出结果。其他说明需要注意的内容logging.basicConfig()函数是一个一次性的简单配置工具，也就是说只有在第一次调用该函数时会起作用，后续再次调用该函数时完全不会产生任何操作的，多次调用的设置并不是累加操作日志器（Logger）是有层级关系的，上面调用的logging模块级别的函数所使用的日志器是RootLogger类的实例，其名称为root，它是处于日志器层级关系最顶层的日志器，且该实例是以单例模式存在的如果要记录的日志中包含变量数据，可使用一个格式字符串作为这个事件的描述消息(logging.debug、logging.info等函数的第一个参数)，然后将变量数据作为第二个参数*args的值进行传递，如:logging.warning(&#39;%s is %d years old.&#39;, &#39;Tom&#39;, 10)，输出内容为WARNING:root:Tom is 10 years old..日志级别方法参数的补充说明logging.debug(), logging.info()等方法的定义中，除了msg和args参数外，还有一个**kwargs参数。它们支持3个关键字参数: exc_info、stack_info、extra，下面对这几个关键字参数作个说明:exc_info：其值为布尔值，如果该参数的值设置为True，则会将异常信息添加到日志消息中；如果没有异常信息则添加None到日志信息中stack_info：其值也为布尔值，默认值为False。如果该参数的值设置为True，栈信息将会被添加到日志信息中，相当于是哪一行输入了这个log信息extra：这是一个字典（dict）参数，它可以用来自定义消息格式中所包含的字段，但是它的key不能与logging模块定义的字段冲突示例：在日志消息中添加exc_info和stack_info信息，并添加两个自定义的字端ip和user:1234567LOG_FORMAT = "%(asctime)s - %(levelname)s - %(user)s[%(ip)s] - %(message)s"DATE_FORMAT = "%m/%d/%Y %H:%M:%S %p"logging.basicConfig(format=LOG_FORMAT, datefmt=DATE_FORMAT)# 设置exc_info、stack_info、extra参数logging.warning("Some one delete the log file.", exc_info=True, stack_info=True, extra=&#123;'user': 'Tom', 'ip':'47.98.53.222'&#125;)输出结果：1234503/23/2019 09:28:06 AM - WARNING - Tom[47.98.53.222] - Some one delete the log file.NoneType: NoneStack (most recent call last): File "logging_learn.py", line 75, in &lt;module&gt; logging.warning("Some one delete the log file.", exc_info=True, stack_info=True, extra=&#123;'user': 'Tom', 'ip':'47.98.53.222'&#125;)日志模块四大组件以及日志流处理流程在介绍logging模块的高级用法之前，很有必要对logging模块所包含的重要组件以及其工作流程做个全面、简要的介绍，这有助于我们更好的理解我们所写的代码（将会触发什么样的操作）。日志模块四大组件在介绍logging模块的日志流处理流程之前，我们先来介绍下logging模块的四大组件：组件名称对应类名功能描述日志器Logger提供了应用程序可一直使用的接口处理器Handler将logger创建的日志记录发送到合适的目的输出过滤器Filter提供了更细粒度的控制工具来决定输出哪条日志记录，丢弃哪条日志记录格式器Formatter决定日志记录的最终输出格式logging模块就是通过这些组件来完成日志处理的，上面所使用的logging模块日志级别的函数也是通过这些组件对应的类来实现的。四大组件之间的关系日志器(logger)需要通过处理器(handler)将日志信息输出到目标位置，如：文件、sys.stdout、网络等；不同的处理器(handler)可以将日志输出到不同的位置；日志器(logger)可以设置多个处理器(handler)将同一条日志记录输出到不同的位置；每个处理器(handler)都可以设置自己的过滤器(filter)实现日志过滤，从而只保留感兴趣的日志；每个处理器(handler)都可以设置自己的格式器(formatter)实现同一条日志以不同的格式输出到不同的地方。简单点说就是：日志器(logger)是入口，真正干活儿的是处理器(handler)，处理器(handler)还可以通过过滤器(filter)和格式器(formatter)对要输出的日志内容做过滤和格式化等处理操作。组件相关类与常用方法介绍Logger类Logger对象有3个任务要做：向应用程序代码暴露几个方法，使应用程序可以在运行时记录日志消息；基于日志严重等级(默认的过滤设施)或filter对象来决定要对哪些日志进行后续处理；将日志消息传送给所有感兴趣的日志handlers。Logger对象最常用的方法分为两类：配置方法消息发送方法(创建日志)最常用的配置方法方法描述Logger.setLevel()设置日志器将会处理的日志消息的最低严重级别Logger.addHandler()和Logger.removeHandler()为该logger对象添加和移除一个handler对象Logger.addFilter()和Logger.removeFilter()为该logger对象添加和移除一个filter对象关于Logger.setLevel()方法的说明：内建等级中，级别最低的是DEBUG，级别最高的是CRITICAL。例如setLevel(logging.INFO)，此时函数参数为INFO，那么该logger将只会处理INFO、WARNING、ERROR和CRITICAL级别的日志，而DEBUG级别的消息将会被忽略/丢弃。创建日志记录方法logger对象配置完成后，可以使用下面的方法来创建日志记录：方法描述Logger.debug(), Logger.info(), Logger.warning(), Logger.error(), Logger.critical()创建一个与它们的方法名对应等级的日志记录Logger.exception()创建一个类似于Logger.error()的日志消息Logger.log()需要获取一个明确的日志level参数来创建一个日志记录Logger.exception()与Logger.error()的区别在于：Logger.exception()将会输出堆栈追踪信息，另外通常只是在一个exception handler中调用该方法Logger.log()与Logger.debug()、Logger.info()等方法相比，虽然需要多传一个level参数，显得不是那么方便，但是当需要记录自定义level的日志时还是需要该方法来完成得到一个Logger对象得到Logger对象方法有两种：第一种方式是通过Logger类的实例化方法创建一个Logger类的实例第二种方式是logging.getLogger()方法，这是通常使用的方法logging.getLogger()方法有一个可选参数name，该参数表示将要返回的日志器的名称标识，如果不提供该参数，则其值为’root’。若以相同的name参数值多次调用getLogger()方法，将会返回指向同一个logger对象的引用。关于logger的层级结构与有效等级的说明：logger的名称是一个以.分割的层级结构，每个.后面的logger都是.前面的logger的children，例如，有一个名称为 foo 的logger，其它名称分别为 foo.bar, foo.bar.baz 和 foo.bam都是 foo 的后代logger有一个有效等级(effective level)的概念。如果一个logger上没有被明确设置一个level，那么该logger就是使用它parent的level；如果它的parent也没有明确设置level则继续向上查找parent的parent的有效level，依次类推，直到找到个一个明确设置了level的祖先为止。需要说明的是，root logger总是会有一个明确的level设置(默认为 WARNING)。当决定是否去处理一个已发生的事件时，logger的有效等级将会被用来决定是否将该事件传递给该logger的handlers进行处理。child loggers在完成对日志消息的处理后，默认会将日志消息传递给与它们的祖先loggers相关的handlers。因此，我们不必为一个应用程序中所使用的所有loggers定义和配置handlers，只需要为一个顶层的logger配置handlers，然后按照需要创建child loggers就可足够了。我们也可以通过将一个logger的propagate属性设置为False来关闭这种传递机制。Handler类Handler对象的作用是（基于日志消息的level）将消息分发到handler指定的位置（文件、网络、邮件等）。Logger对象可以通过addHandler()方法为自己添加0个或者更多个handler对象。比如，一个应用程序可能想要实现以下几个日志需求：把所有日志都发送到一个日志文件中；把所有严重级别大于等于error的日志发送到stdout（标准输出）；把所有严重级别为critical的日志发送到一个email邮件地址。这种场景就需要3个不同的handlers，每个handler复杂发送一个特定严重级别的日志到一个特定的位置。一个handler中只有非常少数的方法是需要应用开发人员去关心的。对于使用内建handler对象的应用开发人员来说，似乎唯一相关的handler方法就是下面这几个配置方法：方法描述Handler.setLevel()设置handler将会处理的日志消息的最低严重级别Handler.setFormatter()为handler设置一个格式器对象Handler.addFilter()和Handler.removeFilter()为handler添加和删除一个过滤器对象需要说明的是，应用程序代码不应该直接实例化和使用Handler实例。因为Handler是一个基类，它只定义了所有handlers都应该有的接口，同时提供了一些子类可以直接使用或覆盖的默认行为。下面是一些常用的Handler：Handler描述logging.StreamHandler将日志消息发送到输出到Stream，如std.out, std.err或任何file-like对象。logging.FileHandler将日志消息发送到磁盘文件，默认情况下文件大小会无限增长logging.handlers.RotatingFileHandler将日志消息发送到磁盘文件，并支持日志文件按大小切割logging.hanlders.TimedRotatingFileHandler将日志消息发送到磁盘文件，并支持日志文件按时间切割logging.handlers.HTTPHandler将日志消息以GET或POST的方式发送给一个HTTP服务器logging.handlers.SMTPHandler将日志消息发送给一个指定的email地址logging.NullHandler该Handler实例会忽略error messages，通常被想使用logging的library开发者使用来避免'No handlers could be found for logger XXX'信息的出现。Formater类Formater对象用于配置日志信息的最终顺序、结构和内容。与logging.Handler基类不同的是，应用代码可以直接实例化Formatter类。另外，如果你的应用程序需要一些特殊的处理行为，也可以实现一个Formatter的子类来完成。Formatter类的构造方法定义如下：1logging.Formatter.__init__(fmt=None, datefmt=None, style='%')可见，该构造方法接收3个可选参数：fmt：指定消息格式化字符串，如果不指定该参数则默认使用message的原始值datefmt：指定日期格式字符串，如果不指定该参数则默认使用%Y-%m-%d %H:%M:%Sstyle：Python 3.2新增的参数，可取值为%、{和$，如果不指定该参数则默认使用%Filter类Filter可以被Handler和Logger用来做比level更细粒度的、更复杂的过滤功能。Filter是一个过滤器基类，它只允许某个logger层级下的日志事件通过过滤。该类定义如下：12class logging.Filter(name='') filter(record)比如，一个filter实例化时传递的name参数值为’A.B’，那么该filter实例将只允许名称为类似如下规则的loggers产生的日志记录通过过滤：’A.B’，’A.B,C’，’A.B.C.D’，’A.B.D’，而名称为’A.BB’, ‘B.A.B’的loggers产生的日志则会被过滤掉。如果name的值为空字符串，则允许所有的日志事件通过过滤。filter方法用于具体控制传递的record记录是否能通过过滤，如果该方法返回值为0表示不能通过过滤，返回值为非0表示可以通过过滤。如果有需要，也可以在filter(record)方法内部改变该record，比如添加、删除或修改一些属性我们还可以通过filter做一些统计工作，比如可以计算下被一个特殊的logger或handler所处理的record数量等logging日志流处理流程下面这个图描述了日志流的处理流程：我们来描述下上面这个图的日志流处理流程：（在用户代码中进行）日志记录函数调用，如：logger.info(…)，logger.debug(…)等；判断要记录的日志级别是否满足日志器设置的级别要求（要记录的日志级别要大于或等于日志器设置的级别才算满足要求），如果不满足则该日志记录会被丢弃并终止后续的操作，如果满足则继续下一步操作；根据日志记录函数调用时掺入的参数，创建一个日志记录（LogRecord类）对象；判断日志记录器上设置的过滤器是否拒绝这条日志记录，如果日志记录器上的某个过滤器拒绝，则该日志记录会被丢弃并终止后续的操作，如果日志记录器上设置的过滤器不拒绝这条日志记录或者日志记录器上没有设置过滤器则继续下一步操作–将日志记录分别交给该日志器上添加的各个处理器；判断要记录的日志级别是否满足处理器设置的级别要求（要记录的日志级别要大于或等于该处理器设置的日志级别才算满足要求），如果不满足记录将会被该处理器丢弃并终止后续的操作，如果满足则继续下一步操作；判断该处理器上设置的过滤器是否拒绝这条日志记录，如果该处理器上的某个过滤器拒绝，则该日志记录会被当前处理器丢弃并终止后续的操作，如果当前处理器上设置的过滤器不拒绝这条日志记录或当前处理器上没有设置过滤器测继续下一步操作；如果能到这一步，说明这条日志记录经过了层层关卡允许被输出了，此时当前处理器会根据自身被设置的格式器（如果没有设置则使用默认格式）将这条日志记录进行格式化，最后将格式化后的结果输出到指定位置（文件、网络、类文件的Stream等）；如果日志器被设置了多个处理器的话，上面的第5-8步会执行多次；这里才是完整流程的最后一步：判断该日志器输出的日志消息是否需要传递给上一级logger（之前提到过，日志器是有层级关系的）的处理器，如果propagate属性值为1则表示日志消息将会被输出到处理器指定的位置，同时还会被传递给parent日志器的handlers进行处理直到当前日志器的propagate属性为0停止，如果propagate值为0则表示不向parent日志器的handlers传递该消息，到此结束。可见，一条日志信息要想被最终输出需要依次经过以下几次过滤：日志器等级过滤日志器的过滤器过滤日志器的处理器等级过滤日志器的处理器的过滤器过滤需要说明的是： 关于上面第9个步骤，如果propagate值为1，那么日志消息会直接传递交给上一级logger的handlers进行处理，此时上一级logger的日志等级并不会对该日志消息进行等级过滤。使用四大组件记录日志现在，我们对logging模块的重要组件及整个日志流处理流程都应该有了一个比较全面的了解，下面我们来看一个例子。需求现在有以下几个日志记录的需求：要求将所有级别的所有日志都写入磁盘文件中all.log文件中记录所有的日志信息，日志格式为：日期和时间 - 日志级别 - 日志信息error.log文件中单独记录error及以上级别的日志信息，日志格式为：日期和时间 - 日志级别 - 文件名[:行号] - 日志信息要求all.log在每天凌晨进行日志切割分析要记录所有级别的日志，因此日志器的有效level需要设置为最低级别–DEBUG;日志需要被发送到两个不同的目的地，因此需要为日志器设置两个handler；另外，两个目的地都是磁盘文件，因此这两个handler都是与FileHandler相关的；all.log要求按照时间进行日志切割，因此他需要用logging.handlers.TimedRotatingFileHandler; 而error.log没有要求日志切割，因此可以使用FileHandler;两个日志文件的格式不同，因此需要对这两个handler分别设置格式器.实现12345678910111213141516171819202122232425262728293031import loggingimport logging.handlersimport datetimelogger = logging.getLogger('mylogger')# 设置日志器的日志级别logger.setLevel(logging.DEBUG)# 设置第一个handler，实现日志切割rf_handler = logging.handlers.TimedRotatingFileHandler('all.log', when='midnight', interval=1, backupCount=7, atTime=datetime.time(0, 0, 0, 0))# 设置第一个handler的格式器，使用了formatter类rf_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))# 设置第二个handlerf_handler = logging.FileHandler('error.log')# 设置这个handler的日志级别，实现日志过滤，在上面日志器的过滤结果中进行进一步的过滤f_handler.setLevel(logging.ERROR)# 设置第二个handler的日志格式，使用了formatter类f_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(filename)s[:%(lineno)d] - %(message)s"))# 给日志器添加第一个handlerlogger.addHandler(rf_handler)# 给日志器添加第二个handlerlogger.addHandler(f_handler)# 不同级别的日志信息 logger.debug('debug message')logger.info('info message')logger.warning('warning message')logger.error('error message')logger.critical('critical message')输出结果：12345678910cat all.log 2019-03-23 16:53:48,763 - DEBUG - debug message 2019-03-23 16:53:48,766 - INFO - info message 2019-03-23 16:53:48,766 - WARNING - warning message 2019-03-23 16:53:48,766 - ERROR - error message 2019-03-23 16:53:48,766 - CRITICAL - critical messagecat error.log 2019-03-23 16:53:48,766 - ERROR - logging_learn.py[:100] - error message 2019-03-23 16:53:48,766 - CRITICAL - logging_learn.py[:101] - critical message%(filename)s[:%(lineno)d]可以用来显示哪个文件的哪一行进行了这个日志输出其他实例日志同时输出到文件和屏幕上面的那个实例是创建了两个handler来进行相关操作，其实也可以使用四大组件和日志级别函数结合来进行设置，以下是将日志同时输出到文件和屏幕的示例：12345678910111213141516171819202122232425262728import logging# 使用logging.basicConfig()来自定义日志输出信息，将日志信息输入到文件中logging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s', datefmt='%a, %d %b %Y %H:%M:%S', filename='myapp.log', filemode='w')################################################################################################## 使用四大组件来控制日志，因为一个handler只能输出到一个地方# 这种需要输出到多个地方的肯定是需要两个handler的，上面的logging.basicConfig()相当于一个，所以还需要自己创建一个# 定义一个StreamHandler，将INFO级别或更高的日志信息打印到标准错误，并将其添加到当前的日志处理对象#console = logging.StreamHandler()# 设置handler的日志级别console.setLevel(logging.INFO)# 使用foramtter类设置formatterformatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')# 设置handler的formatterconsole.setFormatter(formatter)# 得到Logger类的对象并添加handlerlogging.getLogger('').addHandler(console)#################################################################################################logging.debug('This is debug message')logging.info('This is info message')logging.warning('This is warning message')配置logging的几种方式作为开发者，我们可以通过以下3中方式来配置logging:使用Python代码显式的创建loggers, handlers和formatters并分别调用它们的配置函数；创建一个日志配置文件，然后使用fileConfig()函数来读取该文件的内容；创建一个包含配置信息的dict，然后把它传递个dictConfig()函数；具体说明请参考另一篇博文《python之配置日志的几种方式》向日志输出中添加上下文信息除了传递给日志记录函数的参数外，有时候我们还想在日志输出中包含一些额外的上下文信息。比如，在一个网络应用中，可能希望在日志中记录客户端的特定信息，如：远程客户端的IP地址和用户名。这里我们来介绍以下几种实现方式：通过向日志记录函数传递一个extra参数引入上下文信息使用LoggerAdapters引入上下文信息使用Filters引入上下文信息具体说明请参考另一篇博文《Python之向日志输出中添加上下文信息》实战技巧中文乱码FileHandler 创建对象时可以设置文件编码，如果将文件编码设置为 utf-8（utf-8 和 utf8 等价），就可以解决中文乱码问题啦。一种方法是自定义 Logger 对象，需要写很多配置另一种方法是使用默认配置方法 basicConfig()，传入 handlers 处理器列表对象，在其中的 handler 设置文件的编码关键参考代码如下：12345# 自定义 Logger 配置handler = logging.FileHandler(filename="test.log", encoding="utf-8")# 使用默认的 Logger 配置，传入handlers时设置编码方式logging.basicConfig(handlers=[logging.FileHandler("test.log", encoding="utf-8")], level=logging.DEBUG)临时禁用日志输出有时候我们又不想让日志输出，但在这后又想输出日志。一种方法是在使用默认配置时，给 logging.disabled() 方法传入禁用的日志级别，就可以禁止设置级别以下的日志输出了另一种方法时在自定义 Logger 时，Logger 对象的 disable 属性设为 True，默认值是 False，也即不禁用12345# 使用默认配置logging.disable(logging.INFO)# 使用自定义的Loggerlogger.disabled = True分割日志文件logging.handlers文件中提供了TimedRotatingFileHandler和RotatingFileHandler类分别可以实现按时间和大小划分:12345# 每隔 1000 Byte 划分一个日志文件，备份文件为 3 个file_handler = logging.handlers.RotatingFileHandler("test.log", mode="w", maxBytes=1000, backupCount=3, encoding="utf-8")# 每隔 1小时 划分一个日志文件，interval 是时间间隔，备份文件为 10 个handler2 = logging.handlers.TimedRotatingFileHandler("test.log", when="H", interval=1, backupCount=10)这个在前面的使用四大组件记录日志的示例中也有提及。补充信息datefmt支持的时间格式格式含义%a本地（locale）简化星期名称%A本地完整星期名称%b本地简化月份名称%B本地完整月份名称%c本地相应的日期和时间表示%d一个月中的第几天（01 - 31）%H一天中的第几个小时（24小时制，00 - 23）%I第几个小时（12小时制，01 - 12）%j一年中的第几天（001 - 366）%m月份（01 - 12）%M分钟数（00 - 59）%p本地am或者pm的相应符%S秒（01 - 61）%U一年中的星期数。（00 - 53星期天是一个星期的开始。）第一个星期天之前的所有天数都放在第0周。%w一个星期中的第几天（0 - 6，0是星期天）%W和%U基本相同，不同的是%W以星期一为一个星期的开始。%x本地相应日期%X本地相应时间%y去掉世纪的年份（00 - 99）%Y完整的年份%Z时区的名字（如果不存在为空字符）%%‘%’字符参考链接Logging HOWTO-官方细致教程Logging Cookbook-官方实例官方链接Python之日志处理（logging模块）python 的日志logging模块学习项目中比较需要用到的]]></content>
      <categories>
        <category>Python</category>
        <category>常用模块</category>
      </categories>
      <tags>
        <tag>常用模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cat-显示、读取或拼接文件内容]]></title>
    <url>%2Fposts%2F24399.html</url>
    <content type="text"><![CDATA[这篇文章主要学习了使用Linux的cat命令来执行文件的查看、合并和创建功能。在查看文件方面包括的参数有：-n、-b、-s、-E、-T；在合并文件方面学习了结合输出重定向以及前面的查看功能的参数进行合并；在创建文件方面主要有三个命令：cat &gt;filename、cat &lt;&lt; EOF和cat &gt; filename &lt;&lt; EOF。cat简介cat 是一个文本文件(查看)和(连接)工具，通常是用于查看某个文件的内容，其主要有三大功能：显示整个文件内容将几个文件合并为一个文件从键盘创建一个文件cat命令用法cat命令格式1234Usage: cat [OPTION]... [FILE]...Description: Concatenate FILE(s), or standard input, to standard output.cat options说明table th:first-of-type{width:15%}table th:nth-of-type(2){width:25%}table th:nth-of-type(3){width:60%}参数完整参数说明-n–number由1开始对所有输出的行数编号-b–number-nonblank和-n相似，只不过对于空白行不编号-s–squeeze-blank当遇到有连续两行以上的空白行，只输出一行的空白行-E–show-ends在每行结束处显示$-v–show-nonprinting使用^和M-符号，除了LFD和TAB之外-T–show-tabs将TAB字符显示为^I-A–show-all等价于 -vET-e等价于-vE选项-t等价于-vT选项cat用法实例测试文件cat test1.txtab 1\====cat test2.txtcd\==查看文件功能-n-对所有行编号所有行包含空白行：cat -n test1.txt1 a2 b 1345 ====-b-对除空白行之外的行进行编号cat -b test1.txt1 a2 b 13 ==== 需要和上面的-n参数进行区分-s-只输出连续多行空白行的其中一行结合前面的-n参数：cat -sn test1.txt1 a2 b 134 ====可以发现只输出了连续两行空白行中的一个，并进行编号，说明是先输出一个，然后编号的，不是先编号再输出其中一行-E-在每行结束处显示$cat -E test1.txta \$b 1\$\$\$====\$-T-将TAB字符显示为^Icat -nT test1.txt1 a2 b ^I1345 ====合并文件功能将test1.txt和test2.txt合并后重定向到test3.txt中：cat test1.txt test2.txt &gt;test3.txtcat test3.txtab 1\====cd\==可以结合前面查看文件的参数：cat -n test1.txt test2.txt1 a2 b 1345 ====6 c7 d8 ==后面不接文件的话会输出到标准输出文件内容是按照文件顺序连接起来的编号是连续的，不是每个文件单独的编号创建文件相关功能这一部分主要有三个比较重要和常见的命令：cat &lt;&lt; EOFcat &gt; filenamecat &gt; filename &lt;&lt; EOF`cat &lt;&lt; EOF以EOF输入字符为标准输入结束，这里的EOF并不是固定的(EOF是end of file，表示文本结束符，使用有含义的字符可能更容易记住用法)，可以设置为mmm等其他自定义的字符，示例如下：1234567891011121314cat &lt;&lt; EOF &gt; ad # 开始从标准输入读取&gt; adad&gt; EOF # 遇到了标准输入结束字符，结束标准输入 ad # 直接输出adad# 更换标准输入结束字符cat &lt;&lt; mmm&gt; ad&gt; ad&gt; mmm # 遇到了上面定义的标准输入结束字符，结束标准输入 adad这一部分输入输入和输出重定向部分，还可以参考这篇文章cat &gt; filename创建文件，并把标准输入输出到filename文件中，以ctrl+d作为输入结束:123456789# 创建文件并写入cat &gt; filenameadadad # 这一行输入完成之后按下快捷键ctrl+d结束输入# 查看文件内容cat filename adadadcat &gt; filename命令和上面的cat &lt;&lt; EOF不同之处在于：cat &lt;&lt; EOF不会创建文件，而cat &gt; filename会创建文件cat &lt;&lt; EOF可以自定义结束的字符，而cat &gt; filename则是使用快捷键ctrl+d作为输入结束cat &lt;&lt; EOF输入的时候有&gt;提示输入，而cat &gt; filename没有任何提示输入的此内容cat &gt; filename &lt;&lt; EOF这个是上面两个的合并版，既可以创建文件，又可以自定义停止输入字符：1234567891011121314# 创建文件并设置停止输入字符cat &gt; test4.txt &lt;&lt; EOF&gt; a&gt; b&gt; c&gt; d&gt; EOF # 遇到了标准输入结束字符，结束标准输入，但是不会直接输入，因为内容已经重定向到test4.txt中# 查看test4.txt文件内容，是刚刚输入的内容cat test4.txt abcd上面的创建文件也可以改为追加文件：cat &gt;&gt; test4.txt &lt;&lt; EOFcat &gt; filename &lt;&lt; EOF书写的前后顺序可以调换，比如可写成：cat &lt;&lt; EOF &gt; filename参考链接cat命令Linux cat命令Linux cat命令详解Linux中cat、more、less、tail、head命令的区别]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git系列-Git实战总结]]></title>
    <url>%2Fposts%2F5778.html</url>
    <content type="text"><![CDATA[这篇文章主要记录了在使用Git中遇到的比较使用的技巧和问题解决方案，便于后续查询和使用。.gitignore文件不起作用以及文件规则文件书写规则在使用Git管理代码的过程中，可以修改.gitignore文件中的标示的方法来忽略开发者想忽略掉的文件或目录(实际项目中，很多文件都是不需要版本管理的)，如果没有.gitignore文件，可以自己手工创建。在.gitignore文件中的每一行保存一个匹配的规则例如：1234567# 此为注释 – 将被 Git 忽略 *.a # 忽略所有 .a 结尾的文件!lib.a # 但 lib.a 除外/TODO # 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODObuild/ # 忽略 build/ 目录下的所有文件doc/*.txt # 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt需要强调的一点是，如果你不慎在创建.gitignore文件之前就push了项目，那么即使你在.gitignore文件中写入新的过滤规则，这些规则也不会起作用，Git仍然会对所有文件进行版本管理。简单来说，出现这种问题的原因就是Git已经开始管理这些文件了，所以你无法再通过过滤规则过滤它们。所以大家一定要养成在项目开始就创建.gitignore文件的习惯，否则一旦push，处理起来会非常麻烦。忽略整个文件夹，只需要build/即可，千万不要build/*，这样的话不会起效清除本地缓存如果一不小心在创建.gitignore文件之前就使用了git push，这样可能会使得.gitignore的忽略规则失效，这是因为新建的文件在git中会有缓存，如果某些文件已经被纳入了版本管理中，就算是在.gitignore中已经声明了忽略路径也是不起作用的，这时候我们就应该先把本地缓存删除，然后再进行git push，这样就不会出现忽略的文件了。git清除本地缓存命令如下：123456# 清除缓存git rm -r --cached .# 将所有文件改变上传到暂存区git add .# 将暂存区的所有内容提交到当前分支上git commit -m 'update .gitignore'git push -u VS git pushgit push的用法：12Usage: git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;使用实例：12345678# 将本地的master分支推送到origin主机的master分支。如果master不存在，则会被新建git push origin master# 如果当前分支与多个主机存在追踪关系(连接)，则可以使用-u选项指定一个默认主机，这样后面就可以不加任何参数使用：# 先使用带-u参数的git pushgit push -u origin master # 后续的git push可以省略参数git push将已有的文件夹上传到github背景：可能有些时候并没有在文件夹创建之初没有考虑到上传到Github的情况，所以就需要将已有的文件夹上传到Github，但是又不希望先建立空的repo，然后clone下来将文件复制进去，然后就有了下面的方法：在bash下进入需要上传的文件夹：cd dir初始化产生版本库：git init将所有文件添加到暂存区：git add .提交文件：git commit -m &quot;message&quot;添加远程仓库：git remote add origin git@github.com:showteeth/orth_blast_docker.git上传本地代码：git push -u origin master后续上传：git add .git commit -m &quot;message&quot;git push origin master或者git push在使用git push -u origin master上传本地代码时，如果报错：1error: failed to push some refs to 'git@github.com:showteeth/orth_blast_docker.git'按照这个issue的说法，可以试试git push -u origin master --force或者按照这篇文章的做法：合并代码：git pull origin master或者git pull --rebase origin master(文章中使用的这个，但我感觉是不是应该使用前面的，下次可以先试试前面的可不可以)上传代码：git push -u origin master]]></content>
      <categories>
        <category>其他内容学习</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker系列-Dockerfile]]></title>
    <url>%2Fposts%2F31987.html</url>
    <content type="text"><![CDATA[这里写摘要，显示更好看开始于二级标题参考链接Dockerfile详解docker学习(3)–Dockfile详解Dockerfile参考(8) – CMD设置运行容器时执行的命令Docker CMDdocker学习笔记16：Dockerfile 指令 ADD 和 COPY介绍Dockerfile创建自定义Docker镜像以及CMD与ENTRYPOINT指令的比较九个编写Dockerfiles的常见错误]]></content>
      <categories>
        <category>其他内容学习</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-构建第一个docker镜像]]></title>
    <url>%2Fposts%2F371.html</url>
    <content type="text"><![CDATA[这是我的第一个Docker镜像，主要是依托项目是寻找两个基因之间的同源基因对。这篇文章主要记录了创建第一个镜像的过程，包括前期测试、编写Dockfile、查看镜像、运行镜像、修改镜像、退出、关闭、重启镜像、删除镜像以及后面的发布镜像、拉取镜像等操作，同时也记录了运行中的一些错误和解决办法。Docker 镜像docker 镜像是一个只读的 docker 容器模板，含有启动 docker 容器所需的文件系统结构及其内容(包括对资源需求、环境的要求、依赖的类库和运行的代码等等)，因此是启动一个 docker 容器的基础。DockerfileDockerfile用于构建一致的Docker镜像，其定义了容器中的运行环境，包括像网络接口和虚拟化的磁盘驱动等硬件资源，这些资源是与宿主系统隔离开的，不会对系统有任何影响。使用Docker镜像运行Docker容器，可以让定义在该镜像中的应用程序无论在哪里运行，都有一致的功能。示例Dockerfile学习以下是官方的Dockerfile:1234567891011121314151617181920212223# 使用官方python镜像作为根镜像FROM python:2.7-slim# 这行定义的是维护人和维护人邮箱，由MAINTAINER开头MAINTAINER "user_id&lt;email address&gt;"# 将容器工作目录设置为 /appWORKDIR /app# 将当前目录（宿主机）中的内容全部复制到容器的 /app 目录下ADD . /app# 安装 requirements.txt 中定义好的包RUN pip install -r requirements.txt# 对外公开容器的80端口EXPOSE 80# 定义一个环境变量worldENV NAME World# 在容器启动时，运行 python app.py命令CMD ["python", "app.py"]示例Dockerfile解读FROM：FROM命令是必须的，可以是基于某个镜像从0开始构建：需要使用scratch，scratch代表着一个空白的镜像**，此时基本命令就是FROM scratch；基于某个镜像：如上使用官方python镜像作为根镜像，所有的官方镜像可以在这个网站看到MAINTAINER：就是将维护人信息添加到脚本文件中，不一定需要，可有可无WORKDIR：定义工作目录ADD：将主机构建环境（上下文）目录中的文件和目录、以及一个URL标记的文件拷贝到镜像中RUN：用来执行基本命令的，基本格式有两种第一种是Shell格式：如上面安装包的命令以及RUN npm install第二种是exec格式：如RUN [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;]由于Dockerfile每一个命令都会建立一层，RUN也不例外，在不必要的情况下使用多行RUN命令会使得镜像非常冗余和庞大，以下是一个示例:1234567FROM debian:jessieRUN apt-get updateRUN apt-get install -y gcc libc6-dev makeRUN wget -O redis.tar.gz "http://download.redis.io/releases/redis-3.2.5.tar.gz" RUN mkdir -p /usr/src/redisRUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1RUN make -C /usr/src/redisRUN make -C /usr/src/redis install类似上述例子，一共构建了7层镜像，这是完全没有意义的，而且很多运行时不需要的东西，都被装进了镜像里，比如编译环境、更新的软件包等等，结果就是产生非常臃肿、非常 多层的镜像，不仅仅增加了构建部署的时间，也很容易出错。正确写法：123456789101112FROM debian:jessieRUN buildDeps='gcc libc6-dev make' \&amp;&amp; apt-get update \&amp;&amp; apt-get install -y $buildDeps \&amp;&amp; wget -O redis.tar.gz "http://download.redis.io/releases/redis-3.2.5.tar.gz" \ &amp;&amp; mkdir -p /usr/src/redis \ &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \ &amp;&amp; make -C /usr/src/redis \ &amp;&amp; make -C /usr/src/redis install \ &amp;&amp; rm -rf /var/lib/apt/lists/* \ &amp;&amp; rm redis.tar.gz \ &amp;&amp; rm -r /usr/src/redis \ &amp;&amp; apt-get purge -y --auto-remove $buildDeps首先，之前所有的命令只有一个目的：编译、安装redis可执行文件。因此没有必要建立很多层，这只是一层的事情。因此，这里没有使用很多个 RUN 对一一对应不同的命令，而是仅仅使用一个RUN指令，并使用 &amp;&amp;将各个所需命令串联起来。将之前的7层，简化为了1层。其中每行命令后的 \ 代表着换行，使dockerfile的RUN命令更具有可读性。此外，命令的最后一行还有一个 --auto-remove命令，这个为清理工作的命令，删除了编译所需要的软件，清理下载以及展开的文件，并且还清理了apt缓存文件。由于镜像是一层一层构建的，每一层的多余东西并不会在下一层中被删除掉，到后面镜像会越来越大，因此清理这些没有用处的东西很有必要.RUN示例参考博客在了解了上述规则之后，我们看看最开始的示例Dockerfile，其中安装Python所需要的依赖包时使用了文件进行安装，没有使用多行命令以及上述提及的使用&amp;&amp;的方法：1RUN pip install -r requirements.txt示例的requirements.txt文件内容：12FlaskRedisEXPOSE：将指定的端口暴露出来，可以供外界访问，或者映射到宿主机的端口上去CMD：容器启动命令，CMD命令和RUN命令相似，也是两种格式，分别为 shell命令格式和 exec命令格式。CMD 指令就是用于指定默认的容器主进程的启动命令的。在exec命令格式上，一般会被解析成json数组格式，需要用双引号，不能使用单引号!!!在了解了上述规则之后，我们看看最开始的示例Dockerfile的CMD命令：CMD [&quot;python&quot;, &quot;app.py&quot;]，属于 exec命令格式，注意使用的是双引号，意思是容器使用Python运行app.py文件，至于具体的app.py文件信息就不列举了。各个参数的官方解释动手测试Dockerfile基于上面对示例Dockerfile的学习，接下来自己建立自己的Dockerfile建立centos的测试Dockerfile内容如下：12345678# 使用centos7FROM centos:7# 维护人信息MAINTAINER showteeth# 设置工作目录WORKDIR /orth# 看看是否安装了python以及版本CMD python -v创建docker镜像基于上述Dockerfile使用命令docker build -f .\Dockerfile -t centos:1.0 .建立镜像：123456789101112131415161718192021222324252627docker build -f .\Dockerfile -t centos:1.0 .Sending build context to Docker daemon 3.072kB# 第一步对应于第一行Step 1/4 : FROM centos:77: Pulling from library/centos8ba884070f61: Pull completeDigest: sha256:ca58fe458b8d94bc6e3072f1cfbd334855858e05e1fd633aa07cf7f82b048e66Status: Downloaded newer image for centos:7 ---&gt; 9f38484d220f# 第二步对应于第二行Step 2/4 : MAINTAINER showteeth ---&gt; Running in 75f880e1b2d9Removing intermediate container 75f880e1b2d9 ---&gt; 9ea90a7b7832# 第三步对应于第三行Step 3/4 : WORKDIR /orth ---&gt; Running in 2c117f20ad92Removing intermediate container 2c117f20ad92 ---&gt; 07e0e346b57d# 第四步对应于第四行 Step 4/4 : CMD python -v ---&gt; Running in 297b155a52beRemoving intermediate container 297b155a52be ---&gt; 1f29d9e70facSuccessfully built 1f29d9e70facSuccessfully tagged centos:1.0SECURITY WARNING: You are building a Docker image from Windows against a non-Windows Docker host. All files and directories added to build context will have '-rwxr-xr-x' permissions. It is recommended to double check and reset permissions for sensitive files and directories.查看镜像创建完成之后使用命令docker images查看镜像：123# 注意这里信息和build命令以及输出信息的对应REPOSITORY TAG IMAGE ID CREATED SIZEcentos 1.0 1f29d9e70fac 8 minutes ago 202MB运行镜像使用docker run -it centos:1.0运行镜像：12345678910# /usr/lib64/python2.7/encodings/aliases.pyc matches /usr/lib64/python2.7/encodings/aliases.pyimport encodings.aliases # precompiled from /usr/lib64/python2.7/encodings/aliases.pyc# /usr/lib64/python2.7/encodings/ascii.pyc matches /usr/lib64/python2.7/encodings/ascii.pyimport encodings.ascii # precompiled from /usr/lib64/python2.7/encodings/ascii.pycPython 2.7.5 (default, Oct 30 2018, 23:45:53)[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux2Type "help", "copyright", "credits" or "license" for more information.dlopen("/usr/lib64/python2.7/lib-dynload/readline.so", 2);import readline # dynamically loaded from /usr/lib64/python2.7/lib-dynload/readline.so&gt;&gt;&gt;如上，运行之后自动运行了python -v，因为前面的Dockerfile的CMD写的就是这个命令，如果没有Python，可以参考这个链接来安装Python修改镜像由于开始的时候设置了CMD python -v，导致镜像运行之后自动进入Python程序，退出Python之后也退出了整个docker环境，所以想知道可不可以修改CMD命令，查询相关文档之后，可以使用如下进行修改：1234docker run -it --entrypoint=/bin/bash $IMAGE -i# 如我可以使用如下命令进入bash shell的交互环境docker run -it --entrypoint=/bin/bash centos:1.0 -i退出、关闭、重启镜像使用命令exit来退出正在使用的镜像，注意退出之后并没有关闭，后台还在运行，使用docker ps -a可看到使用docker stop image_id|name来关闭镜像删除镜像测试版本镜像和真正想要使用的镜像有很大差距，所以打算直接删掉重新创建一个镜像：1234567891011121314151617# 停止所有的container，这样才能够删除其中的images：docker stop $(docker ps -a -q) # Linux下可以这么使用，windows还是单个单个操作吧# 如果想要删除 所有container 的话再加一个指令：docker rm $(docker ps -a -q)# 查看当前有些什么imagesdocker images# 删除images，通过image的 id 来指定删除谁，注意和上面的删除容器相区分docker rmi &lt;image id&gt;# 想要删除untagged images，也就是那些id为&lt;None&gt;的image的话可以用docker rmi $(docker images | grep "^&lt;none&gt;" | awk "&#123;print $3&#125;")# 要删除 全部 image的话docker rmi $(docker images -q)注意：运行docker时docker desktop必须也在运行，而且不要关闭，一旦关闭，正在运行的container会直接退出编写Dockfile准备文件信息blast软件包python相关运行文件初始文件(fasta文件)相关的脚本正式的Dockerfile经过上述所有的学习和尝试，这里给出了最终可以运行的Dockerfile：12345678910111213141516171819202122232425# 使用centos镜像FROM centos:7# 这行定义的是维护人和维护人邮箱，由MAINTAINER开头MAINTAINER showteeth# 将容器工作目录设置为 /orthWORKDIR /orth# 将当前目录（宿主机）中的内容全部复制到容器的 /orth 目录下ADD . /orth# 安装 requirements.txt 中定义好的包RUN yum -y install epel-release \ &amp;&amp; yum -y install python-pip \ &amp;&amp; yum -y install vim \ &amp;&amp; pip install -r requirements.txt \ &amp;&amp; chmod 744 /orth/scripts/docker_blast.sh \ &amp;&amp; tar -zxvf /orth/ncbi-blast-2.8.1+-x64-linux.tar.gz# 将blast加入环境变量ENV PATH /orth/ncbi-blast-2.8.1+/bin:$PATH# 在容器启动时，运行命令CMD /bin/bash上面使用ADD没有执行自动解压操作，后续添加了自动解压操作，这个是官方的一个issue，后续版本会改进。创建和运行镜像创建镜像：docker build -f .\Dockerfile -t orth_project:2.0 .运行镜像：docker run -it orth_project:2.0在镜像中使用bash /orth/scripts/docker_blast.sh运行查找同源基因的程序发布镜像主要步骤如下：第一步：开通阿里云镜像服务第二步：创建镜像仓库第三步：推送镜像第四步：查找验证镜像首先是开通阿里云镜像服务：接下来创建镜像仓库：仓库类型选择公开代码源选择本地仓库创建完成镜像仓库后，点击刚刚创建的镜像的管理，发现如下信息：然后，就可以按照上述图片中的提示完成镜像的推送，下面也列出了镜像推送的命令：docker login --username=username registry.cn-beijing.aliyuncs.com输入这一步需要验证密码，验证成功会显示Login Succeededdocker tag [ImageId] registry.cn-beijing.aliyuncs.com/showteeth/orth_blast_project:[镜像版本号]这一步前面的[ImageId]使用docker images查看，[镜像版本号]是你上传上去想要显示的版本号，运行完成没有输出信息docker push registry.cn-beijing.aliyuncs.com/showteeth/orth_blast_project:[镜像版本号]这里的[镜像版本号]是你上传上去想要显示的版本号，和上一步的保持一致，这一步完成会显示如下信息：123456The push refers to repository [registry.cn-beijing.aliyuncs.com/showteeth/orth_blast_project]788a64a2f222: Pushedf652370971d2: Pushedd245b64a20a7: Pushedd69483a6face: Pushed1.0: digest: sha256:2bf8b43babcdecbd0d06dda78e3b585439e17b07642f1445f7911563afb98ca7 size: 1161上传完成镜像后，本地也会出现一个名为registry.cn-beijing.aliyuncs.com/showteeth/orth_blast_project的镜像(该镜像具有和原始镜像相同的iamge id)，可以删除，通过命令docker rmi -f registry.cn-beijing.aliyuncs.com/showteeth/orth_blast_project:1.0删除最后是查找验证镜像，经过上面几步已经成功将镜像上传到阿里云，接下来到阿里云中搜索自己刚刚上传的镜像：拉取镜像在上述查询到镜像结果之后，点击查看镜像的详细信息：复制公网地址并使用如下命令拉取镜像：docker pull registry.cn-beijing.aliyuncs.com/showteeth/orth_blast_project:[镜像版本号]注意这个[镜像版本号]一定要指定，因为可能会存在很多版本号，这里指定后会拉取指定版本运行完成之后输出如下信息：1231.0: Pulling from showteeth/orth_blast_projectDigest: sha256:2bf8b43babcdecbd0d06dda78e3b585439e17b07642f1445f7911563afb98ca7Status: Downloaded newer image for registry.cn-beijing.aliyuncs.com/showteeth/orth_blast_project:1.0错误build with gRPC error使用命令docker build -f .\Dockerfile -t centos:1.0 .报错：1ERRO[0000] failed to dial gRPC: cannot connect to the Docker daemon. Is 'docker daemon' running on this host?: open //./pipe/docker_engine: The system cannot find the file specified.解决办法：在Github上看到了类似的issue，主要的解决方法是在docker的设置中开启experimental features，如下图：开启完成之后就解决了问题docker image is being used在使用docker rmi 20ffdd2f28c0删除镜像是发现：1Error response from daemon: conflict: unable to delete 20ffdd2f28c0 (must be forced) - image is being used by stopped container 7356c1e7efc0解决方法：先删除上面提示的那个占用当前镜像的7356c1e7efc0：1docker rm 7356c1e7efc0然后再使用命令docker rmi 20ffdd2f28c0：1docker rmi 20ffdd2f28c0参考链接Docker工作基本流程Docker初体验，向Docker Hub推送第一个Docker镜像第一次构建、运行、发布、获取docker镜像Docker入门（二）创建您的第一个Docker镜像10张图带你深入理解Docker容器和镜像]]></content>
      <categories>
        <category>其他内容学习</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python-博客转载项目]]></title>
    <url>%2Fposts%2F26003.html</url>
    <content type="text"><![CDATA[这个项目主要是基于在转载博客时直接复制HTML后期不好修改，不能像Markdown一样生成大纲，不易管理，所以这里想做这样一个项目，项目地址。实现过程HTML装换为markdown要想实现博客的装载，其中HTML装换为markdown是最为关键的一步，目前github上使用较多的(star较多)的HTML装换为markdown工具有三个：turndown，使用javascript代码，有网页版可以使用，比较好用，如果没有太大需要可以使用这个html2text，使用Python代码，可以嵌入其他程序使用，比较方便(很多印象笔记转文本的都是使用这个的)，这次我也打算使用这个tomd，这个也是使用Python代码，但是star没有前面一个高，作为备用吧html2text使用1234567&gt;&gt;&gt; import html2text&gt;&gt;&gt; print (html2text.html2text("&lt;p&gt;Hello, world.&lt;/p&gt;"))Hello, world.&gt;&gt;&gt; h = html2text.HTML2Text()&gt;&gt;&gt; print (h.handle("&lt;p&gt;Hello, &lt;a href='http://earth.google.com/'&gt;world&lt;/a&gt;!"))Hello, [world](http://earth.google.com/)!爬取网站内容有了HTML装换markdown的工具，还需要使用工具将网页内容爬取下来，这里使用Python爬虫实现。XPATH和selector都可以通过右键复制得到Selenium模拟登陆很好用博客园、CSDN、简书博客这几个网站作为统一的博客平台，爬虫时选取的部位固定，所以直接内置了.其他自建博客需要给双引号增加转义，如下：1python blog_parse.py -u http://rvdsd.top/2017/09/22/BioStatistics/%E7%94%9F%E7%89%A9%E7%BB%9F%E8%AE%A1-13%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/ -b others -c //*[@id=\"posts\"]/article/div/div -t //*[@id=\"posts\"]/article/div/header/h1印象笔记网上有将印象笔记先到处enex格式文件，然后根据这个文件进行转换格式的工具，但是我使用后发现并不好用.所以这里的想法是先将印象笔记分享为html的形式，然后再进行html转换为markdown，这样应该效果会好很多。印象笔记开发者文档印象笔记 Python SDK 快速入门指南申请印象笔记 API Key见官网教程下载印象笔记 Python SDK不要使用官网的那个链接，使用Python3的版本，然后执行：1python setup.py install测试 SDK进入Python环境，尝试导入包：123456from evernote.api.client import EvernoteClientTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "C:\Users\14910\Anaconda3\lib\site-packages\evernote3-1.25.0-py3.7.egg\evernote\api\client.py", line 6, in &lt;module&gt;ModuleNotFoundError: No module named 'oauth2'按照上面的提示，安装oauth2包：12345pip install oauth2# 再进入Python环境from evernote.api.client import EvernoteClient# 成功认证常规的按照印象笔记网站上的步骤，但是进行的过程中发现使用网站上的代码一直报错：1234567891011# 代码from evernote.api.client import EvernoteClientdev_token = "personal taken"client = EvernoteClient(token=dev_token,sandbox=False,service_host='app.yinxiang.com')userStore = client.get_user_store()user = userStore.getUser()print (user.username)# 报错evernote.edam.error.ttypes.EDAMSystemException: EDAMSystemException(message='authenticationToken', errorCode=8, rateLimitDuration=None)在官方文档的各种地方查找都没有找到合适的方法，最后在这篇文章中找到了解决方案：1234567from evernote.api.client import EvernoteClientdev_token = "personla taken"client = EvernoteClient(token=dev_token,sandbox=False,service_host='app.yinxiang.com')userStore = client.get_user_store()user = userStore.getUser()print (user.username)吐槽一句：印象笔记的官方文档实在是太差了！！！忍不了！！！这篇文章中解决问题的步骤很值得我们学习，查看源码，找出问题，然后解决问题，很关键。NoteStore-笔记本仓库NoteStore 是用来创建、更新和删除笔记、笔记本还有其他在用户帐户中可找到的印象笔记的数据的。12345noteStore = client.get_note_store()notebooks = noteStore.listNotebooks()# 输出笔记本的名称for n in notebooks: print (n.name)输出内容：12我的第一个笔记本导入的笔记Notebook-笔记本通过NoteStore类的listNotebooks方法可以获取一个包含所有笔记本的列表在客户端视图中存在笔记本的嵌套，但实际上数据存储中所有笔记本都在同一层其下的笔记并不能通过该类的某个属性或者方法获取不管笔记本为空还是有笔记，属性都会有值123456for notebook in noteStore.listNotebooks(): # 得到笔记本的名字 notebookName = notebook.name # 得到笔记本的guid notebookGuid = notebook.guid print('&#123;&#125;: &#123;&#125;'.format(notebookName, notebookGuid))输出信息：1234我的第一个笔记本: dd36443d-2ef1-4289-aeb6-527e57ce173b导入的笔记: 5c1dd2ec-8e0a-4a6e-b5f0-22507c178086笔记本2: 3f683ab0-4ea7-4ffb-800d-4c0864413c4b笔记本1: 61bb02cd-1fc2-404e-9bc6-2c20555dedecenml to markdownenml格式讲解不合算，放弃爬取动态页面使用selenium模拟登陆遇到的问题：123456789browser = webdriver.Chrome()Traceback (most recent call last): File "C:\Users\14910\Anaconda3\lib\site-packages\selenium\webdriver\common\service.py", line 76, in start stdin=PIPE) File "C:\Users\14910\Anaconda3\lib\subprocess.py", line 769, in __init__ restore_signals, start_new_session) File "C:\Users\14910\Anaconda3\lib\subprocess.py", line 1172, in _execute_child startupinfo)FileNotFoundError: [WinError 2] 系统找不到指定的文件。这是因为没有将浏览器驱动以及没有将浏览器驱动添加到环境变量：12345678910111213# 驱动下载地址http://npm.taobao.org/mirrors/chromedriver/# 下载对应的chrome版本之后将压缩包解压，我下载的是chromedriver_win32.zip# 发现32位的也能用，关键是只提供了32位的# 解压上述包，然后将exe文件写入环境变量，可将exe文件放在C:\Program Files (x86)\Google\Chrome\Application目录下# 添加环境变量(可能需要重启电脑才会生效)之后直接输入chromedriver.exeStarting ChromeDriver 72.0.3626.69 (3c16f8a135abc0d4da2dff33804db79b849a7c38) on port 9515Only local connections are allowed.Please protect ports used by ChromeDriver and related test frameworks to prevent access by malicious code.用法博客园、CSDN、简书博客博客园：python blog_parse.py -u https://www.cnblogs.com/zhaof/p/6953241.html -p C:/Users/14910/DesktopCSDN：python blog_parse.py -b csdn -u https://blog.csdn.net/work_you_will_see/article/details/84638750 -p C:/Users/14910/Desktop简书博客：python blog_parse.py -b jianshu -u https://www.jianshu.com/p/95331e7a98cd -p C:/Users/14910/Desktop自建博客得到title的xpath：得到content的xpath：使用命令：python blog_parse.py -b others -c //*[@id=\&quot;posts\&quot;]/article/div/div[1] -t //*[@id=\&quot;posts\&quot;]/article/div/header/h1 -u http://showteeth.tech/posts/56982.html -p C:/Users/14910/Desktop印象笔记将笔记导出单个html文件将图片上传到图床，如果上传到图床的某个文件夹，需要指定下面的-f参数使用命令：python blog_parse.py -l &quot;C:/Users/14910/Desktop/VS code配置.html&quot; -f VS_code配置 -b evernote开发日志 启动这个项目 2019-3-21 印象笔记转载-API 爬虫的方法，enml-这个就相当于使用印象笔记转markdown的那些工具，效果不好 爬虫，模拟登陆— failed 既然能够模拟登陆了，那就不用在使用分享链接了啊，直接在网页版的印象笔记操作即可—&gt; failed 博客园 CSDN 其他自建博客 爬取文章标题作为新建的markdown文件的标题 提供多种方法，加上另一个html转markdown的工具—&gt;do not have the need 图片链接会自动换行，导致图片显示不出来 fixed with set body_width = 0[ ] 图片保留html形式，设置images_as_html=True，但没有起作用[x] 印象笔记导出之前需要将其图片名称进行修改—&gt;两图片的空格替换为%20 参数分组 爬取整个博客然后转化为markdown(不是很实用) 增加配置文件参考链接EasierLifeEvernote2Blog使用Python操作Evernote API]]></content>
      <categories>
        <category>Python</category>
        <category>项目实战</category>
      </categories>
      <tags>
        <tag>实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sublime text3使用以及配置]]></title>
    <url>%2Fposts%2F53131.html</url>
    <content type="text"><![CDATA[这篇文章主要记录了在学习和使用sublime text编辑器过程中对其进行的配置和优化，包括一些插件的用法，便于后续使用和查询常规配置插件配置显示目录插件使用的是插件：SublimeOutline显示效果：具体使用：打开侧边栏：ctrl + shift + p打开命令框，然后再输入Browse Mode: Outline (Right)关闭侧边栏：ctrl + shift + p打开命令框，然后再输入Browse mode: Close sidebar(s)设置自定义的模板使用的插件是：SublimeTmpl ，该插件默认支持html、ruby、html、php、js和python，由于平时使用bash脚本也比较多，所以想设置一下bash的模板添加自定义模板：C:\Users\user\AppData\Roaming\Sublime Text 3\Packages\User\SublimeTmpl\templates(说是会优先使用这个目录下的自定义模板)，按照插件已存在的模板来看看如何写，我写的如下：1234567891011#!/bin/bash# @Date : $&#123;date&#125;# @Author : $&#123;author&#125; ($&#123;email&#125;)#BSUB -J $1#BSUB -o $1.%J#BSUB -e $1.%J#BSUB -n 16#BSUB -q TEST-A$0需要特别注意模板的命名：需要结合已存在的对bash语言的支持，如下一步的语言支持中是shellscript，这里的模板命令也要是shellscript，不然不会高亮脚本，保存的时候也不会出现默认的后缀名。查看是不是有bash语言的支持：在Sublime Text/Preferences/Package Settings/SublimeTmpl/Setting-Default中查看，这里有bash语言的支持，所以就不需要进行进一步的配置，如果没有的话需参考官方设置语言的方式：1234"shellscript": &#123; "syntax": "Packages/ShellScript/Shell-Unix-Generic.tmLanguage", "extension": "sh" &#125;新增开始菜单：可以在Sublime Text/Preferences/Package Settings/SublimeTmpl/Menu-Default里：123456789101112&#123; "id": "shellscript", "caption": "shellscript", "command": "sublime_tmpl", "args": &#123; "type": "shellscript" &#125;&#125;,# 上面的type是自己创建的模板名称，我创建的是shellscript.tmpl，所以这里是shellscript，还需要和支持的bash语言的名称相对应# caption是menu里面显示的名称# 这我设置user menu没有起效，不知道为啥，只有设置了default menu才起效如果需要给一种语言增加两种模板，想我需要一个server版的、一个本地的版的：bash语言的支持中增加：1234"shellscript_basic": &#123; "syntax": "Packages/ShellScript/Shell-Unix-Generic.tmLanguage", "extension": "sh" &#125;,User\SublimeTmpl\templates中创建shellscript_basic.tmpl：12345#!/bin/bash# @Date : $&#123;date&#125;# @Author : $&#123;author&#125; ($&#123;email&#125;)$0Menu-Default中添加：12345678&#123; "id": "bash_basic", "caption": "bash_basic", "command": "sublime_tmpl", "args": &#123; "type": "shellscript_basic" &#125;&#125;,这里没有设置快捷键，因为快捷键多了容易冲突，所以就没有设置，直接在菜单栏中选择也是不错的。参考链接开发者的中文说明，可以看看评论区插件的github支持GBK编码的文件sublime text的默认打开文件的编码方式是UTF-8，打开GBK编码的文件出现乱码， 并且reopen with encoding也没有找到对应GBK的编码，需要安装插件GBK support]]></content>
      <categories>
        <category>折腾</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>sublime text3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客图床-阿里云+PicGo上传照片]]></title>
    <url>%2Fposts%2F41221.html</url>
    <content type="text"><![CDATA[这篇文章主要是关于使用阿里云搭建图床以及使用PicGo进行上传照片的操作，便与后续查询使用前言本来图床使用的是七牛的服务，但是前几天七牛给我发了一封”测试域名回收通知”的邮件，看了邮件，然后查看相关说明发现如果想要使用就有添加自己的域名，然后为了添加自己的域名还要去公安部备案，尝试了一下，太麻烦了，然后看了一下关于阿里和腾讯的，本着天下没有免费的午餐的理念，我选择了阿里(腾讯的存储不要钱)，然后就有了接下来的故事。开通阿里云oss主要流程：实名认证—&gt;开通对象存储服务 OSS—&gt;购买资源包—&gt;新建Bucket购买资源包的时候可以选取资源包类型和规格等信息，按照自己的需求选取即可，我这里选择的是存储包以及40G大小，作为博客图片应该是足够用了(如果有再小一点的我肯定就选了)。关于阿里oss收费，比较复杂，主要包括：存储容量，流量，请求次数。刚刚购买的只是存储容量，具体的收费详情请查看这个链接接下来就是新建Bucket了，我按照如下选项进行的创建：使用PicGo上传图片PicGo是一款图片上传的工具，目前支持微博图床、七牛图床、腾讯云、又拍云、GitHub、阿里等主流图床，并且支持macOS、windows 64位（&gt;= v1.3.1），linux（&gt;= v1.6.0），可是说是全平台很强大了，这是Github链接、这是官方网站下载并安装之后进入图床设置，选择对应的图床，我这里选取了阿里oss：accesskey和accesskeySecret可以从阿里云控制台获取(就在新建Bucket旁边)存储空间名是bucket的名字存储区域按照提示填写(在bucket的访问域名中可以看到)存储路径按照提示填写自定义域名可以不填写PicGo插件使用这里给出的PicGo中包含的插件，我觉得比较好的是vs-picgo，其可以在vscode中使用，刚好自己使用的就是vscode，所以非常方便，这里记录这个插件的主要用法。安装插件，直接在vscode应用商店中搜索PicGo即可配置插件：修改vscode的setting.json文件，加入如下内容：123456789101112131415// 其中的XXX使用自己的信息填写进去"picgo": &#123; "path": ""&#125;,"picBed": &#123; "current": "aliyun", "aliyun": &#123; "accessKeyId": "XXX", "accessKeySecret": "XXX", "bucket": "XXX", "area": "XXX", "path": "XXX", "customUrl": "" &#125;&#125;,插件上传的图片不会显示在PicGo软件的相册中，直接上传在了阿里云如果想要对上传的图片更改名称，可以先选中名称，然后再插入图片上传只支持markdown的链接，不支持其他类型(如html)链接，这个没有PicGo桌面版好用支持从剪贴板、文件选取以及输入框上床，对应的快捷键如下：ctrl+alt+u：剪贴板图片上传ctrl+alt+e：打开文件管理器上传ctrl+alt+o：打开输入框输入路径上传]]></content>
      <categories>
        <category>折腾</category>
        <category>博客</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之argparse-命令行选项与参数解析]]></title>
    <url>%2Fposts%2F19941.html</url>
    <content type="text"><![CDATA[这篇文章主要学习了Python用于解析命令行参数的argparse模块，按照其使用过程依次学习了生成参数分析器、添加参数、参数解析和输出传入参数值，最后还学习了参数群组、比较强大的创建子命令以及互斥参数组的使用。前言argparse是 Python 标准库中用来解析命令行参数和选项的模块，很早之前就想学习和使用这个模块了，但由于种种原因没能实现；之前一直使用的是sys模块的argv来传递参数，但是这种传递参数的方法比较简单，不能输出一些提示信息，导致有些脚本很久之后再看可能不知道当时设置的参数的含义或者需要打开具体的脚本才能知道参数的含义，比较麻烦，所以这里来对argparse进行学习，在以后的脚本中替换sys模块。初识argparse创建python文件(注意不要将文件命名为argparse.py，不然会报错，因为文件名和模块名相同，导入会出问题)，并在其中写入如下代码：1234567891011121314151617import argparse# 生成参数分析器parser = argparse.ArgumentParser(description='Process some integers.')# 添加参数parser.add_argument('integers', metavar='N', type=int, nargs='+', help='an integer for the accumulator')parser.add_argument('--sum', dest='accumulate', action='store_const', const=sum, default=max, help='sum the integers (default: find the max)')# 参数解析args = parser.parse_args()# 输出传入参数值 print(args.accumulate(args.integers))运行上述python文件：python argparse_test.py -husage: argparse_test.py [-h] [–sum] N [N …]Process some integers.positional arguments:N an integer for the accumulatoroptional arguments:-h, –help show this help message and exit–sum sum the integers (default: find the max)从上述输出结果可以发现：argparse会自动生成帮助文档，也就是说即使在程序中不添加任何参数，argparse也会自动默认生成一个参数-h，用于输出帮助文档在上述argparse使用过程中依次经过了生成参数分析器、添加参数、参数解析和输出传入参数值这几步，接下来我就按照这个顺序进行学习。创建解析器-ArgumentParser类上述argparse测试代码中使用argparse.ArgumentParser()创建参数分析器也就是解析器，这里就先对这个解析器进行一定的了解，其原型如下：123456789101112class argparse.ArgumentParser(prog=None, usage=None, description=None, epilog=None, parents=[], formatter_class=argparse.HelpFormatter, prefix_chars='-', fromfile_prefix_chars=None, argument_default=None, conflict_handler='error', add_help=True, allow_abbrev=True)其中参数的含义：table th:first-of-type{width:30%}table th:nth-of-type(2){width:50%}table th:nth-of-type(3){width:20%}参数含义默认值prog程序的名字，help中显示的sys.argv[0]usage描述程序用途的字符串从解析器的参数生成description参数帮助信息之前的文本noneepilog参数帮助信息之后的文本noneparentsArgumentParser 对象的一个列表，这些对象的参数应该包括进去(参数继承)formatter_class定制化输出的帮助信息prefix_chars可选参数的前缀字符‘-‘fromfile_prefix_chars从文件中读取参数时文件的前缀字符Noneargument_default参数的全局默认值Noneconflict_handler解决冲突的可选参数的策略（通常没有必要）add_help解析器添加-h/–help 选项Trueallow_abbrev如果前缀是明确的，则允许缩写长参数Trueproc-help中描述程序的名称proc参数代表程序的名字，默认为sys.argv[0]，用来在help信息中描述程序的名称:12# 修改上述代码解析器的部分如下parser = argparse.ArgumentParser(prog='myprogram')并使用python argparse_test.py -h运行程序：usage: myprogram [-h]发现usage后面接着的文字由默认的argparse_test.py(sys.argv[0])变成了现在的prog=&#39;myprogram&#39;定义的内容usage-描述程序用途12# 可以结合proc一起使用parser = argparse.ArgumentParser(prog='myprogram', usage='%(prog)s is a test of argparse')使用python argparse_test.py -h运行程序：usage: myprogram is a test of argparse发现usage后面接着的文字由默认的argparse_test.py [-h]变成了现在的myprogram is a test of argparsedescription和epilog-程序描述信息，help 信息前后的文字1parser = argparse.ArgumentParser(description='before help',epilog="after help")使用python argparse_test.py -h运行程序：usage: argparse_test.py [-h]before helpoptional arguments:-h, –help show this help message and exitafter helpprefix_chars-参数前缀1parser = argparse.ArgumentParser(prefix_chars='+')使用python argparse_test.py +h运行程序：usage: argparse_test.py [+h]optional arguments:+h, ++help show this help message and exitparents-参数继承我们常常需要实现一套命令行程序，这些程序都带一组参数，只是在某些方面有特殊化。例如，如果所有程序都需要在用户进行任何实际的操作之前对用户进行认证，那么它们就都需要支持--user和--password选项。你可以共享的选项来定义一个“父母”解析器，然后令单个程序的解析器从该“父母”解析器继承共享选项，这样就不必显式为每个ArgumentParser添加共享选项。第一步是以共享的参数定义建立“父母”解析器。注意：由于“父母”解析器的后代使用者会添加相同的帮助选项，从而会引发一个异常(见下面冲突解决)，所以在基础解析器中我们关闭自动帮助选项生成。123456import argparse# 注意这里的add_help=Falseparser = argparse.ArgumentParser(add_help=False)parser.add_argument('--user', action="store")parser.add_argument('--password', action="store")文件保存在名为argparse_parent_base.py的文件中第二步以父母解析器集创建另一个解析器：123456789101112import argparse# 导入parent的文件import argparse_parent_base# 继承父母解析器的参数parser = argparse.ArgumentParser(parents=[argparse_parent_base.parser])# 设置自己的参数parser.add_argument('--local-arg', action="store_true", default=False)# 输出所有的参数print parser.parse_args()输出信息：1234567891011python argparse_uses_parent.py -h# 输出内容usage: argparse_uses_parent.py [-h] [--user USER] [--password PASSWORD] [--local-arg]# 可以发现继承了父母解析器的参数optional arguments: -h, --help show this help message and exit --user USER --password PASSWORD --local-argconflict_handler-冲突解决前一个例子指出以相同的参数名字为一个解析器添加两个参数处理器会引发一个异常(就是parent中提到的的帮助选项)。可以通过传递一个conflict_handler来改变冲突消除行为。argparse有两个内置的冲突处理器error（默认）和resolve，resolve会基于冲突选项的添加顺序来选择一个参数处理器:12345678910import argparse# 设置冲突解决的策略为resolveparser = argparse.ArgumentParser(conflict_handler='resolve')parser.add_argument('-a', action="store")# 两个相同参数名的参数parser.add_argument('-b', action="store", help="Short alone")parser.add_argument('--long-b', '-b', action="store", help="Long and short together")print parser.parse_args(['-h'])由于最后一个处理器所给定的参数名已被使用，那么本例中独立选项-b将被--long-b所覆盖:1234567891011python argparse_conflict_handler_resolve.py# 输出内容usage: argparse_conflict_handler_resolve.py [-h] [-a A] [--long-b LONG_B]optional arguments: -h, --help show this help message and exit -a A # 只出现了后定义的参数，前面定义的参数被覆盖了 --long-b LONG_B, -b LONG_B Long and short together切换add_argument()的调用顺序就可以使两个选项都可以使用：12345678910import argparseparser = argparse.ArgumentParser(conflict_handler='resolve')parser.add_argument('-a', action="store")# 同样是定义两个相同参数名的参数，只是顺序发生改变parser.add_argument('--long-b', '-b', action="store", help='Long and short together')parser.add_argument('-b', action="store", help='Short alone')print parser.parse_args([-h])1234567891011python argparse_conflict_handler_resolve2.py# 输出内容usage: argparse_conflict_handler_resolve2.py [-h] [-a A] [--long-b LONG_B] [-b B]optional arguments: -h, --help show this help message and exit -a A # 两个参数都可以使用了，没有进行覆盖 --long-b LONG_B Long and short together -b B Short alonefromfile_prefix_chars-从文件中读取参数时文件的前缀字符集123456&gt;&gt;&gt; with open('args.txt', 'w') as fp:... fp.write('-f\nbar')&gt;&gt;&gt; parser = argparse.ArgumentParser(fromfile_prefix_chars='@')&gt;&gt;&gt; parser.add_argument('-f')&gt;&gt;&gt; parser.parse_args(['-f', 'foo', '@args.txt'])Namespace(f='bar')当参数过多时，可以将参数放到文件中读取，例子中parser.parse_args([&#39;-f&#39;, &#39;foo&#39;, &#39;@args.txt&#39;])解析时会从文件args.txt读取，相当于[&#39;-f&#39;, &#39;foo&#39;, &#39;-f&#39;, &#39;bar&#39;]add_help-解析器添加-h/–help 选项设为 False 时，help 信息里面不再显示 -h --help 信息以上是我觉得比较重要的参数，但不是全部参数，具体参数的解释请参考官方文档allow_abbrev-长参数缩写参考后面解析参数-parse_args()的参数缩写添加参数-add_argument()创建解析器之后如果需要为程序序添加参数选项需要用 ArgumentParser 对象的 add_argument 方法，该方法原型如下:12345ArgumentParser.add_argument(name or flags...[, action][, nargs] [, const][, default] [, type][, choices] [, required][, help] [, metavar][, dest])参数含义name or flags选项字符串的名字或者列表，例如foo 或者-f, --fooaction在命令行遇到该参数时采取的基本动作类型nargs应该读取的命令行参数个数const某些action和nargs选项要求的常数值default如果命令行中没有出现该参数时的默认值type命令行参数应该被转换成的类型choices包含参数可允许的值的一个容器required该命令行选项是否可以省略(只针对可选参数)help参数的简短描述metavar参数在帮助信息中的名字dest给parse_args()返回的对象要添加的属性名称位置参数和可选参数在学习具体的各个参数的含义之前，先了解一下argparse中的两种参数类型：位置参数和可选参数，位置参数在定义时没有前缀，而可选参数需要加前缀（默认为’-‘）。位置参数123456# 在前面的代码中按如下进行修改# 添加echo这个位置参数，且定义参数的帮助信息parser.add_argument("echo", help = "echo the string you use here")# 添加print args.echo使用python argparse_test.py -h运行程序：usage: argparse_test.py [-h] echopositional arguments:echo echo the string you use hereoptional arguments:-h, –help show this help message and exit如果直接使用python argparse_test.py运行程序，不加参数：python argparse_test.pyusage: argparse_test.py [-h] echoargparse_test.py: error: the following arguments are required: echo位置参数相当于默认情况下使用了参数，如果不进行传参会报错，当然这可以通过action=&#39;store_true&#39;解决使用python argparse_test.py test运行程序：python argparse_test.py testtest在添加参数后程序正常执行，输出参数值(通过解析后，参数的值保存在echo变量中)可选参数可选参数有两种：通过一个-来指定的短参数，如-h通过--来指定的长参数，如--help长参数是完整版，使用比较麻烦，而短参数则是简写版，便于使用，两个可以同时存在，也可以只写其中一个1parser.add_argument("-v", "--verbosity", help="increase output verbosity")显示出帮助信息：python argparse_test.py -husage: argparse_test.py [-h] [-v VERBOSITY]optional arguments:-h, –help show this help message and exit-v VERBOSITY, –verbosity VERBOSITYincrease output verbosity可选参数-v或--verbosity，通过解析后，其值保存在args.verbosity变量中:12# 添加一句print (args.verbosity)python argparse_test.py -v 22位置参数和可选参数是通过-来区分，如果不加-，argparse会将其当做位置参数解析位置参数在解析时，值存储在位置参数同名的变量中；可选参数在解析时，如果没有添加长参数，则和位置参数一样，储存在同名变量中，而如果添加了长参数，则存储在长参数的变量中name or flags-参数名1234# 添加位置参数，echo即为参数名parser.add_argument("echo", help = "echo the string you use here")# 添加可选参数，-v和--verbosity都为参数名parser.add_argument("-v", "--verbosity", help="increase output verbosity")action-对参数采取的动作action包括六种不同的取值，分别为store(默认选项)、store_const、store_true、store_false、append、append_const、count、help、version。只存储值–action=’store1parser.add_argument('--foo', action='store')这是默认情况，可以不用加，这种情况如果使用了参数但是不传入值，就会报错常量参数–action=’store_const’store_const，表示参数为固定值，该固定值存放在 const 中:1234567import argparseparser = argparse.ArgumentParser() # 生成参数分析器parser.add_argument('--foo', action='store_const', const=42)args = parser.parse_args()print (args.foo)python argparse_test.py --foo42不能修改值(默认值，不能修改)，如果修改值就会报错：python argparse_test.py --foo 20usage: argparse_test.py [-h] [–foo]argparse_test.py: error: unrecognized arguments: 20True or False–store_true和store_falsestore_true和store_false，值存为 True 或 False。这个很实用，比如前面在位置参数中如果直接执行(可选参数也是一样，不过需要调用)，不对参数传值的话就会报错，但是设置这个之后参数即使不传参，调用后也会返回值，不过是True或者False：123parser.add_argument('--foo', action='store')parser.add_argument('--foo', action='store_true')使用python argparse_test.py --foo执行程序：usage: argparse_test.py [-h] [–foo FOO]argparse_test.py: error: argument –foo: expected one argumentTrue存储列表参数-action=’append’1parser.add_argument('--foo', action='append')python argparse_test.py --foo 2 --foo 3[‘2’, ‘3’]参数出现次数–action=’count’1parser.add_argument('--foo', action='count')python argparse_test.py --foo --foo2保存常量到列表–action=’append_const’1234567parser.add_argument('-A', action='append_const', dest='const_collection', const='value-1-to-append', default=[], help='Add different values to list')parser.add_argument('-B', action='append_const', dest='const_collection', const='value-2-to-append', help='Add different values to list')python argparse_test.py -A -B[‘value-1-to-append’, ‘value-2-to-append’]可以参考上面的action=&#39;store_const&#39;版本信息–action=’version’1parser.add_argument('--version', action='version', version='%(prog)s 2.0')python argparse_test.py --versionargparse_test.py 2.0nargs-参数数量参数可以传入的值的数目，可以为：整数N：N个传入值，返回传入值的列表，即使为1， 也返回列表&#39;*&#39;：任意多个传入值(包括0个)，返回列表&#39;+&#39;：一个或更多，不加传入值的时候会报错，返回列表&#39;?&#39;：首先从命令行获得参数，若没有则从const获得，然后从default获得；还可以使用该参数指定输入和输出文件argparse.REMAINDER：将剩余的参数作为列表搜集起来整数N1parser.add_argument('--foo', nargs=2)python argparse_test.py --foo 1 2[‘1’, ‘2’]注意使用整数N(N个)时返回的是一个列表，即使N=1，返回的也是一个元素的列表，这和默认行为(传入一个参数)返回传入值本身不同使用&#39;?&#39;进行文件操作1234567# 读取文件，默认值为从标准输入读取parser.add_argument('infile', nargs='?', type=argparse.FileType('r'), default=sys.stdin)# 写入文件，默认值为标准输出parser.add_argument('outfile', nargs='?', type=argparse.FileType('w'), default=sys.stdout)如果没有提供nargs参数，传入值的数量将由action决定，通常情况下只有一个参数const-保存常量在以下两种情况使用：action中的action=&#39;store_const&#39;和action=&#39;append_const&#39;给参数设置固定值nargs中的&#39;?&#39;，首先从命令行获得参数，若没有则从const获得，然后从default获得default-设置默认值和前面的const的区别在于：const设置之后不能修改这个值，但是default设置之后只有命令行中没有传入参数值才会使用default，传入值的话就使用传入的值。type-参数类型默认情况下将传入的参数值统一作为字符读入，可以通过设置type来确定传入的参数值的类型：type=float：浮点type=float：整型type=argparse.FileType()：创建可写入文件，其中的参数包括mode=、bufsize=、encoding=和errors=，前面的nargs中的&#39;?&#39;也是用于文件123456789import argparseparser = argparse.ArgumentParser() # 生成参数分析器parser.add_argument('bar', type=argparse.FileType(mode='w',encoding='UTF-8'))args = parser.parse_args()print (args.bar)# python argparse_test.py out.txt# 输出：# &lt;_io.TextIOWrapper name='out.txt' mode='w' encoding='UTF-8'&gt;type还可以接受一个可以调用的函数(输入单个字符，返回转化后的类型)choices-参数的范围choices设置参数的范围，例如通过choices=range(1, 4)设定数字的，也可以通过choices=[&#39;rock&#39;, &#39;paper&#39;, &#39;scissors&#39;]设置字符的需要注意：传入值先进行type的类型转换，然后才看检查choices范围，所以choices范围的类型要和type一致支持in操作(for i in sth)的都可以作为choices的范围，例如常规的dict、set、list等required-参数是否必须required只针对可选参数12345parser.add_argument('--foo', required=True)# 调用的时候如果不加--foo# 输出：# argparse.py: error: option --foo is requiredhelp-参数的帮助信息对参数的简短描述，可以帮助选择参数为了避免与argparse的参数重叠，帮助信息中的有些关键字(prog、default)可以使用%包围(文字中需要出现%的话用%%)：12345678parser.add_argument('bar', nargs='?', type=int, default=42, help='the bar to %(prog)s (default: %(default)s)') # 显示帮助信息时：# usage: frobble [-h] [bar]## positional arguments:# bar the bar to frobble (default: 42)不输出某个参数的帮助信息，使用help=argparse.SUPPRESS:1234567parser.add_argument('--foo', help=argparse.SUPPRESS)# 显示帮助信息时显示：# usage: frobble [-h]# optional arguments:# -h, --help show this help message and exitmetavar-参数在帮助信息中的名称默认情况下，参数使用dest值作为名称，例如位置参数的参数名称就是位置参数的名称，而可选参数如果使用了长参数则是长参数的名称，如果只使用了短参数则是短参数的名称(前面位置参数也有讲解)默认情况：123parser.add_argument('--foo')parser.add_argument('bar')args = parser.parse_args()python argparse_test.py -husage: argparse_test.py [-h] [–foo FOO] barpositional arguments:baroptional arguments:-h, –help show this help message and exit–foo FOO通过metavar设置：12parser.add_argument('--foo', metavar='YYY')parser.add_argument('bar', metavar='XXX')python argparse_test.py -husage: argparse_test.py [-h] [–foo YYY] XXXpositional arguments:XXXoptional arguments:-h, –help show this help message and exit–foo YYY可以发现上述加粗的地方的名称出现了改变需要注意的是metavar只是改变了名称的显示内容，真正的变量解析的名称还是有dest决定：12345# 上述输出变量值，使用metavar设置的名称print (args.YYY)# 上述输出变量值，使用dest的名称print (args.foo)print (args.YYY)的输出：python argparse_test.py --foo test test2Traceback (most recent call last):File “argparse_test.py”, line 6, in \&lt;module>print (args.YYY)AttributeError: ‘Namespace’ object has no attribute ‘YYY’print (args.foo)的输出：python argparse_test.py --foo test test2test可以发现只有使用print (args.foo)才能正常输出，说明参数解析存放的变量还是没变，metavar设置的名称只是改变了显示形式参数解析存放的变量还是没变(还是由dest决定)，metavar设置的名称只是改变了显示形式如果参数设置了nargs(例如：nargs=2)，会导致metavar设置的名称(如果只指定了一个名称)重复出现dest-传入值的属性名称如果存在长参数(–开头的)，则dest取第一个长参数的值作为属性名称；如果没有长参数，则dest取第一个短参数的值作为属性名称所有字符中间的-都会被转化为_，保证属性名称是有效的12345678910111213141516171819202122import argparseparser = argparse.ArgumentParser() # 生成参数分析器parser.add_argument('-f', '--foo-bar', '--foo')parser.add_argument('-x', '-y')args = parser.parse_args()# 使用第一个长参数以及将-转化为_print (args.foo_bar)# 如果使用短参数print (args.f)# 如果使用第二个长参数print (args.foo)# 第一个短参数print (args.x)# 第二个短参数print (args.y)查看帮助信息：python argparse_test.py -husage: argparse_test.py [-h] [-f FOO_BAR] [-x X]optional arguments:-h, –help show this help message and exit-f FOO_BAR, –foo-bar FOO_BAR, –foo FOO_BAR-x X, -y X使用第一个长参数以及将-转化为_：python argparse_test.py --foo testtest如果使用短参数:python argparse_test.py --foo testTraceback (most recent call last):File “argparse_test.py”, line 6, in \&lt;module>print (args.f)AttributeError: ‘Namespace’ object has no attribute ‘f’如果使用第二个长参数:python argparse_test.py --foo testTraceback (most recent call last):File “argparse_test.py”, line 6, inprint (args.foo)AttributeError: ‘Namespace’ object has no attribute ‘foo’第一个短参数:python argparse_test.py -x testtest第二个短参数:python argparse_test.py -x testTraceback (most recent call last):File “argparse_test.py”, line 6, in \&lt;module>print (args.y)AttributeError: ‘Namespace’ object has no attribute ‘y’使用dest自定义属性名称：123456789101112import argparseparser = argparse.ArgumentParser() # 生成参数分析器parser.add_argument('-f', '--foo-bar', '--foo',dest="my_set")args = parser.parse_args()# 如果还使用最开始的foo_barprint (args.foo_bar)# 使用自定义的my_setprint (args.my_set)输出帮助信息：python argparse_test.py -husage: argparse_test.py [-h] [-f MY_SET]optional arguments:-h, –help show this help message and exit-f MY_SET, –foo-bar MY_SET, –foo MY_SET如果还使用最开始的foo_bar:python argparse_test.py --foo testTraceback (most recent call last):File “argparse_test.py”, line 5, in \&lt;module>print (args.foo_bar)AttributeError: ‘Namespace’ object has no attribute ‘foo_bar’使用自定义的my_set:python argparse_test.py --foo testtestdest就是命令行参数(传入值)在经过解析后存储的变量名，默认情况下：如果存在长参数，就是第一个长参数的值(--后面接着的字符串)如果不存在长参数，就是第一个短参数的值(-后面接着的字符串)参数中间的-都会被转化为_，保证属性名称是有效的当然可以通过dest参数进行自定义解析后存储的变量名解析参数-parse_args()上述添加完所有参数之后，就可以给 parse_args() 传递一组参数字符串来解析命令行。默认情况下，参数是从 sys.argv[1:] 中获取，但你也可以传递自己的参数列表。因为一般使用argparse都是用来解析命令行参数，所以使用其默认情况即可，这里对自己传递参数的方法没有进行学习，需要的时候可以去看官方文档。parse_args() 的返回值是一个命名空间，包含传递给命令的参数。该对象将参数保存其属性，因此如果你的参数 dest 是 &quot;myoption&quot;，那么你就可以args.myoption 来访问该值(可以参考前面dest的用法).1ArgumentParser.parse_args(args=None, namespace=None)args - List of strings to parse. The default is taken from sys.argv.namespace - An object to take the attributes. The default is a new empty Namespace object.参数缩写parse_args()默认允许长参数缩写为前缀(前缀是不相同的)：123456789101112&gt;&gt;&gt; parser = argparse.ArgumentParser(prog='PROG')&gt;&gt;&gt; parser.add_argument('-bacon')&gt;&gt;&gt; parser.add_argument('-badger')&gt;&gt;&gt; parser.parse_args('-bac MMM'.split())Namespace(bacon='MMM', badger=None)&gt;&gt;&gt; parser.parse_args('-bad WOOD'.split())Namespace(bacon=None, badger='WOOD')&gt;&gt;&gt; parser.parse_args('-ba BA'.split())usage: PROG [-h] [-bacon BACON] [-badger BADGER]PROG: error: ambiguous option: -ba could match -badger, -bacon解析部分参数-parse_known_args()有时间一个脚本只需要解析所有命令行参数中的一小部分，剩下的命令行参数给另一个脚本或者程序。在这种情况下，parse_known_args()就很有用。它很像parse_args()，但是它在接受到多余的命令行参数时不报错。相反的，返回一个tuple类型的命名空间和一个保存着余下的命令行字符的list。1234567891011import argparse parser = argparse.ArgumentParser() parser.add_argument( '--flag_int', type=float, default=0.01, help='flag_int.' ) FLAGS, unparsed = parser.parse_known_args() print(FLAGS.flag_int) print(unparsed)python argparse_test.py --flag_int 0.02 --double 0.03 a 10.02[‘–double’, ‘0.03’, ‘a’, ‘1’]binbin师兄的项目中有所使用，可以看看参数群组argparse能将参数定义组合成“群组”。默认情况下是使用两个群组，一个是可选参数的群组，另一个是必须的位置参数的群组，这可以在程序的帮助信息中看到，使用optional arguments和positional arguments将群组分开，可以参考前面的位置参数和可选参数部分在实际使用中，可以调整群组来提高帮助信息中群组的逻辑性，这样相关选项或值能记录在一起。可以使用自定义群组来重写之前的共享选项的示例，如在帮助信息中身份认证的选项就可以显示在一起：第一步：在基础解析器中使用add_argument_group()来创建一个“身份认证”群组，然后逐个添加身份认证相关的选项到该群组12345678import argparseparser = argparser.ArgumentParser(add_help=False)# 创建名为authentication的群组group = parser.add_argument_group('authentication')# 给这个群组添加参数group.add_argument('--user', action="store")group.add_argument('--password', action="store")以上内容保存在名为argparse_parent_with_group.py的文件中第二步：和之前parent中讲到的一样进行参数继承12345678import argparseimport argparse_parent_with_group# 继承参数，注意parent中是ArgumentParser类，所以这里依然导入的是parser，而不是groupparser = argparse.ArgumentParser(parents=[argparse_parent_with_group.parser])parser.add_argument('--local-arg', action="store_true", default=False)print (parser.parse_args())输出信息：12345678910111213python argparse_test.py -h# 输出如下usage: argparse_test.py [-h] [--user USER] [--password PASSWORD] [--local-arg]optional arguments: -h, --help show this help message and exit --local-arg# 自定义的群组authentication: --user USER --password PASSWORD创建子命令有时候，我们可以根据功能将命令行分组成一系列相关的子命令，为了实现这种分组行为argparse提供了ArgumentParser.add_subparsers()方法，其使用如下：123ArgumentParser.add_subparsers([title][, description][, prog] [, parser_class][, action][, option_string] [, dest][, required][, help][, metavar])示例1234567891011121314151617181920212223242526import argparse# 生成参数分析器parser = argparse.ArgumentParser(prog='cmd')# 创建sub-commandssub_parser = parser.add_subparsers(title='subcommands', description='valid subcommands', help='config subscommand help')# 添加第一个分组，相当于单个分组中的argparse.ArgumentParseradd_parser = sub_parser.add_parser('add',help='add user config')# 添加参数add_parser.add_argument('--name', required=True, help='user name')add_parser.add_argument('--addr', required=False, help='user address')add_parser.add_argument('--phone', required=False, help='phone number')# 添加第二个分组delete_parser = sub_parser.add_parser('delete', help='delete user config')delete_parser.add_argument('--name', required=True, help='user name')# 添加第三个分组show_parser = sub_parser.add_parser('show', help='show user config')# 解析参数args = parser.parse_args()python argparse_test.py -husage: cmd [-h] {add,delete,show} …optional arguments:-h, –help show this help message and exitsubcommands:valid subcommands{add,delete,show} config subscommand helpadd add user configdelete delete user configshow show user config上述过程讲解：ArgumentParser对象使用add_subparsers()方法创建子命令组；该方法通常在调用的时候不传递参数，并返回一个特殊的action实例，这个实例只有一个方法：add_parser()；对这个实例分别调用add_parser()方法来创建子命令对应的ArgumentParser(包含了其所有可以使用的参数，还包含了一个子命令组名称的参数)，再调用这个ArgumentParser实例的add_argument()方法来添加子命令的参数。从上述帮助输出可以看出，对整体使用-h不会返回每个子命令组详细的帮助信息，如果想查看每个子命令组详细的帮助信息需要使用python argparse_test.py add -h:python argparse_test.py add -husage: cmd add [-h] –name NAME [–addr ADDR] [–phone PHONE]optional arguments:-h, –help show this help message and exit–name NAME user name–addr ADDR user address–phone PHONE phone number通过ArgumentParser的set_defaults()方法来设置不同的子命令执行的函数：12345678# 设置子命令add的执行函数为add_fnadd_parser.set_defaults(func=add_fn)# 设置子命令delete的执行函数为delete_fndelete_parser.set_defaults(func=delete_fn)# 设置子命令show的执行函数为show_fnshow_parser.set_defaults(func=show_fn)创建互斥参数使用ArgumentParser的add_mutually_exclusive_group()来创建互斥参数组：123456789101112131415161718192021import argparseparser = argparse.ArgumentParser(description="calculate X to the power of Y")# 创建互斥参数group = parser.add_mutually_exclusive_group()group.add_argument("-v", "--verbose", action="store_true")group.add_argument("-q", "--quiet", action="store_true")parser.add_argument("x", type=int, help="the base")parser.add_argument("y", type=int, help="the exponent")args = parser.parse_args()answer = args.x**args.yif args.quiet: print (answer)elif args.verbose: print ("&#123;&#125; to the power &#123;&#125; equals &#123;&#125;".format(args.x, args.y, answer))else: print ("&#123;&#125;^&#123;&#125; == &#123;&#125;".format(args.x, args.y, answer))查看帮助信息：python argparse_test.py -husage: argparse_test.py [-h] [-v | -q] x ycalculate X to the power of Ypositional arguments:x the basey the exponentoptional arguments:-h, –help show this help message and exit-v, –verbose-q, –quiet如果同时使用会报错：python argparse_test.py -v -qusage: argparse_test.py [-h] [-v | -q] x yargparse_test.py: error: argument -q/–quiet: not allowed with argument -v/–verboseadd_mutually_exclusive_group(required=True)支持required=True参数(但是不支持title和description参数)，表明两个互斥的参数中必须使用一个使用总结可以将共有的参数放在一个父参数文件中，然后其他的文件直接导入(parent的使用)，这样比较简单参数群组(add_argument_group())，可以自己组织参数出现的分组，看着比较清晰，如果没有必要用到子命令(add_subparsers())的时候可以尝试一下如果传入参数只带有双引号，需要对双引号进行转义，否则接受的参数中将不含双引号如果传入的参数带有空格，传入时可以使用双引号将其括起来：-d &quot;abc def&quot;参考链接官方文档python argparse用法总结python命令行参数解析Python 模块简介 – argparseargarse.ArgumentParser.parse_known_args()解析非常好的讲解，但是适合回顾的时候看，需要基础]]></content>
      <categories>
        <category>Python</category>
        <category>常用模块</category>
      </categories>
      <tags>
        <tag>常用模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python-main函数的理解]]></title>
    <url>%2Fposts%2F32155.html</url>
    <content type="text"><![CDATA[这是一篇之前学习过的关于Python main函数的理解，主要学习了main函数的作用、在作为包引入以及直接运行时的区别，同时对Python的代码运行机制也有了一定的了解.背景介绍程序入口：&emsp;&emsp;对于很多编程语言来说，程序都必须要有一个入口，比如 C，C++，以及完全面向对象的编程语言 Java，C# 等。如果你接触过这些语言，对于程序入口这个概念应该很好理解，C 和 C++ 都需要有一个 main 函数来作为程序的入口，也就是程序的运行会从 main 函数开始。同样，Java 和 C# 必须要有一个包含 Main 方法的主类来作为程序入口。&emsp;&emsp;而 Python 则有不同，它属于脚本语言，不像编译型语言那样先将程序编译成二进制再运行，而是动态的逐行解释运行。也就是从脚本第一行开始运行，没有统一的入口，结合Python使用缩进对齐组织代码的执行，所有没有缩进的代码（非函数定义和类定义），都会被当成Python的main函数，在载入时自动执行。&emsp;&emsp; 一个 Python 源码文件除了可以被直接运行外，还可以作为模块（也就是库）被导入。不管是导入还是直接运行，最顶层的代码都会被运行（没有设置缩进的代码），而实际上在导入的时候，有一部分代码我们是不希望被运行的，这一部分代码可以放在main函数中，当作为模块进行导入时就不会被执行使用实例1234567891011# -*- coding: utf-8 -*-print ('AAA') #没有所进的代码，会被直接运行def test(): print ('BBB') #函数中的内容，被调用后会被执行print (__name__) #是内置变量，用于表示当前模块的名字if __name__ == '__main__': #当name是main的时候执行 test() print ('CCC')直接运行直接运行文件的输出：123456AAA__main__BBBCCC可以看出直接执行文件的时候先是两个print会被执行，并且从输出信息可以看出__name__是__main__，满足if的判断条件，所以test()函数会被执行，并且输出CCC。当成模块引入将上述代码保存为test_main.py文件在同一个目录下创建另一个文件，里面只写入from test_main import test，运行该文件1234567891011121314# 只导入包的时候出现from test_main import testAAAtest_main# 在文件中继续写入 test()，输出AAAtest_mainBBB# 如果只写 test，输出AAAtest_main&lt;function test at 0x03433970&gt;可以看出，导入包的时候，和上面一样，两个print也会被直接执行，需要注意的是这里的__name__已经变成了module的名称（test_main），由于此时的__name__不等于__main___，不满足if的条件，所以不会直接执行test函数和输出CCC；导入之后，调用其中的test函数（被导入的函数），原始的test函数就会被执行。详细解释&emsp;&emsp;__name__ == &#39;__main__&#39;含义是“Make a script both importable and executable”，也就是让你写的脚本模块既可以导入到别的模块中用，另外该模块自己也可执行。每个python模块(python文件)都包含内置的变量__name__，当运行模块被直接执行的时候，__name__等于&#39;__main__&#39;；如果import到其他模块中，则__name__等于模块名称(不包含后缀.py)。而在程序中的判断条件是if __name__ == &#39;__main__&#39;，所以当模块被直接执行时，__name__ == &#39;__main__&#39;结果为真；而当模块被import到其他模块中时，__name__ == &#39;__main__&#39;结果为假，就是不调用对应的方法。简单来说： 如果模块是被直接运行的，则if语句中的代码块被运行，如果模块是被导入的，则if语句中的代码块不被运行。这个功能有一个用处：调试代码的时候，在if __name__ == &#39;__main__&#39;中加入一些我们的调试代码，我们可以让外部模块调用的时候不执行我们的调试代码，但是如果我们想排查问题的时候，直接执行该模块文件，调试代码能够正常运行！典型的python文件结构参考链接浅析python 中name = ‘main‘ 的作用python编程中的if name == ‘main’ 的作用和原理Python 源码剖析读书笔记Python 中的 if name == ‘main‘ 该如何理解]]></content>
      <categories>
        <category>Python</category>
        <category>其他技巧整理</category>
      </categories>
      <tags>
        <tag>其他技巧整理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python常用程序块]]></title>
    <url>%2Fposts%2F58475.html</url>
    <content type="text"><![CDATA[这篇博客总结一些常用的Python程序块，避免重复造轮子添加中文注释1# -*- coding: utf-8 -*-正则匹配(分组、非贪婪)正则匹配是经常使用的，也是经常容易出错的，这个给出比较常用的带分组和非贪婪模式的匹配：1234567import res='&gt;AT1G01060.4 | Symbols: LHY, LHY1 | Homeodomain-like superfamily protein | chr1:33992-37061 REVERSE LENGTH=644'# 匹配前面的AT1G01060pattern=re.compile('^&gt;(.*?)\.')re.search(pattern,s).group(1)‘AT1G01060’需要注意的：&#39;^&gt;(.*?)\.&#39;这里?加在*的后面，因为*才是贪婪匹配的来源；不应该加载()后面，那样起不到非贪婪匹配的作用group(0)或者group()表示的是整个匹配上的字符串，比如这里指的就是&#39;&gt;AT1G01060.&#39;；group(1)才是匹配的括号内的内容re.match只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回None；而re.search匹配整个字符串，直到找到一个匹配re.match 和 re.search 是匹配一次 re.findall 匹配所有，返回列表自动调用函数执行关于main函数的理解，请参考这篇文章12345678#定义主函数def main(): my_func() my_func_1() my_func_2()#调用if __name__ == '__main__': main()输出固定长度的字串123# 修改every即可def write_wrapped(string, every=60): return '\n'.join(string[i:i+every] for i in range(0, len(string), every))字典相关操作字典创建12345678# 简单的字典dic=&#123;'a': '1', 'b': '2', 'c': '3'&#125;# 调用collections中的defaultdictfrom collections import defaultdictdic_test=defaultdict(list)dic_test['a'].append(1)# 具体的形式：defaultdict(&lt;type 'list'&gt;, &#123;'a': [1]&#125;)两个列表组成字典12345678keys = ['a', 'b', 'c'] values = [1, 2, 3] dictionary = dict(zip(keys, values)) print (dictionary) # 输出: # &#123;'a': 1, 'c': 3, 'b': 2&#125;字典遍历1234# 两种方法创建方法都可以使用以下方法遍历for k,v in dic.items(): print (k) print (v)字典是否有该键值123# 使用inif k in dic.keys(): print(k)将字典写入文本文件处理fasta以下是将fasta文件格式生成的字典写入文件：1234567891011121314# 定义每一行的字符数def write_wrapped(string, every=60): return '\n'.join(string[i:i+every] for i in range(0, len(string), every))# 将fasta格式文件产生的字典写入文件# k是&gt;开头的信息# v是核苷酸或者蛋白质序列def write_dic_file(dic,out_file): with open(out_file,'w') as out: for k,v in dic.items(): out.write(k+'\n') out_s=write_wrapped(v, every=60) out.write(out_s) out.write('\n')处理值为列表处理普通的当值为列表时的字典，形如：{key:[value1,value2,value3]}：12345678# 当字典value是列表的时候可将值先join起来def write_dic_file(dic,out_file): with open(out_file,'w') as out: for k,v in dic.items(): out.write(k+'\t') out_s='\t'.join(v) out.write(out_s) out.write('\n')将字典写入excel中字典特征：key为样本名，value为dataframe：12345def write_to_excel(df_dic,out_file): writer = pd.ExcelWriter(out_file) for k,v in df_dic.items(): v.to_excel(writer,sheet_name='&#123;&#125;'.format(str(k)),index=False) writer.save()获取字典最值利用min(dict, key=dict.get)：1234d = &#123;1:1, 2:0, 3:2&#125;min(d, key=d.get)# 输出：# 2利用lambda函数：123456789# 得到索引和值min(d.items(), key=lambda x: x[1])# 输出：# (2, 0)# 只得到值min(d, key=lambda x: d[x])# 输出：# 2判断最后一行文本1234567891011121314151617181920212223# bug:if second last is same as last, this will be wrong def judge_last_line(in_file,line): with open(in_file,'r') as judge_file: pre_total_lines=judge_file.readlines() total_lines=[i.strip() for i in pre_total_lines] last_line=total_lines[-1] if line == last_line: tag=1 else: tag=0 return tag# fix bug abovedef judge_last_line(in_file,line_num): with open(in_file,'r') as judge_file: pre_total_lines=judge_file.readlines() total_lines=[i.strip() for i in pre_total_lines] total_line_num=len(total_lines) if line_num==total_line_num: tag=1 else: tag=0 return tag读取fasta文件使用biopython包12345678910111213from Bio import SeqIO# 如果可能存在小写的序列，可以使用SeqRecord 对象的 upper() 方法轻易的实现# seq_record.upper()for seq_record in SeqIO.parse("/home/songyabing/genome/Ca22chrA.fa", "fasta"): print ("Chr: &#123;chr_name&#125; with length: &#123;seq_length&#125;".format(chr_name=seq_record.id,seq_length=str(len(seq_record)))) print (repr(seq_record.upper().seq))# 输出Chr: chr1 with length: 3188341Seq('GAGTCACGCCAATCACAAATTCCTTTGAAAAACTTGATTCGACCACATTCACAA...ACA', SingleLetterAlphabet())Chr: chr2 with length: 2231883Seq('ACACTCACCGTTTCTAACTGCTTAACCTATTACTATTAAGAATTCGCTATTGTT...GGG', SingleLetterAlphabet()).........其他常见用法：12345678910111213141516171819from Bio import SeqIOfor seq_record in SeqIO.parse("/home/songyabing/genome/genome.fa", "fasta"):# print ("Chr: &#123;chr_name&#125; with length: &#123;seq_length&#125;".format(chr_name=seq_record.id,seq_length=str(len(seq_record)))) if seq_record.id == "chrM": # 输出染色体的name，和seq_record.name作用相同，如 # &gt;chrM AC:J01415.2 gi:113200490 LN:16569 rl:Mitochondrion M5:c68f52674c9fb33aef52dcf399755519 AS:GRCh38 tp:circular # 输出的是chrM print (seq_record.id) # 输出染色体的具体序列(字符串)，不会输出前面的&gt;chrM等信息 print (seq_record.upper().seq) # 显示序列但不直接输出字符 print (repr(seq_record.upper().seq)) # 输出字符串的序列以及&gt;chrM等信息 print(seq_record.format("fasta")) # 修改序列的描述信息 seq_record.description +=' extend:400bp' # 输出序列的描述信息，包括长度，来源等 print (seq_record.description)如果想要使用其中seq序列信息，可以使用str将其转化str(seq_record.seq)，直接输出可能不是很好。biopython还可以很方便地统计GC含量，关于biopython的更多使用可以参考：用biopython解析序列Biopython中文文档自己编写代码自己编写的读取会很慢，所以建议还是使用上面的biopython包：123456789with open("/home/user/genome/Ca22chrA.fa","r") as fa_in: fa_seq = &#123;&#125; for line in fa_in.readlines(): line = line.strip() if line[0] == "&gt;": chr_name=line.split()[0].replace('&gt;','') fa_seq[chr_name]='' else: fa_seq[chr_name] = fa_seq[chr_name] + line判断一个列表是不是另一个列表的子集参考链接：Python | Check if one list is subset of otherall()方法如果all(x)参数x对象的所有元素不为0、&#39;&#39;、False或者x为空对象，则返回True，否则返回False：123456789all(['a', 'b', 'c', 'd']) True# 存在空字符串all(['a', 'b', 'c', '']) False# 存在元素为0all([0,1,2,3]) False判断子集：1234567if all(x in test_list for x in sub_list): print ("yes, &#123;sub_list&#125; is subset of &#123;total_list&#125;".format(sub_list=sub_list,total_list=test_list))else: print ("no")# 输出 yes, [10, 5, 4] is subset of [9, 4, 5, 8, 10]与all(x)方法相对应的是any(x)方法，判断x对象是否全为空对象，如果都为&#39;&#39;、0、false，则返回false，如果不都为&#39;&#39;、0、false，则返回true。集合的issubset()方法最好用也最方便的就是使用集合的相关方法，主要是issubset()、issuperset()：12345678910111213141516# 需要先将两个列表转换为集合# 使用subset方法if set(sub_list).issubset(set(test_list)): print ("yes, &#123;sub_list&#125; is subset of &#123;total_list&#125;".format(sub_list=sub_list,total_list=test_list))else: print ("no")# 使用superset方法与这个类似# 需要注意两者是对应关系if set(test_list).issuperset(set(sub_list)): print ("yes, &#123;sub_list&#125; is subset of &#123;total_list&#125;".format(sub_list=sub_list,total_list=test_list))else: print ("no")# 输出 yes, [10, 5, 4] is subset of [9, 4, 5, 8, 10]]]></content>
      <categories>
        <category>Python</category>
        <category>其他技巧整理</category>
      </categories>
      <tags>
        <tag>其他技巧整理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python常见错误]]></title>
    <url>%2Fposts%2F61409.html</url>
    <content type="text"><![CDATA[这篇文章主要整理了在Python学习过程中遇到的具有典型性的问题，搜集起来，以免以后遇到同样的错误重新找解决方法。常规报错pandas报错jupyter报错jupyter启动报错错误提示123456789101112131415Traceback (most recent call last): File "C:\Users\user\Anaconda3\Scripts\jupyter-notebook-script.py", line 6, in &lt;module&gt; from notebook.notebookapp import main File "C:\Users\user\Anaconda3\lib\site-packages\notebook\notebookapp.py", line 81, in &lt;module&gt; from .services.kernels.kernelmanager import MappingKernelManager File "C:\Users\user\Anaconda3\lib\site-packages\notebook\services\kernels\kernelmanager.py", line 19, in &lt;module&gt; from jupyter_client.session import Session File "C:\Users\user\Anaconda3\lib\site-packages\jupyter_client\session.py", line 61, in &lt;module&gt; from jupyter_client.jsonutil import extract_dates, squash_dates, date_default File "C:\Users\user\Anaconda3\lib\site-packages\jupyter_client\jsonutil.py", line 11, in &lt;module&gt; from dateutil.parser import parse as _dateutil_parse File "C:\Users\user\Anaconda3\lib\site-packages\dateutil\parser.py", line 158 l.append("%s=%s" % (attr, `value`)) ^SyntaxError: invalid syntax解决方法12pip uninstall python-dateutilpip install python-dateutil问题来源之前安装的将印象笔记转化为markdown格式的时候安装的包将某个包的版本降低了：1ever2simple 2.0 has requirement python-dateutil&lt;2.0, but you'll have python-dateutil 2.8.0 which is incompatible.]]></content>
      <categories>
        <category>Python</category>
        <category>其他技巧整理</category>
      </categories>
      <tags>
        <tag>其他技巧整理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell-数组]]></title>
    <url>%2Fposts%2F46714.html</url>
    <content type="text"><![CDATA[这篇文章主要对Shell的数组进行了学习，主要内容包括创建数组、数组赋值、读取数组、获取数组长度、获取数组使用的下标、在数组末尾添加元素、数组排序、删除数组和关联数组。shell数组简介数组是可以存放多个值的一种数据结构，Bash shell也支持数组，但是其对数组的支持比较有限，下面列出了Bash shell数组的特征：Bash Shell 只支持一维数组(不支持多维数组)初始化时不需要定义数组大小数组元素的下标由0开始(与大部分编程语言类似)数组用括号来表示，元素用”空格”符号分割开创建数组提前创建特殊符号( )被用于数组的声明中，因此可以使用如下命令提前创建数组：1234array=(element1 element2 element3 ...)# 创建数组时直接指定元素的索引值array=([1]=element1 [2]=element2 [3]=element3)更多关于特殊符号( )的用法参考这篇文章也可以使用declare命令创建数组：1declare -a array='(element1 element2 element3 ...)'自动创建数组变量就像其它 bash 变量一样命名，当被访问的时候，它们会被自动地创建1234a[1]=fooecho $&#123;a[1]&#125;# 输出 foo上面是一个赋值并访问数组元素的例子，通过a[1]=foo，数组索引为1(开始于0)的元素被赋值为foo(索引为0的位置可以访问，但是输出为空)；通过echo ${a[1]}访问数组索引为1的元素，${}可以进行数组操作，具体的请看这篇文章可以不使用连续的下标创建数组，而且下标的范围没有限制数组赋值在上述创建数组的过程中其实已经实现了数组的赋值：单个元素赋值：array[index]=value多个元素赋值：array=(element1 element2 element3 ...)多个元素结合索引进行赋值：array=([1]=element1 [2]=element2 [3]=element3)在不指定索引的情况下，两次赋值会出现覆盖：12345678# 第一次赋值a=(a b c)# $&#123;a[@]&#125;是获取数组所有元素，后面会讲到echo $&#123;a[@]&#125;# 第二次赋值a=(d e f g)echo $&#123;a[@]&#125;a b cd e f g数组的index是一个大于或等于零的整数（或算术表达式）数组第一个元素的下标是0， 而不是1数组元素的值可以是一个字符串或整数在不指定索引的情况下，两次赋值会出现覆盖读取数组读取数组单个元素读取数组使用特殊符号${}，一般形式为：1$&#123;array_name[index]&#125;示例：12345array=(1 2 3 4)echo $&#123;array[0]&#125;echo $&#123;array[1]&#125;echo $&#123;array[2]&#125;echo $&#123;array[3]&#125;1234任何引用一个不带下标的数组变量，则指的是数组元素0：12345array=Aecho $&#123;array[0]&#125;echo $&#123;array[1]&#125;echo $&#123;array[2]&#125;echo $&#123;array[3]&#125;A234读取数组所有元素如果想要获取数组的所有元素，使用@ 或 * :12echo $&#123;array[@]&#125;echo $&#123;array[*]&#125;1 2 3 41 2 3 4@和*的区别和使用$*或$@得到所有脚本变量的区别相同：不使用双引号括起来时完全相同：都以”element1” “element2” … “elementn” 的形式输出所有参数使用双引号括起来时不同：&quot;${!array[*]}&quot; 会将所有的元素作为一个整体，以”element1 element2 … elementn”的形式输出所有元素；&quot;${!array[@]}&quot; 会将各个元素分开，以”element1” “element2” … “elementn” 的形式输出所有元素1234567891011# 使用$&#123;array[@]&#125;，但不使用双引号括起来for i in $&#123;array[@]&#125;do echo $idone# 使用$&#123;array[*]&#125;，但不使用双引号括起来for i in $&#123;array[*]&#125;do echo $idone不使用双引号括起来时输出结果完全相同：12341234567891011# 使用$&#123;array[@]&#125;，但使用双引号括起来for i in "$&#123;array[@]&#125;"do echo $idone# 使用$&#123;array[*]&#125;，但使用双引号括起来for i in "$&#123;array[*]&#125;"do echo $idone使用双引号括起来时输出结果不同：12341 2 3 4读取数组所有元素需要注意${array[*]}和${array[@]}加引号和不加引号输出结果的区别任何引用一个不带下标的数组变量，则指的是数组元素0数组长度获取数组长度(元素个数)的方法与获取字符串长度的方法相同，仍然是使用特殊符号${}：123echo $&#123;#array[*]&#125;或者echo $&#123;#array[@]&#125;4如果上面不是使用了@和*，而是使用了具体的索引位置，则会得到指定索引位置的元素长度：12array[1]=test_lengthecho $&#123;#array[1]&#125;11 &emsp;&emsp;&emsp;# 输出的是test_length的长度还有需要注意的地方是：如果赋值时数组的索引不是连续的，数组的长度不是最大索引对应的长度，而是有具体值的索引的个数，也就是说没有赋值的那些索引不计入数组长度(但是仍然可以通过索引访问，返回结果为空)。示例如下：12array[100]=100echo $&#123;#array[@]&#125;5 &emsp;&emsp;&emsp;# 这里输出结果是5，而不是101，即使最后一个有值的索引为100，但是5-99的索引位置并没有赋值，也就没有计入数组长度使用@和*获取的是数组的长度使用具体的索引位置获取的是指定索引位置的元素长度未赋值的索引不计入输入长度的计算获取数组使用的下标因为shell数组允许赋值的数组下标包含 “间隔”，所以确定哪些下标在数组中是具有值的有时候很关键：123echo $&#123;!array[@]&#125;或者echo $&#123;!array[*]&#125;0 1 2 3 100和前面提到的使用双引号和不使用双引号括起来输出结果不同相同，这里两种方法在使用双引号括起来的时候也会存在差异：1234567891011# 使用$&#123;!array[@]&#125;，但使用双引号括起来for i in "$&#123;!array[@]&#125;"do echo $idone# 使用$&#123;!array[*]&#125;，但使用双引号括起来for i in "$&#123;!array[*]&#125;"do echo $idone&quot;${!array[@]}&quot;输出结果：0123100&quot;${!array[*]}&quot;输出结果：0 1 2 3 100获取数组下标时需要注意${!array[*]}和${!array[@]}加引号和不加引号输出结果的区别${array[*]}和${array[@]}是获取数组所有元素的方法，而!具有取反的作用，数组元素的反理解为索引的话就很好记忆了在数组末尾添加元素如果我们需要在数组末尾附加数据，那么知道数组中元素的个数是没用的，直接不加索引继续赋值的话第二次的赋值会覆盖前一次的赋值结果。幸运地是，shell 为我们提供了一种解决方案：通过使用 += 赋值运算符，我们能够自动地把值附加到数组末尾(索引接着最后一个索引)。1234567891011121314test=(a b c)test[100]=decho $&#123;test[@]&#125;# 输出：a b c decho $&#123;!test[@]&#125;#输出：0 1 2 100test+=(e f g)echo $&#123;test[@]&#125;# 输出：a b c d e f gecho $&#123;!test[@]&#125;#输出：0 1 2 100 101 102 103数组排序Shell 没有直接对数组元素排序的方法，但是可以通过获取值然后排序再利用排序后的值重新赋值给另一个数组即可：1234567891011a=(a d c f e)# 将排序后的结果赋值给新数组，这里使用了循环接入管道的操作# 可以不使用新数组，直接赋值给原始数组即可覆盖原始数组的值a_sorted=($(for i in $&#123;a[@]&#125;;do echo $i;done |sort))# 在同一行输出新数组for i in "$&#123;a_sorted[*]&#125;"do echo $idonea c d e f删除数组相关操作删除数组相关操作都会使用 unset 命令删除整个数组123456789foo=(a b c d e f)echo $&#123;foo[@]&#125;# 输出：a b c d e f# 删除整个数组unset fooecho $&#123;foo[@]&#125;# 输出为空删除数组元素123456789foo=(a b c d e f)echo $&#123;foo[@]&#125;# 输出：a b c d e f# 删除整个数组unset 'foo[2]'echo $&#123;foo[@]&#125;# 输出：a b d e f关联数组现在最新的 bash 版本支持关联数组了，关联数组使用字符串而不是整数作为数组索引(AWK只支持关联数组，但可以把数字下标转化为字符)。12345678910111213# 可以使用-A也可以使用-a# 也可以直接在使用的时候创建declare -A colorscolors["red"]="#ff0000"colors["green"]="#00ff00"colors["blue"]="#0000ff"echo $&#123;colors[@]&#125;# 输出：#ff0000 #0000ff #00ff00# 这种创建输出会出问题：array=(["red"]="#ff0000" ["green"]="#00ff00" ["blue"]="#0000ff")echo $&#123;array[@]&#125;# 输出：#0000ff参考链接The Linux Command Line 中文版shell-guideshell编程中使用数组进行操作Shell 数组]]></content>
      <categories>
        <category>Linux</category>
        <category>shell编程</category>
      </categories>
      <tags>
        <tag>shell编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git系列(一):Git简介]]></title>
    <url>%2Fposts%2F60073.html</url>
    <content type="text"><![CDATA[在有了前面两篇转载的偏实战文章的学习之后，打算针对Git进行一系列的学习，这次是偏系统，因为在实战学习中发现有些命令和操作不是很懂，同时在这篇文章的参考链接中也给出了一些Git相关的系列教程开始于二级标题参考链接廖雪峰的Git教程Git官方教程Git教程Git教程Git实例]]></content>
      <categories>
        <category>其他内容学习</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git常用命令及日常问题集锦(转载)]]></title>
    <url>%2Fposts%2F13404.html</url>
    <content type="text"><![CDATA[这是一篇转载的博客，主要记录了Git的常用命令，包括新建代码库、Git相关配置、添加文件到暂存区、删除工作区文件、代码提交、分支操作、标签、查看信息、远程同步，还整理了一些使用过程中常见的问题。新建代码库在当前目录新建一个Git代码库(初始化)：git init新建一个目录，将其初始化为Git代码库：git init [project-name]下载一个项目和它的整个代码历史：git clone [url]Git相关配置显示当前的Git配置：git config --list编辑Git配置文件：git config -e [--global]设置提交代码时的用户信息：git config [--global] user.name &quot;[name]&quot;和git config [--global] user.email &quot;[email address]&quot;添加文件到暂存区添加指定文件到暂存区：git add [file1] [file2] ...添加指定目录到暂存区，包括子目录：git add [dir]添加当前目录的所有文件到暂存区：git add .添加每个变化前，都会要求确认(对于同一个文件的多处变化，可以实现分次提交)：git add -p删除工作区文件删除工作区文件，并且将这次删除放入暂存区：git rm [file1] [file2] ...停止追踪指定文件，但该文件会保留在工作区：git rm --cached [file]改名文件，并且将这个改名放入暂存区：git mv [file-original] [file-renamed]代码提交提交暂存区到仓库区：git commit -m [message]提交暂存区的指定文件到仓库区：git commit [file1] [file2] ... -m [message]提交工作区自上次commit之后的变化，直接到仓库区：git commit -a提交时显示所有diff信息：git commit -v使用一次新的commit，替代上一次提交(如果代码没有任何新变化，则用来改写上一次commit的提交信息)：git commit --amend -m [message]重做上一次commit，并包括指定文件的新变化：git commit --amend [file1] [file2] ...分支操作列出所有本地分支：git branch列出所有远程分支：git branch -r列出所有本地分支和远程分支：git branch -a新建一个分支，但依然停留在当前分支：git branch [branch-name]新建一个分支，并切换到该分支：git checkout -b [branch]新建一个分支，指向指定commit：git branch [branch] [commit]新建一个分支，与指定的远程分支建立追踪关系(连接)：git branch --track [branch] [remote-branch]切换到指定分支，并更新工作区：git checkout [branch-name]切换到上一个分支：git checkout -建立追踪关系(连接)，在现有分支与指定的远程分支之间：git branch --set-upstream [branch] [remote-branch]合并指定分支到当前分支：git merge [branch]选择一个commit，合并进当前分支：git cherry-pick [commit]删除分支：git branch -d [branch-name]删除远程分支：git push origin --delete [branch-name]或者git branch -dr [remote/branch]标签列出所有tag：git tag查看tag信息：git show [tag]新建一个tag在当前commit：git tag [tag]新建一个tag在指定commit：git tag [tag] [commit]删除本地tag：git tag -d [tag]删除远程tag：git push origin :refs/tags/[tagName]提交指定tag：git push [remote] [tag]提交所有tag：git push [remote] --tags新建一个分支，指向某个tag：git checkout -b [branch] [tag]查看信息显示有变更的文件：git status显示暂存区和工作区的差异：git diff显示暂存区和上一个commit的差异：git diff --cached [file]显示工作区与当前分支最新commit之间的差异：git diff HEAD显示两次提交之间的差异：git diff [commit_1] [commit_2]显示今天你写了多少行代码：git diff --shortstat &quot;@{0 day ago}&quot;显示某次提交的元数据和内容变化：git show [commit]显示某次提交发生变化的文件：git show --name-only [commit]显示某次提交时，某个文件的内容：git show [commit]:[filename]显示当前分支的版本历史：git log显示commit历史，以及每次commit发生变更的文件：git log --stat根据关键词搜索提交历史：git log -S [keyword]显示某个commit之后的所有变动，每个commit占据一行：git log [tag] HEAD --pretty=format:%s显示某个commit之后的所有变动，其”提交说明”必须符合搜索条件：git log [tag] HEAD --grep feature显示某个文件的版本历史，包括文件改名：git log --follow [file]或者git whatchanged [file]显示指定文件相关的每一次diff：git log -p [file]显示过去5次提交，且每个commit占据一行：git log -5 --pretty --oneline记录几乎当前分支的所有改变，带版本号：git reflog显示所有提交过的用户，按提交次数排序：git shortlog -sn显示指定文件是什么人在什么时间修改过：git blame [file]远程同步下载远程仓库的所有变动：git fetch [remote]取回远程仓库的变化，并与本地分支合并：git pull [remote] [branch]上传本地指定分支到远程仓库：git push [remote] [branch]强行推送当前分支到远程仓库，即使有冲突：git push [remote] --force推送所有分支到远程仓库：git push [remote] --all显示所有远程仓库：git remote -v显示某个远程仓库的信息：git remote show [remote]增加一个新的远程仓库，并命名：git remote add [shortname] [url]撤销恢复暂存区的指定文件到工作区：git checkout [file]恢复暂存区的所有文件到工作区：git checkout .恢复某个commit的指定文件到暂存区和工作区：git checkout [commit] [file]重置暂存区的指定文件，与上一次commit保持一致，但工作区不变：git reset [file]重置暂存区与工作区，与上一次commit保持一致：git reset --hard重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变：git reset [commit]重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致：git reset --hard [commit]重置当前HEAD为指定commit，但保持暂存区和工作区不变：git reset --keep [commit]新建一个commit，用来撤销指定commit(后者的所有变化都将被前者抵消，并且应用到当前分支)：git revert [commit]暂时将未提交的变化移除，稍后再移入：git stash和git stash pop原文信息：作者： 蘇小小链接：http://www.imooc.com/article/20411来源：慕课网常见问题failed to push some refs to gitQuestion1如何解决: failed to push some refs to git Answer1git pull --rebase origin master # 进行代码合并 git push -u origin master # 即可完成代码上传 git pull未指定本地与远程连接报错Question2If you wish to set tracking information for this branch you can do so with:git branch --set-upstream-to=origin/ masterAnswer2指定当前工作分支跟远程仓库分支之间的联系git branch --set-upstream master origin/master获取最新代码报错Question3git pull 获取最新代码报以下错误fatal: refusing to merge unrelated historiesAnswer3git pull之后加上可选参数 --allow-unrelated-histories 强制合并git pull origin master --allow-unrelated-histories使用钩子报错Question4使用钩子pre-commit，提交代码提示如下错误：$ git commit -m '.' sh: eslint: command not found pre-commit: pre-commit: We've failed to pass the specified git pre-commit hooks as the `fix` pre-commit: hook returned an exit code (1). If you're feeling adventurous you can pre-commit: skip the git pre-commit hooks by adding the following flags to your commit: pre-commit: pre-commit: git commit -n (or --no-verify) pre-commit: pre-commit: This is ill-advised since the commit is broken. pre-commit: Answer4打开项目中的.git/hooks文件夹，找到pre-commit.sample文件，将以下代码替换到文件中，或者，npm install pre-commit --save也可以，这个命令会自动执行以下操作。#!/bin/bash TSLINT="$(git rev-parse --show-toplevel)/node_modules/.bin/tslint" for file in $(git diff --cached --name-only | grep -E '\.ts$') do git show ":$file" | "$TSLINT" "$file" if [ $? -ne 0 ]; then exit 1 fi done 将pre-commit.sample文件名修改为pre-commit。.gitignore规则不生效Question5.gitignore规则不生效的解决办法Answer5把某些目录或文件加入忽略规则，按照上述方法定义后发现并未生效，原因是.gitignore只能忽略那些原来没有被追踪的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。那么解决方法就是先把本地缓存删除（改变成未被追踪状态），然后再提交：git rm -r --cached . 或者 git rm -r README.md git add . git commit -m 'update .gitignore' 作者：五月君链接：http://www.imooc.com/article/269298来源：慕课网本文首次发布于慕课网 ，转载请注明出处，谢谢合作]]></content>
      <categories>
        <category>其他内容学习</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git讲解与使用实战(转载)]]></title>
    <url>%2Fposts%2F13035.html</url>
    <content type="text"><![CDATA[这是一篇转载的文章，主要偏向实战，通过实战讲解Git的用法，比较全面，包括创建版本库、版本回退、撤销修改和删除文件操作、远程仓库相关操作以及分支操作，总的来说是一篇不错的文章。Git简介与安装Git是什么？Git是目前世界上最先进的分布式版本控制系统。工作原理 / 流程：Workspace：工作区Index / Stage：暂存区Repository：仓库区（或本地仓库）Remote：远程仓库SVN与Git的最主要的区别SVN是集中式版本控制系统，版本库是集中放在中央服务器的，而干活的时候，用的都是自己的电脑，所以首先要从中央服务器哪里得到最新的版本，然后干活，干完后，需要把自己做完的活推送到中央服务器。集中式版本控制系统是必须联网才能工作，如果在局域网还可以，带宽够大，速度够快，如果在互联网下，如果网速慢的话，就纳闷了。Git是分布式版本控制系统，那么它就没有中央服务器的，每个人的电脑就是一个完整的版本库，这样，工作的时候就不需要联网了，因为版本都是在自己的电脑上。既然每个人的电脑都有一个完整的版本库，那多个人如何协作呢？比如说自己在电脑上改了文件A，其他人也在电脑上改了文件A，这时，你们两之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。在windows上安装Gitmsysgit是 windows版的Git,如下：需要从网上下载一个，然后进行默认安装即可。安装完成后，在开始菜单里面找到 "Git --&gt; Git Bash",如下：会弹出一个类似的命令窗口的东西，就说明Git安装成功。如下：安装完成后，还需要最后一步设置，在命令行输入如下：因为Git是分布式版本控制系统，所以需要填写用户名和邮箱作为一个标识。注意：git config --global 参数，有了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然你也可以对某个仓库指定的不同的用户名和邮箱。Git使用创建版本库什么是版本库？版本库又名仓库，英文名repository,你可以简单的理解一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改，删除，Git都能跟踪，以便任何时刻都可以追踪历史，或者在将来某个时刻还可以将文件”还原”。所以创建一个版本库也非常简单，如下我是D盘 –&gt; www下 目录下新建一个testgit版本库。pwd 命令是用于显示当前的目录。把这个目录变成git可以管理的仓库通过命令 git init 把这个目录变成git可以管理的仓库，如下：这时候你当前testgit目录下会多了一个.git的目录，这个目录是Git来跟踪管理版本的，没事千万不要手动乱改这个目录里面的文件，否则，会把git仓库给破坏了。如下：把文件添加到版本库中首先要明确下，所有的版本控制系统，只能跟踪文本文件的改动，比如txt文件，网页，所有程序的代码等，Git也不列外，版本控制系统可以告诉你每次的改动，但是图片，视频这些二进制文件，虽能也能由版本控制系统管理，但没法跟踪文件的变化，只能把二进制文件每次改动串起来，也就是知道图片从1kb变成2kb，但是到底改了啥，版本控制也不知道。示例demo：我在版本库testgit目录下新建一个记事本文件 readme.txt 内容如下：11111111第一步：使用命令 git add readme.txt添加到暂存区里面去，如下：如果和上面一样，没有任何提示，说明已经添加成功了。第二步：用命令 git commit告诉Git，把文件提交到仓库:这样我们就已经提交了一个readme.txt文件了第三步：使用命令git status来查看是否还有文件未提交，如下：说明没有任何文件未提交第四步：继续来修改readme.txt内容，比如我在下面添加一行2222222222内容，继续使用git status来查看下结果，如下：上面的命令告诉我们 readme.txt文件已被修改，但是未被提交的修改。接下来我想看下readme.txt文件到底改了什么内容，如何查看呢？第五步：使用git diff readme.txt查看文件到底改了什么内容，如下：如上可以看到，readme.txt文件内容从一行11111111改成二行添加了一行22222222内容。知道了对readme.txt文件做了什么修改后，我们可以放心的提交到仓库了，提交修改和提交文件是一样的2步(第一步是git add；第二步是：git commit)，如下：版本回退如上，我们已经学会了修改文件，现在我继续对readme.txt文件进行修改，再增加一行内容为33333333333333继续执行命令如下：现在我已经对readme.txt文件做了三次修改了，那么我现在想查看下历史记录，如何查呢？使用命令 git log 查看历史记录git log命令显示从最近到最远的修改日志，我们可以看到最近有三次提交，最近的一次是：增加内容为333333；上一次是添加内容222222；第一次默认是 111111.如果嫌上面显示的信息太多的话，我们可以使用命令 git log –pretty=oneline演示如下：使用命令 git reset 进行版本回退现在我想使用版本回退操作，我想把当前的版本回退到上一个版本，要使用什么命令呢？可以使用如下2种命令：第一种是：git reset --hard HEAD^，那么如果要回退到上上个版本只需把HEAD^ 改成 HEAD^^，以此类推第二种是：git reset --hard HEAD~1，第一种方法如果要回退到前100个版本的话，肯定不方便，这时可以使用简便命令操作：git reset --hard HEAD~100未回退之前的readme.txt内容如下：如果想回退到上一个版本的命令如下操作：使用命令cat readme.txt查看下 readme.txt内容，如下：可以看到，内容已经回退到上一个版本了。我们可以继续使用git log 来查看下历史记录信息，如下：发现增加333333内容已经没有了使用命令 git reset 结合 git reflog 进行版本号回退如果现在想回退到最新的版本，如：有333333的内容要如何恢复呢？我们可以通过版本号回退，使用命令：git reset --hard 版本号 ，但是现在的问题假如我已经关掉过一次命令行或者333内容的版本号我并不知道呢？要如何知道增加3333内容的版本号呢？可以通过git reflog命令获取到版本号，演示如下：通过上面的显示我们可以知道，增加内容3333的版本号是 6fcfc89。我们现在可以使用命令：git reset --hard 6fcfc89来恢复了，演示如下：可以看到目前已经是最新的版本了。理解工作区与暂存区的区别工作区：就是你在电脑上看到的目录，比如目录下testgit里的文件(.git隐藏目录版本库除外)。或者以后需要再新建的目录文件等等都属于工作区范畴。版本库(Repository)：工作区有一个隐藏目录.git,这个不属于工作区，这是版本库。其中版本库里面存了很多东西，其中最重要的就是stage(暂存区)，还有Git为我们自动创建了第一个分支master,以及指向master的一个指针HEAD。我们前面说过使用Git提交文件到版本库有两步：第一步：是使用git add把文件添加进去，实际上就是把文件添加到暂存区第二步：使用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支上继续使用demo来演示下：我们在readme.txt再添加一行内容为4444444，接着在目录下新建一个文件为test.txt 内容为test，我们先用命令git status来查看下状态，如下：现在我们先使用git add命令把2个文件都添加到暂存区中，再使用git status来查看下状态，如下：接着我们可以使用git commit一次性提交到分支上，如下：撤销修改和删除文件操作撤销修改现在在readme.txt文件里面增加一行内容为555555555555，我们先通过命令查看如下：在我未提交之前，我发现添加5555555555555内容有误，所以我得马上恢复以前的版本，现在我可以有如下几种方法可以做修改：第一：如果我知道要删掉那些内容的话，直接手动更改去掉那些需要的文件，然后add添加到暂存区，最后commit掉第二：使用git reset --hard HEAD^直接恢复到上一个版本第三：使用撤销命令git checkout --，下面讲解如何使用撤销命令首先在做撤销之前，我们可以先用git status查看下当前的状态。如下所示：可以发现，Git会告诉你，git checkout -- file可以丢弃工作区的修改，例如使用git checkout -- readme.txt：命令git checkout --readme.txt意思就是：把readme.txt文件在工作区做的修改全部撤销，这里有2种情况：readme.txt自动修改后，还没有放到暂存区，使用撤销修改就回到和版本库一模一样的状态readme.txt已经放入暂存区了，接着又作了修改，撤销修改就回到添加暂存区后的状态也就是说git checkout --readme.txt只能撤销没有提交到暂存区的修改对于上面列举的第二种情况，我想我们继续做demo来看下，假如现在我对readme.txt添加一行 内容为6666666666666，我git add添加到暂存区后，接着添加内容7777777，我想通过撤销命令让其回到暂存区后的状态。如下所示：注意：命令git checkout -- readme.txt中的--很重要，如果没有--的话，那么命令变成创建分支了。删除文件假如我现在版本库testgit目录添加一个文件b.txt,然后提交，如下：如上：一般情况下，可以直接在文件目录中把文件删了，或者使用如上rm命令：rm b.txt，如果我想彻底从版本库中删掉了此文件的话，可以再执行commit命令提交掉，现在目录是这样的：撤销删除操作只要没有commit之前，如果我想在版本库中恢复此文件如何操作呢？，可以使用如下命令git checkout -- b.txt，如下所示：再来看看我们testgit目录，添加了3个文件了。如下所示：远程仓库建立传输连接以Github为例进行远程仓库的操作，首先需要建立本地Git仓库和Github仓库之间的传输(通过SSH加密的)连接第一步：创建SSHKey。在用户主目录下，看看有没有.ssh目录，如果有，再看看这个目录下有没有id_rsa和id_rsa.pub这两个文件，如果有的话，直接跳过此如下命令，如果没有的话，打开命令行，输入命令：ssh-keygen -t rsa –C “youremail@example.com”, 结果如下所示：注意：id_rsa是私钥，不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。第二步：在Github中添加公钥。登录Github,打开“settings”中的SSH Keys页面，然后点击“Add SSH Key”,填上任意title，在Key文本框里黏贴id_rsa.pub文件的内容。点击Add Key，你就应该可以看到已经添加的key。添加远程库现在的情景是：我们已经在本地创建了一个Git仓库后，又想在Github创建一个Git仓库，并且希望这两个仓库进行远程同步，这样Github的仓库可以作为备份，又可以其他人通过该仓库来协作。首先，登录Github上，然后在右上角找到“create a new repo”创建一个新的仓库。如下：在Repository name填入testgit，其他保持默认设置，点击“Create repository”按钮，就成功地创建了一个新的Git仓库：目前，在GitHub上的这个testgit仓库还是空的，GitHub提示我们，可以从这个仓库克隆出新的仓库，也可以把一个已有的本地仓库与之关联，然后，把本地仓库的内容推送到GitHub仓库。现在，我们根据GitHub的提示，在本地的testgit仓库下运行命令：把本地库的内容推送到远程，使用git push命令，实际上是把当前分支master推送到远程。由于远程库是空的，我们第一次推送master分支时，加上了–u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。推送成功后，可以立刻在Github页面中看到远程库的内容已经和本地一模一样了:从现在起，只要本地作了提交，就可以通过命令：git push origin master把本地master分支的最新修改推送到Github上了，现在你就拥有了真正的分布式版本库了。克隆远程库到本地上面我们了解了先有本地库，后有远程库时候，如何关联远程库。现在我们想，假如远程库有新的内容了，我想克隆到本地来，如何克隆呢？首先，登录Github，创建一个新的仓库，名字叫testgit2，如下： 接下来，使用命令git clone克隆一个本地库了。如下所示：操作完成后可以发现在我本地目录下生成testgit2目录了，如下所示：分支操作在版本回填退里，我们已经知道，每次提交，Git都把它们串成一条时间线，这条时间线就是一个分支。截止到目前，只有一条时间线，在Git里，这个分支叫主分支，即master分支。HEAD严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。Git的分支操作主要包括：创建分支、合并分支、删除分支创建分支首先，我们来创建dev分支，然后切换到dev分支上，如下操作：git checkout命令加上–b参数表示创建并切换，相当于2条命令：git branch dev(新建分支)git checkout dev(切换分支)git branch查看分支，会列出所有的分支，当前分支前面会添加一个星号接下来我们在dev分支上继续做demo，比如我们现在在readme.txt再增加一行 7777777777777首先我们先来查看下readme.txt内容，接着添加内容77777777，如下：现在dev分支工作已完成，现在我们切换到主分支master上，继续查看readme.txt内容如下：不同分支上的内容修改是不共享的，如果想要共享需要使用合并操作，具体请看下文合并分支现在我们可以把dev分支上的内容合并到分支master上了，可以在master分支上，使用如下命令git merge dev如下所示：git merge命令用于合并指定分支到当前分支上，合并后，再查看readme.txt内容，可以看到，和dev分支最新提交的是完全一样的注意到上面的Fast-forward信息，Git告诉我们，这次合并是“快进模式”，也就是直接把master指向dev的当前提交，所以合并速度非常快删除分支合并完成后，我们可以使用命令git branch –d dev删除dev分支了，操作如下：总结创建与合并分支命令如下：查看分支：git branch创建分支：git branch name切换分支：git checkout name创建+切换分支：git checkout –b name合并某分支到当前分支：git merge name删除分支：git branch –d name分支合并冲突当我们同时在两个分支中修改同一个文件，并将其合并的时候会出现分支合并冲突，示例如下：首先，先新建一个新分支，比如名字叫fenzhi1，在readme.txt添加一行内容8888888，然后提交，如下所示：然后，我们现在切换到master分支上来，也在readme.txt最后一行添加内容，内容为99999999，然后提交，如下所示：接下来，我们在master分支上来合并fenzhi1，直接使用git merge会提示conflict，然后使用git status查看发现在两个分支中readme.txt都被修改了，此时打开readme.txt文件发现出现了冲突的内容显示，具体内容和操作截图如下：Git用&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同分支的内容，其中&lt;&lt;&lt;HEAD是指主分支修改的内容，&gt;&gt;&gt;&gt;&gt;fenzhi1 是指fenzhi1上修改的内容，我们可以手动对readme.txt文件进行如下修改后保存：最后，使用命令git log命令查看分支合并的情况：分支合并模式通常合并分支时，Git一般使用”Fast forward”模式，在这种模式下，删除分支后，会丢掉分支信息，现在我们来使用带参数 –no-ff来禁用”Fast forward”模式。首先我们来做demo演示下： 创建一个dev分支; 修改readme.txt内容; 添加到暂存区; 切换回主分支(master); 合并dev分支，使用命令 git merge –no-ff -m “注释” dev; 查看历史记录; 分支管理策略首先master主分支应该是非常稳定的，也就是用来发布新版本，一般情况下不允许在上面干活，干活一般情况下在新建的dev分支上干活，干完后，比如上要发布，或者说dev分支代码稳定后可以合并到主分支master上来。创建bug分支在开发中，会经常碰到bug问题，那么有了bug就需要修复，在Git中，分支是很强大的，每个bug都可以通过一个临时分支来修复，修复完成后，合并分支，然后将临时的分支删除掉。例如，我在开发中接到一个404 bug时候，我们可以创建一个404分支来修复它，但是，当前的dev分支上的工作还没有提交，具体如下：这里并不是我不想提交，而是工作进行到一半时候，我们还无法提交，比如我这个分支bug要2天完成，但是我issue-404 bug需要5个小时内完成。怎么办呢？还好，Git还提供了一个stash功能，可以把当前工作现场”隐藏起来”，等以后恢复现场后继续工作。如下：现在我可以通过创建issue-404分支来修复bug了，具体的实施步骤如下：首先，我们要确定在哪个分支上修复bug，比如我现在是在主分支master上来修复的，现在我要在master分支上创建一个临时分支，演示如下：然后，在修复完成后切换到master分支上，并完成合并，最后删除issue-404分支。演示如下：接下来，我们回到dev分支上干活:但是，我们发现工作区是干净的，那么我们工作现场去哪里呢？我们可以使用命令git stash list来查看工作现场。如下：通过git stash list发现工作现场还在，Git把stash内容存在某个地方了，但是需要恢复一下，可以使用如下2个方法：git stash apply恢复，恢复后，stash内容并不删除，你需要使用命令git stash drop来删除另一种方式是使用git stash pop，恢复的同时把stash内容也删除了示例如下：多人协作查看远程库的信息当你从远程库克隆时候，实际上Git自动把本地的master分支和远程的master分支对应起来了，并且远程库的默认名称是origin。要查看远程库的信息，使用git remote要查看远程库的详细信息，使用git remote –v，具体操作如下：推送分支推送分支就是把该分支上所有本地提交到远程库中，推送时要指定本地分支，这样Git就会把该分支推送到远程库对应的远程分支上把本地分支推送到远程分支，使用git push origin master例如，我的Github(远程库)上的readme.txt代码如下：本地的readme.txt代码如下：现在我想把本地更新的readme.txt代码推送到远程库中，使用命令如下：我们可以看到如上Git信息提示，推送成功，然后我们可以看看Github上的readme.txt内容 如下：可以看到推送成功了，如果我们现在要推送到其他分支，比如dev分支上，我们还是那个命令git push origin dev那么一般情况下，那些分支要推送呢？master分支是主分支，因此要时刻与远程同步；一些修复bug分支不需要推送到远程去，可以先合并到主分支(或者dev分支)上，然后把主分支master(或者dev分支)推送到远程去抓取分支多人协作时，大家都会往master分支上推送各自的修改。现在我们可以模拟另外一个同事，可以在另一台电脑上（注意要把SSH key添加到Github上）或者同一台电脑上另外一个目录克隆，新建一个目录名字叫testgit2，具体的协作步骤如下：首先，我要把dev分支也要推送到远程去，如下：然后，进入testgit2目录，进行克隆远程的库到本地来(模拟的协作)，如下：现在目录下生成有如下所示：接下来，我们的小伙伴要在dev分支上做开发，就必须把远程的origin的dev分支到本地来，于是可以使用命令创建本地dev分支：git checkout –b dev origin/dev。创建完成后，小伙伴们就可以在dev分支上做开发了，开发完成后把dev分支推送到远程库时，如下：下一步，小伙伴们已经向origin/dev分支上推送了提交，而我在我的目录文件下也对同样的文件同个地方作了修改，也试图推送到远程库时，如下：由上面可知：推送失败，因为我的小伙伴最新提交的和我试图推送的有冲突，解决的办法也很简单，上面已经提示我们，先用git pull把最新的提交从origin/dev抓下来，然后在本地合并，解决冲突，再推送。git pull也失败了，原因是没有指定本地dev分支与远程origin/dev分支的链接，根据提示，设置dev和origin/dev的链接，使用git branch --set-upstream dev origin/dev，如下：这回git pull成功，但是合并有冲突，需要手动解决，解决的方法和分支管理中的解决冲突完全一样。解决后，提交，再push。我们可以先来看看readme.txt内容：手动解决完后，接着再提交，再push到远程库里面去。如下所示：总结一下，多人协作工作模式一般是这样的：首先，可以试图用git push origin branch-name推送自己的修改；如果推送失败，则因为远程分支比你的本地更新早，需要先用git pull试图合并；如果合并有冲突，则需要解决冲突，并在本地提交，然后再用git push origin branch-name推送。感谢龙恩的贡献：http://www.cnblogs.com/tugenhua0707/p/4050072.html原文信息：作者： 蘇小小链接：http://www.imooc.com/article/20411来源：慕课网]]></content>
      <categories>
        <category>其他内容学习</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell解析命令行过程以及eval命令]]></title>
    <url>%2Fposts%2F29719.html</url>
    <content type="text"><![CDATA[这里写摘要，显示更好看开始于二级标题参考链接shell解析命令行的过程以及eval命令Linux Shell 通配符、元字符、转义符使用实例介绍]]></content>
      <categories>
        <category>Linux</category>
        <category>常用内容总结</category>
      </categories>
      <tags>
        <tag>常用内容总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML常用字符实体]]></title>
    <url>%2Fposts%2F45689.html</url>
    <content type="text"><![CDATA[这篇文章总结了HTML常用字符实体(在某些特殊情况下使用，如表格中插入竖线等)，包括特色字符实体、常用字符实体、货币类字符实体、数字类字符实体、方向类字符实体以及其他字符实体，以供需要时查阅HTML字符实体一些字符在 HTML 中拥有特殊的含义，比如小于号&lt;用于定义 HTML 标签的开始，在这种情况下如果我们希望浏览器正确地显示这些字符，我们必须在 HTML 源码中插入字符实体来使HTML不将其当做具有特殊含义的字符，例如，要在 HTML 文档中显示小于号，我们需要这样写：&amp;lt; 或者 &amp;#60;。字符实体有三部分：一个和号&amp;一个实体名称，或者 # 和一个实体编号以及一个分号 ;使用实体名称而不是实体编号的好处在于，名称相对来说更容易记忆；而这么做的坏处是，并不是所有的浏览器都支持最新的实体名称，然而几乎所有的浏览器对实体编号的支持都很好。注意：实体对大小写敏感。特色HTML字符实体table th:first-of-type{width:20%}table th:nth-of-type(2){width:20%}table th:nth-of-type(3){width:20%}table th:nth-of-type(4){width:40%}字符名字编码说明©&amp;copy;&amp;#169;版权标志|&nbsp;&amp;#124;竖线，常用作菜单或导航中的分隔符·&amp;middot;&amp;#183;圆点，有时被用来作为菜单分隔符↑&amp;uarr;&amp;#8593;上箭头，常用作网页“返回页面顶部”标识€&amp;euro;&amp;#8364;欧元标识²&amp;sup2;&amp;#178;上标2，数学中的平方，在数字处理中常用到，例如：1000²½&amp;frac12;&amp;#189;二分之一♥&amp;hearts;&amp;#9829;心型，用来表达你的心常用HTML字符实体字符名字编码说明&nbsp;&amp;nbsp;&amp;#160;空格&amp;&amp;amp;&amp;#38;and符号，与"&amp;quot;&amp;#34;引号©&amp;copy;&amp;#169;版权标志®&amp;reg;&amp;#187;注册标志™&amp;trade;&amp;#153;商标标志“&amp;ldquo;&amp;#147;左双引号”&amp;rdquo;&amp;#148;右双引号‘&amp;lsquo;&amp;#145;做单引号’&amp;rsquo;&amp;#146;右单引号«&amp;laquo;&amp;#171;左三角双引号»&amp;raquo;&amp;#187;右三角双引号‹&amp;lsaquo;&amp;#8249;左三角单引号›&amp;rsaquo;&amp;#8250;右三角单引号§&amp;sect;&amp;#167;章节标志¶&amp;para;&amp;#182;段落标志•&amp;bull;&amp;#149;列表圆点（大）·&amp;middot;&amp;#183;列表圆点（中）…&amp;hellip;&amp;#8230;省略号|&nbsp;&amp;#124;竖线¦&amp;brvbar;&amp;#166;断的竖线–&amp;ndash;&amp;#150;短破折号—&amp;mdash;&amp;#151;长破折号货币类HTML字符实体字符名字编码说明¤&amp;curren;&amp;#164;一般货币符号$&nbsp;&amp;#36;美元符号¢&amp;cent;&amp;#162;分£&amp;pound;&amp;#163;英镑¥&amp;yen;&amp;#165;日元€&amp;euro;&amp;#8364;欧元数字类HTML字符实体字符名字编码说明&lt;&amp;lt;&amp;#60;小于号&gt;&amp;gt;&amp;#62;大于号≤&amp;le;&amp;#8804;小于等于号≥&amp;ge;&amp;#8805;大于等于号×&amp;times;&amp;#215;乘号÷&amp;divide;&amp;#247;除号−&amp;minus;&amp;#8722;减号±&amp;plusmn;&amp;#177;加/减 号≠&amp;ne;&amp;#8800;不等于号¹&amp;sup1;&amp;#185;上标1²&amp;sup2;&amp;#178;上标2³&amp;sup3;&amp;#179;上标3½&amp;frac12;&amp;#189;二分之一¼&amp;frac14;&amp;#188;四分之一¾&amp;frac34;&amp;#190;四分之三‰&amp;permil;&amp;#8240;千分率°&amp;deg;&amp;#176;度√&amp;radic;&amp;#8730;平方根∞&amp;infin;&amp;#8734;无限大方向类HTML字符实体字符名字编码说明←&amp;larr;&amp;#8592;左箭头↑&amp;uarr;&amp;#8593;上箭头→&amp;rarr;&amp;#8594;右箭头↓&amp;darr;&amp;#8595;下箭头↔&amp;harr;&amp;#8596;左右箭头↵&amp;crarr;&amp;#8629;回车箭头⌈&amp;lceil;&amp;#8968;左上限⌉&amp;rceil;&amp;#8969;右上限⌊&amp;lfloor;&amp;#8970;左下限⌋&amp;rfloor;&amp;#8971;右下限其他HTML字符实体字符名字编码说明♠&amp;spades;&amp;#9824;黑桃♣&amp;clubs;&amp;#9827;梅花♥&amp;hearts;&amp;#9829;红桃，心♦&amp;diams;&amp;#9830;方块牌◊&amp;loz;&amp;#9674;菱形†&amp;dagger;&amp;#8224;匕首‡&amp;Dagger;&amp;#8225;双剑号¡&amp;iexcl;&amp;#161;反向感叹号¿&amp;iquest;&amp;#191;反向问号参考链接HTML实体符号网页中常用HTML字符实体]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux通配符和正则表达式及其区别]]></title>
    <url>%2Fposts%2F37480.html</url>
    <content type="text"><![CDATA[这篇文章主要学习了linux通配符和正则表达式及其区别，linux中常见通配符只有*、?、[]、{}这几种，是由shell解析之后作为参数传给linux命令，而正则匹配字符则相对较多；注意正则匹配和通配符在命令中的使用区别：像awk、sed、grep使用正则表达式、像find、ls、cp使用通配符。通配符问题引出12345678ls test2.txt test3.txt test.txtls test*.txt test2.txt test3.txt test.txtls d*.txt ls: cannot access d*.txt: No such file or directory通配符的作用方式通配符是由shell处理的(不是由所涉及到命令语句处理的，其实我们在shell各个命令中也没有发现有这些通配符介绍), 它只会出现在命令的参数里(它不用在命令名称里， 也不用在操作符上)。当shell在参数中遇到了通配符时，shell会将其当作路径或文件名去在磁盘上搜寻可能的匹配：若符合要求的匹配存在，则进行代换(路径扩展)；否则就将该通配符作为一个普通字符传递给命令，然后再由命令进行处理。总之，通配符实际上就是一种shell实现的路径扩展功能。在通配符被处理后, shell会先完成该命令的重组，然后再继续处理重组后的命令，直至执行该命令。我们回过头分析上面命令：在第2个命令中，test*.txt 实际shell搜索文件,找到了符合条件的文件，命令会变成：ls test2.txt test3.txt test.txt ,实际在执行ls时候传给它的参数是test2.txt test3.txt test.txt。而命令3，d*.txt 由于当前目录下面没有这样的文件或目录，直接将d*.txt作为普通字符传给ls作为参数。这个时候*只是一个普通的 ls参数而已，已经失去了它通配意义。由于找不到文件，所以会出现：无法访问提示！了解了shell通配符，我们现在看下，shell常见通配符有哪些了。常用通配符table th:first-of-type{width:15%}table th:nth-of-type(2){width:35%}table th:nth-of-type(3){width:50%}字符含义实例*匹配 0 或多个字符a*b：a与b之间可以有任意长度的任意字符, 也可以一个也没有, 如aabcb, axyzb, a012b, ab?匹配任意一个字符a?b：a与b之间必须也只能有一个字符, 可以是任意字符, 如aab, abb, acb, a0b\转义字符，将特殊符号的特殊意义去除例如：rm a[*]c.txt是删除a[*]c.txt文件[char]匹配原始字符char，相当于转义操作a[?]b：a与b之间只有一个字符且为?,此时的?已经不再具有匹配任意一个字符的功能 如: a?b.txt[list]匹配 list 中的任意单一字符a[xyz]b：a与b之间必须也只能有一个字符, 但只能是 x 或 y 或 z, 如: axb, ayb, azb[!list]匹配 除list 中的任意单一字符(一定要有一个)a[!0-9]b：a与b之间必须也只能有一个字符, 但不能是阿拉伯数字, 如axb, aab, a-b[^list]匹配 除list 中的任意单一字符(一定要有一个)a[^0-9]b：a与b之间必须也只能有一个字符, 但不能是阿拉伯数字, 如axb, aab, a-b[c1-c2]匹配 c1-c2 中的任意单一字符 如：[0-9] [a-z]a[0-9]b：0与9之间必须也只能有一个字符 如a0b, a1b… a9b{string1,string2,...}匹配 sring1 或 string2 (或更多)其一字符串a{abc,xyz,123}b：a与b之间只能是abc或xyz或123这三个字符串之一需要说明的是：通配符看起来有点象正则表达式语句，但是它与正则表达式不同的，不能相互混淆。把通配符理解为shell 特殊代号字符就可。而且涉及的只有，*、?、[]、{}这几种通配符示例[!list] 和[^list]：ls test[^1-2].txttest3.txtls test[!1-2].txttest3.txt注意不会出现test.txt，因为test和.txt之间必须要有一个字符，而test.txt不具备这个条件正则表达式字符基础正则表达式字符字符含义实例^word待搜寻的字串(word)在行首grep -n ‘^#’ regular_express.txt：搜寻行首为 # 开始的那一行，并列出行号word$待搜寻的字串(word)在行尾grep -n ‘!$’ regular_express.txt：将行尾为 ! 的那一行打印出来，并列出行号.代表一定有一个任意字符的字符grep -n ‘e.e’ regular_express.txt：搜寻的字串可以是 (eve) (eae) (eee) (e e)， 但不能仅有 (ee) ！亦即 e 与 e 中间一定仅有一个字符，而空白字符也是字符！\转义字符，将特殊符号的特殊意义去除grep -n \’ regular_express.txt：搜寻含有单引号 ‘ 的那一行*重复零个到无穷多个的前一个字符grep -n ‘ess*’ regular_express.txt：找出含有 (es) (ess) (esss) 等等的字串，注意，因为 可以是 0 个，所以 es 也是符合带搜寻字串。另外，之前也可以紧接着一个 RE 字符，例如任意字符则为 “.”[list]字符集合，匹配list 中的任意单个字符grep -n ‘g[ld]’ regular_express.txt：搜寻含有 (gl) 或 (gd) 的那一行，需要特别留意的是，在 [] 当中“谨代表一个待搜寻的字符”， 例如“ a[afl]y ”代表搜寻的字串可以是 aay, afy, aly 即 [afl] 代表 a 或 f 或 l 的意思[n1-n2]字符范围，匹配n1-n2中的任意单个字符grep -n ‘[A-Z]’ regular_express.txt：搜寻含有大写字母的那一行。需特别留意，在字符集合 [] 中的减号 - 是有特殊意义的，他代表两个字符之间的所有连续字符！但这个连续与否与 ASCII 编码有关。[^list]字符集合，匹配 除list 中的任意单一字符(一定要有一个)不要大写字符，则为 [^A-Z]。但是，需要特别注意的是，如果以 grep -n [^A-Z] regular_express.txt 来搜寻，却发现该文件内的所有行都被列出，为什么？因为这个 [^A-Z] 是“非大写字符”的意思， 因为每一行均有非大写字符，例如第一行的 “Open Source” 就有 p,e,n,o…. 等等的小写字{n,m}连续 n 到 m 个的前一个字符；若为 {n} 则是连续 n 个的前一个字符；若是 {n,} 则是连续 n 个以上的前一个字符grep -n ‘go{2,3}g’ regular_express.txt：在 g 与 g 之间有 2 个到 3 个的 o 存在的字串，亦即 (goog)(gooog)延伸正则表达式字符字符含义实例+重复一个或一个以上的前一个字符egrep -n ‘go+d’ regular_express.txt：搜寻 (god) (good) (goood)… 等等的字串，那个 o+ 代表一个以上的 o?零个或一个的前一个字符egrep -n ‘go?d’ regular_express.txt：搜寻 (gd) (god) 这两个字串，那个 o? 代表空的或 1 个 o&#124;用或( or )的方式找出数个字串egrep -n ‘gd&#124;good’ regular_express.txt：搜寻 gd 或 good 这两个字串()找出群组字串egrep -n ‘g(la&#124;oo)d’ regular_express.txt：搜寻 (glad) 或 (good) 这两个字串，因为 g 与 d 是重复的，所以， 我就可以将 la 与 oo 列于 ( ) 当中，并以 &#124; 来分隔开来()+多个重复群组的判别echo ‘AxyzxyzxyzxyzC’ &#124; egrep ‘A(xyz)+C’grep 默认仅支持基础正则表达式，如果要使用延伸型正则表达式，你可以使用 grep -E ， 不过更建议直接使用 egrep！直接区分指令比较好记忆！其实 egrep 与 grep -E 是类似命令别名的关系啦！通配符和正则表达式关系在文本过滤工具里，都是用正则表达式，比如像awk、sed、grep等，是针对文件的内容的；而通配符多用在文件名上，比如find、ls、cp等等正则表达式中有部分与通配符是相近的含义，如[list]、[n1-n2]、[^list]，但也有一些差异非常大，如* 在通配符中表示匹配0或多个字符(可以独立使用)，但在正则表达式中表示重复零个到无穷多个的前一个字符(不能独立使用)参考链接Linux Shell 通配符、元字符、转义符使用实例介绍鸟哥的linux私房菜linux通配符和正则表达式]]></content>
      <categories>
        <category>Linux</category>
        <category>常用内容总结</category>
      </categories>
      <tags>
        <tag>常用内容总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell-循环结构]]></title>
    <url>%2Fposts%2F16486.html</url>
    <content type="text"><![CDATA[这篇博客主要学习了shell的循环结构，包括for、while、until循环，重点学习了前两个，整理了这两种循环的不同使用情形，同时也学习了循环控制结构的break和continue语句for循环for循环适用于已经知道需要进行多少次的循环，所以for循环也叫固定循环。循环结构12345Usage: for var in con1 con2 con3 ... do 程序段 done为了防止可能的字符分割(变量存在空格)问题，con1 con2 con3都需要被引用(使用双引号括起来)，关于字符分割的示例可以查看shell-if条件测试使用实例使用变量进行循环1234567891011cat test.txt this is a test that is a test there is a test those are testsfield1=$(cut -d ' ' -f 1 test.txt)for i in $&#123;field1&#125;do echo $idone输出：thisthattherethosename=&quot;my name is test&quot;for i in ${name};do echo $i;done输出：mynameistest使用seq命令进行循环seq命令的用法：12345678910Usage: seq [OPTION]... LAST or: seq [OPTION]... FIRST LAST or: seq [OPTION]... FIRST INCREMENT LASTPrint numbers from FIRST to LAST, in steps of INCREMENT.options: -f, --format=FORMAT use printf style floating-point FORMAT -s, --separator=STRING use STRING to separate numbers (default: \n) -w, --equal-width equalize width by padding with leading zeroes默认用法：123456789for i in `seq 1 5`do echo $i donefor i in $(seq 1 5)do echo $i done设置步长：1234for i in `seq 1 2 5`do echo $i done输出：135-w设置输出等长：1234for i in `seq -w 1 2 12`do echo $idone输出：010305070911使用特殊符号{}进行循环特殊符号{}用法:1234Usage: &#123;FIRST..LAST..INCREMENT &#125; Print numbers from FIRST to LAST, in steps of INCREMENT.对数字循环：12345678910for i in &#123;1..5&#125; do echo $i done# 对数字循环设置步长for i in &#123;1..5..2&#125; do echo $i done135对字母循环：12345678910111213141516171819202122for i in &#123;a..d&#125; do echo $i done# 对字母循环也可以设置步长for i in &#123;a..d..2&#125; do echo $i done# 可以在特殊符号&#123;&#125;之前添加字符或者特殊符号&#123;&#125;for i in a&#123;a..d&#125; do echo $i done# 可以在特殊符号&#123;&#125;之前添加字符或者特殊符号&#123;&#125;for i in &#123;1..2&#125;&#123;a..d&#125;do echo $idone输出：abcdacaaabacad1a1b1c1d2a2b2c2d特殊符号{}中的两个小数点来代表连续出现的意思，更多关于特殊符号{}的用法请参考这篇文章使用特殊符号(())进行循环使用形式：1234for （（ 初始值; 限制值; 执行步阶 ））do 程序段done使用实例：1234567891011121314for ((i=1;i&lt;6;i++))do echo $i donefor ((i=1;i&lt;6;i=i+2))do echo $i donefor ((i=1;i&lt;6;i+=2))do echo $i done特殊符号(())表示执行计算，和linux let命令相似，更多关于特殊符号(())的用法请参考这篇文章使用通配符进行循环通配符主要有星号(*)和问号(?)，用来模糊搜索文件。关于shell中常见的通配符以及通配符和正则表达式的区别请参考这篇文章123456789101112131415161718192021222324252627282930for i in test*.txtdo echo $idone# 输出： test2.txt test3.txt test.txt for file in *# ^ Bash 在检测到通配表达式时，#+ 会进行文件名扩展。do ls -l "$file" # 列出 $PWD（当前工作目录）下的所有文件。 # 回忆一下，通配符 "*" 会匹配所有的文件名， #+ 但是，在文件名扩展中，他将不会匹配以点开头的文件。 # 如果没有匹配到文件，那么它将会扩展为它自身。 # 为了防止出现这种情况，需要设置 nullglob 选项。 #+ (shopt -s nullglob)。donefor file in [jx]*do rm -f $file # 删除当前目录下所有以 "j" 或 "x" 开头的文件。 echo "Removed file \"$file\"".done每个元素多个参数用于循环的每个参数可以继续分解为多个参数，这里使用 set 命令强制解析循环内容中的每一个元素，并将元素的每一个部分分配给位置参数12345678910111213141516171819#!/bin/bash# 将每个行星与其到太阳的距离放在一起。for planet in "Mercury 36" "Venus 67" "Earth 93" "Mars 142" "Jupiter 483"do set -- $planet # 解析变量 "planet" #+ 并将其每个部分赋值给位置参数。 # "--" 防止一些极端情况，比如 $planet 为空或者以破折号开头。 # 因为位置参数会被覆盖掉，因此需要先保存原先的位置参数。 # 你可以使用数组来保存 # original_params=("$@") echo "$1 $2,000,000 miles from the sum" #-------两个制表符---将后面的一系列 0 连到参数 $2 上。doneexit 0输出：Mercury 36,000,000 miles from the sumVenus 67,000,000 miles from the sumEarth 93,000,000 miles from the sumMars 142,000,000 miles from the sumJupiter 483,000,000 miles from the sum示例来源于这本书集成管道符1234for file in "$( find $directory -type 1 )" # -type 1 = 符号链接do echo "$file"done | sortfor i in test*.txt;do echo $i;done |wc -l3while/until循环while/until循环适用于条件判断，条件成立则进行循环，具体多少次的循环不知道，只要条件成立即可，所以while/until循环也叫不定循环。while和until循环在进行条件判断时执行的是完全相反的操作，while是条件成立则进行循环，而until这是条件成立终止循环，是完全相反的，所以后续的学习主要集中于使用较多的while循环，until循环一样的道理，只是将条件判断改变即可。循环结构1234567891011# 当 condition 条件成立时，就进行循环，直到 condition 的条件不成立才停止while [ condition ] # 括号内的状态就是判断式do # do 是循环的开始！ 程序段落done # done 是循环的结束# 当 condition 条件成立时，就终止循环， 否则就持续进行循环的程序段(和while循环相反)until [ condition ]do 程序段落donewhile和until循环中当使用条件测试进行循环时和前面在if条件测试分支结构中使用的条件测试是相同的，具体的各种测试形式这里就不在列出，后续可以查看这篇文章使用实例使用条件测试进行循环和 if 一样， 使用条件测试进行循环时 while 会计算一系列命令的退出状态。只要退出状态为零(条件测试执行成功)，它就执行循环内的命令。123456789s=0 # 这是加总的数值变量i=0 # 这是累计的数值，亦即是 1, 2, 3....while [ "$&#123;i&#125;" != "100" ] # 变量使用双引号在进行变量替换的同时防止字符分割do i=$(($i+1)) # 每次 i 都会增加 1 s=$(($s+$i)) # 每次都会加总一次！ # 使用了特殊符号$(())来执行计算doneecho "The result of '1+2+3+...+100' is $s"如果一个 while 循环可以有多个测试条件，但只有最后的那一个条件决定了循环是否终止，这个也和if命令相同:123456789101112# 无限循环，输出this is truewhile false;truedo echo "this is true"done# 不循环while true;falsedo echo "this is true"done循环读取文件使用read结合标准输入&lt;来读取文件：12345678910cat test.txt this is a test that is a test there is a test those are testswhile read linedo echo $linedone &lt; test.txt输出：this is a testthat is a testthere is a testthose are tests也可以按字段读取文件的每行内容：12345678910111213while read field1 field2 do echo $field1 echo $field2done &lt; test.txtwhile read field1 field2 field3 field4 do echo $field1 echo $field2 echo $field3 echo $field4done &lt; test.txt输出：thisis a testthatis a testthereis a testthoseare teststhisisatestthatisatestthereisatestthosearetests这是空行为了重定向文件到循环中，可以将重定向操作符放置到 done 语句之后。循环使用 read 从重定向文件中读取字段；这个 read 命令读取每个文本行之后，将会退出，其退出状态为零，直到到达文件末尾，这时候它的退出状态为非零数值，因此终止循环。指定字段数小于每行字段数：第一个字段为第一个空格之前的内容，剩下的所有字段为第二个字段(这里只指定了两个字段来读取每一行)指定字段数大于每行字段数：不足的字段使用空格填补集成管道符上面使用使用read结合标准输入&lt;来读取文件的操作也可以使用管道符实现：12345678910cat test.txt|while read linedo echo $linedone# 输出： this is a test that is a test there is a test those are tests因为管道将会在子 shell 中执行循环，当循环终止的时候，循环中创建的任意变量或赋值的变量都会消失，记住这一点很重要(这个还没测试过，先mark一下)循环控制语句break-终止循环break语句：在for、while、until等循环语句中，用于跳出当前所在的循环体(终止循环)，执行循环体之后的语句。终止单层循环1234567891011121314while [ condition ]do commands commands break---------+ | commands | commands | 跳出(终止)循环（通常在循环体中与条件语句一起使用） |done | |commands&lt;-------+commands示例：1234567891011121314151617for f in $(ls)do [ -d "$f" ] &amp;&amp; break # 这种写法很简洁，如果想要使用常规的if条件测试分支结构就会比较复杂doneecho "We have found a directory $f"# 使用常规的if条件测试分支结构就会比较复杂for f in $(ls)do if [ -d "$f" ] then break fi doneecho "We have found a directory $f"在循环中一旦发现目录，则立即停止循环并退出终止多层循环break 命令可以接受一个参数，普通的 break 命令仅仅跳出其所在的那层循环，而 break N 命令则可以跳出其上 N 层的循环123456789101112131415161718for outerloop in 1 2 3 4 5do echo -n "Group $outerloop: " # ------------------------------------------ for innerloop in 1 2 3 4 5 do echo -n "$innerloop " if [ "$innerloop" -eq 3 ] then break 2 # 尝试一下 break 2 看看会发生什么。 # （它同时中止了内层和外层循环。） fi done # ------------------------------------------ echodone直接使用break的输出结果：Group 1: 1 2 3Group 2: 1 2 3Group 3: 1 2 3Group 4: 1 2 3Group 5: 1 2 3使用了break 2的输出结果：Group 1: 1 2 3可以发现使用break 2不仅跳出了本层循环，还跳出了本层循环的外层循环，也就是跳出了2层循环continue-进行下一次循环continue语句：在for、while、until等循环语句中，用于跳过循环体内余下的语句，重新判断条件以便执行下一次循环。影响单层循环123456789101112131415while [ condition ]&lt;-------+do | | commands | 跳回当前循环，重新开始下一次循环（通常在循环体中与条件语句一起使用） commands | | continue ----------------+ commands commands commandsdonecommandscommands示例：12345678910111213141516for f in $(ls)do [ -d "$f" ] || continue # 这种写法很简洁，如果想要使用常规的if条件测试分支结构就会比较复杂 chmod 3777 "$f"done# 使用常规的if条件测试分支结构就会比较复杂for f in $(ls)do if [ -d "$f" ] then chmod 3777 "$f" else continue fidone如果是目录，添加权限；如果不是，跳过当前循环，continue 后面代码不再执行，而是直接执行下次循环。影响多层循环与 break 类似，continue 也可以接受一个参数，普通的 continue 命令仅仅影响其所在的那层循环，而 continue N 命令则可以影响其上 N 层的循环12345678910111213141516171819for outer in I II III IV V # 外层循环do echo; echo -n "Group $outer: " # -------------------------------------------------------------------- for inner in 1 2 3 4 5 6 7 8 9 10 # 内层循环 do if [[ "$inner" -eq 7 &amp;&amp; "$outer" = "III" ]] then continue 2 # 影响两层循环，包括“外层循环”。 # 将其替换为普通的 "continue"，那么只会影响内层循环。 fi echo -n "$inner " # 7 8 9 10 将不会出现在 "Group III."中。 done # --------------------------------------------------------------------done直接使用continue的输出结果(只有第三组少了数字7)：Group I: 1 2 3 4 5 6 7 8 9 10Group II: 1 2 3 4 5 6 7 8 9 10Group III: 1 2 3 4 5 6 8 9 10Group IV: 1 2 3 4 5 6 7 8 9 10Group V: 1 2 3 4 5 6 7 8 9 10使用了continue 2的输出结果(第三组7以后的数字全消失了)：Group I: 1 2 3 4 5 6 7 8 9 10Group II: 1 2 3 4 5 6 7 8 9 10Group III: 1 2 3 4 5 6Group IV: 1 2 3 4 5 6 7 8 9 10Group V: 1 2 3 4 5 6 7 8 9 10continue N 结构不易理解并且可能在一些情况下有歧义，因此不建议使用参考链接鸟哥的linux私房菜The Linux Command Line 中文版高级Bash脚本编程指南中文版Linux Shell——流程控制条件测试操作与流程控制语句Shell 流程控制]]></content>
      <categories>
        <category>Linux</category>
        <category>shell编程</category>
      </categories>
      <tags>
        <tag>shell编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell-if条件测试]]></title>
    <url>%2Fposts%2F58105.html</url>
    <content type="text"><![CDATA[本文主要学习了shell中的条件测试命令，包括test命令、[ ]、[[ ]]、(( ))，主要介绍了前三个，其中[ ]和[[ ]]可以用在if条件测试分支结构中，两者之间的优缺点在文中也有讲解；也学习了if条件测试分支结构在多种情形下的多种形式以及exit命令设定程序退出状态条件测试本来打算直接学习if判断分支结构，但是在阅读相关资料后发现if判断分支中的条件判断其实就是shell条件测试，所以这里先对shell的条件测试进行学习。shell的条件测试可以使用test命令、[ ]判断式、[[ ]]判断式以及(( ))判断式，其中[ ]和[[ ]]是if判断分支结构中主要使用的。test命令测试test命令是 shell 环境中用于测试条件表达式的工具，当条件成立时，命令执行后的返回值为0，否则为其他数值。test命令结构12345Usage: test EXPRESSION test ! EXPRESSION test EXPRESSION -a EXPRESSION test EXPRESSION -o EXPRESSIONtest EXPRESSION执行结果并不会显示任何信息，如果想要显示信息可以使用$?或者使用&amp;&amp;和||的组合来得到信息使用$?：test -f test1.txt # 不输出结果echo $? # $?返回最后运行的命令的结束代码0 # 正常运行的命令结束代码为0，也就是条件成立test -f test2.txtecho $?1 # 出错或者异常结束代码为非0，也就是条件不成立使用&amp;&amp;和||的组合：test -f test2.txt &amp;&amp; echo &quot;exist&quot; || echo &quot;Not exist&quot;Not existtest -f test1.txt &amp;&amp; echo &quot;exist&quot; || echo &quot;Not exist&quot;exist注意&amp;&amp;和||的顺序不能随意，如果上面的顺序调换：test -f test2.txt || echo &quot;Not exist&quot; &amp;&amp; echo &quot;exist&quot;Not existexist上面的判断是按顺序执行的，具体&amp;&amp;和||前后命令的执行规则参考这篇博客文件是否存在测试使用示例：test -e filenametable th:first-of-type{width:20%}table th:nth-of-type(2){width:80%}参数说明-e该“文件名”是否存在（常用）-f该“文件名”是否存在且为文件（file）（常用）-d该“文件名”是否存在且为目录（directory）（常用）-s侦测该文件名是否存在且为“非空白文件”(文件大小不为0) （常用）-b该“文件名”是否存在且为一个 block device 设备-c该“文件名”是否存在且为一个 character device 设备-S该“文件名”是否存在且为一个 Socket 文件-p该“文件名”是否存在且为一个 FIFO （pipe） 文件-L该“文件名”是否存在且为一个链接文件test -f test1.txt &amp;&amp; echo &quot;exist&quot; || echo &quot;Not exist&quot;existtest -e test1.txt &amp;&amp; echo &quot;exist&quot; || echo &quot;Not exist&quot;existtest -d test1.txt &amp;&amp; echo &quot;exist&quot; || echo &quot;Not exist&quot;Not exist权限测试使用示例：test -r filename参数说明-r侦测该文件名是否存在且具有“可读”的权限-w侦测该文件名是否存在且具有“可写”的权限-x侦测该文件名是否存在且具有“可执行”的权限-u侦测该文件名是否存在且具有“SUID”的属性-g侦测该文件名是否存在且具有“SGID”的属性-k侦测该文件名是否存在且具有“Sticky bit”的属性-rw-rw-r– 1 user user 0 Mar 14 20:36 test1.txttest -r test1.txt &amp;&amp; echo &quot;exist&quot; || echo &quot;Not exist&quot;existtest -w test1.txt &amp;&amp; echo &quot;exist&quot; || echo &quot;Not exist&quot;existtest -x test1.txt &amp;&amp; echo &quot;exist&quot; || echo &quot;Not exist&quot;Not exist文件之间的测试使用示例：test file1 -nt file2参数说明-nt（newer than）判断 file1 是否比 file2 新-ot（older than）判断 file1 是否比 file2 旧-ef判断 file1 与 file2 是否为同一文件，可用在判断 hard link 的判定上（通过硬链接两个文件名指向相同的文件）-rw-rw-r– 1 user user 0 Mar 14 20:36 test1.txt-rw-rw-r– 1 user user 0 Mar 14 21:20 test2.txttest test1.txt -nt test2.txt &amp;&amp; echo &quot;exist&quot; || echo &quot;Not exist&quot;Not existtest test1.txt -ot test2.txt &amp;&amp; echo &quot;exist&quot; || echo &quot;Not exist&quot;exist整数之间的测试使用示例：test n1 -eq n2参数说明-eq两数值相等 （equal）-ne两数值不等 （not equal）-gtn1 大于 n2 （greater than）-ltn1 小于 n2 （less than）-gen1 大于等于 n2 （greater than or equal）-len1 小于等于 n2 （less than or equal）test 2 -eq 2 &amp;&amp; echo &quot;exist&quot; || echo &quot;Not exist&quot;existtest 2 -ne 2 &amp;&amp; echo &quot;exist&quot; || echo &quot;Not exist&quot;Not exist字符串的测试使用示例：test str1 == str2参数说明test -z string判定字串是否为 0 ，若 string 为空字串(空格不为空)，则为 truetest -n string判定字串是否非为 0 ，若 string 为空字串，则为 false。 -n 亦可省略test str1 == str2判定 str1 是否等于 str2 ，若相等，则回传 truetest str1 != str2判定 str1 是否不等于 str2 ，若相等，则回传 false注意：==前后需要空格隔开，不用空格隔开可能会出问题逻辑测试使用示例：test -r file -a -x file参数说明-a（and）两状况同时成立！例如 test -r file -a -x file，则 file 同时具有 r 与 x 权限时，才回传 true。-o（or）两状况任何一个成立！例如 test -r file -o -x file，则 file 具有 r 或 x 权限时，就可回传 true。!反向状态，如 test ! -x file ，当 file 不具有 x 时，回传 truetest命令最需要注意的是：单纯的test命令不会返回任何信息，所以如果想要显示信息可以使用$?或者使用&amp;&amp;和||的组合来得到信息[]判断式条件测试会使用一个特殊的命令 [，等同于 test 命令，它是一个内建命令，写法更加简洁高效。该命令将其参数视为比较表达式或文件测试，以比较结果作为其退出状态码返回（0 为真，1 为假）Bash 在 2.02 版本中引入了扩展测试命令 [[ ]]，它提供了一种与其他语言语法更为相似的方式进行比较操作。注意， [[ 是一个关键字 而非一个命令，Bash 将 [[ $a -lt $b ]] 视为一整条语句，执行并返回退出状态[]有几种不同的功能，如果想要用来作为条件测试必须要注意中括号的两端以及判断符前后需要有空白字符来分隔，如[ &quot;$HOME&quot; == &quot;$MAIL&quot; ]中括号和test命令的各种测试是相同的，[ ]判断式和test命令可以相互转换，比如[ &quot;$HOME&quot; == &quot;$MAIL&quot; ]可以转换为test “$HOME” == “$MAIL”，所以上面提到的各种测试都可以在中括号中使用在中括号 [ ] 内的每个元件都需要有空白键来分隔在中括号内的变量，最好都以双引号括号起来在中括号内的常数，最好都以单或双引号括号起来[ ]以及test命令中所有的表达式和操作符都被 shell 看作是命令参数，对于 bash 有特殊含义的字符，比如说 (、 )、&gt;、&lt;必须引起来或者是转义在复合测试中，仅仅引用字符串可能还不够，比如表达式[ -n &quot;$string&quot; -o &quot;$a&quot; = &quot;$b&quot; ] 在某些 Bash 版本下，如果 $string 为空可能会出错。更加安全的方式是，对于可能为空的字符串，添加一个额外的字符，例如 [ &quot;x$string&quot; != x -o &quot;x$a&quot; = &quot;x$b&quot; ]（其中的 x 互相抵消）[]判断式需要注意的问题-字符分割：test=”my name”[ ${test} == “my” ]bash: [: too many arguments上面的出错显示判断式中存在太多参数，但是明明就只有test一个参数，为什么会出现这个问题呢？因为 ${test} 如果没有使用双引号括起来，那么上面的判定式会变成：[ my name == “my” ]如果写成这个样子就会发现问题，因为一个判断式仅能有两个数据的比对，上面 my 与 name 还有 “my” 就有三个数据！所以会出错，而我们需要的是：[ “my name” == “my” ]所以这就说明了(如果字符串中带有空格，以防万一都带上吧)需要使用双引号括起来，不用单引号的原因是单引号会防止任何变量替换[[]]判断式在 Bash(限制条件) 里，[[ ]] 是比 [ ] 更加通用的写法，使用 [[ ]] 代替[ ]可以避免很多逻辑错误。比如可以在 [[ ]] 中使用 &amp;&amp;、||、&lt; 和 &gt; 操作符，而在 [ ] 中使用则会报错下面列出[[ ]] 比 [ ]更好用的几点：使用正则匹配增加了一个重要的新的字符串表达式来使用正则匹配string1 =~ regex不需要使用双引号[[ ]]判断式不需要对其中的变量和常数使用双引号括起来：[[ ${test} == &quot;my&quot; ]] &amp;&amp; echo &quot;right&quot; || echo &quot;wrong&quot;wrong==操作符支持模式匹配:FILE=foo.barif [[ $FILE == foo.* ]]; then> echo “$FILE matches pattern ‘foo.*‘“> fifoo.bar matches pattern ‘foo.*’使[[ ]]有助于计算文件和路径名，如果foo.*外加了双引号就没有正则匹配的意思，单纯的字符相等的意思只有 ==操作符支持通配符，其他的都不支持通配符，这个需要注意多重比较[[ condition1 &amp;&amp; condition2 ]] [[ condition1 || condition2 ]]对不同进制的数直接进行比较12345678910111213141516171819202122232425decimal=15octal=017 # = 15 (十进制)hex=0x0f # = 15 (十进制)if [ "$decimal" -eq "$octal" ]then echo "$decimal equals $octal"else echo "$decimal is not equal to $octal" # 15 不等于 017fi # 在单括号 [ ] 之间不会进行进制转换。if [[ "$decimal" -eq "$octal" ]]then echo "$decimal equals $octal" # 15 等于 017else echo "$decimal is not equal to $octal"fi # 在双括号 [[ ]] 之间会进行进制转换。if [[ "$decimal" -eq "$hex" ]]then echo "$decimal equals $hex" # 15 等于 0x0felse echo "$decimal is not equal to $hex"fi # 十六进制也可以进行转换。(())数值判断使用小于和大于符号，以及==用来测试是否相等，专为整数设计不仔细讲解，因为这些也可以使用上面提到的[ ]和[[ ]]进行较好的替代，后续想学习可以参考：文章一、文章二。if条件测试分支结构在学习test命令以及[ ]判断式过程中我们发现条件测试默认是不会返回任何信息的，如果想要进行操作或者返回信息就要使用&amp;&amp;或者||，这些其实和这里的if条件测试分支结构的作用的相同的，只是if条件测试分支结构可以支持的命令更加多和复杂，有利于大程序的编写。if条件测试分支结构工作原理：通过判断条件测试的退出状态，如果执行成功(命令退出状态为0)则执行then中的命令，否则(命令退出状态为非0)终止判断语句或者执行else或者执行下一层判断等。单层、简单条件判断式1234567Usage: if [ 条件判断式 ] then 当条件判断式成立时，可以进行的指令工作内容； fi 这里的条件判断式就是前面条件测试中使用的[]判断式多个表达式、多重判别前面在test命令中讲过关于使用多个表达式、多重判断的情况，在多个表达式之间使用-a表示and、-o表示or，示例如下：[ &quot;${yn}&quot; == &quot;Y&quot; -o &quot;${yn}&quot; == &quot;y&quot; ]如果想要使用多个括号将不同的表达式隔开可以使用&amp;&amp;和||:[ &quot;${yn}&quot; == &quot;Y&quot; ] || [ &quot;${yn}&quot; == &quot;y&quot; ]上面的多重判别实际是写成了一个判断式的形式，而如果 if 之后跟随一系列命令(使用;隔开)，则将计算列表中的最后一个命令：if false; true; then echo &quot;It&#39;s true.&quot;; fi 因为true在后，所以得到退出状态为0，输出结果It’s true.if true; false; then echo &quot;It&#39;s true.&quot;; fi 因为false在后，所以得到退出状态为非0，不输出结果双层判断式12345678Usage: # 一个条件判断，分成功进行与失败进行 （else） if [ 条件判断式 ] then 当条件判断式成立时，可以进行的指令工作内容； else 当条件判断式不成立时，可以进行的指令工作内容； fi多层、复杂判断式1234567891011Usage: # 多个条件判断 （if ... elif ... elif ... else） 分多种不同情况执行 if [ 条件判断式一 ] then 当条件判断式一成立时，可以进行的指令工作内容； elif [ 条件判断式二 ] then 当条件判断式二成立时，可以进行的指令工作内容； else 当条件判断式一与二均不成立时，可以进行的指令工作内容； fiif、elif后面需要使用then，而else后面就不用使用then，因为elif 也是个判断式，因此出现 elif 后面都要接 then 来处理！但是 else 已经是最后的没有成立的结果了， 所以 else 后面并没有 thenexit程序退出状态12345678910#!/bin/bashif [ $# -lt 1 ] then echo "Usage: $0 &lt;name&gt;" exit 1fiecho "Hello $1"exit 0在运行此脚本时，如果没有输入参数，则提示正确的使用方法，非正常退出(exit 1)；否则，打印输入的参数，程序正常退出(exit 0)。和任何命令连用这里首先再次说明一下if判断的原理：通过判断if后面语句的退出状态，如果执行成功(命令退出状态为0)则执行then中的命令，否则(命令退出状态为非0)终止判断语句或者执行else或者执行下一层判断等。这里将前面的判断条件测试的退出状态修改为了判断if后面语句的退出状态，原因是if可以与任何命令连用，因为后面命令执行肯定会有一个返回状态。最近想判断文件夹中是不是存在压缩文件gz，如果存在希望可以对其进行解压，自然而然这里就涉及到了一个判断语句，然而我按照常规的写法：123456if [[ -f ".gz" ]]then echo "yes"else echo "no"fi却不能得到正确的结果，不管是不是存在，返回的结果都是no，后来发现，除了使用[[]]可以进行~=的正则匹配之外，通配符在if中是不被允许的，所以只能尝试其他方法：123456if ls *.gz &gt;/dev/null 2&gt;&amp;1then echo "yes"else echo "no"fi使用上面的命令就可以得到正确的结果，因为如果存在压缩文件gz，ls命令的退出状态就是0，那么就执行then中的结果；如果不存在压缩文件，那么ls的退出状态就会非0，所以就会执行else中的命令，达到目的！参考链接鸟哥的linux私房菜The Linux Command Line 中文版高级Bash脚本编程指南中文版Linux Shell——流程控制条件测试操作与流程控制语句Shell 流程控制]]></content>
      <categories>
        <category>Linux</category>
        <category>shell编程</category>
      </categories>
      <tags>
        <tag>shell编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML块级标签和行内标签]]></title>
    <url>%2Fposts%2F8829.html</url>
    <content type="text"><![CDATA[这是一篇转载的文章，主要记录了HTML的块级标签和行内标签各自包括的内容块级标签标签描述&lt;address&gt;定义地址&lt;article&gt;定义文章&lt;aside&gt;定义页面内容之外的内容&lt;audio&gt;定义声音内容&lt;blockquote&gt;定义长的引用&lt;canvas&gt;定义图形&lt;caption&gt;定义表格标题&lt;dd&gt;定义定义列表中项目的描述&lt;div&gt;定义文档中的节&lt;dl&gt;定义定义列表&lt;dt&gt;定义定义列表中的项目&lt;details&gt;定义元素的细节&lt;fieldset&gt;定义围绕表单中元素的边框&lt;figcaption&gt;定义 figure 元素的标题&lt;figure&gt;定义媒介内容的分组，以及它们的标题&lt;footer&gt;定义 section 或 page 的页脚&lt;form&gt;定义供用户输入的 HTML 表单&lt;h1&gt; to &lt;h6&gt;定义 HTML 标题&lt;header&gt;定义 section 或 page 的页眉&lt;hr&gt;定义水平线&lt;legend&gt;定义 fieldset 元素的标题&lt;li&gt;定义列表的项目&lt;menu&gt;定义命令的列表或菜单&lt;meter&gt;定义预定义范围内的度量&lt;nav&gt;定义导航链接&lt;noframes&gt;定义针对不支持框架的用户的替代内容&lt;noscript&gt;定义针对不支持客户端脚本的用户的替代内容&lt;ol&gt;定义有序列表&lt;output&gt;定义输出的一些类型&lt;p&gt;定义段落&lt;pre&gt;定义预格式文本&lt;section&gt;定义 section&lt;table&gt;定义表格&lt;tbody&gt;定义表格中的主体内容&lt;td&gt;定义表格中的单元&lt;tfoot&gt;定义表格中的表注内容（脚注）&lt;th&gt;定义表格中的表头单元格&lt;thead&gt;定义表格中的表头内容&lt;time&gt;定义日期/时间&lt;tr&gt;定义表格中的行&lt;ul&gt;定义无序列表行内标签标签描述&lt;a&gt;定义锚&lt;abbr&gt;定义缩写&lt;acronym&gt;定义只取首字母的缩写&lt;b&gt;定义粗体字&lt;bdo&gt;定义文字方向&lt;big&gt;定义大号文本&lt;br&gt;定义简单的折行&lt;button&gt;定义按钮 (push button)&lt;cite&gt;定义引用(citation)&lt;code&gt;定义计算机代码文本&lt;command&gt;定义命令按钮&lt;dfn&gt;定义定义项目&lt;del&gt;定义被删除文本&lt;em&gt;定义强调文本&lt;embed&gt;定义外部交互内容或插件&lt;i&gt;定义斜体字&lt;img&gt;定义图像&lt;input&gt;定义输入控件&lt;kbd&gt;定义键盘文本&lt;label&gt;定义 input 元素的标注&lt;map&gt;定义图像映射&lt;mark&gt;定义有记号的文本&lt;objec&gt;定义内嵌对象&lt;progress&gt;定义任何类型的任务的进度&lt;q&gt;定义短的引用&lt;samp&gt;定义计算机代码样本&lt;select&gt;定义选择列表（下拉列表）&lt;small&gt;定义小号文本&lt;span&gt;定义文档中的节&lt;strong&gt;定义强调文本&lt;sub&gt;定义下标文本&lt;sup&gt;定义上标文本&lt;textarea&gt;定义多行的文本输入控件&lt;time&gt;定义日期/时间&lt;tt&gt;定义打字机文本&lt;var&gt;定义文本的变量部分&lt;video&gt;定义视频&lt;wbr&gt;定义可能的换行符参考链接关于两者之间的转换HTML中块级元素和行内元素的总结和区分，本文内容摘自此文章]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[转载其他博主博客]]></title>
    <url>%2Fposts%2F52283.html</url>
    <content type="text"><![CDATA[这篇博客整理了转载博客到自己搭建的博客的方法，主要包括转载CSDN博客、博客园博客、简书以及其他自建博客等转载CSDN博客博客页面右键，点击【检查】 点击检查后，页面右侧出现html代码，如下图： 找到article_content内容复制article_content内容在选中html的article_content代码处右键，点击【Copy】,再点击【Copy outerHTML】即可，至此，博客内容的html代码复制完成 新建markdown博客如果是转载到CSDN博客需要注意：使用markdown编辑器，CSDN博客默认的是html编辑器，在博客设置中修改成markdown编辑器，在html编辑器中是无法将html代码转换成相应博客内容如果是转载到自己搭建的博客，比如我的这个博客，需要注意：按照上述方法会得到很多的空格，这是因为直接使用html来编写markdown，只要存在换行(如标签换行)都会在最终生成的页面中得到一个空格，为了解决这个问题可以在整个article_content标签外加上escape标签即可，这个和插入html表格的处理是一样的HTML 区块标签间的 Markdown 格式语法将不会被处理，但 Markdown 语法在 HTML 行内标签间是有效的，具体的行内标签和区块标签包含的内容见这篇博客在手动更改html内容时需要注意：每个标题的id是不可以相同的，不然生成的目录会出问题，点击不能到达相应的标题(目录是根据id生成的)最后特别要注意的是，我们发表转载文章的时候一定要标注转载，尊重原创！！转载博客园博客将上述转载CSDN博客中article_content替换成data-note-content即可转载简书博客将上述转载CSDN博客中article_content替换成cnblogs_post_body即可转载其他自建博客将上述转载CSDN博客中article_content替换成post-body即可其他博客依据上述规律找到对应的文章主体内容，然后按照转载CSDN博客的方法进行处理即可参考链接CSDN怎么转载别人的博客]]></content>
      <categories>
        <category>折腾</category>
        <category>博客</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[diff-比较文件差异]]></title>
    <url>%2Fposts%2F56778.html</url>
    <content type="text"><![CDATA[这篇文章主要学习了使用diff命令对文件和目录进行比较，对文件比较时采用的是逐行进行比较；包括的参数有-r、-q、-i、-s、-b、-y、-W、-c、-C、-u和-U。diff简介diff命令能比较(单个)文件或者目录内容。如果指定比较的是文件，则只有当输入为文本文件时才有效，并以逐行的方式，比较文本文件的异同；如果指定比较的是目录，diff 命令会比较两个目录下名字相同但内容不同的文本文件，列出公共子目录和只在一个目录出现的文件和目录。这个和前面讲到的comm命令和cmp命令的不同之处在于：diff和comm命令都是以逐行的方式进行比较，而cmp是Compare two files byte by byte；同时diff命令可以比较单个文件，而comm和cmp都是针对的两个文件的比较，其中comm还需要文件是排过序的；diff命令还能用来对目录进行排序；感觉diff在比较两个文件或目录时是将两个文件当成了同一个文件修改前后的不同版本，通过diff可以知道新文件是在旧文件上进行了哪些操作得到的，得到的结果也更复杂。总结一下三个命令的适用情形：comm适合简单的比较，需要排序，逐行比较，用于比较的文件不是同一个文件的不同版本(新旧文件)，得到的结果简单清晰(文件求交、并、补等)，便于提取分析cmp可以应用于对两个文件逐字节的比较，可以跳过一定的字节(个人感觉这个实用性不是很强，不同系统编码方式字节也有所不同)diff适合逐行比较文件修改前后的区别(类似版本控制，新文件是旧文件经过什么操作得到的)，也可以对目录进行比较，但是输出结果较为复杂，还可以输出上下文关系的信息diff命令用法diff命令格式12Usage: diff [OPTION]... FILESCompare files line by linediff options说明由于diff命令的参数较多，这里就不一一列举，详细请查看帮助文档，比较常用的请看用法实例。diff用法实例测试文件cat test1.txtHi,Hello,How are you?I am fine,Thank you.cat test2.txtHello,Hi,How are you?I am fine.使用默认方式比较文件不同比较两个文件diff test1.txt test2.txt1d0&lt; Hi,2a2> Hi,4,5c4&lt; I am fine,&lt; Thank you.-–> I am fine.结果解读：可以将test1.txt当做旧文件，test2.txt当做新文件，通过比较看旧文件经过什么样的改变可以生成新文件1d0这一行意味着旧文件的第一行应该被删除(d)以使两个文件的第一行同步，旧文件中需要被删除的行以&lt;标记2a2行意味着新文件中的第二行应该加到旧文件的第二行后，要添加的行显示在输出的下一行用&gt;标记4,5c4这一行意味着在旧文件中的4到5行现在已被改变并且需要用新文件中的第4行代替，代替和删除的行分别用&gt;和&lt;表示，---用于隔开先后进行的不同操作，如先删除旧文件中的4到5行，然后再用新文件中的第4行代替，这两步之间使用---分割diff命令的第一个参数被视为旧文件而第二个参数被视为新文件，通过比较看旧文件经过什么样的改变可以生成新文件像1d0、2a2、4,5c4这种表达式可以用语法解码为 [旧文件的行号或者行的范围][行为][新文件的行号或者行的范围]，这里的行为可以是追加(a，代表addition)、删除(d，代表deletion)或者改变替换(c，代表change)&lt;代表删除的行，而&gt;代表添加的行，---用于改变替换(c，代表change)中分割先后的操作比较两个目录ls new_dir/comm_dir new_new_dir test1.txt test2.txt test3.txtls new_dir/new_new_dir/ and ls new_dir/comm_dir/test1.txt test2.txt test3.txtls orig_dir/comm_dir orig_orig_dir test1.txt test2.txt test4.txtls orig_dir/orig_orig_dir/ and ls orig_dir/comm_dir/test1.txt test2.txt test4.txtdiff orig_dir/ new_dir/Common subdirectories: new_dir/comm_dir and orig_dir/comm_dir # 两个目录共有的子目录，不会比较子目录中的文件信息Only in new_dir/: new_new_dir # 只出现在new_dir中的目录，不会比较子目录中的文件信息Only in orig_dir/: orig_orig_dir # 只出现在orig_dir中的目录，不会比较子目录中的文件信息diff orig_dir/test1.txt new_dir/test1.txt # new_dir和orig_dir共有的同名文件内容的差异0a1 # 具体的差异信息> asdfaf # 具体的差异信息Only in new_dir/: test3.txt # 只出现在new_dir中的文件Only in orig_dir/: test4.txt # 只出现在orig_dir中的文件比较两个目录可以找到每个目录共有的、独有的文件和目录信息；对于共有的子目录，不会继续比较子目录中的信息；对于共有的文件，会得出文件的差异信息-r-比较子目录中的文件上述对目录进行比较时默认不会比较子目录中的文件信息，使用-r参数可以对这些文件进行比较：diff -r orig_dir/ new_dir/diff -r orig_dir/comm_dir/test1.txt new_dir/comm_dir/test1.txt0a1> asdfafOnly in new_dir/comm_dir: test3.txtOnly in orig_dir/comm_dir: test4.txtOnly in new_dir/: new_new_dirOnly in orig_dir/: orig_orig_dirdiff -r orig_dir/test1.txt new_dir/test1.txt0a1> asdfafOnly in new_dir/: test3.txtOnly in orig_dir/: test4.txt-q-只显示有无差异默认情况下如果文件存在差异会显示差异信息，使用-q参数只会显示有无差异不会显示具体的差异信息:diff -q test1.txt test2.txtFiles test1.txt and test2.txt differ-i-忽略文件中文本大小写diff file1.txt file2.txt1c1&lt; hi-–> HI默认情况下是会区分文件中文本信息大小写的diff -i file1.txt file2.txt使用了-i参数没有输出内容，因为忽略大小写之后文件中文本信息是相同的-s-在文件内容相同条件下报告信息上面使用了-i参数得到了文件内容是相同的，这时默认就不会输出信息，如果想要在文件内容相同时报告文件内容是相同的，需要使用-s参数diff -is file1.txt file2.txtFiles file1.txt and file2.txt are identical-b-忽略文本中的空格cat file1Hi, how are you?cat file2Hi, how are you?diff file1 file21c1&lt; Hi, how are you?-–> Hi, how are you?上述文件中的区别仅仅是file2多了一个空格，但是使用diff命令后仍然会输出不同，而常规情形下，这应该被认为是相同的，这时就可以使用-b参数diff -bs file1 file2Files file1 and file2 are identical-y-以并列的方式显示文件的异同之处diff -y test1.txt test2.txtHi, &lt;Hello, Hello,&gt; Hi,How are you? How are you?I am fine, | I am fine.Thank you. &lt;|：表示前后2个文件内容存在差异&gt;：表示第一个文件删除的行&lt;：表示第二个文件增加的行-W-在使用-y参数时，指定栏宽如果指定的栏宽太窄，会显示每行的部分信息：diff -y -W 10 test1.txt test2.txtHi &lt;He He> HiHo HoI | ITh &lt;-c-上下文格式输出显示不同行的信息时一同显示上下文信息，默认是存在不同的上下3行：diff -c test1.txt test2.txt*** test1.txt 2019-03-14 15:26:48.960323475 +0800— test2.txt 2019-03-14 15:27:07.411322620 +0800* 1,5 **- Hi,Hello,How are you?! I am fine,! Thank you.— 1,4 —-Hello,+ Hi,How are you?! I am fine.***表示变动前的文件，---表示变动后的文件*** 1,5 ****表示变动前文件的1到5行，--- 1,4 ----表示变动后文件的1到4行文件内容的每一行最前面，还有一个标记位如果为空，表示该行无变化如果是感叹号（!），表示该行有改动如果是减号（-），表示该行被删除如果是加号（+），表示该行为新增-C NUM-指定具体是上下文行数这个功能和上面的-c是相同的，只是-c只能是默认的上下3行，而-C num可以指定具体的上下文行数diff -C 3 test1.txt test2.txt 等同于 diff -c test1.txt test2.txt*** test1.txt 2019-03-14 15:26:48.960323475 +0800— test2.txt 2019-03-14 15:27:07.411322620 +0800* 1,5 **- Hi,Hello,How are you?! I am fine,! Thank you.— 1,4 —-Hello,+ Hi,How are you?! I am fine.-u-合并格式输出如果两个文件相似度很高，那么上下文格式的diff，将显示大量重复的内容，很浪费空间，这个时候使用合并格式输出将f1和f2的上下文(默认3行)合并在一起显示：diff -u test1.txt test2.txt— test1.txt 2019-03-14 15:26:48.960323475 +0800+++ test2.txt 2019-03-14 15:27:07.411322620 +0800@@ -1,5 +1,4 @@-Hi,Hello,+Hi,How are you?-I am fine,-Thank you.+I am fine.---表示变动前的文件，+++表示变动后的文件变动的位置用两个@作为起首和结束，-1,5表示第一个文件的1到5行，+1,4表示第二个文件的1到4行每一行最前面的标志位，空表示无变动，减号表示第一个文件删除的行，加号表示第二个文件新增的行-U NUM-指定合并格式上下文的行数这个功能和上面的-u是相同的，只是-u只能是默认的上下3行，而-U num可以指定具体的上下文行数结合patch进行内容更新这个暂时应该用不到，所以就不学习了，后期如果使用的话再进行学习补充，后面列出的参考链接有对应的示例。注意事项diff的几种输出模式：并列输出(-y)、上下文格式输出(-c)、合并格式输出(-u)之间的不兼容的，只能使用其中一种，参数不能混用参考链接实例较多举例说明Linux diff 命令参数讲解清晰的讲解文件比较 cmp，diff，patch]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cmp-比较文件差异]]></title>
    <url>%2Fposts%2F62860.html</url>
    <content type="text"><![CDATA[这篇文章主要学习了cmp对两个文件进行比较，比较时是逐字节进行的；包括的参数：-b、-i、-i、-l、-n、-s以及显示运行进度。cmp简介cmp命令用于比较两个文件是否有差异；当相互比较的两个文件完全一样时，则该命令不会有输出结果；若发现有所差异，默认会标示出第一个不同之处的字符和列数编号若不指定任何文件名称或是所给予的文件名为-，则cmp指令会从标准输入读取数据这个和前面讲到的comm命令的不同之处在于：comm命令对已排序的文件进行比较并将结果分为3列，便于提取文件比较的结果，如得到两个文件的差集、交集、并集和对称差集等，而cmp命令侧重于比较两个文件差异，大多用于比较同一个文件修改之后和修改之前的差异，并且cmp比较文件不需要进行排序；cmp命令比较文件是byte by byte，而comm命令比较文件是line by line。cmp命令用法cmp命令格式12345Usage: cmp [OPTION] FILE1 [FILE2 [SKIP1 [SKIP2]]]# The optional SKIP1 and SKIP2 specify the number of bytes to skip# at the beginning of each file (zero by default).Compare two files byte by bytecmp options说明table th:first-of-type{width:15%}table th:nth-of-type(2){width:25%}table th:nth-of-type(3){width:60%}参数完整参数说明-b–print-bytes除了标明差异处所在之外，一并显示该字符所对应字符和字节值-i SKIP–ignore-initial=SKIP跳过一定的字节数(不包括SKIP)-i SKIP1:SKIP2–ignore-initial=SKIP1:SKIP2从两个文件中跳过不同的字节数，SKIP1是FILE1跳过的字节数，SKIP为FILE2跳过的字节数-l–verbose显示所有不同字节的字节位置（和值）-n–bytes=LIMIT限制要比较的字节数(包括LIMIT)-s–quiet, –silent抑制正常生成的输出，只返回文件是否相同的退出码(可以通过$?得到)cmp -i选项可选单位简写全称说明kBkilobytes1000Kkibibytes1024MBmegabytes1,000,000Mmebibytes1,048,576GBgigabytes1,000,000,000Ggibibytes1,073,741,824cmp用法实例测试文件cat test1.txtAbsncn 50Asldssja 60Jslkadjls 85cat test2.txtAbsncn 50AsldssjE 62Jslkadjls 85使用默认方式比较文件不同默认会告诉在第几行的第几个字节出现不同：cmp test1.txt test2.txttest1.txt test2.txt differ: byte 18, line 2注意这里的byte 18来源：系统默认编码方式为UTF-8(查看方式见这篇文章)，1个英文字符 = 1个字节；换行符占一个字节；空格占一个字节；第二行的结果存在差异的话，字符会从第一行的第一个开始算起，叠加的，不是单独每一行算-b-显示不同的字节及字节值cmp -b test1.txt test2.txttest1.txt test2.txt differ: byte 18, line 2 is 141 a 105 E只会显示第一个，不会显示所有的，具体是字母a和E不同，字节值分别为141和105(这个没算。。。)-i-跳过指定的字节cmp -b -i 18 test1.txt test2.txttest1.txt test2.txt differ: byte 3, line 1 is 60 0 62 2跳过前18个之后开始的第3个字节，0和2不同注意这个是不包括指定跳过的那个字节位置，比如这里的字节数为18的位置-i-从两个文件跳过不同数量的字节cmp -b -i 18:18 test1.txt test2.txttest1.txt test2.txt differ: byte 3, line 1 is 60 0 62 218:18：第一个文件跳过的字节数为18，第二个文件跳过的字节数也是18-l-显示所有不同字节的字节位置（和值）cmp -l test1.txt test2.txt18 141 10521 60 62输出结果：第一列（如上所示）表示不同字节的位置（字节数）第二列表示第一个文件中不同字节的字节值第三列表示第二个文件中不同字节的字节值前面的-b等参数只会显示第一个不同的字节位置和值，这里会显示所有的字节数字和值-n-限制要比较的字节数最多只比较的字符数：cmp -n 17 test1.txt test2.txtcmp -n 18 test1.txt test2.txttest1.txt test2.txt differ: byte 18, line 2如果和-i参数联合使用：cmp -b -l -i 3 -n 18 test1.txt test2.txt15 141 a 105 E18 60 0 62 2注意这里相比于没有设置跳过字节会多出一行差异的结果，表明-n是相对字节位置，而不是绝对的字节位置和不使用-i的对比：cmp -b -l -n 18 test1.txt test2.txt18 141 a 105 E注意这里是包括指定跳过的那个字节位置，比如这里的字节数为18的位置，因为包括了所以才会输出在byte18位置存在区别-n指定的是相对字节位置，而不是绝对字节位置，比如上面跳过前3个字符之后出现差异的就成了第15个字节位置的，同时因为-n设置为18向后推移3个字节，就会出现了第二个不同的位置，而如果不设置-i参数就不会得到第二个不同的位置-s-抑制正常生成的输出，只返回反映文件是否相同的退出码cmp -s -b test1.txt test2.txt没有输出结果，也就是原本需要输出的在哪一行存在差异都不会输出来了，然后查看命令的退出码：echo $?得到的结果是1，表明文件是不相同的，这样可得到文件是否相同的信息，但是并不关注具体的差异在什么地方而如果不加-s就会正常输出：cmp -b test1.txt test2.txttest1.txt test2.txt differ: byte 18, line 2 is 141 a 105 E同时不加-s查看查看命令的退出码：echo $?得到的结果和加了-s一样都返回的是1在脚本中使用cmp命令时，此选项可以会派上用场。 例如，根据文件是否相同(通过访问命令的退出代码可以知道)来进行下一步的操作，这个时候我们可能并不关心具体文件的差异在什么地方，而是关心文件是不是有差异这个整体的结果显示运行进度这个需要结合pv命令，安装和使用pv命令之后再进行学习，参考参考链接的前两个参考链接Linux cmp command tutorial for beginners （7 examples）Linux初学者的cmp命令教程（7个例子）Linux cmp command-关于-i参数单位的问题很好cmp - Unix, Linux Command]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[journey]]></title>
    <url>%2Fposts%2F34270.html</url>
    <content type="text"><![CDATA[这里写摘要，显示更好看景点磁器口吃的：陈麻花-推荐陈昌银或者夏麻花、张老汉手工酸辣粉（磁器口必吃之一）有很多文艺的小咖啡馆或者书店磁器口的主街人满为患，商业化严重，更建议去侧街，也是咖啡馆一条街，客量少，店面装饰都很有文艺味儿，是来磁器口的正确打开方式。（在此安利一家咖啡馆——懒鱼时光馆，上图即是该咖啡馆，是一家有故事的咖啡馆）洪崖洞晚上去，白天不好看，晚上有灯光主要是建筑构造和风貌南山一棵树观景台可以将重庆所有的美景尽收眼底！建议夜晚去，重庆的夜景很美很美很美！门票：门票30，学生证15吃的：泉水鸡、枇杷园（火锅）十八梯电影《从你的全世界路过》十八梯是重庆渝中半岛的一条街，从重庆城的上半城（山顶）通到下半城（山脚），全部由石阶铺成，把山顶的繁华商业区和山下江边的老城区连起来。拆迁了朝天门两江游重庆很出名的两江交汇：长江与嘉陵江夜景长江索道到达对岸后不用着急回来可以在那边拍拍照，然后再返回来皇冠大扶梯亚洲第二长的一级提升坡地大扶梯这个扶梯不用刻意去，如果方便可以去坐坐，其实就是一个长长的扶梯，但是因为有坡度而且特别长所以很炫酷！中山四路历史遗迹很多，除了中国民主党派博物馆的特园外，此地还有桂园、周公馆、戴公馆、张骧公馆、国民政府总统府旧址等解放碑解放碑是重庆的标志，特别是圣诞节和跨年的时候，大家会不约而同地去解放碑一同度过！场面壮观到每年都会提前进行封路。解放碑那有一条好吃街，可以去吃吃～李串串两江影视城民国街再现了百年老重庆风土人情影视城里重现了当时的解放碑、磁器口、朝天门、十八梯，特别有意思当地也可以租民国服装小吃重庆小面重庆火锅大龙火锅。以超辣闻名，吃这家店的人超级多，中午都得排很久的队串串串串推荐小郡肝、李记、怒火八零等等酸辣粉/凉粉/冰粉凉虾/凉糕莱得快的杂酱酸辣粉阿坤的杂酱酸辣粉、苕皮、海带，有点辣。但是阿坤里面有甜品所以可以也点一份甜品，防止被辣着，推荐它们的双皮奶。好又来酸辣粉（口碑店家）、手工酸辣粉（视觉和味觉两不误）麻辣鱼/酸菜鱼/尖椒兔大渡口，店名是：霸王兔夜啤酒/万州烤鱼/烧烤奶制品重庆本土的天友，以及后发的奶牛梦工厂参考路线两天]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>旅游</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[comm-文件比较，文本文件的交集、差集与求差]]></title>
    <url>%2Fposts%2F39582.html</url>
    <content type="text"><![CDATA[这篇文章学习了使用comm命令对两个文件内容进行比较，注意文件需要排序，相比于其他比较文件的命令，comm可以将文件内容不同的分列显示，便于提取(文件求交、并、差、对称差等)所需要的内容，另外两个文件比较命令包括cmp、diff。comm用法comm命令会一行行(line by line)地比较两个已排序文件的差异，并将其结果显示出来，如果没有指定任何参数，则会把结果分成3行显示：第1行仅是在第1个文件中出现过的列第2行是仅在第2个文件中出现过的列第3行则是在第1与第2个文件里都出现过的列。若给予的文件名称为-，则comm命令会从标准输入设备读取数据comm命令格式12Usage: comm [OPTION] FILE1 FILE2comm options说明table th:first-of-type{width:20%}table th:nth-of-type(2){width:80%}参数说明-1不显示第1列（即不显示只在file1中找到的行）-2不显示第2列（即不显示只在file2中找到的行）-3不显示第3列（即不显示在两个文件中都找到的行）–check-order判断所有输入文件是不是已经排好序–nocheck-order不判断所有输入文件是不是已经排好序–output-delimiter=STR指定输出结果的分隔符comm用法实例测试文件cat a.txtaaabbbccc111dddeee222cat b.txtbbbcccaaahhhtttjjj注意上面两个文件都没有排序，看看comm对没排序文件的处理使用默认方式对文本进行比较comm a.txt b.txtaaabbbccccomm: file 1 is not in sorted ordercomm: file 2 is not in sorted order111aaadddeee222hhhtttjjj从上面可以看出，没排序comm命令会爆出问题，但是仍然会运行得到结果；发现因为没有排序的原因，第二个文件的aaa在第一个文件中也存在但是却被当成了file2独有的。总的来说就是如果没排序，comm命令会爆出问题但不会停止运行，并且结果会存在问题，正常结果如下：sort -k 1,1 a.txt |comm - &lt;(sort -k 1,1 b.txt)111222aaabbbcccdddeeehhhjjjttt可以看出默认情况会输出三列，第一列是第一个文件独有的内容，第二列是第二个文件独有的内容，第三列是第三个文件独有的内容，各列是以制表符\t作为定界符，可以通过对定界符-制表符\t的操作来达到相应的目的。由于参数较为简单，这里就不单独列出每个参数单独的用法的示例，主要给出参数组合用法以及和定界符组合使用的示例如下：集合操作含义及对应的参数组合A∩B文件交集，-12A∪B文件的并集，将输出整合为一列，去掉定界符\tA-B差集，-23B-A差集，-13A∆B对称差集，并集减去交集，也就是去除文件中相同的部分，需要使用-3以及将剩下两列整合为一列-12-A∩B-文件交集默认输出结果的第三列就是两个文件共有的部分：sort -k 1,1 a.txt |comm -12 - &lt;(sort -k 1,1 b.txt)aaabbbccc定界符\t-A∪B-文件的并集并集就是将三列输出结果合并：sort -k 1,1 a.txt |comm - &lt;(sort -k 1,1 b.txt) |sed &#39;s/\t//g&#39;111222aaabbbcccdddeeehhhjjjttt-23-A-B-差集差集就是在A中但是不在B中的部分，去掉第三列(A、B共有的)以及第二列B独有的：sort -k 1,1 a.txt |comm -23 - &lt;(sort -k 1,1 b.txt)111222dddeee-12-B-A-差集差集就是在B中但是不在A中的部分，去掉第三列(A、B共有的)以及第一列A独有的：sort -k 1,1 a.txt |comm -13 - &lt;(sort -k 1,1 b.txt)hhhjjjttt-3+定界符\t-A∆B-对称差集对称差集就是两个文件独有的内容的并集：sort -k 1,1 a.txt |comm -3 - &lt;(sort -k 1,1 b.txt) |sed &#39;s/\t//g&#39;111222dddeeehhhjjjttt多列文件的处理多列文件处理会将一整行当成一个元素进行比较，来列出各个文件独有的、文件共有的信息，具体的每列代表的意思和单列文件相同，注意如果文件内容是使用\t作为分隔符，产生的结果输出会重叠cat c.txtaaa 111bbb 222cat d.txtaaa 222bbb 222ccc 333comm c.txt d.txtaaa 111aaa 222bbb 222ccc 333文件内容是使用\t作为分隔符，产生的结果输出会重叠：sed &#39;s/ /\t/&#39; c.txt |comm - &lt;(sed &#39;s/ /\t/&#39; d.txt)aaa 111aaa 222bbb 222ccc 333参考链接comm命令Linux comm命令简明Linux命令行笔记：comm]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[anaconda安装多版本python及常用命令]]></title>
    <url>%2Fposts%2F34297.html</url>
    <content type="text"><![CDATA[anaconda作为python的包管理工具(现在已经不仅仅是python的，R的包以及其他很多包都有)非常使用和强大，这里主要学习了使用anaconda创建python2和python3环境，并在两者之间进行切换，最后还给出了anaconda的常用命令，后续还可以补充!前言原本是通过anaconda给电脑安装的python3，但是今天在从github上下载使用一个package时候报错：SyntaxError: Missing parentheses in call to ‘print’. Did you mean print(‘File does not exist: %s’ % filepath)?后来发现这个是因为python版本的问题，所以就需要重新再安装一个python2的环境创建环境这个本来可以使用简单地打开anaconda navigator图形界面进行creat环境即可，但是秉承着想对anaconda进行学习的态度，这里主要使用命令行的形式。显示所有环境名字和路径创建新环境之前先看看目前的电脑有哪些环境：1conda info --envs# conda environments:#base * C:\Users\14910\Anaconda3rstudio C:\Users\14910\Anaconda3\envs\rstudio发现电脑只有一个原装的base环境，也就是python3的环境以及我自己安装的rstudio环境，同时需要注意上面的*表明是当前使用的环境！创建环境并指定环境名称和python版本这一步是使用conda create创建环境，同时指定环境的名称为pyenv2_7，使用的python版本为python=2.7：1conda create --name pyenv2_7 python=2.7再次显示所有环境名字和路径创建新环境再次查看现在所有的环境名称和对应的路径：1conda info --envs发现已经出现了新建的环境：# conda environments:#base * C:\Users\14910\Anaconda3pyenv2_7 C:\Users\14910\Anaconda3\envs\pyenv2_7rstudio C:\Users\14910\Anaconda3\envs\rstudio由于只是创建了环境，还没有激活，所以当前使用的环境(*标记的)还是base环境，新建的环境需要激活才能够使用激活环境为了能够使用新创建的环境还需要激活：1activate pyenv2_7为了验证环境是不是已经成功应用，检查python版本：python –versionPython 2.7.15 :: Anaconda, Inc.发现环境已经安装成功退出环境使用完成之后推出新建的环境，回到base环境：1conda deactivate注意conda deactivate后面不需要跟退出的环境名，直接就退出当前环境，退出环境之后直接就进入了base环境。anaconda 常用命令activate // 切换到base环境activate learn // 切换到learn环境conda deactivate // 退出当前环境conda create -n learn python=3 // 创建一个名为learn的环境并指定python版本为3(的最新版本)conda env list (conda env –info) // 列出conda管理的所有环境conda list // 列出当前环境的所有包conda install requests (pip install requests) // 安装requests包conda remove requests (pip uninstall requests) // 卸载requets包conda update requests // 更新requests包conda remove -n learn –all // 删除learn环境及下属所有包conda env export &gt; environment.yaml // 导出当前环境的包信息conda env create -f environment.yaml // 用配置文件创建新的虚拟环境参考链接ananconda创建新环境，python 2.7、3.5共存，pycharm 使用conda新环境，win10、linux下通用利用Anaconda完美解决Python 2与python 3的共存问题常见问题UnavailableInvalidChannel问题表现：解决办法：1234567891011121314151617# 可以试试这个办法# 依次添加后面添加的channels会移到最上面conda config --add channels defaultsconda config --add channels biocondaconda config --add channels conda-forge# 也可以直接修改.condarc文件conda config --show-source==&gt; /root/.condarc &lt;==channels: - defaults# 直接添加conda-forge和biocondavim /root/.condarc channels: - conda-forge - bioconda - defaults参考链接：Biocondaconda-forge退出默认的base环境默认情况下，安装anaconda之后，每次登陆服务器都会自动激活conda的base环境，为了不让这种默认的设置生效可以使用如下命令来关闭：12# 关闭自动激活base环境conda config --set auto_activate_base false参考链接：How do I prevent Conda from activating the base environment by default?]]></content>
      <categories>
        <category>Python</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[未完成-使用Travis CI自动部署github项目]]></title>
    <url>%2Fposts%2F62916.html</url>
    <content type="text"><![CDATA[linux系统，换电脑之后再写！开始于二级标题参考链接Travis CI 自动化部署博客持续集成服务 Travis CI 教程Travis CI用来持续集成你的项目使用travis-ci自动部署github上的项目]]></content>
      <categories>
        <category>折腾</category>
        <category>博客</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[管理多个SSH公钥]]></title>
    <url>%2Fposts%2F51573.html</url>
    <content type="text"><![CDATA[项目托管可能需要在多个平台上进行，这就需要设置多个SSH公钥来简化代码提交步骤，这里学习总结了同时使用多个SSH公钥提交代码至不同平台（coding pages、github）的方法SSH key介绍SSH key提供了一种与GitHub或其他平台通信的方式，通过这种方式，能够在不输入密码的情况下，将GitHub或其他平台作为自己的remote端服务器，进行版本控制。需要注意的是不同平台的SSH key各不相同，所以为了能在各个平台上方便地使用git进行版本控制，就需要设置多个SSH key。使用SSH key的步骤：在客户端生成SSH key（密钥对：公钥-&gt;锁头和私钥-&gt;钥匙，利用了公钥和私钥实现数据加密和解密）在服务端的配置文件中加入你的公钥。（比如我们需要再GitHub中粘贴你的公钥）具体原理：用户将自己的公钥储存在远程主机上，登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回远程主机，远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录，不再要求密码。生成SSH key默认情况下，使用ssh-keygen生成会在C:\Users\user\.ssh目录下生成SSH key(id_rsa和id_rsa.pub(公钥))，为了使生成了SSH key互不干扰，所以需要使用-f参数进行设置生成了SSH key名称，不然可能会覆盖。在git bash中输入：1234567891011121314ssh-keygen -t rsa -C "YOUR_EMAIL@YOUREMAIL.COM" -f ~/.ssh/keyname(eg:github)ssh-keygen -t rsa -C "YOUR_EMAIL@YOUREMAIL.COM" -f ~/.ssh/coding_pages# 参数说明-t：指定要创建的密钥类型，默认是 rsa ，可以省略-C：添加注释，比如邮箱；-f：指定用来保存密钥的文件名；-b：指定密钥长度；-e：读取openssh的私钥或者公钥文件；-i：读取未加密的ssh-v2兼容的私钥/公钥文件，然后在标准输出设备上显示openssh兼容的私钥/公钥；-l：显示公钥文件的指纹数据；-N：提供一个新密语；-P：提供（旧）密语；-q：静默模式；上述命令输入后，会出现如下提示：12Generating public/private rsa key pair.# Enter file in which to save the key (/c/Users/you/.ssh/id_rsa): [Press enter]可以不输入文件名，使用默认文件名（推荐），那么就会生成 github 和 github.pub 两个秘钥文件；接着又会提示你输入两次密码（该密码是你push文件的时候要输入的密码，而不是github管理者的密码）；也可以不输入密码，直接按回车，那么push的时候就不需要输入密码，直接提交到github上了；将 github.pub 文件的内容添加到github上面的ssh key以上是生成一个的过程，生成另一个的过程也是相同的操作。添加生成的SSH将上述得到的公钥(以pub结尾的文件内容复制到平台相应的ssh key添加部位)：修改配置文件在 C:\Users\user\.ssh 目录下新建一个config文件，并添加如下内容：1234567891011121314151617# gitlabHost 公司github的地址 如：github.comHostName 公司github的地址 如：github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/github#githubHost github.com HostName github.com PreferredAuthentications publickey IdentityFile ~/.ssh/github#githubHost git.dev.tencent.com HostName git.dev.tencent.com PreferredAuthentications publickey IdentityFile ~/.ssh/coding_pages上述host地址的得到可以通过点击平台任意一个项目的clone and download看到，冒号:前面的就是host地址了验证SSH key是否添加成功12345# githubssh -T git@github.com# coding pagesssh -T git@git.dev.tencent.com输出结果：Hi showteeth! You’ve successfully authenticated, but GitHub does not provide shell access.Coding 提示: Hello showteeth, You’ve connected to Coding.net via SSH. This is a personal key.showteeth，你好，你已经通过 SSH 协议认证 Coding.net 服务，这是一个个人公钥到这里留完成了管理多个SSH公钥的步骤，接下来就可以不用输入密码地将代码托管到相应的平台上了!参考链接如何同时使用多个SSH公钥提交代码至不同平台管理多个SSH公钥密钥同一台电脑关于多个SSH KEY管理]]></content>
      <categories>
        <category>其他内容学习</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PDF转HTML-pdf2htmlex]]></title>
    <url>%2Fposts%2F40996.html</url>
    <content type="text"><![CDATA[pdf2htmlex是一款将pdf文件转换为html文件的工具，在github上有接近8000个star！这里主要介绍了其安装和使用方法，安装在windows下是使用了docker。安装windows下安装由于电脑是windows系统，所以只能按照这里给定的教程进行安装，无奈尝试了很多次，最终都以失败告终，都有点想放弃使用这个工具了，但是后来尝试了其他工具如pdf-to-html，但是效果很差，出来的效果和原本的pdf差很多，所以还是放弃了。最近忽然发现应该可以使用docker进行安装，所以尝试使用docker，接下来就是安装和使用docker：注册docker账号然后下载安装docker，这里注意如果电脑上安装了360会提示发现黑客新建用户帐号，建议阻止，鉴于360的一贯行为以及阻止后不能顺利安装，我选择了允许操作安装完成之后会注销和重启电脑，这个按照提示操作即可最后需要注意的是运行docker是在命令行形式下运行，而不是直接打开桌面的快捷方式docker安装使用docker安装pdf2htmlex，可以参考官方给出的教程：1docker pull bwits/pdf2htmlex-alpine输入上述命令后发现错误：1Error response from daemon: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)上网搜了一下，发现这个错误是因为网络原因导致无法拉取镜像，解决方法：使用国内的Docker仓库daocloud：进入daocloud关于docker加速器的网站，找到配置 Docker 加速器下对应的操作系统，因为我使用的windows系统，所以选择windows系统下的http://f1361db2.m.daocloud.io将上述所得到的的地址写入docker-&gt;setting-&gt;daemon-&gt;registry mirrors中，然后apply，docker会提示restart：上述操作完成之后重新执行命令，发现下载速度飞快~~~1docker pull bwits/pdf2htmlex-alpine使用通过docker命令详细的使用参考工具的github，这里我只尝试较为简单的：1docker run -ti --rm -v D:/pdf2html:/pdf bwits/pdf2htmlex pdf2htmlEX --zoom 1.8 resume.pdf用到的docker参数说明：-v：挂载宿主机目录，~/pdf对应于C:\Users\user\pdf，/pdf的容器的目录，在容器启动后，容器内会自动创建/pdf目录，也就是冒号:前面的目录是宿主机目录，后面的目录是容器内目录。注意使用时docker会提示需要使用文件权限，如果宿主机目录放在C盘，还要输入电脑密码--rm：默认情况下，每个container在退出时，它的文件系统也会保存下来，该参数可以让docker在container结束时自动清理其所产生的数据-ti：以交互模式启动一个容器创建命令调用别名因为使用的docker安装，每次调用可能全长命令比较麻烦，所以这里使用alias创建命令别名-pdf2htmlEX：12# 自己修改挂载目录alias pdf2htmlEX="docker run -ti --rm -v D:/pdf2html:/pdf bwits/pdf2htmlex pdf2htmlEX"这里一直没有成功不知道是为什么，总是显示文件名、目录名或卷标语法不正确。，但我直接使用命令不使用alias的方式却能正常使用，所以就没有继续使用这个系统自带的cmd是不支持alias的，我这里使用的是cmder，很强大的命令行工具，关于如何在windows下配置这个工具，可以参考博客中关于配置cmder的文章]]></content>
      <categories>
        <category>折腾</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>pdf2htmlex</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[coding_pages和mkdocs使用]]></title>
    <url>%2Fposts%2F54578.html</url>
    <content type="text"><![CDATA[coding pages和mkdocs使用简介注册coding pages前往其官网，常规的注册方法即可关于会员：免费升级好像升级之前不可以创建项目，如果有项目需要转让或者删除，具体操作步骤参考文章创建项目填写项目标识，项目标识在最后创建完pages之后就会显示为username.coding.me/项目标识/项目名称填写：username.coding.me，相当于 github 上面的 name.github.io创建完成即进入项目，选择代码下的代码浏览，创建index.html页面(注意名字一定要叫 index.html)，随意写一段话：12345678&lt;html&gt; &lt;head&gt; &lt;title&gt;My Coding Pages&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Hello Coding!&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt;然后点击左侧代码下的 Pages 服务，选择静态 Pages 服务，一键创建pages静态 Coding Pages 允许的部署分支来源为master 分支和coding-pages 分支，默认部署来源是master 分支，用户可在设置(右上角)里更改部署来源（实测发现只有master分支）。部署成功后后可通过&lt;user_name&gt;.coding.me／&lt;project_name&gt;形式的 URL 访问静态 Pages如果需要自定义域名，这个也在pages服务中的设置(右上角)中进行设置结合mkdocs安装相关packages12345# 安装mkdocspip install mkdocs# 安装主题pip install mkdocs-material常规用法：12345678# 创建新项目mkdocs new my-project# 启动内建服务器mkdocs serve# 站点生成，创建了一个 site 新目录mkdocs build修改配置12345678910111213141516171819202122232425262728293031# 修改主题和头像theme: name: material favicon: '/dark_logo_16x16.jpg'# 添加页面nav:- 主页 : index.md- 软件 : about.md- 项目 : about.md- 关于 : about.md# 支持中文搜索，虽然search功能(lunr.js)暂不直接支持中文，但测试发现设置为日语后，中文和英文搜索都可以使用extra: search: language: 'jp'# 添加扩展markdown_extensions: - admonition - codehilite: guess_lang: false linenums: false ......# 自定义的CSS和JSextra_javascript: - 'js/extra.js' - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML'extra_css: - 'css/extra.css'上传到coding pages将coding pages项目clone到本地：12# 这里本想使用ssh的链接，但是失败，提示repo不存在，但是使用https的却可以成功，需要再看看问题git clone https://git.dev.tencent.com/showteeth/project.git bio_projects将原本mkdoc目录下的文件拷进这个目录部署到coding pages，详细参考官方教程自动将相应内容推送到项目的 master 分支上，默认会部署在 gh-pages 分支上，而我的账户好像只能部署在master分支上，所以只能修改分支12mkdocs gh-deploy -b master输入链接即可访问最后吐槽一句：coding pages真的好慢好慢！！！！参考链接mkdocs的官方网站mkdocs的githubmkdocs主题material的相关材料（拓展、代码高亮）readthedocs的官方网站（介绍的比较简答，具体实施还是需要看mkdocs的网站说明）readthedocs托管文档支持的markdown语法基于mkdocs-material搭建个人静态博客(含支持的markdown语法)使用mkdocs搭建的文档库]]></content>
      <categories>
        <category>折腾</category>
        <category>博客</category>
      </categories>
      <tags>
        <tag>coding pages</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jupyter主题、插件、技巧、server搭建]]></title>
    <url>%2Fposts%2F13473.html</url>
    <content type="text"><![CDATA[针对默认的jupyter notebook的页面进行修改、增加一些插件使jupyter的使用更加方便，整理一些jupyter使用技巧，最后是关于搭建jupyter server的内容，记录了自己搭建jupyterhub的过程的遇到问题的解决办法。jupyter默认页面的修改jupyter默认页面的修改主要是使用jupyter-themes包。jupyter-themes安装常规的pip安装方式：12345# install jupyterthemespip install jupyterthemes# upgrade to latest versionpip install --upgrade jupyterthemes为了达到最好的效果，建议notebook的版本是&gt;=5.6.0，如果低于此版本可以使用pip install --upgrade notebook进行升级refreshing / removing / resetting：如果想要恢复默认值或者使新采用的主题生效，可能需要清除浏览器缓存（不一定非要进行，看自己的浏览器和系统，真遇到情况可以参考issue）；进行上述操作后刷新浏览器肯定是要刷新浏览器的！安装或其他问题直接上github找答案！具体使用命令行：12345jt [-h] [-l] [-t THEME] [-f MONOFONT] [-fs MONOSIZE] [-nf NBFONT] [-nfs NBFONTSIZE] [-tf TCFONT] [-tfs TCFONTSIZE] [-dfs DFFONTSIZE] [-m MARGINS] [-cursw CURSORWIDTH] [-cursc CURSORCOLOR] [-vim] [-cellw CELLWIDTH] [-lineh LINEHEIGHT] [-altp] [-altmd] [-altout] [-P] [-T] [-N] [-r] [-dfonts]具体的参数说明：table th:first-of-type{width:15%}table th:nth-of-type(2){width:10%}table th:nth-of-type(3){width:75%}cl optionsargdefaultUsage help-h–List Themes-l–Theme Name to Install-t–Code Font-f–Code Font-Size-fs11Notebook Font-nf–Notebook Font Size-nfs13Text/MD Cell Font-tf–Text/MD Cell Fontsize-tfs13Pandas DF Fontsize-dfs9Output Area Fontsize-ofs8.5Mathjax Fontsize (%)-mathfs100Intro Page Margins-mautoCell Width-cellw980Line Height-lineh170Cursor Width-cursw2Cursor Color-cursc–Alt Prompt Layout-altp–Alt Markdown BG Color-altmd–Alt Output BG Color-altout–Style Vim NBExt*-vim–Toolbar Visible-T–Name &amp; Logo Visible-N–Kernel Logo Visible-kl–Reset Default Theme-r–Force Default Fonts-dfonts–github上有具体的示例用法，建议大家去看看，我这里挑选我最喜欢的配置如下：1jt -t monokai -f firacode -fs 12 -cellw 70% -ofs 10 -dfs 11 -T -N -altp -lineh 140上述命令是在cmd中输入进行配置，而不是在jupyter notebook中-fs：字体大小-ofs：输出字体大小-dfs：pandas dataframe字体大小-cellw：主体宽度-T：显示导航栏-N：显示文件名称-altp：不显示格子左上角的number-lineh：行高设置完成之后发现jupyter的logo没有完全显示出来，同时文件名称也只显示了一部分，这些需要修改，找到C:\Users\username\.jupyter\custom目录下的custom.css进行修改:12345678910111213&lt;!-- 将none改为block来显示jupyter的logo --&gt;div#ipython_notebook &#123; display: block;&#125;&lt;!-- 将height: initial修改为20px，这个可以自己设置 --&gt;span.save_widget span.filename &#123; margin-left: 8px; height: 22px; font-size: 100%; color: #a6e22e; background-color: #282828;&#125;上述修改每次重新修改主题相关配置后都需要重新修改修改绘图配置：12from jupyterthemes import jtplotjtplot.style(theme='grade3',ticks=True)插件使用主要使用的包是jupyter_contrib_nbextensions，这是一个非常强大的包，里面包含了很多在jupyter notebook只很常用的插件，包括代码段、显示目录等等等，同时这个包还提供了一个链接：A collection of various notebook extensions for Jupyter，里面总结了可以用在jupyter notebook中的插件。插件安装123456789# Install the python package## 这个安装经常失败，下载速度太慢了pip install jupyter_contrib_nbextensions## 换用这个了pip install https://github.com/ipython-contrib/jupyter_contrib_nbextensions/tarball/master# Install javascript and css filesjupyter contrib nbextension install --user上述两步安装完成之后就可以在jupyter的home page看到如下的插件：选取插件安装Code prettify-代码美化插件的快捷键：ctrl + l进行单个cell的prettify（也可以在选中cell时直接点击导航栏的小锤子按钮）、Ctrl-Shift-L进行所有的的prettify12# 这个插件安装后提示yapf没有安装pip install yapfAfter checking “Snippets Menu” in Configurable nbextensions, Snippets did’t appear inCollapsible headings-折叠标题Snippets-自定义代码片段修改C:\Users\user\AppData\Roaming\jupyter\nbextensions\snippets\snippets.json来添加新的代码段，注意是上面的地址，而不是anaconda目录下的文件，如果修改了anaconda下的文件不起作用。123456789&#123; "name" : "common_use", "code" : [ "import os", "import sys", "import numpy as np", "import pandas as pd" ]&#125;编辑完成之后想要生效需要重启jupyter notebookTable of Contents (2)-显示目录结构这个和上面的jupyter-themes好像要有些冲突，导航栏遮挡部分的目录结构，现在还不知道有没有什么解决办法， 可以取舍一下Highlight selected word-高亮代码中与选中部分相同的highlighter-高亮选中的文本ExecuteTime-显示每个cell的运行时间table_beautifier-让输出的table更好看Snippets Menu-和snippet类似，但是没有正常工作，需要看看为什么？？？Hinterland-自动补全代码Split Cells Notebook-拆分单元格可以将单元格拆分为一半，然后将下一个单元格进行同样的操作，两个一半的单元格会在同一行显示，这对于一些试探性的工作会比较有用。Move selected cells同时移动多个选定的cell，选定cell可以使用Shift-up/Shift-down or Shift-K/Shift-J；也可以使用rubberband，这个也是一个插件快速选取多个cell可以结合前面的Move selected cells插件使用，使用shift+鼠标左边选取范围内的cells。最后的插件配置结果：jupyter 使用技巧多行输出关于Jupyter Notebook的28个技巧(快捷键、Magic命令等)jupyter server搭建后来发现jupyter的server是为单人创建的server，有一个专门的为多个用户使用jupyter server的程序叫jupyterhub，这里主要记录配置jupyterhub的过程。关于jupyter的server搭建教程在服务器部署Jupyter Notebook远程使用jupyter在服务器上配置jupyter, 远程登录安装使用conda安装：1234567891011121314conda install -c conda-forge jupyterhub# 出现错误WARNING: The conda.compat module is deprecated and will be removed in a future release.Collecting package metadata: failedUnavailableInvalidChannel: The channel is not accessible or is invalid. channel name: conda-forge channel url: https://conda.anaconda.org/conda-forge error code: 403You will need to adjust your conda configuration to proceed.Use `conda config --show channels` to view your configuration's current state,and use `conda config --show-sources` to view config file locations.使用npm和pip进行安装：1234567891011npm install -g configurable-http-proxypython3 -m pip install jupyterhub # pip安装报错 pip is configured with locations that require TLS/SSL, however the ssl module in Python is not available. Collecting jupyterhub Could not fetch URL https://pypi.python.org/simple/jupyterhub/: There was a problem confirming the ssl certificate: Can't connect to HTTPS URL because the SSL module is not available. - skipping Could not find a version that satisfies the requirement jupyterhub (from versions: ) No matching distribution found for jupyterhub# 直接卸载了原本安装的miniconda，重新安装了anaconda3# 就解决了问题相关配置创建jupyterhub配置文件夹1mkdir -p /etc/jupyterhub &amp;&amp; cd /etc/jupyterhub在上述文件夹下生成配置文件123jupyterhub --generate-config # 输出信息 Writing default config to: jupyterhub_config.py生成自签名的 SSL 证书这是可选的一步，用于enable HTTPS，设置之后必须使用https才能访问，不然会出现下面提到的ERR_EMPTY_RESPONSE错误：12openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout mykey.key -out mycert.pem# 在目录下生成mykey.key、mycert.pem文件配置启动 jupyterlab123456789101112131415161718192021222324import os# 设置ipc.JupyterHub.ip = '192.168.1.231'c.JupyterHub.port = 8000c.PAMAuthenticator.encoding = 'utf-8'# This is an application.# create system users that don't exist yetc.LocalAuthenticator.create_system_users = Truec.Authenticator.whitelist = set(os.listdir('/home'))c.Authenticator.admin_users = &#123;'user'&#125;# 设置笔记本从登陆用户的home目录c.Spawner.notebook_dir = '/'c.Spawner.default_url = '/tree/home/&#123;username&#125;'# 如果设置之后必须使用https才能访问，不然会出错# c.JupyterHub.ssl_cert = '/etc/jupyterhub/mycert.pem'# c.JupyterHub.ssl_key = '/etc/jupyterhub/mykey.key'c.JupyterHub.cookie_secret_file = '/etc/jupyterhub/jupyterhub_cookie_secret'c.ConfigurableHTTPProxy.command = ['/usr/bin/configurable-http-proxy']# 再次打开session不用重新登录# 参考链接：https://github.com/jupyterhub/jupyterhub/issues/323c.PAMAuthenticator.open_sessions = False设置外网映射上面设置的ip地址为192.168.1.231是内网地址，为了能够在外网(不使用实验室的网络)使用，需要通过路由器进行外网映射错误总结Error adding user manasrk already in db删掉jupyterhub.sqlite即可，参考1、参考2注意：jupyterhub_cookie_secret和jupyterhub.sqlite会在安装jupyterlab的目录下，所以尽量在/etc/jupyterhub下进行安装，以免需要重新移动ERR_EMPTY_RESPONSE123该网页无法正常运作 192.168.1.231 未发送任何数据。 ERR_EMPTY_RESPONSE解决办法：1connect to https://127.0.0.1:8000, not http://127.0.0.1:8000安装不同的内核R内核123conda install -c r r-irkernelIRkernel::installspec()python2内核1234567891011# 创建虚拟环境conda create -n py27 python=2.7# 激活虚拟环境conda activate py27# 将kernel安装在指定的目录# /path/to/python3 -m IPython kernel install --prefix=/usr/localpython -m IPython kernel install --prefix=/usr/local# 退出虚拟环境conda deactivate必须要加上--prefix=/usr/local安装，这样最后的kernel安装在/usr/local/share/jupyter/kernels/python2，而默认的pip install ipykernel安装在/root/.local/share/jupyter/kernels/python2，这种情况不会加载这个kernel，这和jupyter不同，具体的jupyterhub自己的设定需要查看这个链接查看所有已有的内核：12345jupyter kernelspec list Available kernels: ir /home/softwares/anaconda3/share/jupyter/kernels/ir python3 /home/softwares/anaconda3/share/jupyter/kernels/python3 python2 /usr/local/share/jupyter/kernels/python2参考链接jupyterhub官方文档jupyterhub的github]]></content>
      <categories>
        <category>Python</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML中的实体空格与markdown空格缩进]]></title>
    <url>%2Fposts%2F58681.html</url>
    <content type="text"><![CDATA[本文主要学习了HTML中的6种实体空格以及在实际markdown写作中会涉及到的空格缩进应该使用哪种空格实体会比较好，最后发现使用&amp;emsp;-全角空格在中文markdown写作中是最合适的简介在markdown写作过程中，我们可能需要再文本中插入一些空格，比如中文的首行缩进，与word文档写作直接使用space键空两格即可出现空格不同，markdown不会识别这种空格(四个空格会代表代码块)，为了达到插入空格的效果就需要使用HTML中的空格实体HTML中的实体空格HTML提供了6种空格实体（space entity），它们拥有不同的宽度，非断行空格（&amp;nbsp;）是常规空格的宽度，可运行于所有主流浏览器。其他几种空格（&amp;ensp;、&amp;emsp;、&amp;thinsp;、&amp;zwnj;、&amp;zwj;）在不同浏览器中宽度各异&amp;nbsp;-不换行空格&emsp;&emsp;它叫不换行空格，全称是 No-Break Space，它是最常见和我们使用最多的空格，大多数的人可能只接触了&amp;nbsp;，它是按下space键产生的空格，一般两个&amp;nbsp;对应于一个中文字符。在HTML中，如果你用空格键产生此空格，空格是不会累加的（只算1个），要使用html实体表示才可累加，该空格占据宽度受字体影响明显而强烈。示例如下：微软雅黑&nbsp;&nbsp;字体，前面有两个&amp;nbsp;空格这是黑体&nbsp;&nbsp;字体，前面有两个&amp;nbsp;空格这是宋体&nbsp;&nbsp;字体，前面有两个&amp;nbsp;空格发现在不同字体中，空格的大小是不同的！&amp;ensp;-半角空格&emsp;&emsp;它叫半角空格，全称是 En Space，en是字体排印学的计量单位，为em宽度的一半。根据定义，它等同于字体度的一半（如16px字体中就是8px）。名义上是小写字母n的宽度。此空格传承空格家族一贯的特性：透明的，此空格有个相当稳健的特性，就是其占据的宽度正好是1/2个中文宽度，而且基本上不受字体影响示例如下：微软雅黑&ensp;&ensp;字体，前面有两个&amp;ensp;空格这是黑体&ensp;&ensp;字体，前面有两个&amp;ensp;空格这是宋体&ensp;&ensp;字体，前面有两个&amp;ensp;空格发现在不同字体中，空格的大小是不变的，并且两格空格占据一个字体大小！&amp;emsp;-全角空格&emsp;&emsp;它叫全角空格，全称是 Em Space，em是字体排印学的计量单位，相当于当前指定的点数。例如，1 em在16px的字体中就是16px。此空格也传承空格家族一贯的特性：透明的，此空格也有个相当稳健的特性，就是其占据的宽度正好是1个中文宽度，而且基本上不受字体影响，和上面的&amp;ensp;-半角空格特性相同，但是是一个中文宽度示例如下：微软雅黑&emsp;&emsp;字体，前面有两个&amp;emsp;空格这是黑体&emsp;&emsp;字体，前面有两个&amp;emsp;空格这是宋体&emsp;&emsp;字体，前面有两个&amp;emsp;空格发现在不同字体中，空格的大小是不变的，并且两格空格占据两个字体大小！&amp;thinsp;-窄空格&emsp;&emsp;它叫窄空格，全称是 Thin Space。我们不妨称之为“瘦弱空格”，就是该空格长得比较瘦弱，身体单薄，占据的宽度比较小。它是em之六分之一宽(前面的&amp;ensp;-半角空格是em宽度的一半，&amp;emsp;-全角空格就是em宽度)示例如下：微软雅黑&emsp;字体，前面有一个&amp;emsp;空格这是黑体&ensp;&ensp;字体，前面有两个&amp;ensp;空格这是宋体&thinsp;&thinsp;&thinsp;&thinsp;&thinsp;&thinsp;字体，前面有六个&amp;thinsp;空格&amp;zwnj;-零宽不连字&emsp;&emsp;它叫零宽不连字，全称是 Zero Width Non Joiner，简称“ZWNJ”，是一个不打印字符，放在电子文本的两个字符之间，抑制本来会发生的连字，而是以这两个字符原本的字形来绘制。Unicode中的零宽不连字字符映射为（zero width non-joiner，U+200C），HTML字符值引用为&amp;#8204&amp;zwj;-零宽连字&emsp;&emsp;它叫零宽连字，全称是 Zero Width Joiner，简称“ZWJ”，是一个不打印字符，放在某些需要复杂排版语言（如阿拉伯语、印地语）的两个字符之间，使得这两个本不会发生连字的字符产生了连字效果。零宽连字符的Unicode码位是U+200D (HTML:&amp;#8205;、&amp;zwj;）。此外，浏览器还会把以下字符当作空白进行解析：空格&amp;#x0020;、制表位&amp;#x0009;、换行&amp;#x000A;、回车&amp;#x000D;和&amp;#12288;等等。markdowm首行缩进方法通过上述对HTML中实体空格的介绍，可以总结出以下几种可以用在markdown中充当首行缩进的方法：使用&amp;emsp;-全角空格，优点：占据的宽度正好是1个中文宽度，而且基本上不受字体影响，推荐使用这个进行首行缩进使用&amp;ensp;-半角空格，优点：占据的宽度正好是1/2个中文宽度，需要使用两格才能达到缩进效果，而且基本上不受字体影响使用&amp;nbsp;-不换行空格，缺点：需要使用四个来代表两个中文字符，并且受字体影响较大参考链接markdown空格缩进以及HTML空格实体markdown编辑器中可以使用的6种空格标记]]></content>
      <categories>
        <category>其他内容学习</category>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[总结|位、字节、字符和编码]]></title>
    <url>%2Fposts%2F56690.html</url>
    <content type="text"><![CDATA[本文主要讲解了编码、字符、字节、位的概念，以及不同编码情况下字节与字符的对应关系，主要包括ASCII码、UTF-8编码、Unicode编码、UTF-16编码和UTF-32编码。编码问题的由来，相关概念的理解字符与编码的发展从计算机对多国语言的支持角度看，大致可以分为三个阶段： 系统内码说明系统阶段一ASCII计算机刚开始只支持英语，其它语言不能够在计算机上存储和显示。英文 DOS阶段二ANSI编码（本地化）为使计算机支持更多语言，通常使用 0x80~0xFF 范围的 2 个字节来表示 1 个字符。比如：汉字 '中' 在中文操作系统中，使用 [0xD6,0xD0] 这两个字节存储。不同的国家和地区制定了不同的标准，由此产生了 GB2312, BIG5, JIS 等各自的编码标准。这些 使用 2 个字节来代表一个字符的各种汉字延伸编码方式，称为 ANSI 编码。在简体中文系统下，ANSI 编码代表 GB2312 编码，在日文操作系统下，ANSI 编码代表 JIS 编码。不同 ANSI 编码之间 互不兼容 ，当信息在国际间交流时，无法将属于两种语言的文字，存储在同一段 ANSI 编码的文本中。中文 DOS，中文 Windows 95/98，日文 Windows 95/98阶段三UNICODE（国际化）为了使国际间信息交流更加方便，国际组织制定了 UNICODE 字符集，为各种语言中的每一个字符设定了统一并且唯一的数字编号，以满足跨语言、跨平台进行文本转换、处理的要求。Windows NT/2000/XP，Linux，Java字符串在内存中的存放方法：在 ASCII 阶段，单字节字符串使用一个字节存放一个字符（SBCS）。比如，”Bob123” 在内存中为：42 6F 62 31 32 33 00&nbsp;B&nbsp;&nbsp;&nbsp;o&nbsp;&nbsp;&nbsp;b&nbsp;&nbsp;&nbsp;1&nbsp;&nbsp;&nbsp;2&nbsp;&nbsp;&nbsp;3&nbsp;&nbsp;&nbsp;\0在使用 ANSI 编码支持多种语言阶段，每个字符使用一个字节或多个字节来表示（MBCS），因此，这种方式存放的字符也被称作多字节字符。比如，”中文123” 在中文 Windows 95 内存中为7个字节，每个汉字占2个字节，每个英文和数字字符占1个字节：D6 D0 CE C4 31 32 33 00&emsp;中&emsp;&emsp;文&emsp;1&nbsp;&nbsp;&nbsp;2&nbsp;&nbsp;&nbsp;3&nbsp;&nbsp;&nbsp;\0在 UNICODE 被采用之后，计算机存放字符串时，改为存放每个字符在 UNICODE 字符集中的序号。目前计算机一般使用 2 个字节（16 位）来存放一个序号（DBCS），因此，这种方式存放的字符也被称作宽字节字符。比如，字符串 “中文123” 在 Windows 2000 下，内存中实际存放的是 5 个序号：2D 4E 87 65 31 00 32 00 33 00 00 00 &lt;-在 x86 CPU 中，低字节在前&emsp;中&emsp;&emsp;文&emsp;&emsp;1&emsp;&emsp;2&emsp;&emsp;3&emsp;&emsp;\0一共占 10 个字节字符、字节、字符串理解编码的关键，是要把字符的概念和字节的概念理解准确。这两个概念容易混淆，我们在此做一下区分： 概念描述举例字符人们使用的记号，抽象意义上的一个符号。'1', '中', 'a', '$', '￥', ……字节计算机中存储数据的单元，一个8位的二进制数，是一个很具体的存储空间。0x01, 0x45, 0xFA, ……ANSI字符串在内存中，如果“字符”是以 ANSI 编码形式存在的，一个字符可能使用一个字节或多个字节来表示，那么我们称这种字符串为 ANSI 字符串或者多字节字符串。"中文123"（占7字节）UNICODE字符串在内存中，如果“字符”是以在 UNICODE 中的序号存在的，那么我们称这种字符串为 UNICODE 字符串或者宽字节字符串。L"中文123"（占10字节）由于不同 ANSI 编码所规定的标准是不相同的，因此，对于一个给定的多字节字符串，我们必须知道它采用的是哪一种编码规则，才能够知道它包含了哪些“字符”。而对于 UNICODE 字符串来说，不管在什么环境下，它所代表的“字符”内容总是不变的。字符集与编码各个国家和地区所制定的不同 ANSI 编码标准中，都只规定了各自语言所需的“字符”。比如：汉字标准（GB2312）中没有规定韩国语字符怎样存储。这些 ANSI 编码标准所规定的内容包含两层含义：使用哪些字符。也就是说哪些汉字，字母和符号会被收入标准中。所包含“字符”的集合就叫做“字符集”。规定每个“字符”分别用一个字节还是多个字节存储，用哪些字节来存储，这个规定就叫做“编码”。各个国家和地区在制定编码标准的时候，“字符的集合”和“编码”一般都是同时制定的。因此，平常我们所说的“字符集”，比如：GB2312, GBK, JIS 等，除了有“字符的集合”这层含义外，同时也包含了“编码”的含义。“UNICODE 字符集”包含了各种语言中使用到的所有“字符”。用来给 UNICODE 字符集编码的标准有很多种，比如：UTF-8, UTF-7, UTF-16, UnicodeLittle, UnicodeBig 等。常用的编码简介简单介绍一下常用的编码规则，为后边的章节做一个准备。在这里，我们根据编码规则的特点，把所有的编码分成三类：分类编码标准说明单字节字符ISO-8859-1最简单的编码规则，每一个字节直接作为一个 UNICODE 字符。比如，[0xD6, 0xD0] 这两个字节，通过 iso-8859-1 转化为字符串时，将直接得到 [0x00D6, 0x00D0] 两个 UNICODE 字符，即 "ÖÐ"。反之，将 UNICODE 字符串通过 iso-8859-1 转化为字节串时，只能正常转化 0~255 范围的字符。ANSIGB2312,BIG5,Shift_JIS,ISO-8859-2 ……把 UNICODE 字符串通过 ANSI 编码转化为“字节串”时，根据各自编码的规定，一个 UNICODE 字符可能转化成一个字节或多个字节。反之，将字节串转化成字符串时，也可能多个字节转化成一个字符。比如，[0xD6, 0xD0] 这两个字节，通过 GB2312 转化为字符串时，将得到 [0x4E2D] 一个字符，即 '中' 字。“ANSI 编码”的特点：1. 这些“ANSI 编码标准”都只能处理各自语言范围之内的 UNICODE 字符。2. “UNICODE 字符”与“转换出来的字节”之间的关系是人为规定的。UNICODEUTF-8,UTF-16, UnicodeBig ……与“ANSI 编码”类似的，把字符串通过 UNICODE 编码转化成“字节串”时，一个 UNICODE 字符可能转化成一个字节或多个字节。与“ANSI 编码”不同的是：1. 这些“UNICODE 编码”能够处理所有的 UNICODE 字符。2. “UNICODE 字符”与“转换出来的字节”之间是可以通过计算得到的。我们实际上没有必要去深究每一种编码具体把某一个字符编码成了哪几个字节，我们只需要知道“编码”的概念就是把“字符”转化成“字节”就可以了。对于“UNICODE 编码”，由于它们是可以通过计算得到的，因此，在特殊的场合，我们可以去了解某一种“UNICODE 编码”是怎样的规则。简介介绍区别位（bit）：计算机存储信息的最小单位，11001100是一个八位二进制数。字节（byte）：是一种计量单位，表示数据量多少，是计算机存储容量基本单位，习惯上用大写 B 来表示,1B（byte,字节）= 8bit（位）字符：是指计算机中使用的字母、数字、字和符号，比如1、2、3、A、B、C、~！·#￥%……—*（）——+、等等。编码：把“字符”转化成“字节”不同编码里，字符和字节的对应关系如下：ASCII码：1个英文字母（不分大小写）= 1个字节的空间1个中文汉字 = 2个字节的空间Unicode编码：1个英文字符 = 2个字节英文标点 = 2个字节1个中文（含繁体） = 2个字节中文标点 = 2个字节UTF-8编码：1个英文字符 = 1个字节英文标点 = 1个字节1个中文（含繁体） = 3个字节中文标点 = 3个字节UTF-16编码：一个英文字母字符或一个汉字字符存储都需要2个字节Unicode扩展区的一些汉字存储需要4个字节UTF-32编码：世界上任何字符的存储都需要4个字节unicode编码、UTF-8编码、UTF-16编码、UTF-32编码都是对Unicode字符集进行编码的实现方式查看系统编码linux系统localeLANG=en_US.UTF-8LC_CTYPE=en_US.UTF-8LC_NUMERIC=”en_US.UTF-8”LC_TIME=”en_US.UTF-8”LC_COLLATE=”en_US.UTF-8”LC_MONETARY=”en_US.UTF-8”LC_MESSAGES=”en_US.UTF-8”LC_PAPER=”en_US.UTF-8”LC_NAME=”en_US.UTF-8”LC_ADDRESS=”en_US.UTF-8”LC_TELEPHONE=”en_US.UTF-8”LC_MEASUREMENT=”en_US.UTF-8”LC_IDENTIFICATION=”en_US.UTF-8”LC_ALL=可以看出linux系统的默认编码是UTF-8windows系统windows在dos环境下输入chcp：chcp活动代码页: 936活动代码页为：936，对应的编码格式为GBK参考链接字符与字节的区别字符，字节和编码位、字节、字符的区别UTF-8和Unicode关系简单几句话总结Unicode，UTF-8和UTF-16]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>计算机基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单行命令嵌套]]></title>
    <url>%2Fposts%2F50164.html</url>
    <content type="text"><![CDATA[单行命令嵌套，也就是一行命令使用另一行命令的结果，或者将命令的结果当做参数传给另一个命令，使用方法command1 &lt;(command2).命令格式将command2的结果作为command1的输入：12Usage: command1 &lt;(command2)使用实例uniq命令去重常常需要先进行排序操作：uniq -c &lt;(sort uniq.txt)1 i am test2 i love test1 i want go abroad4 this is a test1 those are good men1 we are good men1 whom have a try1 WhoM have a try1 you have a try当前上述也可以直接使用管道符|来操作但是如果是像join这种需要操作两个文件的，单纯地使用管道符就很难达到目的，join对指定列进行连接时也需要进行排序操作：cat test1.txtaa 1 2bb 2 3cc 4 6dd 3 3cat test2.txtaa 2 1bb 8 2ff 2 4cc 4 4dd 5 5管道符和命令嵌套合用：sort -k 1,1 test2.txt |join -j 1 &lt;(sort -k 1,1 test1.txt) -aa 1 2 2 1bb 2 3 8 2cc 4 6 4 4dd 3 3 5 5当然也可以直接使用命令嵌套：join -j 1 &lt;(sort -k 1,1 test1.txt) &lt;(sort -k 1,1 test2.txt)aa 1 2 2 1bb 2 3 8 2cc 4 6 4 4dd 3 3 5 5]]></content>
      <categories>
        <category>Linux</category>
        <category>常用内容总结</category>
      </categories>
      <tags>
        <tag>常用内容总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cut-按列切分文件字段工具]]></title>
    <url>%2Fposts%2F64687.html</url>
    <content type="text"><![CDATA[本文主要学习了Linux下对每一行文本按照给定的分隔符进行切割并按照指定的范围提取字段、字符或字节的命令cut，其主要选项包括：-d、-f、--complement、-s、-c、-b、-n和--output-delimiter。cut用法cut命令从文件的每一行剪切字节、字符或字段并将这些字节、字符或字段写至标准输出如果不指定文件，cut命令将读取标准输入cut命令格式12Usage: cut OPTION [FILE]cut options说明table th:first-of-type{width:15%}table th:nth-of-type(2){width:25%}table th:nth-of-type(3){width:60%}参数完整参数说明-b–bytes=LIST以字节为单位进行分割，这些字节位置将忽略多字节字符边界，除非也指定了-n标志-c–characters=LIST以字符为单位进行分割-d–delimiter=DELIM自定义分隔符，默认为制表符tab-f–fields=LIST与-d一同使用，显示指定字段的内容；也会打印不包含分隔符的行，除非指定了-s参数-nwith -b: 取消分割多字节字符，仅和 -b 标志一起使用；如果字符的最后一个字节落在由 -b 标志的 List 参数指示的范围之内，该字符将被写出，否则该字符将被排除–complement补足被选择的字节、字符或字段-s–only-delimited不打印没有包含分隔符的行，有利于去掉注释和标题–output-delimiter=STRING指定输出内容的分隔符cut指定字段、字符或字节范围的方法指定字段、字符或字节范围有以下三种方法：N-：获取连续范围，从第N个字节、字符、字段到结尾；N-M：获取连续范围，从第N个字节、字符、字段到第M个（包括M在内）字节、字符、字段；-M：获取连续范围，从第1个字节、字符、字段到第M个（包括M在内）字节、字符、字段N,M：获取不连续范围，得到第N个字节、字符、字段和第M个字节、字符、字段N,M,Z-P：获取连续范围和不连续范围，第N个字节、字符、字段、第M个字节、字符、字段以及从第Z个字节、字符、字段到第P个（包括P在内）字节、字符、字段逗号(,)可以使用多个cut用法实例测试数据cat cut.txtNo Name Mark Percent01 tom 69 9102 jack 71 8703 alex 68 98-d 自定义分隔符默认-d是制表符tab，这个很关键，不是空白字符，同时自定义的分隔符必须是单个的字符，比如单个的空格，不能是两个或以上空格cut -d &#39; &#39; -f 1 cut.txtNo010203awk &#39;{print $1&quot;;&quot;$2&quot;;&quot;$3&quot;;&quot;$4}&#39; cut.txt |cut -d &#39;;&#39; -f 1No010203-f 提取指定字段内容选取单个filed如上面-d用法示例选取多个字段，直接将多个字段在-f选项后使用,分割即可：cut -d &#39; &#39; -f 1,3 cut.txtNo Mark01 6902 7103 68也可以使用-和,混用的方法：cut -d &#39; &#39; -f 1,3-4 cut.txtNo Mark Percent01 69 9102 71 8703 68 98–complement 提取指定字段之外的内容cut -d &#39; &#39; -f 1,3 --complement cut.txtName Percenttom 91jack 87alex 98这里得到的结果和上面单纯使用-f得到的结果可以说是互补的，因为--complement是提取指定字段之外的内容-s 不打印没有包含分隔符的行在cut.txt上增加一行文本，其分隔符和其他几行不同：cat cut.txt#this-is-testNo Name Mark Percent01 tom 69 9102 jack 71 8703 alex 68 98默认情况，如果一行不包含分隔符，就会输出这一行：cut -d ‘ ‘ -f 1 cut.txt#this-is-testNo010203为了防止上述情形出现，可以使用-s选项：cut -d &#39; &#39; -s -f 1 cut.txtNo010203可以发现，不包含空格作为分隔符的第一行就没有进行输出-c 提取指定字符范围的内容cat cut2.txtabcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz指定连续范围：cut -c -2 cut2.txtabababababcut -c 5- cut2.txtefghijklmnopqrstuvwxyzefghijklmnopqrstuvwxyzefghijklmnopqrstuvwxyzefghijklmnopqrstuvwxyzefghijklmnopqrstuvwxyz指定不连续范围和连续范围（,和-混用）：cut -c 1,3-5 cut2.txtacdeacdeacdeacdeacde-b 提取指定字符范围的内容cut -b 1-5 cut2.txtabcdeabcdeabcdeabcdeabcde这结果咋一看和前面的-c没有什么区别，这是因为操作对象都是英文字母，而在ASCII码和UTF-8编码中英文字母的字节和字符是相等的，具体的字节和字符的区别见这篇博客由于我使用的vscode的默认编码方式为utf-8，所以英文字母的字节和字符是相等的，而中文1个中文（含繁体） = 3个字节，为了凸显-b和-c的区别，下面采用中文进行测试：cat cut3.txt星期一星期二星期三星期四星期五cut -b 1-3 cut3.txt # cut -b 1-2 cut3.txt结果为空，因为需要三个字节才可以星星星星星cut -c 1-3 cut3.txt星期一星期二星期三星期四星期五针对英文字符进行提取指定字符范围内容时，-b和-c选项没什么差别，因为在大部分编码方式中，英文字母的字节和字符是相等的，而针对中文就需要注意不同的编码方式对中文字符对应字节数的设置，当然cut命令还提供了了一个选项-n来解决上述-b可能遇到的问题-n 取消分割多字节字符该选项仅和 -b 选项一起使用，用来取消分割多字节字符cut -b 3 cut3.txtcut -nb 3 cut3.txt星星星星星cut -nb 3,6,9 cut3.txt星期一星期二星期三星期四星期五当-nb后面的数字为3的整数倍（utf-8编码）时就不会分割多字节字符，得到对应的字符，不过感觉这没啥大用处，一般都直接使用了-c参数来获取字符–output-delimiter=STRING 指定输出内容是的分隔符cut -d &#39; &#39; -f 1-3 --output-delimiter=$&#39;\t&#39; cut.txt#this-is-testNo Name Mark01 tom 6902 jack 7103 alex 68注意这里指定输出分割符为tab的时候使用了$&#39;\t&#39;的方式，其中$和单引号都是必须的不能更改的，这个和join命令中指定分隔符的用法相同，具体原因查看这篇文章参考链接cut命令linux的cut命令Linux下的cut选取命令详解linux每日一命令–cut]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[uniq-去重]]></title>
    <url>%2Fposts%2F20744.html</url>
    <content type="text"><![CDATA[本文学习了linux中准备对文本进行去重操作的uniq命令，其重要的参数包括-c、-d、-D、-f、-s、-w、-i、-u。这个命令通常与sort一起使用。uniq用法uniq命令是专门用来去除重复行的命令，使用时需要注意：对文本操作时，它一般会和sort命令进行组合使用，因为uniq 不会检查重复的行，除非它们是相邻的，如果您想先对输入排序，使用sort -u对文本操作时，若域中为先空字符(通常包括空格以及制表符)，然后非空字符，域中字符前的空字符将被跳过uniq命令格式1234Usage: uniq [OPTION] [INPUT [OUTPUT]] # 从输入文件或者标准输入中过滤相邻的匹配行并将结果写入到输出文件或标准输出 # 在不加options的情况下，匹配行将在首次出现处被合并uniq options说明table th:first-of-type{width:15%}table th:nth-of-type(2){width:25%}table th:nth-of-type(3){width:60%}参数完整参数说明-c–count在每行前加上表示行出现次数-d–repeated只输出重复的行，即出现次数&gt;=2的行，且只打印一次-D–all-repeated[=delimit-method]仅显示重复的行，即出现次数&gt;=2的行，且打印重复行的所有行。其中delimit-method表示对重复行集合的分隔方式，有三种取值，分别为none（默认）、prepend和separate。-u–unique只显示唯一的行，即出现次数等于1的行-f–skip-fields=N忽略前N个字段-s–skip-chars=N和-f类似，不过-s是忽略前N个字符-w–check-chars=N指定每行要比较的前N个字符数-i–ignore-case不区分大小写-z–zero-terminatedend lines with 0 byte, not newlineuniq用法实例测试文本cat uniq.txtthis is a testthis is a testthis is a testi am testi love testi love testthis is a testwhom have a tryWhoM have a tryyou have a tryi want go abroadthose are good menwe are good men使用默认方式进行去重uniq uniq.txtthis is a testi am testi love testthis is a testwhom have a tryWhoM have a tryyou have a tryi want go abroadthose are good menwe are good men可以发现，uniq在计算重复的时候只会看相邻行，有一个this is a test没有和其他相邻，结果就被保留下来，当做非重复行-c 显示行出现的次数uniq -c uniq.txt3 this is a test1 i am test2 i love test1 this is a test1 whom have a try1 WhoM have a try1 you have a try1 i want go abroad1 those are good men1 we are good men依旧存在前面提到的问题，uniq在计算重复的时候只会看相邻行，和sort连用：sort uniq.txt |uniq -c1 i am test2 i love test1 i want go abroad4 this is a test1 those are good men1 we are good men1 whom have a try1 WhoM have a try1 you have a try单纯使用sort命令去重的结果和上面是一样的，只是不能得到具体的重复数目，uniq功能更加强大：sort -u uniq.txti am testi love testi want go abroadthis is a testthose are good menwe are good menwhom have a tryWhoM have a tryyou have a try-d 只输出重复的行(输出一行)sort uniq.txt |uniq -dc2 i love test4 this is a test-D 仅输出重复的行(重复输出)sort uniq.txt |uniq -Di love testi love testthis is a testthis is a testthis is a testthis is a test这个就不能和-c连用，因为重复行都显示出来了delimit-method=nonenone表示不进行分隔，为默认选项，uniq -D等同于uniq --all-repeated=none注意使用delimit-method的时候就不能使用option的简写形式，必须使用完整参数delimit-method=prependprepend表示在每一个重复行集合前面插入一个空行sort uniq.txt |uniq --all-repeated=prependi love testi love testthis is a testthis is a testthis is a testthis is a testdelimit-method=separateseparate表示在每个重复行集合间插入一个空行sort uniq.txt |uniq --all-repeated=separatei love testi love testthis is a testthis is a testthis is a testthis is a test-f 忽略前N个字段sort uniq.txt |uniq -f 1 --all-repeated=separatei love testi love testthis is a testthis is a testthis is a testthis is a testthose are good menwe are good menwhom have a tryWhoM have a tryuniq -f 2 --all-repeated=separate uniq2.txtthis is a testthis are a testmy name is showteethyour mmmm is showteeth-f是指定前N个field，而不是仅仅规定单独的field来进行判断是不是重复，如果仅仅想看某一列，可以将那一列放在第一个field，然后使用-f参数即可-s 忽略前N个字符sort uniq.txt |uniq -s 4 --all-repeated=separatei love testi love testthis is a testthis is a testthis is a testthis is a testwhom have a tryWhoM have a tryyou have a try-w 指定每行要比较的前N个字符数sort uniq.txt |uniq -w 2 --all-repeated=separatei am testi love testi love testi want go abroadthis is a testthis is a testthis is a testthis is a testthose are good men注意这个参数和前面的-f、-s相同，都是前N个字段或者字符，而不是单纯地指定某一个字段或者字符-i 不区分大小写sort uniq.txt |uniq -i --all-repeated=separatei love testi love testthis is a testthis is a testthis is a testthis is a testwhom have a tryWhoM have a try-u 只显示唯一的行sort uniq.txt |uniq -ui am testi want go abroadthose are good menwe are good menwhom have a tryWhoM have a tryyou have a try显示在忽略大小写情况下的唯一的行：sort uniq.txt |uniq -u -ii am testi want go abroadthose are good menwe are good menyou have a try上面的whom存在大小写区别的行就没排除在外不会显示去除了重复之后的保留的唯一重复行参考链接Linux uniq命令详解Linux命令——uniq命令实例详细说明linux下去除重复行命令uniquniq命令]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[join-连接文本]]></title>
    <url>%2Fposts%2F5579.html</url>
    <content type="text"><![CDATA[本文学习了可以按照指定field内容来将两个文件连接起来的join命令，其重要的参数包括-1、-2、-j、-o、-t、-a、-e、-v、–nocheck-order。join用法join命令用来将两个文件中指定栏位内容相同的行连接起来，再输出到标准输出设备默认连接的栏位是有空白字符分隔的第一个栏位join命令格式12Usage: join [OPTION] FILE1 FILE2join options说明table th:first-of-type{width:15%}table th:nth-of-type(2){width:25%}table th:nth-of-type(3){width:60%}参数完整参数说明-aFILENUMFILENUM 取1或者2，表示除了显示原来的输出内容之外，还显示指令文件中没有相同栏位的行，相当于指定左外链接还是右外连接-vFILENUM与-a相似 但只显示文件里没匹配上的行-eEMPTY取值为字符串，将需要显示可是文件里不存在的域用此选项指定的字符取代-i–ignore-case比较栏位内容时，忽略大小写的差异-jFIELD-j指定一个域作为匹配字段，等同于 -1 FIELD -2 FIELD-1FIELD以file1中FIELD字段进行匹配-2FIELD以file2中FIELD字段进行匹配-oFORMAT以指定格式输出-tCHAR指定输入输出的分隔符，join 默认以空白字符做分隔符–check-order判断所有输入文件是不是已经排好序–nocheck-order不判断所有输入文件是不是已经排好序join用法实例测试数据cat test1.txtaa 1 2bb 2 3cc 4 6dd 3 3cat test2.txtaa 2 1bb 8 2ff 2 4cc 4 4dd 5 5使用默认方式连接文件join test1.txt test2.txtaa 1 2 2 1bb 2 3 8 2join: file 2 is not in sorted order上面的结果没有输出完整，同时输出了提示信息，file 2(test2.txt)没有进行没有进行排序，结合前面学习的sort命令对其第一列进行排序并进行连接：sort -k 1,1 test2.txt |join test1.txt -aa 1 2 2 1bb 2 3 8 2cc 4 6 4 4dd 3 3 5 5这次得到了完整的结果，同时注意在管道符后使用-表示read standard input也就是前面的sort的输出内容对某一列进行连接，就需要保证文件的这一列是排好序的，而不是只要对整个文件进行排序即可–nocheck-order 检查是否排序针对上面出现的文件没有排序的问题，也可以在不报错的情况下直接输出部分结果，默认情况应该是--check-order的：join --nocheck-order test1.txt test2.txtaa 1 2 2 1bb 2 3 8 2这个感觉没啥意义，得不到正确结果-1、-2 指定连接列-1：指定文件1（写在前面的文件）中用于连接的列-2：指定文件2（写在后面的文件）中用于连接的列sort -k 1,1 test2.txt |join -1 1 -2 1 test1.txt -aa 1 2 2 1bb 2 3 8 2cc 4 6 4 4dd 3 3 5 5这个结果和上面默认的结果相同让文件1的第2列与文件2的第3列进行连接（两列都是已经排好序的，不用再排序）：join -1 2 -2 3 test1.txt test2.txt1 aa 2 aa 22 bb 3 bb 84 cc 6 ff 24 cc 6 cc 4可以发现文件1中的cc 4 6出现了两次，这是因为文件2中在第3列上出现了2个4，这2个4对应的行都和文件1中的对应的行进行连接，从而出现了2次如果在文件1中增加一列重复的cc 4 6，得到如下结果：join -1 2 -2 3 test1.txt test2.txt1 aa 2 aa 22 bb 3 bb 84 cc 6 ff 24 cc 6 cc 44 cc 6 ff 24 cc 6 cc 4即使存在重复，连接也会进行组合操作，得到2x2个结果默认情况下，对哪一列进行连接，输出的结果中，用于连接的那一列就会放在最前面，如果需要自定义输出内容和顺序，可以使用后面提到的-o参数进行修改文件在指定的列上存在相同的，则会进行组合，比如各有2个相同的，则会得到2x2也就是4个结果（这里不管文件是否存在重复）-j 指定用于连接的列如果两个文件中用于连接的列(field)相同，可以直接使用-j参数统一制定，不用使用上面那种-1、-2这种分别指定，较为简便：sort -k 1,1 test2.txt |join -j 1 test1.txt -aa 1 2 2 1bb 2 3 8 2cc 4 6 4 4dd 3 3 5 5-o 自定义输出内容和顺序输出文件1的第1列和第2列以及文件2的第1列和第3列：join -1 2 -2 3 -o 1.{1,2} 2.{1,3} test1.txt test2.txtaa 1 aa 1bb 2 bb 2cc 4 ff 4cc 4 cc 4注意这里大括号{}的用法，详细请参考文章-t 指定分隔符sort -k 1,1 test2.txt|awk &#39;{print $1&quot;\t&quot;$2&quot;\t&quot;$3}&#39;|join -t $&#39;\t&#39; &lt;(awk &#39;{print $1&quot;\t&quot;$2&quot;\t&quot;$3}&#39; test1.txt) -aa 1 2 2 1bb 2 3 8 2cc 4 6 4 4dd 3 3 5 5指定-t $&#39;\t&#39;后，输出的内容也是以tab作为分隔的；使用默认的分隔符也能对上述案例进行连接，但是输出的是空格分隔，不管原始文件内是使用空格份额各还是tab分隔注意这里指定tab作为分隔符的方式，$&#39;\t&#39;设定的原因（单引号+$）参考之前的这篇文章-a 指定外连接join默认进行的是内连接，也就是找到两个文件中在指定列上能够连接起来的行显示出现，但是要想显示共有的以及一个文件有一个文件没有的行就需要涉及到外连接，分为左外链接和右外连接和全外连接。左外链接指除了显示在指定列上能够连接起来的行外，还要把左边文件有，右边文件没有的行显示出来，右外连接类似，全外连接是将左边和右边的都显示出来，不管有没有连接上设置左外连接：join -1 2 -2 3 -a 1 test1.txt test2.txt1 aa 2 aa 22 bb 3 bb 84 cc 6 ff 24 cc 6 cc 43 dd 3设置右外连接：join -1 2 -2 3 -a 2 test1.txt test2.txt1 aa 2 aa 22 bb 3 bb 84 cc 6 ff 24 cc 6 cc 45 dd 5设置全外连接：join -1 2 -2 3 -a1 -a2 test1.txt test2.txt1 aa 2 aa 22 bb 3 bb 84 cc 6 ff 24 cc 6 cc 43 dd 35 dd 5这个顺序好像有点错乱，不管是文件1还是文件2的内容都靠左显示，使用-o指定输出内容：join -1 2 -2 3 -a1 -a2 -o 1.{1..3} 2.{1..3} test1.txt test2.txtaa 1 2 aa 2 1bb 2 3 bb 8 2cc 4 6 ff 2 4cc 4 6 cc 4 4dd 3 3dd 5 5发现文件1的内容靠左，文件2的内容前面会留有3个空格（文件1每一行的长度），刚好错开-e 指定替代字符在上面设置左外链接和右外连接的情况下，使用-e设置字符来填充某个文件没有的行的信息:join -1 2 -2 3 -a 2 -o 1.{1..3} 2.{1..3} -e &quot;empty&quot; test1.txt test2.txtaa 1 2 aa 2 1bb 2 3 bb 8 2cc 4 6 ff 2 4cc 4 6 cc 4 4empty empty empty dd 5 5使用-e选项时必须也要设定-o选项，不然不能使用字符进行填充（可能是因为如-a参数使用中的不设置-o参数会使得结果显示出现问题，指定连接的列会在最左边显示，不能连接的行的内容不管是文件1还是文件2都会靠左显示，不能正确显示出内容和文件的对应关系）-v 显示未匹配行join -1 2 -2 3 -v 1 test1.txt test2.txt3 dd 3join -1 2 -2 3 -v 2 test1.txt test2.txt5 dd 5使用实战指定多个列来进行链接因为join命令只支持单个field的连接，而指定多个field作为连接列又非常常用，所以这里给出了几种解决方法：思路一：既然join命令只支持单个field的连接，那就把多个field转化为单个field进行连接即可将上述test1.txt的第1列和第2列与test2.txt的第1列和第3列进行连接：join -j 1 &lt;(awk &#39;{print $1&quot;-&quot;$2&quot;\t&quot;$0}&#39; test1.txt |sort -k 1,1) &lt;(awk &#39;{print $1&quot;-&quot;$3&quot;\t&quot;$0}&#39; test2.txt |sort -k 1,1)aa-1 aa 1 2 aa 2 1bb-2 bb 2 3 bb 8 2cc-4 cc 4 6 cc 4 4控制输出的时候可以使用-o参数对输出进行控制，来决定输出的内容思路二：通过处理其中一个文件得到匹配的fileds，然后利用grep命令在另一个文件中查找这个fields，得到最终的结果提取test1.txt的第1列和第2列作为pattern_file，在test2.txt文件中对齐进行查找：cut -d &#39; &#39; -f 1,2 test1.txt |grep -f - &lt;(awk &#39;{print $1,$3,$2}&#39; test2.txt )aa 1 2bb 2 8cc 4 4注意这个只能得到test2.txt中的内容，而且还必须得调整列的位置，使test2.txt中需要和pattern_file进行连接的列进行对应（pattern_file是第1、2列，那就需要把test2.txt的第3列换到第2列的位置，和pattern_file进行对应），不然不能查找结果。还可以使用awk命令进行操作，具体参考这个链接需要按照ascii来对key进行排序必须要按照ascii来对key进行排序才能进行join操作，即使是数字也要按照ascii排序，然后进行join，最后可以再选择将其结果按照数字进行排序：12345678910111213141516171819202122232425# 如果对按照数字排序的结果进行join会出现没排序的问题提示sort -k 2,2n sortchrM.uniq100bp.map.base |join -j 2 -o 1.&#123;1,2&#125; 2.3 - &lt;(sort -k 2,2n mapping_uniq_site_depth.txt) |more # 提示没有排序 join: file 1 is not in sorted order join: file 2 is not in sorted order chrM 4 78 chrM 5 83 chrM 6 179# 按照默认的ascii排序就是正常的sort -k 2,2 sortchrM.uniq100bp.map.base |join -j 2 -o 1.&#123;1,2&#125; 2.3 - &lt;(sort -k 2,2 mapping_uniq_site_depth.txt) |more chrM 10 358 chrM 100 3497 chrM 10007 2202 chrM 10019 2213 chrM 10025 2493# 先按照ascii排序连接，然后将结果按照数字排序sort -k 2,2 sortchrM.uniq100bp.map.base |join -j 2 -o 1.&#123;1,2&#125; 2.3 - &lt;(sort -k 2,2 /Share/home/wangjb/songyabing/projects/mt/data/LJ_mt_677_2/chrM/mapping_uniq_site_depth.txt) |sort -k 2,2n |more chrM 4 78 chrM 5 83 chrM 6 179 chrM 7 254 chrM 8 304 chrM 9 308参考链接Linux join命令linux下join命令的用法Linux命令——join命令linux: join]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sort-排序]]></title>
    <url>%2Fposts%2F61024.html</url>
    <content type="text"><![CDATA[本文学习sort-对文件进行排序，主要包括了sort用法(命令格式、参数说明)、用法实例(各种参数：-u、-n、-r、-k、-t、-o、-c、-h和-g等的实例讲解)并在最后给出了几个非常常用的实战示例。sort简介和用法sort命令是在Linux里非常有用，它将文件进行排序，并将排序结果标准输出sort命令既可以从特定的文件，也可以从stdin中获取输入sort命令格式12Usage: sort [OPTION] [FILE]sort options说明table th:first-of-type{width:15%}table th:nth-of-type(2){width:25%}table th:nth-of-type(3){width:60%}参数完整参数说明-b–ignore-leading-blanks忽略每行前面开始出的空格字符-d–dictionary-order排序时，处理英文字母、数字及空格字符外，忽略其他的字符-f–ignore-case排序时，将小写字母视为大写字母，亦即忽略大小写-g–general-numeric-sort按通用数值排序，支持科学计数法-i–ignore-nonprinting排序时，除了040至176之间的ASCII字符外，忽略其他的字符-M–month-sort将前面3个字母依照月份的缩写进行排序 (unknown) &lt; ‘JAN’ &lt; … &lt; ‘DEC’-m–merge将几个排序号的文件进行合并-h–human-numeric-sort使用易读性数字(例如： 2K 1G)-n–numeric-sort依照数值的大小排序-o–output=FILE将排序后的结果存入指定的文件-r–reverse降序排序，默认为升序-t–field-separator=SEP指定排序时所用的栏位分隔字符-k–key=POS1[,POS2]排序从POS1开始，若指定POS2，则POS2结束，否则以pos1排序-u–unique去除重复的行-c–check检查文件是否已经按照顺序排序sort用法实例使用默认方式对文件进行排序sort 命令将以默认的方式将文本文件的第一列以ASCII码的次序排列，并将结果输出到标准输出测试文件default.txt:cat default.txttest 30Hello 95Linux 25sort default.txtHello 95Linux 25test 30-u 去除重复行cat uniq.txttest 30Hello 95Linux 25Linux 25Linux 20文件中存在两行完全相同的信息，这将其去除:sort -u uniq.txtHello 95Linux 20Linux 25test 30会考察所有的列是否相同来进行去除，只有第一列相同是不会进行去除的-n 对数字进行排序cat num.txt102030110120210sort默认会把所有列当成字符来进行排序，因为1小于3，所以110小于20：sort num.txt101101202021030为了避免上述情况，需要使用-n选项，声明是数字进行排序，而不是字符：sort -n num.txt102030110120210-h-带单位地排序结合du命令使用：123456789du -ah . |sort -hr 518M . 259M ./backup/backup_test/B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart.test 259M ./backup/backup_test 259M ./backup 259M ./B2_FKDL190733335-1a-N702-N702_AHYYWCCCXY_L3_1.fq.gz.filepart 16K ./test1.txt 12K ./test2.txt 4.0K ./test.txt关于sort -n和-h参数的区别：-n选项，按数值进行比较，只会傻傻地比较数字，它会认为 98 K大于 2G-h选项，会更加聪明，先优先比较单位（G&gt;M&gt;K），然后再对数值进行比较-r 降序排列从上面的输出结果可以看出：sort默认进行的是升序排列，为了能够得到降序排列的结果，需要使用参数-r：sort -n -r num.txt 等价于 sort -nr num.txt210120110302010-k 指定排序开始(和结束)的位置-k选项的语法格式123FStart.CStart Modifie,FEnd.CEnd Modifier # 详细划分-------Start--------,-------End-------- # 整体划分FStart.CStart 选项 , FEnd.CEnd 选项 # 详细划分解读这个语法格式可以被其中的逗号,分为两大部分，Start部分和End部分Start部分也由两部分组成:Modifier部分是选项部分，可以用到b、d、f、i、n 或 r。FStart.CStart，其中FStart就是表示使用的域而CStart则表示在FStart域中从第几个字符开始算“排序首字符”。C.Start也是可以省略的，省略的话就表示从本域的开头部分开始同理，在End部分中，你可以设定FEnd.CEnd，如果你省略.CEnd，则表示结尾到“域尾”，即本域的最后一个字符。或者，如果你将CEnd设定为0(零)，也是表示结尾到“域尾”如果直接省略了End部分，则会直接从指定的开始位置到一行的结束进行排序实例cat salary.txtbaidu 100 5000sohu 100 4500google 110 5000guge 50 3000从公司英文名称（第一个域）的第二个字母开始进行排序：sort -k 1.2 salary.txtbaidu 100 5000sohu 100 4500google 110 5000guge 50 3000结果解读：使用了-k 1.2，表示对第一个域的第二个字符开始到本域的最后一个字符为止的字符串进行排序，结果是baidu因为第二个字母是a而名列榜首，sohu和 google第二个字符都是o，但sohu的h在google的o前面，所以两者分别排在第二和第三，guge只能排在第四了。只针对公司英文名称的第二个字母进行排序，如果相同的按照员工工资进行降序排序：sort -k 1.2 -k 3nr salary.txtbaidu 100 5000sohu 100 4500google 110 5000guge 50 3000可以发现这个与预期的结果并不一致，和没有按照员工工资进行降序排序的结果相同，所以命令肯定存在问题。首先，-k 3nr没有起作用，相当于只是用前面的-k 1.2就可以达到效果，事实上也正是如此，因为-k 1.2表示对第一个域的第二个字符开始到本域的最后一个字符为止的字符串进行排序，按照上一个示例的分析，可以将这些结果分开，所以就不存在上面所说的如果相同的按照员工工资进行降序排序，因此后面的排序也就没有了意义。随后基于此我做了一个测试，在最后一行增加”google 110 4500”，这样就存在了-k 1.2不能讲所有的分开是现象，依旧使用上面的命令进行排序：sort -k 1.2 -k 3nr salary.txtbaidu 100 5000sohu 100 4500google 110 4500google 110 5000guge 50 3000发现上述并没有按照我预定的-k 1.2不能讲所有的分开，然后就按照第二个指定的-k 3nr进行排序，然后我去google上搜索相关问题发现有个回答说对多行进行排序时需要指定sort keys的开始和结束，如果没指定结束就会在一直到一行的末尾结束（可能是因为第一个key是主key），不会考虑后面继续设置的key，基于此，做了测试：sort -k 1.2,1 -k 3nr salary.txtbaidu 100 5000sohu 100 4500google 110 5000google 110 4500guge 50 3000最终得到了正确的结果，使用-k 1.2,1是省略.CEnd，则表示结尾到“域尾”，同时吸取上面的教训，为了严谨期间，虽然第3列是最后一列，也直接加上sort key的结束位置：sort -k 1.2,1 -k 3,3nr salary.txt，结果和上面相同-k 3nr：表示在第3列上进行按数字的降序进行排列对不同的列进行不同的排序方式时尤其需要指定sort key的结束为止，如果不指定，会以第一个key设置的为主，忽略后续key的设置，这个在对不同的列分别依据ascii和数字进行排序中非常常见-t 指定field分隔符sort使用-t参数来指定分隔符，默认的分隔符为空格(包括空格和tab):cat sep.txtaaa:eeeccc:eeeddd:dddbbb:ccceee:bbbeee:aaa以:为分隔符，对第二列进行排序：sort -t : -k 2 sep.txteee:aaaeee:bbbbbb:cccddd:dddaaa:eeeccc:eee当然也可以指定列来判断重复与否，并进行删除：sort -t : -uk 2 sep.txteee:aaaeee:bbbbbb:cccddd:dddaaa:eee-o 输出到文件输出到文件也可以使用重定向&gt;进行操作，但是如果使用重定向想要写入原文件，这个时候不但写不进去，还把原文件清空了这个问题可以很好的使用-o参数解决，-o后面接原文件，即可将重排序的结果写入原文件-c 检查文件是否已经排序如果乱序，则输出第一个乱序的行的相关信息sort -c uniq.txtsort: uniq.txt:2: disorder: Hello 95使用实战对多行进行排序并进行去重示例文件：含有google共有三行，其中有两行1、2列是完全相同的，有一行是第一列是相同的：cat salary.txtbaidu 100 5000sohu 100 4500google 110 5000guge 50 3000google 110 4500google 120 4500对1、2列进行排序并删除在这两列上的重复行：sort -uk 1,2 salary.txtbaidu 100 5000google 110 5000google 120 4500guge 50 3000sohu 100 4500可以发现达到了目的只针对第一列来看：sort -uk 1 salary.txtbaidu 100 5000google 110 4500google 110 5000google 120 4500guge 50 3000sohu 100 4500这个并没有达到目的，和前面提到的-k选项中提到的一样，必须要指定终止位置，不然会比较整个行，这样最终结果是没有重复的，如果在上面文件中故意加一行重复的，还果真如此，比较的是整个行：cat salary.txtbaidu 100 5000sohu 100 4500google 110 5000guge 50 3000google 110 4500google 120 4500google 120 4500sort -uk 1 salary.txtbaidu 100 5000google 110 4500google 110 5000google 120 4500guge 50 3000sohu 100 4500增加终止位置，得到预期结果：sort -uk 1,1 salary.txtbaidu 100 5000google 110 5000guge 50 3000sohu 100 4500第一列相同的行中进行去重复保留的是原始文件中第一个出现的对文件大小进行排序-h：排序时使用易读性数字(例如： 2K 1G)统计目录下子目录的大小，并按大小进行降序排列：du -h |sort -hr # du -h统计目录下子目录的大小2.6G ./test22.6G . # 整个目录大小6.8M ./test4.0K ./test3系统进程内存占用排序-g：按通用数值排序，支持科学计数法ps aux |less -SUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDps aux|sort -gr -k 4|head -n 5|awk &#39;{print $2,$3,$4}&#39;10742 0.0 0.83916 99.5 0.7110870 99.5 0.4131268 99.5 0.366967 0.0 0.0参考链接linux sort 命令详解sort命令Linux sort命令]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串截取方法]]></title>
    <url>%2Fposts%2F43811.html</url>
    <content type="text"><![CDATA[字符串截取在平常的工作中非常常用，这里总结常用的截取方法，便于查阅和温习，主要包括：${}的字符串截取和正则匹配、cut命令的-c参数、awk的substr函数和FS内置参数以及expr的substr表达式使用${}进行截取${}是一种非常常用的linux特殊符号，一般来说共有五种不同的功能，具体的是哪五种功能，之前已经写过一篇博文，这里就不赘述了，这里主要用示例的形式讲解其中与字符串截取相关的两种功能：字符串截取和正则匹配替换。字符串截取${str:offest}：从字符串开头（左侧）下标offset(含)开始截取到末尾的子串${str:offest:length}：从字符串开头（左侧）下标offset(含)开始向后截取长度为length的子串，长度超出不报错${str:0-offset:length}：从字符串尾端（右侧）下标offset(含)开始以及向后截取长度为length的子串1234567891011121314str="http://showteeth.tech/posts/55603.html"# 截取从下标5到字符串结尾的子串，注意下标是从0开始的echo $&#123;str:0&#125;echo $&#123;str:1&#125;echo $&#123;str:5&#125;# 从下标5开始截取长度为10的子串echo $&#123;str:5:10&#125;# 字符长度超出不会报错echo $&#123;str:5:40&#125;# 从右数下标15开始截取长度为10的子串echo $&#123;str:0-15:10&#125;http://showteeth.tech/posts/55603.htmlttp://showteeth.tech/posts/55603.html//showteeth.tech/posts/55603.html//showteet//showteeth.tech/posts/55603.htmlosts/55603下标（offset）从0开始 （注意与使用awk的substr函数进行字符截取不同）${str:0-offset:length}是从字串右侧开始数坐标，然后和正常的一样，向后截取长度正则匹配替换${\#parameter}：获取变量长度${parameter#word}、${parameter##word}：从头开始扫描word(pattern)，将匹配word(pattern)的字符过滤掉，#为最短匹配，##为最长匹配${parameter%word}、${parameter%%word}：从尾开始扫描word(pattern)，将匹配word(pattern)的字符过滤掉，%为最短匹配，%%为最长匹配${parameter/pattern/string}、${parameter//pattern/string}：使用string替换pattern，/表示只替换一次；//表示全部替换1234567891011121314151617181920212223# 获取变量长度echo $&#123;#str&#125;# 从左边开始删除第一次出现子字符串即其左边字符，保留右边字符echo $&#123;str#*/&#125;# 从左边开始删除最后一次出现子字符串即其左边字符，保留符号最右边字符echo $&#123;str##*/&#125;# 从右边开始删除第一次出现子字符串即其右边字符，保留左边字符echo $&#123;str%/*&#125;# 从右边开始删除最后一次出现子字符串即其右边字符，保留最左边字符echo $&#123;str%%/*&#125;# 替换，只替换第一次出现的字符echo $&#123;str/\//%&#125;# 替换，所有匹配的都进行替换echo $&#123;str//\//%&#125;38/showteeth.tech/posts/55603.html55603.htmlhttp://showteeth.tech/postshttp:http:%/showteeth.tech/posts/55603.htmlhttp:%%showteeth.tech%posts%55603.html#在%的左边，所以#是从左向右删除字符，保留右边子串，而%是从右向左删除字符，保留左边字符一个#或%是匹配并删除第一次出现的pattern，而##或%%是匹配并删除最后一次出现的pattern（相当于贪婪匹配）上述的parameter都是可以不用引用的，因为${var}本来就和$var是一个意思使用awk进行截取使用awk中的substr函数，substr()用于从字符串中指定位置和长度截取出子串：12345usage： substr(s, i [, n]) s 待截取的字符串 i 索引位置，从1开始，按照字符计算、非字节 n 要截取的长度，默认或者填写长度超出字符尾，则截取到字符尾1echo $str |awk '&#123;print substr($str,5,10)&#125;'://showtee也可以使用awk指定输入分割符的方式截取：1echo $str |awk -v FS="/" '&#123; print $3 &#125;'注意这里与使用${}进行字符串截取不同，这里字符的索引开始为1，而上面${}索引开始位置为0FS是awk内置的系统变量，表示域分隔符，默认为空白字符（空格），使用时需要结合-v来传递参数使用cut进行截取直接通过范围得到子串：cut命令的-c参数：仅显示行中指定范围的字符1echo $str |cut -c 2-6ttp:/注意这里与使用${}进行字符串截取不同，与使用awk的substr函数进行字符截取相同，这里字符的索引开始为1，而上面${}索引开始位置为0cut -c 后面接的是index的起始和终止范围，而不是像前面的awk和${}一样是index和length的组合利用cut按分割符分割来得到子串：cut命令的-d参数：指定字段的分隔符，默认的字段分隔符为”TAB”cut命令的-f参数：指定需要显示的字段1echo $str |cut -d / -f 3showteeth.techcut命令的-d和-f参数合用主要用于得到被已知分隔符分割的一块子串使用expr进行截取expr用于计算表达式变量的值，其中有表达式：substr String StartPosition Length，表示从String的StartPosition开始截取Length的子串1expr substr $str 2 6ttp://注意每个单词之间都有空格，不带空格会出错索引位置也是从1开始，和awk的substr函数、cut命令的-c参数相同，和${}不同使用总结一般最为常用的是${}的正则匹配替换方法(保留字符串最左或者最右的子串)，同时awk和cut使用的也非常多使用需要提供索引位置的方法时需要注意索引的开始位置：awk的substr函数、cut命令的-c参数还有expr的substr表达式索引都是从1开始${str:offest:length}方法的索引则开始于0${}、cut命令的-c参数以及awk的FS内置参数都是用于通过已知分割符得到相应的一块子串，而不是具体地通过索引位置]]></content>
      <categories>
        <category>Linux</category>
        <category>常用内容总结</category>
      </categories>
      <tags>
        <tag>常用内容总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[整数计算、浮点计算并保留小数]]></title>
    <url>%2Fposts%2F28430.html</url>
    <content type="text"><![CDATA[在linux中进行整数计算、浮点计算并保留小数，主要包括：使用expr进行整数运算以及简单的字符串操作、let、(( ))、$(())与declare -i、$[]进行整数运算、使用bc进行浮点运算和进制转换以及使用awk进行浮点运算。整数运算shell中默认的操作都是字符操作，如果想要进行数学运算，简单的shell操作可能得不到预期的结果：a=1b=1echo $a + $b1 + 1所以为了执行数学计算就需要有专门的命令来进行操作，以下介绍几种常用的命令和特殊符号。expr 整数或字符串表达式计算expr语法：1expr 表达式表达式说明:expr只能用于整数计算用空格隔开每个项用/(反斜杠)放在shell特定的字符前面对包含空格和其他特殊字符的字符串要用引号括起来整数计算类别语法说明四则运算expr1 \| expr2如果 expr1 不是零或 null 则传回 expr1，否则传回 expr2expr1 \&amp; expr2如果 expr1 及 expr2 都不为零或 null，则传回 expr1，否则传回 0四则运算expr1 + expr2传回 expr1 加 expr2 后的值expr1 - expr2传回 expr1 减 expr2 后的值expr1\* expr2传回 expr1 乘 expr2 后的值expr1 / expr2传回 expr1 除 expr2 后的整数位值（小数位直接丢弃，不四舍五入）expr1 % expr2传回 expr1 除 expr2 的余数大小判断expr1 \&gt; expr2如果 expr1 大于 expr2 则传回 1，否则传回 0。如果 expr1 及 expr2 都是数字，则是以数字大小判断，否则是以文字判断。以下皆同expr1 \&lt; expr2如果 expr1 小于 expr2 则传回 1，否则传回 0expr1 = expr2如果 expr1 等于 expr2 则传回 1，否则传回 0expr1 != expr2如果 expr1 不等于 expr2 则传回 1，否则传回 0expr1 \&gt;= expr2如果 expr1 大于或等于 expr2 则传回 1，否则传回 0expr1 \&lt;= expr2如果 expr1 小于或等于 expr2 则传回 1，否则传回 0123456789expr 2+3expr 2 + 3expr 2 * 3expr 2 \* 3expr 5 / 3expr 2 % 32+3 # 2和3之间没有空格，直接被输出，没有进行计算5 # 输出正确结果expr: syntax error # 因为没有对*进行转义，所以报错6 # 转义后输出正确结果1 # 直接去掉余数，不进行四舍五入2 # 输出余数字符串表达式计算因为expr用于字符串计算并不常见，所以这里不仔细了解，只了解几个个人感觉比较常用的，需要了解的可以参考这篇博客计算字串长度(length)：1expr length "this is a test"14截取子串(substr)：12# substr String StartPosition Lengthexpr substr "this is a test" 3 5is is匹配第一个字符(串)出现的位置(index)：1expr index "this is a test" is3注意四则运算中的*需要进行转义处理，同时还有条件判断中的| &amp;和大小判断中的&gt; &lt;都需要进行转义处理let-运算并赋值let 命令是 BASH 中用于计算的工具，用于执行一个或多个表达式，变量计算中不要加上 $ 来表示变量(否则会报错)。如果表达式中包含了空格或其他特殊字符，则必须引起来(可以看出来与expr命令每个都需要空格隔开不同，let命令最好不要有空格)。自加操作：let no++自减操作：let no--简写形式 let no+=10，let no-=20，分别等同于 let no=no+10，let no=no-20let var +=1 //存在空格但是不带引号会报错-bash: let: +=1: syntax error: operand expected (error token is “+=1”)let “var +=1” //增加引号即可echo $var2let $var+=1 //加上 $ 来表示变量会报错-bash: let: 2+=1: attempted assignment to non-variable (error token is “+=1”)let var+=1 //不加 $ 正常echo $var3a=1b=2let c=a+b //赋值操作echo $c3(( )) 执行计算和linuxlet指令相似，比let命令好的方面是可以在括号内加空格，不会报错123456789101112# 自加操作a=5;b=7((a--));echo $a# 用在for循环中for ((i=0;i&lt;5;i++));do echo $i;done# 赋值((c=b+1))# 加空格(( c = b + 1 ))$(())与declare -i 整数运算12declare -i total=$firstnu*$secnutotal=$(($firstnu*$secnu))区别就是小方括号内可以加上空格符，也是合法的写法，而declare -i 不可以：12345678910111213# 正确的写法declare -i total=2*3# 不正确的写法（加了空格），total=2* 3任何一处存在空格都不可以declare -i total=2* 3# 换用$(())，注意等号和计算公式之间不能存在空格，不然也会报错total=$((2*3))# $(())内的变量可以直接使用变量名称，也可以通过引用的方式获取a=5;b=7;c=2echo $((a+b*c))echo $(($a+$b*$c))declare -i加空格报错：bash: declare: 2: syntax error: operand expected (error token is ““)$(())在等号左右加空格报错：bash: 6: command not found$(())进制转化：将其他进制转成十进制数显示出来12# N为进制，xx为该进制下某个数值，命令执行后可以得到该进制数转成十进制后的值echo $((N#xx))$[]运算a=1echo $[a+1]2echo $[c=a+1]2 //会先输出运算的结果echo $c2 //也会赋值浮点计算并保留小数bcbc命令是任意精度计算器语言，通常在linux下当计算器用, 它类似基本的计算器, 使用这个计算器可以做基本的数学运算。常用的运算：+ 加法- 减法* 乘法/ 除法^ 指数% 余数sqrt 开方语法：1bc (选项) (参数)在shell中直接输入bc即可进入交互式界面，类似于没有图形界面的计算器，输入表达式得到结果具体用法不详细讲解，可以参考这篇博客实际进行浮点运算常用的方法是通过管道符：1234usage: echo 'scale=num; expression'|bc num：表示保留的小数点后位数 expression：表示计算表达式1echo 'scale=2;2/3' |bc.66可以发现上述输出结果中并没有0(因为结果小于0)，如果想要显示可以使用：1echo 'scale=2;a=2/3;if( length(a) == scale(a) ) print 0;print a ,"\n"' |bc0.66bc还能用来进行进制的转换：123456usage： echo "obase=base;ibase=base;num" | bc obase:输出数字的进制，默认值为10 ibase:输入数字的进制，默认值为10 num:进行进制转换的数字 obase一定要放在ibase前，因为ibase设置后，后面的数字都是以ibase的进制来换算的obase如果放在ibase后可能会出错：1234# obase一定要放在ibase前，因为ibase设置后，后面的数字都是以ibase的进制来换算的echo "obase=10;ibase=2;110" | bcecho "ibase=2;obase=10;110" | bc6110awkawk中的计算，默认支持浮点运算：1echo |awk '&#123;print 2/3&#125;'格式化输出：12# 保留两位小数echo |awk '&#123;printf("%.2f\n" , 3/50)&#125;']]></content>
      <categories>
        <category>Linux</category>
        <category>常用内容总结</category>
      </categories>
      <tags>
        <tag>常用内容总结</tag>
        <tag>shell编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux中特殊符号用法]]></title>
    <url>%2Fposts%2F55603.html</url>
    <content type="text"><![CDATA[Linux常见特殊符号作用，包括#、~、~+、~-、;、;;、.、&#39;&#39;、&quot;&quot;、`、,、/、\、|、!、:、*、**、$、$$、?、${}、$*、$@、$#、$(())、(())、()、{}、[]、[[]]、|| 、&amp;&amp;、\&lt;...\&gt;和文件操作符以及重定向。#号-注释在脚本中 #也常出现在一行的开头,或者位于完整指令之后,这类情况表示符号后边是注解文字,不会被执行，如果被用在指令中，或者引号、双引号括住的话，或者在反斜线的后面，那他就变成一般符号，不具上述的特殊功能。123#!/bin/bash#this line is comments~ home目录代表使用者的home目录：cd ~表示进入home目录；也可以直接在符号后加上某帐户的名称：cd ~user表示进入这个user的home目录；或者当成是路径的一部份：~/bin~+表示当前的工作目录~-表示上一个工作目录，这个在目录切换很好用啊，cd ~-直接进入上一次cd之前的目录123456789# 当前工作目录pwdecho ~+# 进入上一次cd之前的目录cd ~-# 进入上一次cd之前目录下的test目录cd ~-/test/; 分号连续命令之间起到连接作用，命令之间没有依赖，不管上一条命令是否执行成功，分号后的命令都会执行。;;连续分号专用在case（多分支条件判断）的选项，担任 Terminator 的角色. 点号(dot)在目录中：一个.表示当前目录，两个..表示上层目录在文件命名中：以.开头的文件表明该文件是隐藏文件，需要使用ls -a才能看到在正则表达式中：一个逗号表示一个任意字符（换行符 \n 之外），如果想要匹配.，需要使用转义\.。‘’ 单引号被单引号用括住的内容，将被视为单一字串，其不允许任何变量、元字符、通配符、转义符的解析，例如在引号内的代表变量的$符号，没有作用，也就是说，他被视为一般符号处理，防止任何变量替换。12345test="hello"echo '$test'test="HELLO"echo "hello WORLD" |sed 's/hello/$test/'输出结果：$test$test WORLD“” 双引号被双引号用括住的内容，将被视为单一字串，其能保护特殊元字符和通配符不被shell解析，但是允许变量和命令替换，以及转义符的解析，这点与单引号的处理方式不同。12345test="hello"echo "$test"test="HELLO"echo "hello WORLD" |sed "s/hello/$test/"输出结果：helloHELLO WORLD`` 反引号在前面的单双引号，括住的是字串，但如果该字串是一列命令列，会怎样？答案是不会执行。要处理这种情况，我们得用反引号来做，被反引号括住的内容是可以执行的。与反引号相同可以用来进行命令执行的还有$()，两者的区别在于如果是使用反引号执行命令在进行命令嵌套时会比较麻烦，而使用$()进行命令的嵌套会比较简单。12test="hello"echo `echo $test`等同于：1echo $(echo $test)命令嵌套：1echo $(echo $(echo $test))不等同于：1echo `echo `echo $test``反引号遇到第一个匹配的反引号就结束，之间的内容会当做命令运行，可以使用转义字符\解决嵌套问题等同于：1echo `echo \`echo $test\``所以还是使用$()来得到命令执行结果更为简便，但是不需要嵌套时两者差不多, 逗号这个符号常运用在运算当中当做区隔用途。1awk '&#123;print $1,$2,$3,$4&#125;' filename/ 斜线在路径表示时，分割不同级别的目录单一的斜线/表示根目录，和上面的~表示的家目录不同在四则运算中，代表除法的符号\ 反斜线在交互模式下的escape字元，有几个作用放在指令前，有取消 aliases的作用；放在特殊符号前，则该特殊符号的作用消失（转义）；放在指令的最末端，表示指令连接下一行。12345678# ls -lll# 取消ll代表ls -l，在ll之前防止反斜线表示暂时取消别名的功能，将 ll 指令还原\ll# 转义，取消变量应用\$test最终ll结果输出：bash: ll: command not found| 管道符连结上个指令的标准输出，做为下个指令的标准输入。! 惊叹号通常它代表反逻辑的作用，如!=表示不等于匹配模式取反：sed -n &#39;1,2!p&#39; test.txt表示打印第1、2行之外的行；ls a[!0-9]表示显示除了a0, a1 …. a9 这几个文件的其他文件在历史命令（history）中：!number ：表示执行history中第number条命令!!：表示执行上一条命令!command：执行最近一条command为开头的命令!$：表示最近一条命令的第二个字符信息12mkdir test!!输出结果：mkdir testmkdir: cannot create directory `test’: File exists12mkdir test!$输出结果：test: 冒号在 bash 中，这是一个内建指令：”什么事都不干”，但返回状态值 0: &gt; f：相当于cat/dev/null&gt;f，这样不仅写法简短了，而且执行效率也好上许多: ${HOSTNAME?} ${USER?} ${MAIL?}这行的作用是，检查这些环境变数是否已设置，没有设置的将会以标准错误显示错误讯息。像这种检查如果使用类似 test 或if这类的做法，基本上也可以处理，但都比不上上例的简洁与效率。(这个具体还没试验过)添加环境变量时需要使用:分割，比如PATH=$PATH:$HOME/fbin:$HOME/fperl:/usr/local/mozilla* 星号在文件名扩展(Filename expansion)上，用来代表0到无穷多个任意字符在正则表达式（Regular Expressions）中，代表重复零个到无穷多个的前一个字符，而代销0到无穷多个任意字符是使用.*。在运算时，它则代表 “乘法”*在不同地方不同的用法需要注意，尤其是代表0到无穷多个任意字符、重复零个到无穷多个的前一个字符这方面。** 次方运算两个星号在运算时代表 “次方” 的意思。$和$$引用变量的前导符号，如var=&quot;test&quot; echo $var在正则表达式里被定义为行的最末端 (end-of-line)，这个常用在grep、sed、awk 以及 vim(vi) 当中在bash中$本身也是个变量。代表的是目前这个shell的进程代码，即所谓的PID（Process ID）$$ Shell本身的PID（ProcessID）$! Shell最后运行的后台Process的PID$? 最后运行的命令的结束代码（返回值），一般指令程序倘若执行成功，其回传值为 0，失败为 1。其他参考该博客$后接引号（单双引号），单引号可以使引号内的内容被特殊对待：会将某些反斜线序列(如\n，\t，\&quot;，\&#39;等)继续转义(\t-&gt;tab;\n-&gt;换行)，而不认为它是字面符号(如果没有$符号，单引号会强制将string翻译为字面符号，包括反斜线)；而双引号则没有上述效果，$&quot;string&quot;和&quot;string&quot;是完全等价的，使用$&quot;&quot;只是为了保证本地化echo &#39;a\nb&#39;a\nb上述结果并没有和预期的一样在a、b之间进行换行，这是因为单引号中的\n被看成了字面意思，就是反斜线加上n，而不是特殊的换行的意思如果在前面加上$：echo $&#39;a\nb&#39;ab这个结果和预期的一样，因为$将\n翻译成了换行，而不是单纯的反斜线加上n，这个在join命令指定分隔符时会用到，具体参考介绍join用法的文章如果将上述单引号转换为双引号：echo $&quot;a\nb&quot;a\nb发现在使用双引号的情况下，得到的结果和没使用$是一样的，这和前面说的$&quot;string&quot;和&quot;string&quot;是完全等价的是相符的。常见的需要注意使用$和单引号的转义字符包括：123456789101112\a alert (bell)\b backspace\e\E an escape character\f form feed\n new line\r carriage return\t horizontal tab\v vertical tab\\ backslash\' single quote\" double quote? 问号在文件名扩展(Filename expansion)上扮演的角色是匹配一个任意的字符，但不包含空字符，注意是一个字符，不能是0个也不能是两个，注意和正则表达式的用法区分。比如：ls a?c.txt可以得到abc.txt和amc.txt 但是不能得到abbc.txt，也不能得到ac.txt在正则表达式式中，?表示匹配前面的字符0次或1次，不是任意字符，注意和文件名拓展的区分。同时在正则表达式中还可以用来表示非贪婪匹配在bash中，这个变量是上一个执行的命令所回传的值。当我们执行某些命令时，这些命令都会回传一个执行后的代码，一般说，如果成功执行该命令，则会回传一个0值，如果执行过程发生错误，就会回传错误代码，一般以非0的数值来替代${} 变量的正规表达式一般情况下，$var与${var}是没有区别的，但是用${}会比较精确的界定变量名称的范围1234# 这个明确说明了var才是变量$&#123;var&#125;_suffix$var_suffix${} 参数替换${var_name} 等价于$var_name（通常用这种简写方式）$(var:-default) 和 $(var-default)$(var:-default)：当var为空或未定义时整个表达式的值为default$(var-default)：当且仅当var未定义时整个表达式的值为default$(var:=default) 和 $(var=default)$(var:=default)：当var为空或未定义时整个表达式的值为default，并且将var的值设置为default$(var=default)：当且仅当var未定义时整个表达式的值为default，并且将var的值设置为default$(var:?default) 和 $(var?message)$(var:?message)：当var为空或未定义时，打印错误信息，信息内容为message表示的值$(var?message)：当且仅当var未定义时，打印错误信息，信息内容为message表示的值$(var:+default) 和 $(var+default)$(var:+default)：当var已定义且不为空时整个表达式的值为default$(var+default)：当var已定义时整个表达式的值为default(不管var是否是空)${} 字符串截取${str:offest}：从下标offset(含)开始截取到末尾的子串${str:offest:length}：从下标offset(含)开始向后截取长度为length的子串，长度超出不报错${str:offest:index}：${} 变量匹配${!prefix*}、${!prefix@}：将带有前缀为prefix的变量名打印出来${} 数组操作${!name[@]}、${!name[*]}：将数组name的所有下标返回，如果变量name不是数组则返回0,不存在则空${name[@]}、${name[*]}：将数组name的所有元素返回，如果变量name不是数组则返回name的值,不存在则空${\#name[@]}、${\#name[*]}：返回数组元素总个数${name[index]}：将数组name的index处的元素返回，如果变量name不是数组且index为0时返回name的值，变量或索引index处的元素不存在则返回空${\#name[index]}：返回数组name的index处的元素长度name[index]=xyz：数组name的index处的元素重新赋值上面的${\#name[@]}中对#做了转义处理，不然博客可能报错，参考github issue，正常情况下使用时不用加\进行转义。${} 正则匹配替换${parameter#word}、${parameter##word}：从头开始扫描word(pattern)，将匹配word(pattern)的字符过滤掉，#为最短匹配，##为最长匹配${parameter%word}、${parameter%%word}：从尾开始扫描word(pattern)，将匹配word(pattern)的字符过滤掉，%为最短匹配，%%为最长匹配${parameter/pattern/string}、${parameter//pattern/string}：使用string替换pattern，/表示只替换一次；//表示全部替换${\#parameter}：获取变量长度上述的parameter都是可以不用引用的，因为${var}本来就和$var是一个意思$* 得到脚本变量$*引用script的执行引用变量，引用参数的算法与一般指令相同，script本身为0，其后第一个为1，然后依此类推。引用变量的代表方式如下：$0, $1, $2, $3, ${10}, ${11}，注意个位数的，可直接使用数字，但两位数以上，则必须使用 {} 符号来括住。$* 则是代表所有引用变量的符号，使用时得视情况加上双引号，如echo &quot;$*&quot;12bash example.sh var1 var2 var3# $0是example.sh、$1是var1、$2是var2、$3是var3$@ 得到脚本变量$* 和 $@ 都表示传递给函数或脚本的所有参数，不被双引号(“ “)包含时，都以&quot;$1&quot; &quot;$2&quot; … &quot;$n&quot; 的形式输出所有参数但是当它们被双引号(“ “)包含时，&quot;$*&quot; 会将所有的参数作为一个整体，以&quot;$1 $2 … $n&quot;的形式输出所有参数；&quot;$@&quot; 会将各个参数分开，以&quot;$1&quot; &quot;$2&quot; … &quot;$n&quot; 的形式输出所有参数也就是说$@不管有没有被双引号包围，其输出结果都是单个的变量形式，而$*在不被双引号包围时输出单个变量的形式，被双引号包围时，所有的参数以整体的形式输出$# 变量总数12# 输出变量总数echo "$#"$(())与declare -i 整数运算12declare -i total=$firstnu*$secnutotal=$(($firstnu*$secnu))区别就是小方括号内可以加上空格符，也是合法的写法，而declare -i 不可以：12345678910111213# 正确的写法declare -i total=2*3# 不正确的写法（加了空格），total=2* 3任何一处存在空格都不可以declare -i total=2* 3# 换用$(())，注意等号和计算公式之间不能存在空格，不然也会报错total=$((2*3))# $(())内的变量可以直接使用变量名称，也可以通过引用的方式获取a=5;b=7;c=2echo $((a+b*c))echo $(($a+$b*$c))declare -i加空格报错：bash: declare: 2: syntax error: operand expected (error token is ““)$(())在等号左右加空格报错：bash: 6: command not found$(())进制转化：将其他进制转成十进制数显示出来12# N为进制，xx为该进制下某个数值，命令执行后可以得到该进制数转成十进制后的值echo $((N#xx))(( )) 执行计算和linuxlet指令相似1234a=5;b=7((a--));echo $afor ((i=0;i&lt;5;i++));do echo $i;done( ) 指令群组用括号将一串连续指令括起来，这被称为指令群组指令群组有一个特性，shell会以产生subshell来执行这组指令，因此，在指令群组所定义的变量，仅作用于指令群组本身：12test="test"(cd ~ ; test=`pwd` ;echo $test);echo $test最终结果：/home/usrtest( )也可被用于数组的声明中：1Array=(element1 element2 element3){ } 大括号作为代码块代码块，又被称为内部组，这个结构事实上创建了一个匿名函数。与上面小括号中的指令群组不同，花括号内的命令不会新开一个子shell运行，即脚本余下部分仍可使用括号内变量，因此，这样写 script也是相当好的一件事。尤其对输出输入的重导向上，这个做法可精简 script 的复杂度。括号内的命令间用分号隔开，最后一个也必须有分号。{}的第一个命令和左括号之间必须要有一个空格。12345678# 第一个命令和左括号之间没有空格&#123;cd ~ ; test=`pwd` ;echo $test&#125;;echo $test# 最后一个命令没有分号&#123; cd ~ ; test=`pwd` ;echo $test&#125;;echo $test# 正确用法&#123; cd ~ ; test=`pwd` ;echo $test;&#125;;echo $test第一个命令和左括号之间没有空格报错：bash: {cd: command not found/home/user/test}/home/user/test最后一个命令没有分号报错：> ^C正确输出：/home/user/home/user作为拓展通配(globbing)将对花括号中的文件名做扩展。在大括号中，不允许有空白，除非这个空白被引用或转义。对大括号中的以逗号分割的文件列表进行拓展。如 touch {a,b}.txt 结果为a.txt b.txt对大括号中以点点（..）分割的顺序文件列表起拓展作用，如：touch {a..d}.txt 结果为a.txt b.txt c.txt d.txt对大括号中以点点（..）分割的顺序文件列表起拓展作用，如 for i in {1..2};do echo $i;done 结果为1 2进行组合大括号{}里面的内容以逗号分隔，两个或多个大括号内的内容进行组合。12345# 3x3的组合，中间的短横线是分割线，可以自定义mkdir &#123;userA,userB,userC&#125;-&#123;home,bin,data&#125;# 进行嵌套使用chown root /usr/&#123;ucb/&#123;ex,edit&#125;,lib/&#123;ex?.?*,how_ex&#125;&#125;[ ] 中括号在通配符和正则表达式中[]代表一定有一个在中括号内的字符，例如[abcd]代表一定有一个字符，可能是a、b、c、d这四个任何一个，[num1-num2]表示范围、[^]表示非流程控制中，扮演括住判断式的作用，[]中可用的比较运算符只有==和!=，两者都是用于字符串比较的，不可用于整数比较，整数比较只能使用-eq，-gt这种形式。无论是字符串比较还是整数比较都不支持大于号小于号。如果实在想用，对于字符串比较可以使用转义形式，如果比较&quot;ab&quot;和&quot;bc&quot;：[ ab &lt; bc ]，结果为真，也就是返回状态为0。[ ]中的逻辑与和逻辑或使用-a 和-o 表示在一个array结构的上下文中，中括号用来引用数组的索引[[ ]] 双中括号这组符号与先前的 [] 符号，基本上作用相同，但是&amp;&amp;、||、&lt;和&gt; 操作符能够正常存在于[[ ]]条件判断结构中，但是如果出现在[ ]结构中的话，会报错。支持字符串的模式匹配，使用=~操作符时甚至支持shell的正则表达式，字符串比较时可以把右边的作为一个模式，而不仅仅是一个字符串，比如[[ hello == hell? ]]，结果为真。[[ ]]中匹配字符串或通配符，不需要引号1234567891011[root@localhost ~]# [[ 2\&lt;3 ]] &amp;&amp; echo true || falsetrue[root@localhost ~]# [[ 2 -lt 3 ]] &amp;&amp; echo true || falsetrue[root@localhost ~]# [[ 2 \&lt; 3 ]] &amp;&amp; echo true || false-bash: 期待二元条件运算符-bash: `\&lt;' 附近有语法错误，这是因为空格的原因[root@localhost ~]# [ 2 \&lt; 3 ] &amp;&amp; echo true || falsetrue[root@localhost ~]# [ 2 &lt; 3 ] &amp;&amp; echo true || false-bash: 3: 没有那个文件或目录|| 逻辑符号在中括号中[]代表 or 逻辑的符号在命令行中：cmd1||cmd2若cmd1执行完毕且正确执行($?=0)，则cmd2不执行若cmd1执行完毕且为错误($?≠0)，则开始执行cmd2&amp;&amp; 逻辑符号在中括号中[]代表 and 逻辑的符号在命令行中如下:cmd1&amp;&amp;cmd2若cmd1执行完毕且正确执行（$?=0）,则开始执行cmd2若cmd1执行完毕且为错误（$?≠0），则cmd2不执行12# 如果./symbol/abc目录不存在则创建这个目录，成功后在目录下创建hehe文件ls ./symbol/abc || mkdir ./symbol/abc &amp;&amp; touch ./symbol/abc/hehe目录不存在，ls的报错信息ls: cannot access ./symbol/abc: No such file or directory\&lt;…\&gt; 单字边界这组符号在规则表达式中，被定义为”边界”的意思。12# 删除能完整匹配This这个单词的行sed '/\&lt;This\&gt;/d' test.txt文件操作符合输出/输入重定向&gt;：表示重定向&amp;：表示等同于的意思文件描述符是和文件的输入、输出相关联的非负整数，Linux内核（kernel）利用文件描述符（file descriptor）来访问文件。打开现存文件或新建文件时，内核会返回一个文件描述符。读写文件也需要使用文件描述符来指定待读写的文件。常见的文件描述符是stdin、stdout和stderr。常用的文件描述符如下：文件描述符名称常用缩写默认值0标准输入stdin键盘1标准输出stdout屏幕2标准错误输出stderr屏幕在简单地用&lt;或&gt;时，相当于使用 0&lt; 或 1&gt;，注意文件描述符和重定向符号之间不能存在空格，同时也可以将&gt;改为&gt;&gt;追加而不是覆盖文本信息cmd &gt; file等同于cmd 1&gt; file：把cmd命令的输出重定向到文件file中，如果file已经存在，则覆盖原有文件cmd &gt;&gt; file等同于cmd 1&gt;&gt; file：把cmd命令的输出重定向到文件file中，如果file已经存在，则把信息加在原有文件后面cmd &lt; file等同于cmd 0&lt; file：使cmd命令从file读入，必须是文件，不能是字符cmd &lt;&lt; text等同于cmd 0&lt;&lt; text：从命令行读取输入，直到一个与text字符相同的行结束cmd 2&gt; file：把cmd命令的标准错误输出重定向到文件file中，如果file已经存在，则覆盖原有文件cmd 2&gt;&gt; file：把cmd命令的标准错误输出重定向到文件file中，如果file已经存在，则把信息加在原有文件后面cmd &gt;&amp;n等同于cmd 1&gt;&amp;n：把输出重定向到文件描述符n，通过对&amp;的解读：标准输出的重定向等同于文件描述符ncmd m&gt;&amp;n ：把输出到文件符m的信息重定向到文件描述符n从命令行读取输入：1cat &lt;&lt; wang &gt; haha.txt从命令行得到输入，直到出现wang为止cat &lt;&lt; wang &gt;haha.txt> test> test2> wangcmd &lt;&lt;&lt; word：将word(字符)，注意不是上面的file读入标准错误输出：123456789101112# test.file不存在，没有任何错误提示，正常运行cat test.file 2&gt; out.txt # 与上面的方法结果相同，错误的信息都被输入到了out.txt中cat test.file &amp;&gt; out.txt# 将错误输出丢弃到/dev/null中，/dev/null是一个特殊的设备文件，这个文件接受到任何数据都会被丢系，通常被称为位桶、黑洞cat test.file 2&gt; /dev/null# 将标准输出重定向大list.txt文件中，标准错误输出重定向到list.err文件中cat test.file 1&gt; list.txt 2&gt; list.err将标准错误stderr与stdout一同重定向到test.log文件:12# 将标准输出重定向到test.log中，然后文件描述符2（标准错误输出）的重定向等同于文件描述符1（标准输出）./test.sh &gt;test.log 2&gt;&amp;1文件描述符支持自定义，参考文章实战总结得到数字用于循环的方法汇总1234567for i in `seq 1 5`;do echo $i ;donefor i in $(seq 1 5);do echo $i ;donefor ((i=1;i&lt;6;i++));do echo $i ;donefor i in &#123;1..5&#125; ;do echo $i ;done转义字符总结有时候，我们想让通配符或者元字符变成普通字符，不需要使用它，那么这里我们就需要用到转义符了，shell提供转义符有三种：字符说明‘’(单引号)又叫硬转义，其内部所有的shell 元字符、通配符都会被关掉。注意，硬转义中不允许出现’(单引号)“”(双引号)又叫软转义，其内部只允许出现特定的shell 元字符：$用于参数代换 `用于命令代替\(反斜杠)又叫转义，去除其后紧跟的元字符或通配符的特殊意义参考链接linux 特殊符号大全Linux命令中特殊符号，排版更好看Linux中的特殊符号及含义linux中特殊符号用法字符分类很好]]></content>
      <categories>
        <category>Linux</category>
        <category>常用内容总结</category>
      </categories>
      <tags>
        <tag>常用内容总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[每日总结和计划]]></title>
    <url>%2Fposts%2F51961.html</url>
    <content type="text"><![CDATA[2019-2-24开始的每日学习总结与计划.tg{border-collapse:collapse;border-spacing:0;border-color:#999}.tg td{font-family:Arial,sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#999;color:#444;background-color:#f7fdfa}.tg th{font-family:Arial,sans-serif;font-size:14px;font-weight:400;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#999;color:#fff;background-color:#26ade4}.tg .tg-phtq{background-color:#d2e4fc;border-color:inherit;text-align:left;vertical-align:top}.tg .tg-hmp3{background-color:#d2e4fc;text-align:left;vertical-align:top}.tg .tg-baqh{text-align:center;vertical-align:top}.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}.tg .tg-0lax{text-align:left;vertical-align:top}2019-2-24今日学习完成情况类别学习内容大致描述大概用时 Linux常用基本命令-sed学习了基本语法、掌握了选项i、n、e、f以及命令s、p、g2小时 Python 机器学习 其他内容markdown完成了markdown基本语法的学习3个小时今日学习情况总结：首先是学习了markdown基本语法，收获了很多，比如html块元素是必须要进行留空白行的、有序列表前的数字不关键、创建表格以及进行相应的优化（还不够完善）等新内容；也开始学习了linux基本命令sed，对其使用有了基本的了解，明天还要接着学习！明日学习哪些内容明日学习计划总览：markdown表格的优化（宽度调整）shell中特殊符号的学习sed命令的学习2019-2-25今日学习完成情况类别学习内容大致描述大概用时 Linux常用基本命令-sed完成了sed的学习大概3个小时 Python 机器学习 其他内容今日学习情况总结：今天主要是完成了sed命令的学习，学习过程中发现sed和之前学的其他命令如awk、grep等有很多相似之处，有了之前的基础学起来更加容易理解，果然是学的越多学得越快！！！通过对sed命令的学习，在以后处理文本时就又增加了一个非常有力的工具！每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：shell中特殊符号的处理~~markdown表格的优化（宽度调整）开始学习师兄安排的任务2019-3-17今日学习完成情况类别学习内容大致描述大概用时 Linuxshell编程完成了shell编程数组的学习2个小时 Python 机器学习 其他内容今日学习情况总结：今天主要学习了shell数组的相关操作，shell数组相对比较简单，同时也只支持一维数组，具有一定的局限性。每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章开始学习师兄安排的任务2019-3-18今日学习完成情况类别学习内容大致描述大概用时 Linux Python其他技巧整理常用程序块、常见错误、main函数的理解2个小时 机器学习 其他内容今日学习情况总结：今天主要是在完成师兄交代的任务，同时也Python相关内容进行了整理，包括常见错误、常用程序块以及之前学习过的main函数的理解每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章学习参数传递，然后修改重构项目文件2019-3-19今日学习完成情况类别学习内容大致描述大概用时 Linux Python常用模块argparse-解析命令行参数一天 机器学习 其他内容今日学习情况总结：今天主要是学习了Python用于命令行参数传递的模块argparse，在学习的过程中发现Python官方库的讲解非常详细，会先给出示例，然后对齐进行详细的讲解，我也比较喜欢这种讲解模式，以后可以多看看，学习学习，同时也发现了比较炫酷的方面就是子命令的使用。每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章完成师兄的交代的项目完成图床的搭建2019-3-20今日学习完成情况类别学习内容大致描述大概用时 Linux Python 机器学习 其他内容博客完善基于阿里云搭建了图床，基本抛弃了七牛云3个小时今日学习情况总结：今天主要是完成了师兄说的项目内容以及完成了博客图床的搭建，还是花钱的东西好使，七牛云需要认证是真的麻烦每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章项目相关学习logging模块完成cat命令的学习完善argparse的用法博客转载的项目，动手搞一搞，启动安装sublime text3显示大纲的插件(打开的两个Github)2019-3-21今日学习完成情况类别学习内容大致描述大概用时 Linux Python常用模块继续完善了模块argparse2个小时 机器学习 其他内容docker学习、sublime text3插件安装部署完成了第一个docker镜像、配置了sublime text34个小时今日学习情况总结：今天主要是对师兄说的项目内容进行了完善，同时也这对这个项目制作了第一个镜像，果然万事开头难，制作第一个镜像的过程中需要了很多问题，但是还好都得到了解决，同时通过这个项目也对docker有了一定的了解，为后面详细学习docker打下了基础。每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章学习logging模块完成cat命令的学习博客转载的项目2019-3-22今日学习完成情况类别学习内容大致描述大概用时 Linux常用基本命令cat-显示、读取或者拼接文本内容1.5h Python常用模块完成了logging模块常规使用部分3个小时 机器学习 其他内容git系列总结了一些Git使用实战0.5个小时今日学习情况总结：今天主要是在学习logging模块以及cat命令，都比较简单，上午主要是完善了Docker，将其上传到了Github，其中遇到的问题已经记录并形成了文章。在学习logging模块过程中发现需要看源码(参考的那篇文章)，果然大佬都是会看源码的，所以需要了解看源码的方法。后续需要学习的Linux命令都比较简单，比较的大的和重要的命令前面都已经学习过了，所以后续对Linux命令的学习可以插缝进行。每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章完成logging模块和xupeng、yufeng一起学习机器学习Python查看包的源代码的方法博客转载的项目给姐姐筛选一下材料2019-3-23今日学习完成情况类别学习内容大致描述大概用时 Linux Python实战项目博客转载项目5个小时 机器学习深度学习和xupeng、yufeng学习机器学习一上午 其他内容今日学习情况总结：今天上午和yufeng、xupeng一起学习了深度学习相关的内容个，发现还是需要一些基础，同时一起学习确实会有一些监督作用，希望下次可以接着学习(每周抽出固定的时间来进行学习)；其次是开始了博客转载的项目。每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客转载的项目2019-3-24今日学习完成情况类别学习内容大致描述大概用时 Linux Python项目实战博客转载项目-印象笔记处理4个小时 机器学习 其他内容今日学习情况总结：今天主要是在继续博客转载项目，主要是处理印象笔记API的问题，想要使用API进行转载印象笔记内容。每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客转载的项目2019-3-25今日学习完成情况类别学习内容大致描述大概用时 Linux Python项目实战博客转载项目-自动化爬虫、模拟登陆5个小时 机器学习 其他内容今日学习情况总结：今天主要学习了Selenium自动化测试来模拟登陆，进而进行爬虫，因为使用印象笔记的API得到的印象笔记的公开链接由于某些原因被封禁，所以想着就登陆然后再爬虫。每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客转载的项目2019-3-26今日学习完成情况类别学习内容大致描述大概用时 Linux常用基本命令more和less查看文件内容2h Python项目实战结束博客转载项目1个小时 机器学习 其他内容今日学习情况总结：今天主要是收尾了博客转载项目的内容，将其上传到了github，同时也大致了解了setup.py的用法，虽然还没有正式学习；开始学习了more和less查看文件内容的命令。每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章师兄交代的任务more和less命令的学习2019-3-27今日学习完成情况类别学习内容大致描述大概用时 Linux常用基本命令more和less查看文件内容；wget命令学习3h Python 机器学习 其他内容今日学习情况总结：今天主要是完成了more和less查看文件内容的命令，也开始学习了wget下载内容的命令。每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章师兄交代的任务wget命令2019-3-28今日学习完成情况类别学习内容大致描述大概用时 Linux常用基本命令wget-命令行下载工具、任务管理命令4h Python 机器学习 其他内容今日学习情况总结：今天主要是linux的相关学习，首先结束了对wget命令的学习，对其下载整个网站以及断点续传操作记忆犹新，同时也学习了任务管理命令，包括nohup、disown以及&amp;，通过学习解决了自己一直以来的疑惑，同时也发现现在网上的很多资源并不完整(狠毒都是相互借鉴，并没有自己实践)，自己以后在学习和参考网上的资料时要持保留态度，自己多实践，然后针对自己的问题找到解决方案。每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章echo命令的学习2019-3-29今日学习完成情况类别学习内容大致描述大概用时 Linux常用基本命令echo-字符串输出4h Python 机器学习 其他内容今日学习情况总结：今天主要是linux的字符串输出命令echo，虽然平常使用echo非常多，但是一直没有理解什么时候需要加-e参数什么时候不加，所以萌生了学习这个的想法，通过学习了解到在需要输出转义字符的时候就需要使用-e参数以及进行样式输出(字体颜色、背景颜色等)也需要使用-e参数，其中还涉及到了之前学习了关于Linux中特殊符号的相关知识，尤其是单双引号的作用，对这方面的知识也进行了巩固(知识是越学越轻松，所以不能放弃学习进步啊)。每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章Python打印彩色字符串linux常用解压缩命令2019-3-30今日学习完成情况类别学习内容大致描述大概用时 Linux常用基本命令linux中常用解压缩命令2h Python其他常用技巧总结Python打印彩色字符串2h 机器学习 其他内容今日学习情况总结：今天主要学习了Python打印彩色字符串以及Linux中常用的解压缩命令，在学习Linux常用解压缩命令中的tar命令时，虽然平常使用这个比较多，但是一直以为它是一个解压缩命令，或者说从来没有思考过这个命令究竟是干嘛的，在学习之后才发现其是打包命令，知道了打包以及压缩的区别，也明白了tar.gz和tar.bz2格式的来源。学习要知其然，也要知其所以然，这样理解之后更有利于命令的记忆和使用，在以后的学习中一定要切记，不到非常急的情况下不要拿过来不管三七二十一就用。每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章准备李航机器学习训练营的内容(这个非常重要)书本ipad(视频+笔记)草稿纸博客和代码Python的os路径处理相关的包2019-3-31今日学习完成情况类别学习内容大致描述大概用时 Linux PythonPython常用模块os文件目录和路径操作4h 机器学习 其他内容今日学习情况总结：今天主要学习了Python中的os模块，这是一个文件目录操作模块，在平常写程序中非常常用，同时对与其相关的模块os.path也进行了学习。有一句话说的很好，学习的目的不是为了学完就忘不掉(当然这是最好的状态，但是一般人都达不到)，而是为了知道这里面有什么功能我可以去用，不然你连有什么功能都不知道何谈去使用呢？，所以还是要持续学习，不能放松！每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章Python的shutil模块学习开始学习统计学习方法2019-4-1今日学习完成情况类别学习内容大致描述大概用时 Linux PythonPython常用模块shutil模块-高级文件操作3h 机器学习书本学习统计机器学习第一章3个小时 其他内容今日学习情况总结：今天主要学习了Python中的shutil模块，这个模块是昨天学习os模块的后续，因为很多非常必要的功能os模块并不具备，而shutil是对os模块的补充，在学习的过程中也深刻体会到看源码才是王道，很多文字说的不清楚的东西看看源码就很很快懂得其意思，所以今后的学习中要多看源码，尤其是自己不是很懂的地方，其次是多实践，多动手就会发现很多有意思的方面；同时今天也开始学习了拖了很久的统计机器学习，学习了其中的第一章，有些公式的推导并没有推，打算第一遍先跟着训练营打卡，然后后面第二遍看视频，第三遍再看一遍的时候仔细推导！每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客下载所有的图片，然后完成替换Python中glob模块的学习以及sys模块的整理文件打开操作的整理复习第一章2019-4-2今日学习完成情况类别学习内容大致描述大概用时 Linux PythonPython其他技巧整理文件读写1.5h 机器学习书本学习统计机器学习第一章3个小时 其他内容今日学习情况总结：今天主要学习了Python中的glob模块以及sys模块；glob模块主要是用来进行文件名的规则匹配的，和linux下一样，对文件名的匹配使用的是通配符而不是正则表达式，glob的通配符与shell的通配符在很多方面都是相同的，可以共用，充分验证了学得越多学的越快，哪有什么学习能力很强，只是积累与练出来的罢了；sys模块主要是用来与解释器的交互，在学习的过程中主要涉及了一个使用sys.stdout来实现百分比进度条的实例，从中学到了Python3在写入文件中会返回写入的字符长度以及如何进行覆盖输出。每日学习之后不要忘了： 修改todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客下载所有的图片，然后完成替换Python中的字符串与字符编码整理统计机器学习sys.exit(n)的异常捕获、exit和break的关系2019-4-3今日学习完成情况类别学习内容大致描述大概用时 Linux Python其他技巧总结Python系列之字符串与字符编码(转载)1.5h 机器学习书本学习统计机器学习第一章3.5个小时 其他内容今日学习情况总结：今天主要学习并整理了Python中的字符串与字符编码，对Python2和Python3在字符串上的操作有了进一步的认识，同时也了解了不同位置指定编码类型的不同作用；完成了轮转的报告；晚上结合视频重新学习了一遍统计机器学习的第一章，发现预习之后学习效果果然会有更大的提升，所以今后的两天学习，第一天当做是预习，第二天再结合讲解视频学习，这样效果可能会更好！每日学习之后不要忘了： 修改 todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客下载所有的图片，然后完成替换搬实验室看文章的分析流程(上午)看看subprocess模块的用法(下午)学习统计机器学习第二章(晚上)学生证上的注册要贴一下，去新实验室之后再贴2019-4-4今日学习完成情况类别学习内容大致描述大概用时 Linux PythonPython常用模块之subprocess子进程管理4h 机器学习书本学习统计机器学习第二章3.5个小时 其他内容今日学习情况总结：主要学习了Python的子进程管理模块subproccess，这也是一个非常常用的模块，这个模块学习完成之后，基础的常用模块就学习完了，编写大型的项目基本不存在问题了；学习了统计机器学习方法的第二章。每日学习之后不要忘了： 修改 todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客下载所有的图片，然后完成替换学习统计机器学习第二章(晚上)2019-4-5今日学习完成情况类别学习内容大致描述大概用时 Linux Python 机器学习书本学习统计机器学习第二章3.5个小时 其他内容其他工具科学上网3今日学习情况总结：今天主要学习了统计机器学习的第二章，发现这本书讲得真的很好！！！肯定是要多看几遍呀；搬到了新实验室，搞了一下科学上网的东西，整理了几种方法和工具。每日学习之后不要忘了： 修改 todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客下载所有的图片，然后完成替换项目学习2019-4-6今日学习完成情况类别学习内容大致描述大概用时 Linux Python 其他内容项目学习项目学习5今日学习情况总结：今天主要是在学习老师交代的项目每日学习之后不要忘了： 修改 todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客下载所有的图片，然后完成替换项目学习统计机器学习第三章2019-4-7今日学习完成情况类别学习内容大致描述大概用时 Linux Python 机器学习书本学习统计机器学习第三章3.5个小时 其他内容今日学习情况总结：今天主要是进行了项目学习同时也看了统计机器学习的第三章，这一章看的比较浅，没有怎么看，同时原理也比较简单，后面需要再看看kd树的信息每日学习之后不要忘了： 修改 todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客下载所有的图片，然后完成替换项目学习统计机器学习第四章2019-4-8今日学习完成情况类别学习内容大致描述大概用时 Linux Python 机器学习 其他内容其他内容项目学习5h今日学习情况总结：今天主要学习了项目的部分，基本可以运行部分程序，明天争取完成整个项目的pipeline试运行工作；推迟学习统计机器学习第四章，明天要补回来。每日学习之后不要忘了： 修改 todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客下载所有的图片，然后完成替换学习统计机器学习第四章2019-4-9今日学习完成情况类别学习内容大致描述大概用时 Linux Python 机器学习书本学习朴素贝叶斯4h 其他内容今日学习情况总结：今天主要学习了统计机器学习中的朴素贝叶斯，从晚上7点45到12点20，完成了第一遍预习以及第二遍的结合视频学习，感觉时间差不多，以后可以就按照这个模式来管理自己的私人学习时间。每日学习之后不要忘了： 修改 todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客下载所有的图片，然后完成替换继续项目学习2019-4-10今日学习完成情况类别学习内容大致描述大概用时 Linux Python 机器学习 其他内容项目学习项目学习3h今日学习情况总结：今天主要学习了项目相关内容每日学习之后不要忘了： 修改 todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客下载所有的图片，然后完成替换继续项目的学习2019-4-11今日学习完成情况类别学习内容大致描述大概用时 Linux常用基本命令paste、split命令4h Python 机器学习 其他内容今日学习情况总结：今天在学习项目的同时也学习了Linux中的常用基本命令paste和split；最近几天都在学习搭建jupyterhub但是效果一直不是很好，有点难受。。。每日学习之后不要忘了： 修改 todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客下载所有的图片，然后完成替换学习统计机器学习第五章-决策树找找斌斌师兄，问问jupyterhub搭建的config文件2019-4-12今日学习完成情况类别学习内容大致描述大概用时 Linux常用基本命令csplit命令1h Python 机器学习书本学习第五章-决策树4h 其他内容今日学习情况总结：今天开始学习了Linux中的常用基本命令csplit，作为前面split命令和paste命令的延续性学习；还学习了书本的决策树内容，决策树虽然已经学习过很多次，但是不同的书本提供不同的角度，总有一种角度比较适合自己理解，比如统计机器学习中的条件熵的概念让我对信息增益的计算有了更深入的认识，从而加深了自己对其的理解，if-then规则以及条件概率模型的提出也和前面的知识结合起来加深了记忆与理解—&gt;说明了一个道理：有些内容理解不了可能还真是书本的问题，所以要找点好书看！或者多个经典的书本对照着学习，一个讲解不是很懂可以参考另一个！！！每日学习之后不要忘了： 修改 todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客下载所有的图片，然后完成替换学习统计机器学习第五章-决策树找找斌斌师兄，问问jupyterhub搭建的config文件2019-4-13今日学习完成情况类别学习内容大致描述大概用时 Linux常用基本命令csplit命令2h Python 机器学习书本学习第五章-决策树4h 其他内容今日学习情况总结：今天主要是接着昨天的学习工作，学习并完成了csplit命令；开始结合视频对决策树的内容进行整理。每日学习之后不要忘了： 修改 todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客下载所有的图片，然后完成替换完成学习统计机器学习第五章-决策树找找斌斌师兄，问问jupyterhub搭建的config文件2019-4-14今日学习完成情况类别学习内容大致描述大概用时 Linux Python 机器学习 其他内容今日学习情况总结：每日学习之后不要忘了： 修改 todo list 修改对应文章中的链接 在前一天对应的学习任务上画删除线明日学习哪些内容明日学习计划总览：学习pv命令，完善pv命令相应的文章博客下载所有的图片，然后完成替换]]></content>
      <categories>
        <category>规划</category>
      </categories>
      <tags>
        <tag>每日总结和计划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown基础语法]]></title>
    <url>%2Fposts%2F65136.html</url>
    <content type="text"><![CDATA[这篇文章总结markdown基础语法，便于后续查找和使用。另有一篇next-markdown技巧和模板总结了博客写作中常用的markdown技巧和模板，有些并不是原生的markdown语法，但是写作效果很好看，需要的时候可以查阅这个。markdown特性Markdown 的目标是实现易读易写兼容HTML，不在 Markdown 涵盖范围之内的标签，都可以直接在文档里面用 HTML 撰写，不需要额外标注这是 HTML 或是 Markdown，只要直接加标签就可以了，不过有一些标签需要特殊注意特殊字符转换：特殊字符如HTML中需要特殊处理的字符&lt;和&amp;，markdown会将其自动转化为&amp;lt; 和 &amp;amp;这种实体的形式（虽然在markdown中看不到，但是实际上在生成html时markdown自动将其转化为上述实体的形式），但是如果是把 &lt; 符号作为 HTML 标签的定界符使用，那 Markdown 不会对它做任何转换。附上HTML 中有用的字符实体在markdown使用HTML标签需要特殊注意的是 HTML 的区块元素，比如 &lt;div&gt;、&lt;table&gt;、&lt;pre&gt;、&lt;p&gt; 等标签，必须在前后加上空行与其它内容区隔开，还要求它们的开始标签与结尾标签不能用制表符或空格来缩进;Markdown 的生成器有足够智能，不会在 HTML 区块标签外加上不必要的 &lt;p&gt; 标签HTML 区块标签间的 Markdown 格式语法将不会被处理，如&lt;p&gt;这是**一个**测试&lt;/p&gt;中一个不会加粗显示HTML 的行内标签如 &lt;span&gt;、&lt;cite&gt;、&lt;del&gt; 可以在 Markdown 的段落、列表或是标题里随意使用与处在 HTML 区块标签间不同，Markdown 语法在 HTML 行内标签间是有效的具体的HTML区块标签和行内标签有哪些，请参考这篇转载的文章基础语法区块元素换行和段落在markdown中进行换行操作：一行文本末尾增加两个以上的空格然后回车，如果只使用回车，不添加或者没加够空格看上去两行的文字会变为一行。markdown区分段落的关键是：这两行文字之间是否有空行，空行的定义是显示上看起来像是空的，便会被视为空行。比如，若某一行只包含空格和制表符，则该行也会被视为空行。如果这两行文字之间有空行，就代表这两行文字为两个段落，如果这两行文字之间没有空行，仅仅使用另个以上空格加回车进行换行，这两行文字仍旧是属于同一个段落。得到空行的方法：在上一行文本末尾加上两个以上空格然后回车，再加上&lt;br /&gt;即可两个段落之间有一个空行就可以证明其为两个段落，再多的空行也不会在html中渲染（上述添加&lt;br /&gt;制造空行的方式除外，增加几个&lt;br /&gt;就会有几个空行）。标题markdown依据#的数量，支持六级的标题，一个#代表一级标题，用于标题的#数目最多为6个，当数目大于6个时不再以标题的形式显现，如####### 7将直接显示为####### 7，而不是以标题的形式。当然也可以选择闭合标题的#，在标题之后加上若干数目的#，标题的级别是依据标题之前的#数目决定，和之后的#数目无关。如# 1 ##########还是代表的1级标题。区块引用 Blockquotesmarkdown使用&gt;进行引用段落内多行一同进行区块引用可以在每一行之前都加上&gt;，也可以进行偷懒，在整个段落的第一行加上&gt;引用一整行引用可以进行嵌套，如加两个&gt;&gt;三个&gt;&gt;&gt;这是一句引用这也是一个引用当然，这个还是一个引用使用blockquotes标签进行引用，可以修改文字颜色以及左边框颜色。1&lt;blockquote style="color:red;border-left: 3px solid #F44336;"&gt;使用blockquotes标签进行引用&lt;/blockquote&gt;效果如下：使用blockquotes标签进行引用引用的区块内也可以使用其他的 Markdown 语法，包括标题、列表、代码区块等1234567&gt; #### 这是一个标题&gt; &gt; 1. 这是第一行列表项&gt; 2. 这是第二行列表项&gt; &gt; &lt;blockquote style="color:red;border-left: 3px solid #F44336;"&gt;使用blockquotes标签进行引用&lt;/blockquote&gt;&gt; **引用**结束列表markdown支持有序列表、无序列表和任务列表。无序列表无序列表使用星号、加号或是减号作为列表标记。123* Red* Green* Blue等同于：123+ Red+ Green+ Blue也等同于：123- Red- Green- Blue有序列表有序列表则使用数字接着一个英文句点作为列表标记。值得注意的是有序列表中英文句号前面的数字并不重要，也就是说可以是完全相同或者不连续的数字，这些都不会影响最终解析得到的html信息，得到的结果都是相同的。1231. Bird2. McHale3. Parish等同于：1231. Bird1. McHale1. Parish任务列表依赖模块: pymdownx.tasklist用法: - [ ] 或 - [x]，其中 [ ]表示不打勾，[x]表示打勾，-可以用+或*替代12345678910- [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit- [x] Nulla lobortis egestas semper- [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est- [ ] Vestibulum convallis sit amet nisi a tincidunt - [x] In hac habitasse platea dictumst - [x] In scelerisque nibh non dolor mollis congue sed et metus - [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis - [ ] Praesent sed risus massa- [x] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque- [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi最终效果： Lorem ipsum dolor sit amet, consectetur adipiscing elit Nulla lobortis egestas semper Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Sed egestas felis quis elit dapibus, ac aliquet turpis mattis Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque Nulla vel eros venenatis, imperdiet enim id, faucibus nisi多级列表多级列表的产生：先得到一级列表，然后使用tab键将后续的列表依次缩进即可得到多级列表。123* this is a test * this is a test * this is a test最终效果：this is a testthis is a testthis is a test包含段落的列表列表项目可以包含多个段落，每个项目下的段落都必须缩进 4 个空格或是 1 个制表符。段落的每一行都可以进行缩进：1234567891. This is a list item with two paragraphs. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. Donec sit amet nisl. Aliquam semper ipsum sit amet velit.2. Suspendisse id sem consectetuer libero luctus adipiscing.效果如下：This is a list item with two paragraphs. Lorem ipsum dolorsit amet, consectetuer adipiscing elit. Aliquam hendreritmi posuere lectus.Vestibulum enim wisi, viverra nec, fringilla in, laoreetvitae, risus. Donec sit amet nisl. Aliquam semper ipsumsit amet velit.Suspendisse id sem consectetuer libero luctus adipiscing.当然也支持只对段落首行进行缩进，和上面的段落每行都缩进结果是一样的：1234567* This is a list item with two paragraphs. This is the second paragraph in the list item. You'reonly required to indent the first line. Lorem ipsum dolorsit amet, consectetuer adipiscing elit.* Another item in the same list.包含引用的列表如果要在列表项目内放进引用，那 &gt; 就需要缩进：1234* A list item with a blockquote: &gt; This is a blockquote &gt; inside a list item.效果如下：A list item with a blockquote:This is a blockquoteinside a list item.包含代码块的列表如果要放代码块的话，该代码块就需要缩进两次，也就是 8 个空格或是 2 个制表符：123* 一列表项包含一个列表区块： &lt;代码写在这&gt;如果在行首出现数字-句点-空白，可能会误认为是有序列表，要避免这样的状况，你可以在句点前面加上反斜杠，如1986. What a great season.标记后面最少有一个空格或制表符必须和前后文本存在空行，不然列表可能不能正确解析以及后面的文本可能出现偏移。表格使用markdown原生的方式插入表格1234| 一个普通标题 | 一个普通标题 | 一个普通标题 || ------ | ------ | ------ || *短文本* | 中等文本 | 稍微长一点的文本 || 稍微长一点的文本 | 短文本 | 中等文本 |效果如下：一个普通标题一个普通标题一个普通标题短文本中等文本稍微长一点的文本稍微长一点的文本短文本中等文本表格的语句上一行必须为空行，不然表格不生效;内容和|之间的多余空格会被忽略，每行第一个|和最后一个|可以省略;-的数量至少有一个;|、-、:之间的多余空格会被忽略，不影响布局;表格内容中可以套用其他用法，如加粗、斜体等；直接在markdown原生表格之前添加html样式（style）也可以对表格样式进行修改。设置表格宽度自适应解决了按照第一列表头宽度进行自适应的问题：12345&lt;style&gt;table th:first-of-type &#123; width: 100px;&#125;&lt;/style&gt;为每一列单独设置宽度：123456789101112131415161718192021&lt;table&gt; &lt;tr&gt; &lt;th width=10%&gt;第一列&lt;/th&gt; &lt;th width=35%&gt;第二列&lt;/th&gt; &lt;th width=45%&gt;第三列&lt;/th&gt; &lt;th width=10%&gt;第四列&lt;/th&gt; &lt;/tr&gt;&lt;/table&gt;&lt;!-- 在markdown原生表格之前加上如下内容，设置每一列宽度 --&gt;&lt;style&gt;table th:first-of-type &#123; width: 15%;&#125;table th:nth-of-type(2) &#123; width: 25%;&#125;table th:nth-of-type(3) &#123; width: 60%;&#125;&lt;/style&gt;第一列占整个表格宽度的10%、第二列占35%、第三列占45%、第四列占10%。th:first-of-type 的意思是每个 &lt;th&gt; 为其父级的第一个元素，就是指第一列的表头，同理第二、三个使用 th:nth-of-type(2)、th:nth-of-type(3)修改表头的宽度表头对应的列的宽度也就得到了修改这里有一篇关于markdown表格样式优化的文章，包括鼠标悬停变色、表格滚动条、隔行变色、表头不换行和首列不换行等优化excel也能导出html，先在excel中创建表格，然后保存为html，最后复制其中的表格，参考文章表格对齐问题-:表示内容和标题栏居右对齐；:-表示内容和标题栏居左对齐；:-:表示内容和标题栏居中对齐；1234| 一个普通标题 | 一个普通标题 | 一个普通标题 || :------ | :------: | ------: || *短文本* | 中等文本 | 稍微长一点的文本 || 稍微长一点的文本 | 短文本 | 中等文本 |效果如下：一个普通标题一个普通标题一个普通标题短文本中等文本稍微长一点的文本稍微长一点的文本短文本中等文本使用html插入表格上述markdown原生的方法只能创建一些简单的表格，如果想创建复杂的表格，如合并单元格、调整表格颜色等就需要直接使用html进行创建表格。实现合并单元格：1234567891011121314151617181920&lt;table&gt; &lt;tr&gt; &lt;th&gt;项目1&lt;/th&gt; &lt;th&gt;项目2&lt;/th&gt; &lt;th&gt;项目3&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;a1&lt;/td&gt; &lt;td colspan="2"&gt;a2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td rowspan="2"&gt;b1&lt;/td&gt; &lt;td&gt;b2&lt;/td&gt; &lt;td&gt;b3&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;c2&lt;/td&gt; &lt;td&gt;c3&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;最终效果：项目1项目2项目3a1a2b1b2b3c2c3table标签：定义 HTML 表格tr 元素定义表格行th 元素定义表头td 元素定义表格单元td标签下的colspan（跨列-合并一行的多列）及rowspan（跨行-合并一列的多行）属性进行单元格的合并。使用html插入表格需要注意空行markdown在处理上述的表格时会产生大量的空行，除非将整个表格写成一行，不然空行的书目和整个html代码占的行数相同，解决方法是加上escape标签，将整个table套起来。12345678910111213141516171819202122&lt;escape&gt; &lt;table&gt; &lt;tr&gt; &lt;th&gt;项目1&lt;/th&gt; &lt;th&gt;项目2&lt;/th&gt; &lt;th&gt;项目3&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;a1&lt;/td&gt; &lt;td colspan="2"&gt;a2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td rowspan="2"&gt;b1&lt;/td&gt; &lt;td&gt;b2&lt;/td&gt; &lt;td&gt;b3&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;c2&lt;/td&gt; &lt;td&gt;c3&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/escape&gt;最终效果：项目1项目2项目3a1a2b1b2b3c2c3偷懒方法之直接复制html代码从上面html代码可以看出来写着比较麻烦，为了解决这个问题，这里有一个专门生成Latex、html、markdown、text、mediawiki支持的表格源码的网站，只需要选取相应的内容即可，还可以调整表格颜色，生成相应的css样式。生成表格源码的网站在markdown表格显示竖线在使用markdown表格时如果想要显示竖线，仅仅使用转义是不能成功的，需要使用HTML实体，竖线的HTML实体为&amp;#124;，一个竖线就使用一个&amp;#124;两个竖线就使用两个&amp;#124;&amp;#124;，使用HTML实体后，网页会自动将其显示为|，关于HTML中的常用字符实体请参考这篇文章代码块代码块有两种写法：使用反引号加代码语言种类，代码写完后面也跟三个相同的符号（这种方法最为常用）；第二种写法就是简单地缩进 4 个空格或是 1 个制表符就可以。123这是一个普通段落： 这是一个代码区块。需要和普通段落之间存在空行最后的三个反引号之后不能存在空格，不然会出错分割线你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线：1234567891011* * *********- - ----------------------------------------_____最终效果：使用带空格的星号、减号、底线建立空格线，空格线会粗一些。行内元素链接markdown支持两种形式的链接语法：行内式和参考式两种形式，一般行内式使用较为简单和普遍，所以这里就采用行内式的方式。链接的使用形式：1[an example](http://example.com/ "Title")最终效果：an example方括号内的文字（an example）表示链接作用的文字圆括号内部第一个是链接地址第二个是title：鼠标移到链接文字上显示的内容如果你是要链接到同样主机的资源，你可以使用相对路径：1See my [About](/about/) page for details.关于参考式链接:参考式的链接其实重点不在于它比较好写，而是它比较好读使用 Markdown 的参考式链接，可以让文件更像是浏览器最后产生的结果，让你可以把一些标记相关的元数据移到段落文字之外，你就可以增加链接而不让文章的阅读感觉被打断具体关于参考是的讲解可以参考这篇文章。123456I get 10 times more traffic from [Google] [1] than from[Yahoo] [2] or [MSN] [3]. [1]: http://google.com/ "Google" [2]: http://search.yahoo.com/ "Yahoo Search" [3]: http://search.msn.com/ "MSN Search"最终效果：I get 10 times more traffic from Google than fromYahoo or MSN.强调斜体markdown使用星号*和底线_作为标记强调字词的符号，被*或 _ 包围的字词会被转成用 &lt;em&gt;标签包围，显示出斜体的效果。1这是关于*斜体*的测试最终效果：这是关于斜体的测试加粗markdown使用两个星号*和底线_作为标记强调字词的符号，被两个*或 _ 包围的字词会被转成用 &lt;strong&gt;（加粗显示）包围，显示出加粗的效果。1这是关于**加粗**的测试最终效果：这是关于加粗的测试斜体加粗使用以上的斜体和加粗叠加可以实现斜体和加粗的效果：1这是关于***斜体加粗***的测试最终效果：这是关于斜体的测试删除线要加删除线的文字左右分别用两个~~号包起来，这个也可以叠加斜体以及加粗标记。1这是关于~~删除线~~的测试最终效果：这是关于删除线的测试星号*和底线_与被包围的文字之间不能有空格，不然星号*和底线_就会被当成普通的字符显示如果想加入普通的星号*和底线_，你可以用反斜线，如行内代码行内插入代码，可以直接使用反引号（`）将代码包围起来即可。如&lt;div&gt; &lt;/div&gt;就是写成：1`&lt;div&gt; &lt;/div&gt;`行内代码中加入反引号：可以用多个反引号来开启和结束代码区段，同时起始和结束端都可以放入一个空白，起始端后面一个，结束端前面一个，这样你就可以在区段的一开始就插入反引号：如 A backtick-delimited string in a code span: `foo`、三个反引号就是写成：1234`` `foo` ``# 三个反引号在hexo博客中显示可能会出问题`` ``` ``插入图片使用markdown语法插入图片：使用markdown插入图片与插入链接类似，也有两种方式：行内式和参考式，这里讲解的主要为行内式。关于参考式的用法可以参考链接参考式的用法。12345![图片描述，相当于alt](https://showteeth.oss-cn-beijing.aliyuncs.com/blog_img/test2.png "Optional title，相当于title")&lt;!-- 居中操作可以使用center标签将上述包裹 --&gt;&lt;center&gt;![图片描述，相当于alt](https://showteeth.oss-cn-beijing.aliyuncs.com/blog_img/test2.png "Optional title，相当于title")&lt;/center&gt;最终效果：Optional title 是用来在鼠标移到图片上时显示的title使用markdown插入图片的缺点：一般的宽和高等属性不好修改，各个编辑器支持的写法可能有区别html代码插入图片针对使用markdown插入图片的缺点，使用html语句可以很好的解决123456&lt;!-- 使用img标签--&gt;&lt;img src="https://showteeth.oss-cn-beijing.aliyuncs.com/blog_img/test2.png" width = "300" height = "200" alt="图片名称" align=center /&gt;&lt;!-- 使用div标签包裹 --&gt;&lt;div align="center"&gt;&lt;img src="https://showteeth.oss-cn-beijing.aliyuncs.com/blog_img/test2.png" title="使用html插入图片" alt="图片名称" /&gt;&lt;/div&gt;最终效果：不推荐使用这个img标签来进行对齐操作，容易和文本混在一起，居中的时候还好；推荐使用div标签包裹img标签。常见问题字符转义markdown支持以下这些符号前面加上反斜杠来帮助插入普通的符号：123456789101112\ 反斜线` 反引号* 星号_ 底线&#123;&#125; 花括号[] 方括号() 括弧# 井字号+ 加号- 减号. 英文句点! 惊叹号常见错误原因集锦html块级元素上下没有空格，块级元素是指 &lt;div&gt;、&lt;table&gt;、&lt;pre&gt;、&lt;p&gt; 等标签列表与前后内容之间没有空格列表内容和标记之间没有空格换行操作只回车没有在上一行文本末尾增加两个以上空格停止引用需要和下一行文本空行（另起一段），不然也会被引用进去代码最后的` 之后不能存在空格，不然会将后面的内容也写入代码内强调，不管是加粗还是斜体，标记*或`不能与文本之间存在距离**，不然会失效，标记会显示成标记本身，即*或**`表格的语句上一行必须为空行，不然表格不生效参考链接markdown融合单元单元格问题Latex|html|markdown|text|mediawiki制作表格并得到相应源代码的利器Markdown 语法说明 (简体中文版)Markdown: Basics （快速入门）Markdown 基本语法Markdown-Chinese-Demo]]></content>
      <categories>
        <category>其他内容学习</category>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sed-文本处理工具]]></title>
    <url>%2Fposts%2F1752.html</url>
    <content type="text"><![CDATA[sed处理文本，包括sed命令的基本格式、参数和命令说明、文本的替换、打印、删除、增加、插入以及其他常用的技巧（分组、传入参数、命令连用以及对文件进行读取和写入等）。sed简介sed是一种流编辑器，它是文本处理中非常中的工具，能够完美的配合正则表达式使用，功能不同凡响。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕，接着处理下一行，这样不断重复，直到文件末尾（和awk都是对文件和输入的每一行进行操作）。文件内容并没有改变，除非你使用重定向存储输出。sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。sed 用法sed 命令格式12345Usage: sed [OPTION]... &#123;script-only-if-no-other-script&#125; [input-file]...sed [options] 'command' file(s)sed [options] -f scriptfile file(s)sed options说明参数完整参数说明-e script–expression=script以选项中的指定的script来处理输入的文本文件，直接在命令行模式上进行sed动作编辑，此为默认选项-f script–files=script以选项中的指定的script文件来处理输入的文本文件-i–in-place直接在原位修改原文件-n–quiet –silent仅显示script处理后的结果-E正则表达式该选项后面的正则表达式不需要进行转义，比如(、+等-V–version显示版本信息-h–help显示帮助sed command说明命令说明a在当前行下面插入文本。i在当前行上面插入文本。c把选定的行改为新的文本。d删除，删除选择的行D删除模板块的第一行s替换指定字符h拷贝模板块的内容到内存中的缓冲区H追加模板块的内容到内存中的缓冲区g获得内存缓冲区的内容，并替代当前模板块中文本G获得内存缓冲区的内容，并追加到当前模板块文本的后面l列表不能打印字符的清单n读取下一个输入行，用下一个命令处理新的行而不是第一个命令N追加下一个输入行到模板块后面并在二者间嵌入一个新行，改变当前行号码p打印模板块的行P打印模板块的第一行q退出sedb label分支到脚本中带有标记的地方，如果分支不存在则分支到脚本的末尾r file从file中读行t labelif分支，从最后一行开始，条件一旦满足或者T，t命令，将导致分支到带有标号的命令处，或者到脚本的末尾T label错误分支，从最后一行开始，一旦发生错误或者T，t命令，将导致分支到带有标号的命令处，或者到脚本的末尾w file写并追加模板块到file末尾W file写并追加模板块的第一行到file末尾!表示后面的命令对所有没有被选定的行发生作用=打印当前行号#把注释扩展到第一个换行符以前sed 正则匹配元字符集命令说明^匹配行开始，如：/^sed/匹配所有以sed开头的行。$匹配行结束，如：/sed$/匹配所有以sed结尾的行。.匹配一个非换行符的任意字符，如：/s.d/匹配s后接一个任意字符，最后是d。*匹配0个或多个字符，如：/*sed/匹配所有模板是一个或多个空格后紧跟sed的行。[]匹配一个指定范围内的字符，如/[sS]ed/匹配sed和Sed。[^]匹配一个不在指定范围内的字符，如：/[^A-RT-Z]ed/匹配不包含A-R和T-Z的一个字母开头，紧跟ed的行。(..)匹配子串，保存匹配的字符，如s/(love)able/\1rs，loveable被替换成lovers。&amp;保存搜索字符用来替换其他字符，如s/love/&amp;/，love这成love。&lt;匹配单词的开始，如:/&lt;love/匹配包含以love开头的单词的行。&gt;匹配单词的结束，如/love&gt;/匹配包含以love结尾的单词的行。x{m}重复字符x，m次，如：/0{5}/匹配包含5个0的行。x{m,}重复字符x，至少m次，如：/0{5,}/匹配至少有5个0的行。x{m,n}重复字符x，至少m次，不多于n次，如：/0{5,10}/匹配5~10个0的行。需要转义的字符在sed使用中经常遇到需要对字符进行转义的情况，这里列出需要转义的字符集：123456789101112?*+()[\^$.| &lt;&gt;如果在使用sed命令进行正则匹配的时候不想进行转义(记住这些需要转义的字符太麻烦了吧，而且有时候容易忘)，可以使用-E选项sed 用法实例测试文件cat test.txtmy cat’s name is bettyThis is your dogmy dog’s name is frankThis is your fishmy fish’s name is georgeThis is your goatmy goat’s name is adam替换操作sed 替换标记table th:first-of-type{width:10%}命令说明g表示行内全面替换p表示打印行w表示把行写入一个文件x表示互换模板块中的文本和缓冲区中的文本y表示把一个字符翻译为另外的字符（但是不用于正则表达式）\1子串匹配标记&amp;已匹配字符串标记sed s 替换指定字符将每一行文本中的This替换为sub1234sed -e 's/is/are/' test.txt# 省略-esed 's/is/are/' test.txt输出结果：my cat’s name are bettyThare is your dogmy dog’s name are frankThare is your fishmy fareh’s name is georgeThare is your goatmy goat’s name are adamoption的默认就是-e，所以-e可以省略s命令：替换指定字符指的是每一行的第一个发生替换，第二个以及后续的不会发生替换只打印那些发生替换的行-n选项和p命令一起使用表示只打印那些发生替换的行-n选项:仅显示script处理后的结果p命令:打印模板块的行选项、命令、命令三者连用就是：打印处理后的模板块的行1sed -n 's/is/are/p' test.txt输出结果：my cat’s name are bettyThare is your dogmy dog’s name are frankThare is your fishmy fareh’s name is georgeThare is your goatmy goat’s name are adam全局替换g命令表示行内全面替换1sed 's/is/are/g' test.txt输出结果:my cat’s name are bettyThare are your dogmy dog’s name are frankThare are your farehmy fareh’s name are georgeThare are your goatmy goat’s name are adam注意与单独的s命令的结果对比命令s、命令g之间的顺序是固定的从第几处开始替换从第二处开始替换：1sed 's/is/are/2' test.txt输出结果:my cat’s name is bettyThis are your dogmy dog’s name is frankThis are your fishmy fish’s name are georgeThis are your goatmy goat’s name is adam数字后面可以接命令g或者命令p等从每行中第N除开始全局替换：g命令之前加上数字N，表示从第N处之后的匹配开始全局替换1sed 's/is/are/2g' test.txt输出结果：my cat’s name is bettyThis are your dogmy dog’s name is frankThis are your farehmy fish’s name are georgeThis are your goatmy goat’s name is adam从第二处（包括）开始，后面的所有匹配上的都被替换掉了以行为单位进行替换命令c：把选定的行改为新的文本将第2-5行的内容取代成为this is sub of line 2-512# c 和文字之间有没有空行都可以sed '2,5c this is sub of line 2-5' test.txt最终结果：my cat’s name is bettythis is sub of line 2-5my fish’s name is georgeThis is your goatmy goat’s name is adam替换为多行的内容，只需要通过\n进行文本的换行即可：1sed '2,5cthis is sub of line 2-5 \nthis is a second sub' test.txt最终结果：my cat’s name is bettythis is sub of line 2-5this is a second submy fish’s name is georgeThis is your goatmy goat’s name is adam原位修改文件选项i：在文件的原位修改，不在屏幕输出，如果-i后跟着suffix，则会产生备份文件，形式为原文件名suffix。命令g也可以替换为其他命令。1sed -i_suffix 's/is/are/g' test.txt输出结果：lstest.txttest.txt_suffixcat test.txtmy cat’s name are bettyThare are your dogmy dog’s name are frankThare are your farehmy fareh’s name are georgeThare are your goatmy goat’s name are adam定界符/命令中字符 / 在sed中作为定界符使用，也可以使用任意的定界符.1234# 使用冒号替代echo sksksksksksk | sed 's:sk:ma:4g'# 使用竖线替代echo sksksksksksk | sed 's|sk|ma|4g'输出结果：skskskmamamaskskskmamama定界符出现在样式内部时，需要进行转义或者直接更换定界符这个定界符个人感觉其实是用来作为正则匹配的，和awk用法相似1234# 转义echo '/usr/local/bin' |sed 's/\/usr/\/test/g'# 直接更换定界符echo '/usr/local/bin' |sed 's|/usr|/test|g'输出结果：/test/local/bin/test/local/bin已匹配字符串标记&amp;&amp;：已经匹配上的内容暂存在这个变量中，方便对已匹配内容进行处理正则表达式\w\+匹配每一个单词，使用[&amp;]替换它，&amp;对应之前所匹配到的单词：1echo this is a test line | sed 's/\w\+/[&amp;]/g'最终结果：echo test is a test line |sed &#39;s/\w\+/[&amp;]/g&#39;[test] [is] [a] [test] [line]从上面可以看出，这种方法主要是用来针对一次匹配多个字符串，然后对多个字符串进行分开处理，而不是使用相同的处理（如使用同一个字符替换）正则匹配 -E前面的使用&amp;的过程中对+进行正则匹配时需要在前面加上\用来转义，这样比较麻烦，可以在sed中使用-E选项来直接使用+，而不用进行转义：echo test is a test line |sed &#39;s/\w+/[&amp;]/g&#39;[test] [is] [a] [test] [line]正则匹配-非贪婪不管是基础的还是拓展的Posix/GNU正则表达式都不支持非贪婪匹配(Neither basic nor extended Posix/GNU regex recognizes the non-greedy quantifier)，如果想要使用非贪婪匹配需要进行问题的转化处理。例：希望从http://www.suon.co.uk/product/1/7/3/得到http://www.suon.co.uk需要使用非贪婪匹配，如果直接使用sed:123# 直接使用sed结合?进行非贪婪匹配并不能得到正确的结果echo "http://www.suon.co.uk/product/1/7/3/" |sed -n -E 's|(http://.*?)/.*|\1|p' http://www.suon.co.uk/product/1/7/3这个问题可以有如下几种解决办法：借助perl来进行正则匹配123# 使用perl强大的正则匹配功能echo "http://www.suon.co.uk/product/1/7/3/" | perl -pe 's|(http://.*?)/.*|\1|' http://www.suon.co.uk仍然使用sed命令1234# 借助了一般的正则匹配都支持的[^/]表示匹配任意非/的字符# [^/]*表示前面的[^/]重复n次echo "http://www.suon.co.uk/product/1/7/3/" |sed -n -E 's|(http://[^/]*)/.*|\1|p' http://www.suon.co.ukgrep结合了perl的正则12345# 注意grep不能得到匹配的分组信息# 借助其他的技巧可以# 使用sed却可以echo "http://www.suon.co.uk/product/1/7/3/" |grep -oP '(http://.*?)/' http://www.suon.co.uk/参考链接：Can GNU Grep output a selected group?、Non greedy (reluctant) regex matching in sed?分组标记\1 、\2\1 、\2：表示正则匹配的分组1echo this is digit 7 in a number | sed 's/digit \([0-9]\)/\1/'最终结果：echo this is digit 7 in a number |sed &#39;s/digit \([0-9]\)/\1/&#39;this is 7 in a number命令中digit 7，被替换成7。样式匹配到的子串是7，\(..\)用于匹配子串，对于匹配到的第一个子串标记为\1，依此类推匹配到的第二个结果就是\2,例如：1echo aaa BBB | sed 's/\([a-z]\+\) \([A-Z]\+\)/\2 \1/'最终结果：echo aaa BBB | sed &#39;s/\([a-z]\+\) \([A-Z]\+\)/\2 \1/&#39;BBB aaa上面的括号需要进行转义，可以直接使用-E来不用进行转义：echo aaa BBB | sed -E &#39;s/([a-z]+) ([A-Z]+)/\2 \1/&#39;BBB aaa括号和+需要进行转义可以使用-E选项来不进行转义传入变量-引用sed作为文本处理工具，可能经常需要传入变量来进行操作，这里提供了关于传入变量的方法，但是需要注意的是，如果表达式内部存在变量字符串，command的单引号就要变成双引号。123test="HELLO"echo "hello WORLD" |sed "s/hello/$test/"最终结果：echo &quot;hello WORLD&quot; |sed &quot;s/hello/$test/&quot;HELLO WORLD组合多个命令 ;命令组合在Linux中是非常常见的，一般是使用管道符，在sed命令中可以使用;分割命令，这种用法同样和awk使用非常相似。1sed '表达式' | sed '表达式'等价于：1sed '表达式; 表达式'多个命令连用 -e选项-e本就是sed的默认选项，用于说明使用的是command而不是文件命令形式，多个命令连用，注意是有前后顺序的连用，在连用的command之前加上-e即可。1sed -e '1,5d' -e 's/my/MY/' test.txt先删除test.txt文件中的第1、5行，输出删除的内容，然后对这两行进行将my替换为MY。最终结果：This is your goatMY goat’s name is adam这个方式进行命令的连用和上面使用分号;将不同命令连写的方式效果相同使用{}连用命令使用{}将需要连用的命令包围，并使用;将多个命令隔开1sed -n '/This/&#123;s/This/this/;n;p&#125;' test.txt最终结果：my dog’s name is frankmy fish’s name is georgemy goat’s name is adam命令n：当前匹配行的下一行选项n：仅显示script处理后的结果选定行的范围 ,(逗号)选取行的范围来对文本进行处理，可以使用在不同行之间加逗号,的方式打印从第5行开始到第一个包含以this开始的行之间的所有行：1sed -n '5,/^This/p' test.txt最终结果：sed -n ‘5,/^This/p’ test.txtmy fish’s name is georgeThis is your goat行的索引开始于1需要注意的是：是包含尾部的，5,7p是包含第七行的选取行号之后不仅仅可以用来做打印，还可以进行其他操作，具体见本文使用实战打印命令 p12345678910111213141516171819202122# 打印第3行sed -n '3p' test.txt# 打印第3-5行sed -n '3,5p' test.txt# 数字和正则表达式连用# 打印从第1行开始，第一次出现This结束之间的行（起始行固定，终止行第一次正则匹配位置）sed -n '1,/This/p' test.txt# 起始行固定，终止行第一次正则匹配位置sed -n "/my cat's name is betty/,/This/p" test.txt# 打印从第一次匹配到This的行到第3行，然后再输出所有匹配到This的行sed -n '/This/,3p' test.txt# 如果含有This的行在第1行之后，则打印所有含有This的行sed -n '/This/,1p' test.txt# 起始行和终止行都不固定，打印全文sed -n '/my/,/This/p' test.txt最终结果：sed -n &#39;3p&#39; test.txtmy dog’s name is franksed -n &#39;3,5p&#39; test.txtmy dog’s name is frankThis is your fishmy fish’s name is georgesed -n &#39;1,/This/p&#39; test.txtmy cat’s name is bettyThis is your dogsed -n &quot;/my cat&#39;s name is betty/,/This/p&quot; test.txtmy cat’s name is bettyThis is your dogsed -n &#39;/This/,3p&#39; test.txtThis is your dogmy dog’s name is frankThis is your fishThis is your goatsed -n &#39;/This/,1p&#39; test.txtThis is your dogThis is your fishThis is your goatsed -n &#39;/my/,/This/p&#39; test.txtmy cat’s name is bettyThis is your dogmy dog’s name is frankThis is your fishmy fish’s name is georgeThis is your goatmy goat’s name is adam使用打印命令p时需要注意，sed默认会打印出所有的行（命令d除外，只会打印保留下来的行），所以想要打印出特定修改过的行需要加上选项n，如果不加，匹配上的行会打印两遍使用正则表达式进行匹配打印时需要特别小心如果数字在前面，是从数字开始到第一次匹配到正则表达式的部分（1就是从1开始，3就是从3开始看后面第一次匹配的）如果数字在后面，正则表达式在前面，那么一定会将全文中包含正则表达式的全部输出，其他部分如果数字大于正则表达式第一次出现的行，则输出正则表达式第一次出现的行到数字之间的其他内容，如果数字小于正则表达式第一次出现的行，那就只会打印包含正则表达式的行。全文匹配正则表达式的输出以及正则表达式第一次出现的行到数字之间的其他内容输出如果前后都为正则表达式，则输出全文内容关于上述正则表达式我的理解：因为数字是完全确定的，开始和结束行都很确定，所以可以很明确输出想要的结果，但是如果是正则表达式的话，不是唯一的匹配结果（段落中有几行都可以匹配上），那么如果正则表达式在前，则不知道从第几行开始当起始行，所以如果数字大于第一个匹配位置所在的行，那么以第一个匹配位置所在的行为起始行到数字规定的终止行之间的行都会输出，同时起始行可能有很多（其他位置也有匹配），所以还会输出其他匹配位置作为开始，这时如果数字小于第二个匹配位置的话，就只会输出匹配正则表达式的行，同时如果数字大于第二个匹配位置，由于第一个匹配位置的输出已经包含第二个位置，所以不会再输出一遍第二个匹配位置到终止行的信息说了很多，总结一下：使用正则表达式结果要想正确，起始行必须固定（可以使用数字或者使用唯一匹配的正则表达式），这样才会输出起始行到终止行之间的内容，如果终止行是正则表达式，则会输出起始行到第一次匹配到正则表达式的终止行之间的内容。匹配模式取反 ！打印除第一行和第二行之外的其他行：1sed -n '1,2!p' test.txt最终结果：sed -n &#39;1,2!p&#39; test.txtmy dog’s name is frankThis is your fishmy fish’s name is georgeThis is your goatmy goat’s name is adam显示行号 =1sed -n '/my/&#123;=;p&#125;' test.txt最终结果：sed -n &#39;/my/{=;p}&#39; test.txt1my cat’s name is betty3my dog’s name is frank5my fish’s name is george7my goat’s name is adam删除命令 d命令d：删除，删除选择的行删除空白行cat test2.txtmy cat’s name is bettythis is your this dogmy dog’s name is this frankthis is your fishmy fish’s name is this georgethis is your goatmy goat’s name is this adam1sed '/^$/d' test2.txt最终结果：my cat’s name is bettythis is your this dogmy dog’s name is this frankthis is your fishmy fish’s name is this georgethis is your goatmy goat’s name is this adam空白行的表示方法：^$ (开头和结尾之间的内容为空)删除含有固定单词的行&lt;：匹配单词的开始，注意需要转义&gt;：匹配单词的结束，注意需要转义1sed '/\&lt;This\&gt;/d' test.txtsed &#39;/\&lt;This\&gt;/d&#39; test.txtmy cat’s name is bettymy dog’s name is frankmy fish’s name is georgemy goat’s name is adam正则匹配删除-删除文件中所有以my开头的行1sed '/^my/d' test2.txt最终结果：this is your this dogthis is your fishthis is your goat从某一行开始删除1sed '2,$d' test2.txt最终结果：sed &#39;2,$d&#39; test2.txtmy cat’s name is betty最后一行：$首行不是^，直接使用1删除文件最后一行1sed '$d' test2.txt最终结果：my cat’s name is bettythis is your this dogmy dog’s name is this frankthis is your fishmy fish’s name is this georgethis is your goat最后一行：$可以发现前面删掉空行的操作没有影响原始文件，如果想修改原始文件，可以加上选项i写入文件 w命令在test.txt中所有包含my的行都被写入test2.txt里：1sed -n '/my/w test2.txt' test.txt最终结果：cat test2.txtmy cat’s name is bettymy dog’s name is frankmy fish’s name is georgemy goat’s name is adam从文件读入 r命令file里的内容被读进来，显示在与test.txt匹配的行后面，如果匹配多行，则file的内容将显示在所有匹配行的下面：cat test1.txtaaaaaaaa1sed '/my/r test1.txt' test.txt最终结果：my cat’s name is bettyaaaaaaaaaThis is your dogmy dog’s name is frankaaaaaaaaaThis is your fishmy fish’s name is georgeaaaaaaaaaThis is your goatmy goat’s name is adamaaaaaaaaa追加文件 a\追加与上述读取不同，虽然两者都是讲在匹配的行下增加文本信息，但是读取处理的是两个文件，追加处理的是一个文件和一行或多行文本。a后面的反斜杠可有可无1sed '/^my/a\this is a test line' test.txt最终效果：my cat’s name is bettythis is a test lineThis is your dogmy dog’s name is frankthis is a test lineThis is your fishmy fish’s name is georgethis is a test lineThis is your goatmy goat’s name is adamthis is a test line同样也可以通过追加操作也增加两行甚至多行内容：1sed '/^my/a\this is a test line \nthis is second line' test.txt通过使用\n进行换行操作来达到增加多行的目的最终结果：my cat’s name is bettythis is a test linethis is second lineThis is your dogmy dog’s name is frankthis is a test linethis is second lineThis is your fishmy fish’s name is georgethis is a test linethis is second lineThis is your goatmy goat’s name is adamthis is a test linethis is second line如果命令a之前什么都不加，表明给在每一行下都增加文本当然，a之前也可以是单纯的数字插入操作 i\插入操作和上述追加和读取操作都不同，插入是在匹配行的上面进行插入，而追加和读取是在匹配行的下方进行的追加，同时插入和追加操作都是针对单个文件和一行或多行文本。1sed '/^my/i\this is insert line' test.txtthis is insert linemy cat’s name is bettyThis is your dogthis is insert linemy dog’s name is frankThis is your fishthis is insert linemy fish’s name is georgeThis is your goatthis is insert linemy goat’s name is adam在匹配文本上方插入多行的操作与追加类似，都是使用\n换行1sed '/^my/i\this is insert line \nthis is second insert line' test.txt最终效果：this is insert linethis is second insert linemy cat’s name is bettyThis is your dogthis is insert linethis is second insert linemy dog’s name is frankThis is your fishthis is insert linethis is second insert linemy fish’s name is georgeThis is your goatthis is insert linethis is second insert linemy goat’s name is adam匹配行的下一行 n命令打印匹配字符串的下一行：12345# 下面这个写法会使得以my开头的行被打印两遍，是错误的sed '/my/&#123;n;p&#125;' test.txt# 正确的写法是仅显示script处理后的结果sed -n '/my/&#123;n;p&#125;' test.txt最终结果：sed -n &#39;/my/{n;p}&#39; test.txthhhh is your dogThis is your fishThis is your goat在原始test文件中增加了一行用于防止和普通的替换混淆如果my被匹配，则移动到匹配行的下一行，替换这一行的this为This,并打印该行：1234sed '/my/&#123;n;s/This/this/; &#125;' test.txt# 上述式子不等于sed '/my/n;s/This/this/' test.txt最终输出：my cat’s name is bettyhhhh is your dogThis is your dogmy dog’s name is frankthis is your fishmy fish’s name is georgethis is your goatmy goat’s name is adam不是以my为开头的下一行的This不会被替换为this注意花括号{}，不能丢掉使用grep、awk得到匹配行的下一行123grep -A 1 my test.txtsed -n '/my/&#123;n;p&#125;' test.txtawk '/my/&#123;getline; print&#125;' test.txt字符变换 y命令把1~10行内所有abcde转变为大写，注意，正则表达式元字符不能使用这个命令：1sed '1,10y/abcde/ABCDE/' test.txt最终结果：my CAt’s nAmE is BEttyhhhh is your DogThis is your Dogmy Dog’s nAmE is frAnkThis is your fishmy fish’s nAmE is gEorgEThis is your goAtmy goAt’s nAmE is ADAm注意这个和普通的替换不同，替换是将abcde这个字符串进行替换为ABCDE字符串，而这里是将a、b、c、d、e变为大写；与通过已匹配字符串&amp;也不同，这个更为简单显示分隔符等详细信息 l命令如果想知道文件内容的具体分割符，以及其他不能打印的字符信息可以使用’l’命令：sed -n &#39;l&#39; test3.txttab\tsep\tend$blank sep end$adsfaaaaaaaaaaaaaaaaafdadfasdfasdfasdfasdfsaaavfcadsasd asda asafdafa\sd$每行显示30个字符（包括最后的\）:sed -n &#39;l30&#39; test3.txttab\tsep\tend$blank sep end$adsfaaaaaaaaaaaaaaaaafdadfasd\fasdfasdfasdfsaaavfcadsasd as\da asafdafasd$l命令用明确的形式显示模版空间的数据：以C-style的转义形式显示不能打印的字符(换行符、制表符等)和本身的\Char形式长的行将进行分割，以字符\结尾的行表示分割，以字符$结尾的行表示分割结束n指定显示行的长度，超过就进行分割；若为0表示不分割所有行；没有指定时就取命令行选项-l的设置，再没有就取默认值70。这是GNU的扩展功能打印奇数行或偶数行方法一：通过下一行（命令n）的方式打印奇数行：1sed -n 'p;n' test.txt最终结果：my cat’s name is bettyThis is your dogThis is your fishThis is your goat打印偶数行：1sed -n 'n;p' test.txt最终结果：hhhh is your dogmy dog’s name is frankmy fish’s name is georgemy goat’s name is adam命令n在前而p在后为打印偶数行命令p在前而n在后为打印奇数行命令n为当前匹配的下一行方法二：简单方法12345# 打印奇数行sed -n '1~2p' test.txt# 打印偶数行sed -n '2~2p' test.txt使用实战在开头添加start12# 主要里面的空格也是有用的sed 's/^/start /' test.txt最终效果：sed &#39;s/^/start /&#39; test.txtstart my cat’s name is bettystart This is your dogstart my dog’s name is frankstart This is your fishstart my fish’s name is georgestart This is your goatstart my goat’s name is adam在结尾增加end12# 主要里面的空格也是有用的sed 's/$/ END/' test.txt最终效果：sed &#39;s/$/ END/&#39; test.txtmy cat’s name is betty ENDThis is your dog ENDmy dog’s name is frank ENDThis is your fish ENDmy fish’s name is george ENDThis is your goat ENDmy goat’s name is adam END在前三行之前增加#号做注释1sed '1,3s/^/# /' test.txt最终结果：sed &#39;1,3s/^/# /&#39; test.txt# my cat’s name is betty# This is your dog# my dog’s name is frankThis is your fishmy fish’s name is georgeThis is your goatmy goat’s name is adam将连续的空白替换为tab123456789# cat -A # 存在连续的多个空白，也存在tabLJ_WB_mtDNA_1^I14963320^I2553170^I17.06^I1785293^I11.93$LJ_WB_mtDNA_5 6511598 587331 9.01 413712 6.35$LJ_WB_mtDNA_4 8663156 531768 6.13 375148 4.33$LJ_WB_mtDNA_2^I16236228^I1298993^I8.00^I907074^I5.58$LJ_WB_mtDNA_3^I13546770^I1206932^I8.90^I842322^I6.21$LJ_frozen_2 6214534 1868771 30.07 1477904 23.78$LJ_frozen_1 9232822 3122994 33.82 2476874 26.82$如果想要将连续的多个空白替换为单个tab键：1234567891011# 直接将空白替换会出现很多的tabsed 's/ /\t/g' batch_9.txt |cat -A LJ_WB_mtDNA_2^I16236228^I1298993^I8.00^I907074^I5.58$ LJ_WB_mtDNA_3^I13546770^I1206932^I8.90^I842322^I6.21$ LJ_frozen_2^I^I^I6214534^I1868771^I30.07^I^I^I1477904^I23.78$ LJ_frozen_1^I^I^I9232822^I3122994^I33.82^I^I^I2476874^I26.82$# 直接使用+不起作用sed 's/ +/\t/g' batch_9.txt# 注意这里的+号需要转义sed 's/ \+/\t/g' batch_9.txt使用技巧及注意事项使用打印命令p时需要注意，sed默认会打印出所有的行（命令d除外，只会打印保留下来的行），所以想要打印出特定修改过的行需要加上选项n区分选项和命令的关系和书写相对位置（如选项和命令都有n，但是作用却不同）使用正则表达式进行匹配打印时需要特别小心，总结一下：使用正则表达式结果要想正确，起始行必须固定（可以使用数字或者使用唯一匹配的正则表达式），这样才会输出起始行到终止行之间的内容，如果终止行是正则表达式，则会输出起始行到第一次匹配到正则表达式的终止行之间的内容。参考链接sed命令sed命令详解，很多关于实战的讲的很好！！！sed命令用法sed_and_awk，github上148星]]></content>
      <categories>
        <category>Linux</category>
        <category>常用基本命令</category>
      </categories>
      <tags>
        <tag>常用基本命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大致计划]]></title>
    <url>%2Fposts%2F18198.html</url>
    <content type="text"><![CDATA[对于想学习内容的大致实施计划，需要根据实际情况灵活更改。总体思路Linux的内容比较细小，可以使用零散的时间来学习；机器学习的内容需要学习的连贯性，需要大量时间学习和理解；Python学习还好，介于Linux和机器学习内容之间；其他内容的学习不是很急切，但是一些工具性的可以先学习，比如git以及markdown，时间需求不是很大；可以将Linux中比较大的内容和其他内容学习中比较小的内容搭配，比如sed命令和下面的markdown搭配这种；大块的内容比如机器学习和Python可以放在晚上10-1点半之间（每天3个小时）？这个还需要考虑；机器学习和Python学习的内容可以放在github上。Linux学习 一个常用命令的学习 总结一个常用内容 shell编程一个技巧Python学习 一个常用命令的学习 总结一个常用内容 shell编程一个技巧机器学习学习 一个常用命令的学习 总结一个常用内容 shell编程一个技巧其他内容学习 一个常用命令的学习 总结一个常用内容 shell编程一个技巧]]></content>
      <categories>
        <category>规划</category>
      </categories>
      <tags>
        <tag>每日学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[其他想学习的内容]]></title>
    <url>%2Fposts%2F49862.html</url>
    <content type="text"><![CDATA[其他想学习的内容汇总，包括Latex排版、git使用、readthedocs+mkdocs静态网站、markdown学习、docker学习以及snakemake等内容，如果遇到后续会持续添加。markdown学习&emsp;&emsp;在后面的学习中，我将尽可能使用markdown进行文档的编写，这样看着更加美观，所以有必要对齐进行完善的学习，同时在真正的语法与在博客中遇到的可能有所差别，所以这里的将主要关注一些基础的语法，其他在博客写作中常用的可以参考之前写的博客。markdown基础语法学习next-markdown技巧和模板Git使用&emsp;&emsp;接触到github之后，git操作是经常需要使用的，所以对其进行学习非常有必要。转载-Git讲解与使用实战转载-Git常用命令及日常问题集锦Latex排版&emsp;&emsp;第一次真正见识到latex是看到清本大佬使用latex对课程论文进行排版以及数学公式编写，觉得非常牛逼，同时也反思了自己的本科经历，果然大佬就是大佬！啥也不说了学习吧。一份其实很短的 LaTeX 入门文档Markdown中输入数学公式及LaTex常用数学符号整理刘海洋-latex入门readthedocs+mkdocs静态网站&emsp;&emsp;在binbin师兄的带领下，也算是接触了一下readthedocs+mkdocs静态网站（写技术文档），感觉也挺好看的，可以用来展示自己使用markdown编写的一些文本，主要是指项目。mkdocs的官方网站好用的参考很好的教程mkdocs可用的拓展docker&emsp;&emsp;docker是开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。Docker-构建第一个docker镜像Docker——从入门到实践snakemake&emsp;&emsp;snakemake是用来编写任务流程的工具。snakemake使用笔记snakemake-tutorial使用Snakemake搭建分析流程实例-binbin师兄写的]]></content>
      <categories>
        <category>规划</category>
      </categories>
      <tags>
        <tag>学习计划</tag>
        <tag>其他内容学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习学习计划]]></title>
    <url>%2Fposts%2F130.html</url>
    <content type="text"><![CDATA[需要学习的机器学习内容汇总，包括自己总结的学习路线、书本和视频内容学习、竞赛等实战项目、很好的博主和网站以及收藏的shell相关书本等相关内容。自己规划的学习路线第一阶段-经典课程学习&emsp;&emsp;我觉得可以先通过一些经典课程，比如吴恩达老师或者林轩田老师在Coursera上的课程视频来对机器学习有一个初步了解，并通过课程配套的编程习题来动手实现一下算法，来提升一些感性的认识。第二阶段-经典教材学习&emsp;&emsp;之后再选择一本经典教材，学习其中理论和算法的基础部分。同时也可以尝试把讲到的算法实现一下，这样将书本和实践结合起来的办法，我觉得比较有效，这个过程的学习可以与第一个阶段同时进行，学习经典的书本的时候参考视频可以加深理解，目前很多书本都有相应的视频学习课程。第三阶段-实战&emsp;&emsp;通过这两个阶段的学习，已经掌握了机器学习的基本原理，并且对常用的经典算法，如boosting, svm, logistic regression乃至neural network比较熟悉以后，就可以考虑做一个大的project, 例如尝试参加一个在线的数据科学竞赛，通过这样一个过程，可能就能真正体会到入门的感觉。第三阶段-提升&emsp;&emsp;借助一些比较经典的、但是也需要一些基础的书来进行提升阶段的学习。如果只是想在毕业之后能找到算法工程师的工作，《统计学习方法》、CS229、CS231N、《deep learning》这些书再加上leetcode、数据挖掘比赛、以及相关项目经验就已经足够课程与教材学习&emsp;&emsp;现在机器学习部分主要是想根据书本进行学习，同时借助相应的视频课程，也就是上面自己总结学习路线的第一个和第二个阶段。 《统计学习方法》（李航） 《机器学习》（周志华） ISL(An Introduction to Statistical Learning: with Applications in R) 机器学习Machine-Learning 《机器学习实战》 《机器学习实战：基于Scikit-Learn和TensorFlow》 机器学习基石、技法视频 吴恩达机器学习视频 ISL配套视频 上交张志华统计机器学习视频《统计学习方法》（李航）这本书比较精炼，基本上是把模型推导一遍然后给出一个很简单的例子帮助你理解（完整的解释与论证）。《统计学习方法》（李航）《机器学习》（周志华）比较简单，有些只是提及，并没有很好地解释和证明，更系统和全面一点；是偏教材的书籍，需要有人引导才能更好地使用。《机器学习》（周志华）ISL(An Introduction to Statistical Learning: with Applications in R)ESL的基础书，统计学习的入门书，通俗易懂；监督学习占了大部分篇幅，我觉得这本书最好的部分就是模型的讨论都围绕variance和bias的trade-off展开，还有就是对模型的整体性能。ISL(An Introduction to Statistical Learning: with Applications in R)机器学习Machine-Learninggithub上别人总结的学习路径，可以看看。机器学习Machine-Learning《机器学习实战》用最基本的pyton语法，从底层上让你构建代码；理论讲的不是很清楚不是很透彻《机器学习实战》《机器学习实战：基于Scikit-Learn和TensorFlow》评价较好《机器学习实战：基于Scikit-Learn和TensorFlow》机器学习基石、技法视频机器学习基石视频机器学习基技法视频吴恩达机器学习视频吴恩达机器学习视频ISL配套视频ISL配套视频上交张志华统计机器学习视频上交张志华统计机器学习视频机器学习实战项目好的项目&emsp;&emsp;搜集的好的机器学习项目 AI项目实战AI项目实战AI项目实战竞赛Kaggle“泰迪杯”数据挖掘挑战赛中国高校计算机大赛——大数据挑战赛Kesci 科赛AI Challenger 全球AI挑战赛datafountain-DF竞赛平台sas中国高校数据分析大赛统计建模大赛研究生数学建模竞赛深圳杯数学建模挑战赛电工杯数学建模竞赛名称时间范围所需时间“泰迪杯”数据挖掘挑战赛3.31 4.11 4.15差不多一个半月中国高校计算机大赛-大数据挑战赛5.26 7.25 8.20差不多三个月研究生数学建模竞赛9.10 9.13 9.15 9.19 9.20 9.21三天深圳杯数学建模挑战赛4.15 6.10 8月下旬不详电工杯数学建模5.23 5.25 5.28 7.15不详统计建模大赛5-6月不详sas中国高校数据分析大赛10.10不详竞赛对应的教程学习Kaggle Competition Past SolutionsKaggle入门，看这一篇就够了Kaggle比赛：Text Normalization for English银牌全程记录Kaggle 首战拿银总结House Prices: 比赛经验分享Kaggle泰坦尼克如何在 Kaggle 首战中进入前 10%大数据竞赛平台——Kaggle 入门篇Python机器学习kaggle案例DATA TRAIN | 数据分析学习计划可视化与可视分析优秀的博主和网站机器学习、深度学习各种资料，很完善Jupyter notebooks Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow.各种资源的中文翻译人大机器学习笔记机器学习算法Python3机器学习机器学习、深度学习鹅厂大佬Scikit-learn使用总结收藏的机器学习相关书本和笔记李沐 动手学深度学习斯坦福机器学习笔记Sklearn 与 TensorFlow 机器学习实用指南Sklearn 与 TensorFlow 机器学习实用指南scikit-learn (sklearn) 官方文档中文版国科大机器学习课程&amp;机器学习笔记AiLearning: 机器学习 - MachineLearning - ML、深度学习 - DeepLearning - DL、自然语言处理 NLP机器学习算法機器學習：使用PythonNeural Networks and Deep Learning中文神经网络与深度学习另一个版本机器学习训练秘籍Algorithm_Interview_Notes-ChineseNotebooks for my “Deep Learning with TensorFlow 2 and Keras” course]]></content>
      <categories>
        <category>规划</category>
      </categories>
      <tags>
        <tag>学习计划</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python学习计划]]></title>
    <url>%2Fposts%2F22463.html</url>
    <content type="text"><![CDATA[需要学习的Python内容汇总，包括面向对象、常用模块使用、其他技巧整理、常用工具整理、实战项目、优秀的博主和网站以及收藏的Python相关书本等相关内容。面向对象&emsp;&emsp;这个是我一直想要学习的内容，但是由于诸多原因还没能学习，所以把这个放在了Python学习的第一位。面向对象面向对象-网页收藏夹标准库与常用模块&emsp;&emsp;这里是一些比较常用的模块的学习。 numpy-数组与矩阵运算 matplotlib-绘图 Seaborn-绘图 SciPy-科学计算 argparse-命令行选项与参数解析 Bokeh-交互式数据可视化 HDF5-大数据存储与读取 tqdm-显示运行进度条 logging-日志 glob-文件名规则匹配 os-使用操作系统相关功能 shutil-高级文件操作 sys-程序与python解释器的交互 subprocess-子进程管理 rpy2-调用R语言 collections-内建的一个集合模块numpy-数组与矩阵运算numpy-数组与矩阵运算numpy-数组与矩阵运算numpy-数组与矩阵运算numpy-数组与矩阵运算numpy-数组与矩阵运算matplotlib-绘图matplotlib-绘图matplotlib-绘图Seaborn-绘图Seaborn-绘图SciPy-科学计算SciPy-科学计算argparse-命令行选项与参数解析argparse-命令行选项与参数解析Bokeh-交互式数据可视化Bokeh-交互式数据可视化HDF5-大数据存储与读取HDF5-大数据存储与读取tqdm-显示运行进度条tqdm-显示运行进度条logging-日志logging-日志glob-文件名规则匹配glob-文件操作相关模块os-使用操作系统相关功能os-使用操作系统相关功能shutil-高级文件操作shutil-高级文件操作sys-程序与python解释器的交互sys-程序与python解释器的交互subprocess-子进程管理subprocess-子进程管理rpy2-调用R语言rpy2-调用R语言rpy2-调用R语言collections-内建的一个集合模块collections-内建的一个集合模块其他技巧整理&emsp;&emsp;这部分内容虽然不是具体的模块，但是对他们的理解和应用对于Python的学习非常有益处。 main函数的理解 Python常用程序块 Python常见错误 Python系列之打印彩色字符串 接入pipelinemain函数的理解main函数的理解Python常用程序块Python常用程序块Python常见错误Python常见错误Python系列之打印彩色字符串Python系列之打印彩色字符串接入pipeline接入pipeline常用工具整理jupyter notebookjupyter主题、插件、技巧、server搭建实战项目&emsp;&emsp;这部分是收集的一些实战项目，可以在学习的过程中穿插学习，巩固对知识的掌握 Python-博客转载项目 以撸代码的形式学习Python Python项目-w3cschool 电影分析-爬虫+可视化 12个Python实战项目教程 Python练手项目推荐 Python100例测试Python-博客转载项目Python-博客转载项目-博客 Python-博客转载项目-code以撸代码的形式学习Python以撸代码的形式学习PythonPython项目-w3cschool以撸代码的形式学习Python电影分析-爬虫+可视化电影分析-爬虫+可视化12个Python实战项目教程12个Python实战项目教程Python练手项目推荐Python练手项目推荐Python100例测试Python100例测试优秀的博主和网站云游道士廖雪峰Python数据之道刘江的博客及教程收藏的Python相关书本Python之numpy教程Matplotlib用户指南类与对象编写高质量代码改善 Python 程序的 91 个建议Python 核心编程 第二版Python进阶Python数据结构与算法Python 数据科学入门教程Sklearn 与 TensorFlow 机器学习实用指南scikit-learn (sklearn) 官方文档中文版Scikit-learn 秘籍python数据分析与挖掘实战的代码笔记Python3网络爬虫开发实战Python 文本数据分析初学指南]]></content>
      <categories>
        <category>规划</category>
      </categories>
      <tags>
        <tag>学习计划</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux学习计划]]></title>
    <url>%2Fposts%2F34794.html</url>
    <content type="text"><![CDATA[需要学习的Linux内容汇总，包括基本命令、其他一些常用的总结、shell编程、小技巧、其他博主的命令总结、很好的博主和网站以及收藏的shell相关书本等相关内容。常用基本命令&emsp;&emsp;这些命令是在工作和学习中常用的一些命令，有些我之前系统的学习过，但是学习的笔记都存放在我的印象笔记上，等有时间了会把这些笔记整理到这个博客上（回顾之前学习的内容），感觉博客上面记笔记会比较清爽，便于后期回顾学习，还没有系统学习过的命令后期都将直接呈现在这个博客上。下面列出了需要学习的常用命令，接下来将依据这个进行学习，同时在学习中遇到新的常用命令也会进行补充和完善，同时这一页主要是一个综括页，具体的每一个命令的学习笔记都将单独的页面展示，但是可以通过这个页面直接链接过去。 awk系列-强大的文本处理语言 find-搜索文件名 grep-搜索文件内容 sed-文本处理工具 sort-排序 uniq-去重 join-连接文本 cut-按列切分文件字段工具 comm-文件比较，文本文件的交集、差集与求差 cmp-文件比较命令 diff-文件比较命令 cat-显示、读取或拼接文件内容 more和less-查看文本内容 wget-命令行下载工具 nohup、disown和&amp;-任务管理 echo-字符串的输出 Linux中常用的解压缩命令 paste-按列合并文件 split-按大小分割文件 csplit-根据文本内容切割文件 scp-跨平台复制命令 shuf-随机打乱文件 seq-产生固定步长整数 printf-格式化输出字符串 ps-报告当前系统的进程状态 pgrep-使用进程名直接查找pid等信息 rsnyc-远程数据同步 xargs-将输入转换成命令行参数 read-从键盘或文件中获取输入 time-计算命令执行花费的时间 获取时间日期格式和延时 pv-命令执行的进度信息 screen-远程会话管理工具 du-显示目录或文件大小awk系列-强大的文本处理语言该系列包括13个小节，已经学习完毕 ，笔记都保存在印象笔记上。find-搜索文件名grep-搜索文件内容sed-文本处理工具sed-文本处理工具sort-排序sort-排序uniq-去重uniq-去重join-连接文本join-连接文本cut-按列切分文件字段工具cut-按列切分文件字段工具comm-文件比较，文本文件的交集、差集与求差comm-文件比较，文本文件的交集、差集与求差cmp-文件比较命令cmp-文件比较命令diff-文件比较命令diff-文件比较命令cat-显示、读取或拼接文件内容cat-显示、读取或拼接文件内容more和less-查看文本内容more和less-查看文本内容wget-命令行下载工具wget-命令行下载工具nohup、disown和&amp;-任务管理nohup、disown和&-任务管理echo-字符串的输出echo-字符串的输出Linux中常用的解压缩命令Linux中常用的解压缩命令paste-按列合并文件paste-合并文件split-按大小分割文件split-按大小分割文件csplit-根据文本内容切割文件csplit-根据文本内容切割文件scp-跨平台复制命令scp-跨平台复制命令shuf-随机打乱文件shuf-随机打乱文件seq-产生固定步长整数seq-产生固定步长整数ps-报告当前系统的进程状态ps-报告当前系统的进程状态pgrep-使用进程名直接查找pid等信息ps-报告当前系统的进程状态rsnyc-远程数据同步rsnyc-远程数据同步xargs-将输入转换成命令行参数xargs-将输入转换成命令行参数read-从键盘或文件中获取标准输入read-从键盘或文件中获取标准输入time-计算命令执行花费的时间time-计算命令执行花费的时间获取时间日期格式和延时获取时间日期格式和延时pv-命令执行的进度信息pv-命令执行的进度信息screen-远程会话管理工具screen-远程会话管理工具du-显示目录或文件大小du-显示目录或文件大小其他一些常用内容总结&emsp;&emsp;这些虽然不是具体的linux命令，但是在具体学习中页非常实用，所以有必要进行积累和整理。 Linux中特殊符号用法 浮点计算并保留小数 字符串截取方法 单行命令嵌套 输入输出重定向Linux中特殊符号用法Linux中特殊符号用法浮点计算并保留小数浮点计算并保留小数字符串截取方法字符串截取方法单行命令嵌套单行命令嵌套输入输出重定向输入输出重定向shell编程&emsp;&emsp;这一块平常接触没有那些常用命令那么频繁，但是也很多很实用（不用为了一个简单的目的去编写一个Python脚本），所以这里需要系统的学习一下。 传递参数 循环结构 if判断 数组 数学运算循环结构循环结构if判断if判断传递参数传递参数数组数组数学运算数学运算小技巧&emsp;&emsp;这里总结一下使用常用命令以及进行shell编程的一些常用小技巧。awk使用技巧awk使用技巧shell技巧-非shell脚本shell技巧-非shell脚本shell脚本技巧shell脚本技巧其他博主的命令总结&emsp;&emsp;其他优秀的博主整理的常用命令，可作为自查以及必要时查阅。97条 Linux 常用命令总结文件与目录基础自查很好的博主和网站大佬博客，讲解非常细致常用命令和shell总结、很完善查询各种linux命令，基本都有且分类清楚查询各种linux命令，基本都有其他博主的每日一个linux命令讲解以及实际问题代码收藏的shell相关书本鸟哥的Linux私房菜：基础学习篇高级Bash脚本编程指南Shell 编程范例shell脚本linux command line中文版]]></content>
      <categories>
        <category>规划</category>
      </categories>
      <tags>
        <tag>学习计划</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[next-markdown技巧和模板-持续更新]]></title>
    <url>%2Fposts%2F37746.html</url>
    <content type="text"><![CDATA[博客中常用markdown的样式和模板markdown技巧分割线和空行1234&lt;hr /&gt;上面是分割线&lt;br /&gt;上面是空行上面是分割线上面是空行markdown引用以及html写法123&lt;blockquote&gt;引用内容&lt;/blockquote&gt;&lt;!-- 如果前后间隙很小，可以像下面这样写 --&gt;&lt;p&gt;&lt;blockquote&gt;引用内容&lt;/blockquote&gt;&lt;/p&gt;效果如下：引用内容引用内容居中和右对齐1234&lt;!-- 居中 --&gt;&lt;center&gt;内容&lt;/center&gt;&lt;!-- 右对齐 --&gt;&lt;div style="text-align:right"&gt;内容&lt;/div&gt;效果如下：内容内容字体大小和颜色123&lt;font color="#FF0000" size="8px"&gt;红色&lt;/font&gt;&lt;font color="#FFFF00" size="6px"&gt;黄色&lt;/font&gt;&lt;font color="#00FF00" size="4px"&gt;绿色&lt;/font&gt;效果如下：红色黄色绿色更多颜色请查看 web安全色、颜色对照表字体高亮显示使用mark标签进行标记，高亮显示文档中的文字12&lt;mark&gt;这是一个标记&lt;/mark&gt;使用mark标签进行标记，&lt;mark&gt;高亮显示&lt;/mark&gt;文档中的文字效果如下：使用mark标签进行标记，高亮显示文档中的文字插入表格1234| 一个普通标题 | 一个普通标题 | 一个普通标题 || ------ | ------ | ------ || *短文本* | 中等文本 | 稍微长一点的文本 || 稍微长一点的文本 | 短文本 | 中等文本 |效果如下：一个普通标题一个普通标题一个普通标题短文本中等文本稍微长一点的文本稍微长一点的文本短文本中等文本表格的语句上一行必须为空行，不然表格不生效;内容和|之间的多余空格会被忽略，每行第一个|和最后一个|可以省略;-的数量至少有一个;|、-、:之间的多余空格会被忽略，不影响布局;表格内容中可以套用其他用法，如加粗、斜体等。表格对齐问题-:表示内容和标题栏居右对齐；:-表示内容和标题栏居左对齐；:-:表示内容和标题栏居中对齐；1234| 一个普通标题 | 一个普通标题 | 一个普通标题 || :------ | :------: | ------: || *短文本* | 中等文本 | 稍微长一点的文本 || 稍微长一点的文本 | 短文本 | 中等文本 |效果如下：一个普通标题一个普通标题一个普通标题短文本中等文本稍微长一点的文本稍微长一点的文本短文本中等文本合并单元格、修改表格样式Todo list1234&lt;ul&gt;&lt;li&gt;&lt;i class="fa fa-check-square"&gt;&lt;/i&gt; 已完成&lt;/li&gt;&lt;li&gt;&lt;i class="fa fa-square"&gt;&lt;/i&gt; 未完成&lt;/li&gt;&lt;/ul&gt;效果如下： 已完成 未完成Note 嵌套 Todo list123456789101112131415161718192021222324&lt;!-- 一共有两种写法，效果看下面 --&gt;&lt;div class="note primary"&gt; &lt;i class="fa fa-check-square"&gt;&lt;/i&gt; 已完成 &lt;i class="fa fa-check-square"&gt;&lt;/i&gt; 已完成 &lt;i class="fa fa-check-square"&gt;&lt;/i&gt; 已完成 &lt;i class="fa fa-check-square"&gt;&lt;/i&gt; 已完成 &lt;i class="fa fa-check-square"&gt;&lt;/i&gt; 已完成 &lt;i class="fa fa-square"&gt;&lt;/i&gt; 未完成 &lt;i class="fa fa-square"&gt;&lt;/i&gt; 未完成 &lt;i class="fa fa-square"&gt;&lt;/i&gt; 未完成&lt;/div&gt;&lt;div class="note primary"&gt; &lt;p&gt; &lt;i class="fa fa-check-square"&gt;&lt;/i&gt; 已完成 &lt;i class="fa fa-check-square"&gt;&lt;/i&gt; 已完成 &lt;i class="fa fa-check-square"&gt;&lt;/i&gt; 已完成 &lt;i class="fa fa-check-square"&gt;&lt;/i&gt; 已完成 &lt;i class="fa fa-check-square"&gt;&lt;/i&gt; 已完成 &lt;i class="fa fa-square"&gt;&lt;/i&gt; 未完成 &lt;i class="fa fa-square"&gt;&lt;/i&gt; 未完成 &lt;i class="fa fa-square"&gt;&lt;/i&gt; 未完成 &lt;/p&gt;&lt;/div&gt;效果如下： 已完成 已完成 已完成 已完成 已完成 未完成 未完成 未完成 已完成 已完成 已完成 已完成 已完成 未完成 未完成 未完成插入代码代码块1&lt;!-- ```[language] [title] [url] [link-text] --&gt;注意前后都，上面演示如果后面加了会出错language表示代码语言title表示出现在代码框左上角的标题url表示超链接地址link-text表示超链接的名称这 4 项应该是根据空格来分隔，而不是[]，故请不要加[]。除非如果你想写后面两个，但不想写前面两个，那么就必须加 [] 了，要这样写：[] [] [url] [link text] 个人只验证出可以加title，url和text没验证成功。效果如下：title1&lt;div&gt;&lt;/div&gt;各种支持语言的名称可以查看这篇文章行内代码1`test`Font Awesome放大图标的方法示例：123456&lt;i class="fa fa-download"&gt;&lt;/i&gt; 普通&lt;i class="fa fa-download fa-lg"&gt;&lt;/i&gt; 变大 33%&lt;i class="fa fa-download fa-2x"&gt;&lt;/i&gt; 两倍大#fa-fw：ensuring proper alignment of the icons&lt;i class="fa fa-download fa-fw"&gt;&lt;/i&gt; 图标和文字之间合适间距效果如下： 普通 变大 33% 两倍大 图标和文字之间合适间距fa-fw：ensuring proper alignment of the iconsnote标签next主题的note标签功能我一发现就爱上了，实在很好看啊~~~~首先该功能可以在next\_config.yml配置文件中进行配置，默认是打开的，但是可以挑选自己喜欢的模式。12345678910111213# Note tag (bs-callout).note: # Note tag style values: # - simple bs-callout old alert style. Default. # - modern bs-callout new (v2-v3) alert style. # - flat flat callout style with background, like on Mozilla or StackOverflow. # - disabled disable all CSS styles import of note tag. style: flat icons: true border_radius: 3 # Offset lighter of background in % for modern and flat styles (modern: -12 | 12; flat: -18 | 6). # Offset also applied to label tag variables. This option can work with disabled note tag. light_bg_offset: 0我自己选择了其中的flat style，其用法如下：123456789101112131415&lt;div class="note default"&gt;&lt;p&gt;default&lt;/p&gt;&lt;/div&gt;&lt;div class="note primary"&gt;&lt;p&gt;primary&lt;/p&gt;&lt;/div&gt;&lt;div class="note success"&gt;&lt;p&gt;success&lt;/p&gt;&lt;/div&gt;&lt;div class="note info"&gt;&lt;p&gt;info&lt;/p&gt;&lt;/div&gt;&lt;div class="note warning"&gt;&lt;p&gt;warning&lt;/p&gt;&lt;/div&gt;&lt;div class="note danger"&gt;&lt;p&gt;danger&lt;/p&gt;&lt;/div&gt;&lt;div class="note danger no-icon"&gt;&lt;p&gt;danger no-icon&lt;/p&gt;&lt;/div&gt;&lt;div class="note danger"&gt;&lt;p&gt;danger&lt;/p&gt;&lt;p&gt;danger&lt;/p&gt;&lt;p&gt;danger&lt;/p&gt;&lt;/div&gt;&#123;% note danger %&#125;note danger, note danger, note dangernote danger, note danger, note dangernote danger, note danger, note danger&#123;% endnote %&#125;效果如下：defaultprimarysuccessinfowarningdangerdanger no-iconnote danger, note danger, note dangernote danger, note danger, note dangernote danger, note danger, note dangernext\_config.yml三种样式的具体情况请看网站label标签该标签也是在next\_config.yml配置文件中，默认是打开的123456* Usage:** &#123;% label [class] %&#125;Content&#123;% endlabel %&#125;** [class] : default | primary | success | info | warning | danger.* If not defined, default class will be selected.default1&#123;% label default@default %&#125;primary1&#123;% label primary@primary %&#125;success1&#123;% label success@success %&#125;info1&#123;% label info@info %&#125;warning1&#123;% label warning@warning %&#125;danger1&#123;% label danger@danger %&#125;12345Lorem &#123;% label @ipsum %&#125; &#123;% label primary@dolor sit %&#125; amet, consectetur &#123;% label success@adipiscing elit, %&#125; sed &#123;% label info@do eiusmod %&#125; tempor incididunt ut labore et dolore magna aliqua.Ut enim *&#123;% label warning @ad %&#125;* minim veniam, quis **&#123;% label danger @nostrud %&#125;** exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.Duis aute irure dolor in reprehenderit in voluptate ~~&#123;% label default @velit %&#125;~~ &lt;mark&gt;esse&lt;/mark&gt; cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.效果如下：Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.更多相关使用请看网站Tab 选项卡该标签也是在next\_config.yml配置文件中1234567# Tabs tag.tabs: enable: true transition: tabs: true labels: true border_radius: 3用法讲解：123456789101112131415161718192021222324tabs.js | global hexo script.Usage:&#123;% tabs [Unique name], [index] %&#125;&lt;!-- tab [Tab caption]@[icon] --&gt;Any content (support inline tags too).&lt;!-- endtab --&gt;&#123;% endtabs %&#125;[Unique name] : Unique name of tabs block tag without comma. Will be used in #id's as prefix for each tab with their index numbers. If there are whitespaces in name, for generate #id all whitespaces will replaced by dashes. Only for current url of post/page must be unique![index] : Index number of active tab. If not defined, first tab (1) will be selected. If index is -1, no tab will be selected. It's will be something like spoiler. May be not defined.[Tab caption] : Caption of current tab. If not caption specified, unique name with tab index suffix will be used as caption of tab. If not caption specified, but specified icon, caption will empty. May be not defined.[icon] : Font awesome icon. May be not defined.设定选中第二个选项卡应用示例：1234567891011&#123;% tabs 选项卡, 2 %&#125;&lt;!-- tab --&gt;**这是选项卡 1** 呵呵哈哈哈哈哈哈&lt;!-- endtab --&gt;&lt;!-- tab --&gt;**这是选项卡 2** 额。。。&lt;!-- endtab --&gt;&lt;!-- tab --&gt;**这是选项卡 3** 哇，你找到我了！&lt;!-- endtab --&gt;&#123;% endtabs %&#125;效果如下：选项卡 1选项卡 2选项卡 3这是选项卡 1 呵呵哈哈哈哈哈哈这是选项卡 2 额。。。这是选项卡 3 哇，你找到我了！tabs 选项卡, 2：选项卡表示选项卡的名称，如果为tab，得到的选项卡显示为tab 1、tab 2、tab 3；2 表示一开始在第二个选项卡，非必须，若数值为 -1 则隐藏选项卡内容(也就是不显示呵呵哈哈哈哈哈哈这一些话，点击之后才会显示)。自定义每个选项卡的名称1234567891011&#123;% tabs Fourth unique name %&#125;&lt;!-- tab Solution 1 --&gt;**This is Tab 1.**&lt;!-- endtab --&gt;&lt;!-- tab Solution 2 --&gt;**This is Tab 2.**&lt;!-- endtab --&gt;&lt;!-- tab Solution 3 --&gt;**This is Tab 3.**&lt;!-- endtab --&gt;&#123;% endtabs %&#125;效果如下：Solution 1Solution 2Solution 3This is Tab 1.This is Tab 2.This is Tab 3.上面的solution 1、2、3即为自定义的，每个tab都可以设置自己的每个tab只显示图标1234567891011&#123;% tabs Fifth unique name %&#125;&lt;!-- tab @text-width --&gt;**This is Tab 1.**&lt;!-- endtab --&gt;&lt;!-- tab @amazon --&gt;**This is Tab 2.**&lt;!-- endtab --&gt;&lt;!-- tab @bold --&gt;**This is Tab 3.**&lt;!-- endtab --&gt;&#123;% endtabs %&#125;效果如下：This is Tab 1.This is Tab 2.This is Tab 3.上面的@amazon即为图标icon既显示图标有显示名称1234567891011&#123;% tabs Sixth unique name %&#125;&lt;!-- tab Solution 1@text-width --&gt;**This is Tab 1.**&lt;!-- endtab --&gt;&lt;!-- tab Solution 2@amazon --&gt;**This is Tab 2.**&lt;!-- endtab --&gt;&lt;!-- tab Solution 3@bold --&gt;**This is Tab 3.**&lt;!-- endtab --&gt;&#123;% endtabs %&#125;效果如下：这个貌似会报错制作链接，快速访问多个tabs组参见网址tabs中套用其他标签12345678910111213141516171819202122232425262728293031323334353637383940&#123;% tabs Tags %&#125;&lt;!-- tab --&gt;**This is Tab 1.**1. One2. Two3. ThreeTabbed code block: nano /etc&#123;% code %&#125;code block tagcode block tagcode block tag&#123;% endcode %&#125;&#123;% note default %&#125;Note default tag.&#123;% endnote %&#125;&#123;% youtube A1Qb4zfurA8 %&#125;&lt;!-- endtab --&gt;&lt;!-- tab --&gt;**This is Tab 2.*** Five* Six* Seven&#123;% note primary %&#125;&#123;% youtube rX3W5evpeJE %&#125;&#123;% endnote %&#125;&lt;!-- endtab --&gt;&lt;!-- tab --&gt;**This is Tab 3.**&#123;% note success %&#125;Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Phasellus hendrerit. Pellentesque aliquet nibh nec urna. In nisi neque, aliquet vel, dapibus id, mattis vel, nisi. Sed pretium, ligula sollicitudin laoreet viverra, tortor libero sodales leo, eget blandit nunc tortor eu nibh. Nullam mollis. Ut justo. Suspendisse potenti. Pellentesque fermentum dolor. Aliquam quam lectus, facilisis auctor, ultrices ut, elementum vulputate, nunc.&#123;% endnote %&#125;&lt;!-- endtab --&gt;&#123;% endtabs %&#125;最终效果：Tags 1Tags 2Tags 3This is Tab 1.OneTwoThreeTabbed code block:nano /etc 123code block tagcode block tagcode block tagNote default tag.This is Tab 2.FiveSixSevenThis is Tab 3.Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Phasellus hendrerit. Pellentesque aliquet nibh nec urna. In nisi neque, aliquet vel, dapibus id, mattis vel, nisi. Sed pretium, ligula sollicitudin laoreet viverra, tortor libero sodales leo, eget blandit nunc tortor eu nibh. Nullam mollis. Ut justo. Suspendisse potenti. Pellentesque fermentum dolor. Aliquam quam lectus, facilisis auctor, ultrices ut, elementum vulputate, nunc.按钮样式12345678# fa-lg：放大图标33%# fa-fw：图标和文字之间合理间距显示# download：图标的名称，fa-download，这里只写download即可&#123;% btn https://almostover.ru/2016-01/hexo-theme-next-test/#Button-tag-test, 更多关于按钮的使用点这里, download fa-lg fa-fw %&#125;&lt;div class="text-center"&gt;&#123;% btn https://almostover.ru/2016-01/hexo-theme-next-test/#Button-tag-test, 更多关于按钮的使用点这里, download fa-lg fa-fw %&#125;&lt;/div&gt;&#123;% btn https://almostover.ru/2016-01/hexo-theme-next-test/#Button-tag-test, 更多关于按钮的使用点这里, download fa-lg fa-rotate-90 %&#125;最终效果：更多关于按钮的使用点这里更多关于按钮的使用点这里更多关于按钮的使用点这里点击上面的按钮可以跳转到另一个网址，查看更过关于按钮的操作可以将其放在html语句中进行居中等各种操作btn后跟着点击按钮之后想访问的链接fa-lg：放大图标33%fa-fw：图标和文字之间合理间距显示fa-rotate-90：顺时针旋转90度download：图标的名称，fa-download，这里只写download即可插入照片因为图片功能在markdown语法中比较常用，所以将其单列出来，便于查找。使用七牛作为图床用法实例：123456&#123;% qnimg test2.png title:"test" alt:"图片说明" 'class:class1 class2' extend:?imageView2/2/w/600 %&#125;&lt;!-- 将其插入html语句中 --&gt;&lt;div align="right"&gt;&#123;% qnimg test2.png title:"test" alt:"图片说明" 'class:class1 class2' extend:?imageView2/2/w/600 %&#125;&lt;/div&gt;title：鼠标移到图片上显示的名称alt：图片不能正常加载时显示的说明文字extend:?imageView2/2/w/600 ：表示生成宽度最多600px的缩略图已经放弃七牛图床，并采用阿里云作为图床，具体请参考这篇文章常规markdown语法12345![图片描述，相当于alt](https://showteeth.oss-cn-beijing.aliyuncs.com/blog_img/test2.png "Optional title，相当于title")&lt;!-- 居中操作可以使用center标签将上述包裹 --&gt;&lt;center&gt;![图片描述，相当于alt](https://showteeth.oss-cn-beijing.aliyuncs.com/blog_img/test2.png "Optional title，相当于title")&lt;/center&gt;最终效果：Optional title 是用来在鼠标移到图片上时显示的title使用markdown插入图片的缺点：一般的宽和高等属性不好修改，各个编辑器支持的写法可能有区别html代码插入图片针对使用markdown插入图片的缺点，使用html语句可以很好的解决123456&lt;!-- 使用img标签--&gt;&lt;img src="http://pn9abh3rj.bkt.clouddn.com/test.png" width = "300" height = "200" alt="图片名称" align=center /&gt;&lt;!-- 使用div标签包裹 --&gt;&lt;div align="center"&gt;&lt;img src="http://pn9abh3rj.bkt.clouddn.com/test.png" title="使用html插入图片" alt="图片名称" /&gt;&lt;/div&gt;最终效果：不推荐使用这个img标签来进行对齐操作，容易和文本混在一起，居中的时候还好；推荐使用div标签包裹img标签。tips博客一般都以二级标题开始写起html代码如div标签后面一定要空行标签之间一般都是可以嵌套的插入图片推荐使用div标签包裹img标签实现写完一段记得空行！！！尽量每写完一段就空一行，尤其是代码段和文字之间，不然可能会出现markdown语法不能识别的情况（前面的错误可能导致后续很多语法都不能正常识别，在找错误的时候看第一个不能识别的位置）参考链接很详细很好的技巧文章也是很好的教程，可结合上一个看支持highlight的语言note、label、button、tab使用讲解及示例note、label、tab使用讲解及示例]]></content>
      <categories>
        <category>折腾</category>
        <category>博客</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>博客</tag>
        <tag>next</tag>
      </tags>
  </entry>
</search>
